<?xml version="1.0" encoding="ISO-8859-1"?>

<bugs>
	<bug>
		<id>1172</id>
		<title>垃圾回收指定g1时Could not find or load main class g1</title>
		<body> 通过命令bin/start-hugegraph.sh  -g g1时，无法启动，提示Could not find or load main class g1； 版本用的时0.10.4；不知为何，否则垃圾回收一直有问题。</body>
		<created>2020-09-14 10:37:15</created>
		<closed>2020-09-15 09:59:22</closed>
	</bug>
	<bug>
		<id>1049</id>
		<title>通过limit限制返回结果条件下仍报索引数超过80W错误</title>
		<body>### Expected behavior 期望表现 返回正常结果   ### Actual behavior 实际表现 Too many records(must &lt;= 800000) for the query: Query for SECONDARY_INDEX where id in [] and [INDEX_LABEL_ID == 4, FIELD_VALUES == 26e33582-ba3d-479a-9e10-ccb719377be1]   ### Steps to reproduce the problem 复现步骤 `g.V().hasLabel('process').has('timestamp', between('2020-06-03 04:34:25.000', '2020-06-03 04:39:25.000')).has('environmentId', 'xxxx-xxxx-xxxx-xxxx').limit(100)` - environmentId有单列索引，索引节点数量超过80w  ### Status of loaded data 数据状态  #### Vertex/Edge summary 数据量 - loaded vertices amount: {100万左右} - loaded edges amount: {80左右} - loaded time: {抛出异常}   ### Specifications of environment 环境信息 - hugegraph version: {0.10.4} - operating system: {centos 7.4, 32 CPUs, 128G RAM} - hugegraph backend: {cassandra} </body>
		<created>2020-06-20 13:01:07</created>
		<closed>2020-07-22 12:43:03</closed>
	</bug>
	<bug>
		<id>864</id>
		<title>range查询不同范围得到的结果相同</title>
		<body>hugegraph-v0.10 + hbase 顶点量100w，边量1000w  ### Expected behavior 期望表现 使用range查询不同范围的顶点的has_Value属性值： g.V().has('TEST','has_Category','success').range(0,5).values('has_Value') g.V().has('TEST','has_Category','success').range(10,15).values('has_Value') 正常情况下这两个语句得到的结果是不一样的  ### Actual behavior 实际表现 实际上这两个语句得到的结果是完全相同的，换成其他的范围得到的结果还是一样的。  这种情况出现的比较随机，不一定能完全复现 请问是否有人遇到过类似的情况，可以如何解决？</body>
		<created>2020-02-24 11:34:04</created>
		<closed>2020-02-28 05:53:49</closed>
	</bug>
	<bug>
		<id>850</id>
		<title> Gremlin RESTFul API 接口图名不能使用中划线</title>
		<body>### Expected behavior 期望表现  图名中包含中划线时 Gremlin RESTFul API 接口能正常访问。  ### Actual behavior 实际表现  图名中包含中划线时 Gremlin RESTFul API 接口报异常。 图名定义为 `my_graph-g1` 通过 Grelmin RESTFul API 访问:  ` GET http://127.0.0.1:8080/gremlin?gremlin=my_graph-g1.traversal().V('1:marko') `  ` {"message":"No such property: my_graph for class: Script5","Exception-Class":"groovy.lang.MissingPropertyException","exceptions":["groovy.lang.MissingPropertyException"],"stackTrace":"groovy.lang.MissingPropertyException: No such property: my_graph for class: Script5\n\tat org.codehaus.groovy.runtime.ScriptBytecodeAdapter.unwrap(ScriptBytecodeAdapter.java:53)\n\tat org.codehaus.groovy.runtime.callsite.PogoGetPropertySite.getProperty(PogoGetPropertySite.java:52)\n\tat org.codehaus.groovy.runtime.callsite.AbstractCallSite.callGroovyObjectGetProperty(AbstractCallSite.java:307)\n\tat Script5.run(Script5.groovy:1)\n\tat org.apache.tinkerpop.gremlin.groovy.jsr223.GremlinGroovyScriptEngine.eval(GremlinGroovyScriptEngine.java:834)\n\tat org.apache.tinkerpop.gremlin.groovy.jsr223.GremlinGroovyScriptEngine.eval(GremlinGroovyScriptEngine.java:547)\n\tat javax.script.AbstractScriptEngine.eval(AbstractScriptEngine.java:233)\n\tat org.apache.tinkerpop.gremlin.groovy.engine.ScriptEngines.eval(ScriptEngines.java:120)\n\tat org.apache.tinkerpop.gremlin.groovy.engine.GremlinExecutor.lambda$eval$2(GremlinExecutor.java:314)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat com.baidu.hugegraph.auth.HugeGraphAuthProxy$ContextTask.run(HugeGraphAuthProxy.java:282)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n"} ` </body>
		<created>2020-02-13 02:49:07</created>
		<closed>2020-02-19 02:57:21</closed>
	</bug>
	<bug>
		<id>843</id>
		<title>hubble-1.1.0 显示数据报错</title>
		<body>### Expected behavior 期望表现 能够正常查询出边；   ### Actual behavior 实际表现 g.E().hasLabel('注册人').limit(1)  报错：Could not write JSON: Can not write a field name, expecting a value; nested exception is com.fasterxml.jackson.core.JsonGenerationException: Can not write a field name, expecting a value  g.E().hasLabel('注册人').limit(1).inV()  正常：        {             "id": "12:whoisguard protected",             "label": "registrant",             "properties": {                 "registrant_name": "whoisguard protected"             }         }   g.E().hasLabel('注册人').limit(1).outV()  正常：        {             "id": "4:8as8.com",             "label": "domain",             "properties": {                 "status": "clientTransferProhibited https://icann.org/epp#clientTransferProhibited",                 "creation_time": "2019-01-25 16:00:00.000",                 "main_domain": "8as8.com",                 "expiration_time": "2020-01-25 16:00:00.000",                 "update_time": "2019-01-25 16:00:00.000",                 "state": "Panama",                 "domain_name_search": "8as8.com",                 "domain_name": "8as8.com"             }         }  查询出inV和outV之后，双击点，都可以查询出边。  ### Specifications of environment 环境信息 "versions":{ "version": "v1", "core": "0.10.4.0", "gremlin": "3.4.3", "api": "0.48.0.0" }</body>
		<created>2020-01-23 09:49:51</created>
		<closed>2020-02-24 04:38:56</closed>
	</bug>
	<bug>
		<id>818</id>
		<title>Batch update edge with edgeId and unmatched sortKeys will create a new edge</title>
		<body>### Expected behavior 期望表现 Tips: Don't allowed to update edge sortKey values when I specified edgeId  ### Actual behavior 实际表现 Created a new edge with passed sortKey values</body>
		<created>2020-01-08 08:36:50</created>
		<closed>2020-02-04 03:43:12</closed>
	</bug>
	<bug>
		<id>806</id>
		<title>Delete schema in async should set schema(QUEUED) status DELETING</title>
		<body></body>
		<created>2019-12-31 14:09:22</created>
		<closed>2020-07-25 03:53:59</closed>
	</bug>
	<bug>
		<id>802</id>
		<title>bug traverseByLabel() with LabelIndex disable</title>
		<body>https://github.com/hugegraph/hugegraph/blob/release-0.10/hugegraph-core/src/main/java/com/baidu/hugegraph/backend/tx/GraphTransaction.java#L1542 also should add rebuildIndex() and remove() test for index-label, vertex-label and edge-label</body>
		<created>2019-12-28 18:17:29</created>
		<closed>2020-01-07 03:10:57</closed>
	</bug>
	<bug>
		<id>796</id>
		<title>长时间大量并发发送gremlin请求时,随时间增长会耗尽CPU</title>
		<body>### Actual behavior 实际表现 CPU使用率越积越高，大量GremlinServer线程互相等待锁资源，Gremlin解析时间越来越长，直至最后达到几乎不可用的状态   ### Steps to reproduce the problem 复现步骤 例如使用以下Gremlin语句 g.V('1:xxxx').has('A','xxxx')...... 比较长的Gremlin语句 大量并发并且长时间持续请求  </body>
		<created>2019-12-26 09:52:39</created>
		<closed>2020-01-06 14:21:24</closed>
	</bug>
	<bug>
		<id>795</id>
		<title>在ID建唯一索引，web界面用g.V().has("id","1223")查询报错</title>
		<body>### Expected behavior 期望表现 使用g.V().has("id","1223") 可查出该点信息。  ### Actual behavior 实际表现 g.V().has("eid","1702") Error! Unknown index type 'UNIQUE' 使用g.V().hasLabel("person").has("eid","1702") Error! Unknown index type 'UNIQUE'  ### Steps to reproduce the problem 复现步骤 1. {step 1} 2. {step 2} 3. {step 3}   ### Status of loaded data 数据状态  #### Vertex/Edge summary 数据量 - loaded vertices amount: {like 10 million} - loaded edges amount: {like 20 million} - loaded time: {like 200s}  #### Vertex/Edge example 数据示例 {type something here...}  #### Schema(VertexLabel, EdgeLabel, IndexLabel) 元数据结构 {type something here...}   ### Specifications of environment 环境信息 - hugegraph version: {like v0.7.4} - operating system: {like centos 7.4, 32 CPUs, 64G RAM} - hugegraph backend: {like cassandra 3.10, cluster with 20 nodes, 3 x 1TB HDD disk each node} </body>
		<created>2019-12-26 09:29:02</created>
		<closed>2020-01-07 05:55:45</closed>
	</bug>
	<bug>
		<id>793</id>
		<title>gremlin计数 HugeGraph OOM</title>
		<body>### Expected behavior 期望表现  ### Actual behavior 实际表现 在数据量比较大的情况下， 运行类似下面语句时，出现HugeGraph OOM  ``` g.V().hasLabel('vbsku').count()  g.V().hasLabel('vbsku').groupCount().by(properties('p_trade').value()) ```  ### Steps to reproduce the problem 复现步骤  运行上面命令时，查看rocksdb的统计信息，最高点如下: ![image](https://user-images.githubusercontent.com/7587298/71398008-23ef0300-265a-11ea-835d-08e7526d1eab.png) 过两分钟后，rocksdb的统计信息如下： ![image](https://user-images.githubusercontent.com/7587298/71398077-454fef00-265a-11ea-9542-f8c51a5f5082.png)  根据[Memory-usage-in-RocksDB](https://github.com/facebook/rocksdb/wiki/Memory-usage-in-RocksDB)和[RocksDBMetrics](https://github.com/hugegraph/hugegraph/blob/master/hugegraph-rocksdb/src/main/java/com/baidu/hugegraph/backend/store/rocksdb/RocksDBMetrics.java)， 当前hugegraph中rocksdb统计内存，只统计了其中的三个部分，Blocks pinned by iterators没有统计在内。 目前还不能确认是系统的哪个部分把内存吃掉了。  ### Status of loaded data 数据状态  #### Vertex/Edge summary 数据量 1000w级别的点边数据   ### Specifications of environment 环境信息 - hugegraph version: 0.10.4 - operating system: centos 6， 32CPUs， 180G RAM - hugegraph backend: rocksdb </body>
		<created>2019-12-24 06:39:12</created>
		<closed>2020-03-13 05:57:56</closed>
	</bug>
	<bug>
		<id>792</id>
		<title>hugegraph-load重复导入顶点，如何移除旧数据中不要的顶点属性</title>
		<body>使用hugegraph-load导入了顶点数据，此时顶点中有has_Category这个属性， 现在在JSON数据集中移除掉has_Category这个属性后，又用hugegraph-load导了一遍，此时查询顶点没有看到has_Category这个属性，但过了一晚后这个属性又可以在顶点上查询到，请问这是什么原因？有什么方法可以删除大量顶点的某个属性？  ### Expected behavior 期望表现 hugegraph-loader重复导入顶点，属性以最新的数据集为准。 使用过https://hugegraph.github.io/hugegraph-doc/quickstart/hugegraph-loader.html中的update_strategies=overwrite，由于是旧数据有该属性，新数据没有该属性，貌似没有被真正覆盖。   ### Actual behavior 实际表现 第二次导入，当时查询顶点没有看到被移除的属性，过一段时间这个属性又出现了。 ![image](https://user-images.githubusercontent.com/58197479/71060302-0f18f800-21a0-11ea-9f97-8a51a86fcbb5.png) </body>
		<created>2019-12-18 06:11:53</created>
		<closed>2020-02-13 05:46:41</closed>
	</bug>
	<bug>
		<id>774</id>
		<title>List option must be registered with class ConfigListOption</title>
		<body>### Actual behavior 实际表现 Start server with error when config `rocksdb.compression_per_level`: ``` Caused by: java.lang.reflect.InvocationTargetException at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_111] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_111] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_111] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_111] at org.apache.tinkerpop.gremlin.structure.util.GraphFactory.open(GraphFactory.java:78) ~[gremlin-core-3.4.3.jar:3.4.3] ... 16 more Caused by: java.lang.IllegalStateException: List option must be registered with class ConfigListOption at com.google.common.base.Preconditions.checkState(Preconditions.java:199) ~[guava-19.0.jar:?] at com.baidu.hugegraph.util.E.checkState(E.java:68) ~[hugegraph-common-1.6.16.jar:1.6.16.0] at com.baidu.hugegraph.config.HugeConfig.validateOption(HugeConfig.java:151) ~[hugegraph-common-1.6.16.jar:1.6.16.0] at com.baidu.hugegraph.config.HugeConfig.addProperty(HugeConfig.java:138) ~[hugegraph-common-1.6.16.jar:1.6.16.0] at com.baidu.hugegraph.config.HugeConfig.&lt;init&gt;(HugeConfig.java:54) ~[hugegraph-common-1.6.16.jar:1.6.16.0] at com.baidu.hugegraph.HugeFactory.open(HugeFactory.java:42) ~[classes/:?] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_111] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_111] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_111] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_111] at org.apache.tinkerpop.gremlin.structure.util.GraphFactory.open(GraphFactory.java:78) ~[gremlin-core-3.4.3.jar:3.4.3] ... 16 more ```  ### Specifications of environment 环境信息 - hugegraph version: 0.10 - operating system: mac - hugegraph backend: rocksdb 6.3.6 </body>
		<created>2019-12-01 15:57:05</created>
		<closed>2020-01-08 15:36:02</closed>
	</bug>
	<bug>
		<id>760</id>
		<title>索引创建失败Requested permits (0) must be positive</title>
		<body>导入数据后再创建的索引，顶点量约65w  用hugegraph-studio执行graph.schema().indexLabel("testByhas_Conclusion").onV("TEST").by("has_Conclusion").secondary().ifNotExist().create(); 报错：Task '116' was not completed in 10 seconds 查看hugegraph日志：java.lang.IllegalArgumentException: Requested permits (0) must be positive  使用hugegraph-tools执行异步任务：  [hugegraph-tools-1.3.0]$ ./bin/hugegraph gremlin-schedule -s "graph.schema().indexLabel("testByhas_Conclusion").onV("TEST").by("has_Conclusion").secondary().ifNotExist().create();" 查看任务信息： Task info: {task_name=graph.schema().indexLabel(testByhas_Conclusion).onV(TEST).by(has_Conclusion).secondary().ifNotExist().create();, task_progress=0, task_create=1574731429860, **task_status=failed**, task_update=1574731430378, **task_result=java.lang.IllegalArgumentException: Requested permits (0) must be positive**, task_retries=0, id=118, task_type=gremlin, task_callable=com.baidu.hugegraph.api.job.GremlinAPI$GremlinJob, task_input={"gremlin":"graph.schema().indexLabel(testByhas_Conclusion).onV(TEST).by(has_Conclusion).secondary().ifNotExist().create();","aliases":{"hugegraph":"graph"},"bindings":{},"language":"gremlin-groovy"}}  ### Specifications of environment 环境信息 - hugegraph version: 0.9.2 - operating system: centos 7.4 - hugegraph backend: hbase 2.2  请问这是什么原因？</body>
		<created>2019-11-26 01:53:47</created>
		<closed>2019-12-03 07:30:28</closed>
	</bug>
	<bug>
		<id>758</id>
		<title>初始化mysql数据库连接失败</title>
		<body>### Expected behavior 期望表现 {希望成功连接数据库}  ### Actual behavior 实际表现 {后端存储选择mysql，进行初始化时提示连接数据库失败}   ### Steps to reproduce the problem 报错截图  (https://user-images.githubusercontent.com/27463147/69526368-feac9d80-0fa4-11ea-8366-ea3ba34eecb7.jpg)    ### Status of loaded data 数据状态  #### Vertex/Edge summary 数据量 - loaded vertices amount: {like 10 million} - loaded edges amount: {like 20 million} - loaded time: {like 200s}  #### Vertex/Edge example 数据示例 {type something here...}  #### Schema(VertexLabel, EdgeLabel, IndexLabel) 元数据结构 {type something here...}   ### Specifications of environment 环境信息 - hugegraph version: {v0.10.4} - operating system: {lUbuntu16.04 } - hugegraph backend: {like mysql 5.7} </body>
		<created>2019-11-25 09:00:05</created>
		<closed>2019-12-06 16:49:16</closed>
	</bug>
	<bug>
		<id>751</id>
		<title>Setting property with cardinality 'single' fails</title>
		<body>### Expected behavior 期望表现 Setting a vertex property with cardinality 'single' should succeed: `g.addV('Test').property(single, 'foo', 123).property(single, 'bar', 123)`    ### Actual behavior 实际表现 I'm getting error: `All non-null property keys [foo, bar] of vertex label 'Test' must be setted, missed keys [foo, bar]`  Running without the cardinality attribute works as expected: `g.addV('Test').property('foo', 123).property('bar', 123)`  ### Steps to reproduce the problem 复现步骤 Run the query above.  #### Schema(VertexLabel, EdgeLabel, IndexLabel) 元数据结构 ``` graph.schema().propertyKey('foo').asInt().ifNotExist().create() graph.schema().propertyKey('bar').asInt().ifNotExist().create() graph.schema().vertexLabel('Test').properties('foo', 'bar').ifNotExist().create() ```  ### Specifications of environment 环境信息 - hugegraph version: v0.10.4 - operating system: Ubuntu 18.04.3 LTS - hugegraph backend: RocksDB </body>
		<created>2019-11-14 13:28:55</created>
		<closed>2019-12-18 10:10:10</closed>
	</bug>
	<bug>
		<id>697</id>
		<title>Invalid column family specified in write batch</title>
		<body>Accidental error when truncating rocksdb and running api tests at the same time: ``` 2019-09-26 14:08:23 608650 [grizzly-http-server-5] [ERROR] com.baidu.hugegraph.server.RestServer [] - Failed to commit com.baidu.hugegraph.backend.BackendException: Exception in backend at com.baidu.hugegraph.backend.store.rocksdb.RocksDBStdSessions$StdSession.commit(RocksDBStdSessions.java:513) ~[classes/:?] at com.baidu.hugegraph.backend.store.rocksdb.RocksDBStdSessions$StdSession.commit(RocksDBStdSessions.java:1) ~[classes/:?] at com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore.commitTx(RocksDBStore.java:400) ~[classes/:?] at com.baidu.hugegraph.backend.tx.AbstractTransaction.commitMutation2Backend(AbstractTransaction.java:247) ~[classes/:?] at com.baidu.hugegraph.backend.cache.CachedGraphTransaction.commitMutation2Backend(CachedGraphTransaction.java:209) ~[classes/:?] at com.baidu.hugegraph.backend.tx.IndexableTransaction.commit2Backend(IndexableTransaction.java:57) ~[classes/:?] at com.baidu.hugegraph.backend.tx.AbstractTransaction.commit(AbstractTransaction.java:168) ~[classes/:?] at com.baidu.hugegraph.backend.tx.GraphTransaction.commit(GraphTransaction.java:364) ~[classes/:?] at com.baidu.hugegraph.HugeGraph$Txs.commit(HugeGraph.java:805) ~[classes/:?] at com.baidu.hugegraph.HugeGraph$TinkerpopTransaction.doCommit(HugeGraph.java:692) ~[classes/:?] at org.apache.tinkerpop.gremlin.structure.util.AbstractTransaction.commit(AbstractTransaction.java:104) ~[gremlin-core-3.4.3.jar:3.4.3] at com.baidu.hugegraph.HugeGraph$TinkerpopTransaction.commit(HugeGraph.java:658) ~[classes/:?] at com.baidu.hugegraph.api.API.commit(API.java:94) [classes/:?] at com.baidu.hugegraph.api.graph.BatchAPI.commit(BatchAPI.java:75) [classes/:?] at com.baidu.hugegraph.api.graph.VertexAPI.create(VertexAPI.java:112) [classes/:?] at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source) ~[?:?] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_111] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_111] at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory$1.invoke(ResourceMethodInvocationHandlerFactory.java:81) [jersey-server-2.25.1.jar:?] at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:144) [jersey-server-2.25.1.jar:?] at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:161) [jersey-server-2.25.1.jar:?] at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$TypeOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:205) [jersey-server-2.25.1.jar:?] at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:99) [jersey-server-2.25.1.jar:?] at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:389) [jersey-server-2.25.1.jar:?] at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:347) [jersey-server-2.25.1.jar:?] at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:102) [jersey-server-2.25.1.jar:?] at org.glassfish.jersey.server.ServerRuntime$2.run(ServerRuntime.java:326) [jersey-server-2.25.1.jar:?] at org.glassfish.jersey.internal.Errors$1.call(Errors.java:271) [jersey-common-2.22.jar:?] at org.glassfish.jersey.internal.Errors$1.call(Errors.java:267) [jersey-common-2.22.jar:?] at org.glassfish.jersey.internal.Errors.process(Errors.java:315) [jersey-common-2.22.jar:?] at org.glassfish.jersey.internal.Errors.process(Errors.java:297) [jersey-common-2.22.jar:?] at org.glassfish.jersey.internal.Errors.process(Errors.java:267) [jersey-common-2.22.jar:?] at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:317) [jersey-common-2.22.jar:?] at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:305) [jersey-server-2.25.1.jar:?] at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:1154) [jersey-server-2.25.1.jar:?] at org.glassfish.jersey.grizzly2.httpserver.GrizzlyHttpContainer.service(GrizzlyHttpContainer.java:384) [jersey-container-grizzly2-http-2.25.1.jar:?] at org.glassfish.grizzly.http.server.HttpHandler$1.run(HttpHandler.java:224) [grizzly-http-server-2.3.28.jar:2.3.28] at org.glassfish.grizzly.threadpool.AbstractThreadPool$Worker.doWork(AbstractThreadPool.java:593) [grizzly-framework-2.3.28.jar:2.3.28] at org.glassfish.grizzly.threadpool.AbstractThreadPool$Worker.run(AbstractThreadPool.java:573) [grizzly-framework-2.3.28.jar:2.3.28] at java.lang.Thread.run(Thread.java:745) [?:1.8.0_111] Caused by: org.rocksdb.RocksDBException: Invalid column family specified in write batch at org.rocksdb.RocksDB.write0(Native Method) ~[rocksdbjni-5.14.2.jar:?] at org.rocksdb.RocksDB.write(RocksDB.java:602) ~[rocksdbjni-5.14.2.jar:?] at com.baidu.hugegraph.backend.store.rocksdb.RocksDBStdSessions$StdSession.commit(RocksDBStdSessions.java:510) ~[classes/:?] ... 39 more ```  The second time: ``` 2019-09-26 20:29:15 114776 [task-worker-1] [WARN ] com.baidu.hugegraph.task.HugeTask [] - An exception occurred when running task: 7 java.lang.AssertionError: null at com.baidu.hugegraph.backend.store.rocksdb.RocksDBStdSessions$StdSession.scan(RocksDBStdSessions.java:651) ~[classes/:?] at com.baidu.hugegraph.backend.store.rocksdb.RocksDBTable.queryByPrefix(RocksDBTable.java:173) ~[classes/:?] at com.baidu.hugegraph.backend.store.rocksdb.RocksDBTable.query(RocksDBTable.java:129) ~[classes/:?] at com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore.query(RocksDBStore.java:320) ~[classes/:?] at com.baidu.hugegraph.backend.tx.AbstractTransaction.query(AbstractTransaction.java:105) ~[classes/:?] at com.baidu.hugegraph.backend.tx.GraphIndexTransaction.doIndexQueryOnce(GraphIndexTransaction.java:513) ~[classes/:?] at com.baidu.hugegraph.backend.tx.GraphIndexTransaction.lambda$doIndexQuery$0(GraphIndexTransaction.java:499) ~[classes/:?] at com.baidu.hugegraph.backend.page.IdHolder.fetchNext(IdHolder.java:98) ~[classes/:?] at com.baidu.hugegraph.backend.page.QueryList$IndexQuery.iterator(QueryList.java:250) ~[classes/:?] at com.baidu.hugegraph.backend.page.QueryList.fetchNext(QueryList.java:124) ~[classes/:?] at com.baidu.hugegraph.backend.page.PageEntryIterator.fetch(PageEntryIterator.java:79) ~[classes/:?] at com.baidu.hugegraph.backend.page.PageEntryIterator.hasNext(PageEntryIterator.java:66) ~[classes/:?] at com.baidu.hugegraph.iterator.MapperIterator.fetch(MapperIterator.java:42) ~[hugegraph-common-1.6.14.jar:1.6.14.0] at com.baidu.hugegraph.iterator.WrappedIterator.hasNext(WrappedIterator.java:41) ~[hugegraph-common-1.6.14.jar:1.6.14.0] at com.baidu.hugegraph.iterator.FilterIterator.fetch(FilterIterator.java:42) ~[hugegraph-common-1.6.14.jar:1.6.14.0] at com.baidu.hugegraph.iterator.WrappedIterator.hasNext(WrappedIterator.java:41) ~[hugegraph-common-1.6.14.jar:1.6.14.0] at com.baidu.hugegraph.backend.tx.GraphTransaction.traverseByLabel(GraphTransaction.java:1504) ~[classes/:?] at com.baidu.hugegraph.backend.tx.GraphTransaction.traverseVerticesByLabel(GraphTransaction.java:1474) ~[classes/:?] at com.baidu.hugegraph.job.schema.RebuildIndexCallable.rebuildIndex(RebuildIndexCallable.java:126) ~[classes/:?] at com.baidu.hugegraph.job.schema.RebuildIndexCallable.rebuildIndex(RebuildIndexCallable.java:68) ~[classes/:?] at com.baidu.hugegraph.job.schema.RebuildIndexCallable.execute(RebuildIndexCallable.java:53) ~[classes/:?] at com.baidu.hugegraph.job.Job.call(Job.java:40) ~[classes/:?] at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_111] at com.baidu.hugegraph.task.HugeTask.run(HugeTask.java:203) [classes/:?] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_111] at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_111] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_111] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_111] at java.lang.Thread.run(Thread.java:745) [?:1.8.0_111] 2019-09-26 20:29:16 116322 [task-worker-3] [WARN ] com.baidu.hugegraph.task.HugeTask [] - An exception occurred when running task: 8 com.baidu.hugegraph.backend.BackendException: Exception in backend at com.baidu.hugegraph.backend.store.rocksdb.RocksDBStdSessions$StdSession.commit(RocksDBStdSessions.java:513) ~[classes/:?] at com.baidu.hugegraph.backend.store.rocksdb.RocksDBStdSessions$StdSession.commit(RocksDBStdSessions.java:1) ~[classes/:?] at com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore.commitTx(RocksDBStore.java:400) ~[classes/:?] at com.baidu.hugegraph.backend.tx.AbstractTransaction.commitMutation2Backend(AbstractTransaction.java:247) ~[classes/:?] at com.baidu.hugegraph.backend.cache.CachedGraphTransaction.commitMutation2Backend(CachedGraphTransaction.java:209) ~[classes/:?] at com.baidu.hugegraph.backend.tx.IndexableTransaction.commit2Backend(IndexableTransaction.java:57) ~[classes/:?] at com.baidu.hugegraph.backend.tx.AbstractTransaction.commit(AbstractTransaction.java:168) ~[classes/:?] at com.baidu.hugegraph.backend.tx.GraphTransaction.commit(GraphTransaction.java:364) ~[classes/:?] at com.baidu.hugegraph.HugeGraph$Txs.commit(HugeGraph.java:805) ~[classes/:?] at com.baidu.hugegraph.HugeGraph$TinkerpopTransaction.doCommit(HugeGraph.java:692) ~[classes/:?] at org.apache.tinkerpop.gremlin.structure.util.AbstractTransaction.commit(AbstractTransaction.java:104) ~[gremlin-core-3.4.3.jar:3.4.3] at com.baidu.hugegraph.HugeGraph$TinkerpopTransaction.commit(HugeGraph.java:658) ~[classes/:?] at com.baidu.hugegraph.job.schema.IndexLabelRemoveCallable.removeIndexLabel(IndexLabelRemoveCallable.java:64) ~[classes/:?] at com.baidu.hugegraph.job.schema.IndexLabelRemoveCallable.execute(IndexLabelRemoveCallable.java:39) ~[classes/:?] at com.baidu.hugegraph.job.Job.call(Job.java:40) ~[classes/:?] at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_111] at com.baidu.hugegraph.task.HugeTask.run(HugeTask.java:203) [classes/:?] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_111] at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_111] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_111] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_111] at java.lang.Thread.run(Thread.java:745) [?:1.8.0_111] Caused by: org.rocksdb.RocksDBException: Invalid column family specified in write batch at org.rocksdb.RocksDB.write0(Native Method) ~[rocksdbjni-5.14.2.jar:?] at org.rocksdb.RocksDB.write(RocksDB.java:602) ~[rocksdbjni-5.14.2.jar:?] at com.baidu.hugegraph.backend.store.rocksdb.RocksDBStdSessions$StdSession.commit(RocksDBStdSessions.java:510) ~[classes/:?] ... 21 more ```</body>
		<created>2019-09-26 06:14:34</created>
		<closed>2019-10-09 02:41:22</closed>
	</bug>
	<bug>
		<id>652</id>
		<title>HugeGraph-Loader导入数据报错</title>
		<body>### Expected behavior 期望表现 谁用HugeGraph-Loader导入数据，Boolean类型的数据有问题   ### Actual behavior 实际表现 &gt;&gt;&gt;&gt; PARSE ERROR: The value 'true' can't convert to class class java.lang.Boolean with cardinality SINGLE 1|39309691526354826263|KFC_APP_SHARING1807|18795801091||2019-08-15 16:08:30.440|30|true|"[{\"rewardKey\":\"KCKFCMS226201807\",\"rewardName\":\"\",\"sendDate\":1565856510424,\"rewardType\":2}]"|False|</body>
		<created>2019-08-20 03:42:38</created>
		<closed>2019-08-23 08:49:21</closed>
	</bug>
	<bug>
		<id>613</id>
		<title>Query by eq with range index in page only return first page data</title>
		<body></body>
		<created>2019-07-18 02:39:30</created>
		<closed>2019-07-22 03:37:42</closed>
	</bug>
	<bug>
		<id>602</id>
		<title>RocksDB后端的内存消耗统计不准确</title>
		<body>### Actual behavior 实际表现  hugegraph后端存储是RocksDB时，  1. `top`和`ps`看到的HugeGraphServer进程使用的物理内存是51GB 2. `metrics/system/` API返回堆内存总共13GB，已使用8GB，空闲5GB 3. `/metrics/backend` API返回已使用内存是26GB  1和2中的统计都是准确的，所以`/metrics/backend` API统计的RocksDB内存占用少了 `12GB = 51GB - 13GB - 26GB`  ### Steps to reproduce the problem 复现步骤  使用loader持续导入数据达10亿（9亿边，5000万顶点）  ### Specifications of environment 环境信息 - hugegraph version: 0.9.2 - operating system: centos 6.3， 32 core，198GB memory - hugegraph backend: RocksDB，所有日志数据都使用同一块机械盘2.7TB </body>
		<created>2019-07-03 12:45:50</created>
		<closed>2020-04-08 15:40:53</closed>
	</bug>
	<bug>
		<id>597</id>
		<title>The 'hugegraph' store of rocksdb has not been opened</title>
		<body>2019-07-01 20:35:19 287026 [main] [ERROR] com.baidu.hugegraph.HugeGraph [] - Failed to close GraphTransaction ``` java.lang.IllegalStateException: The 'hugegraph' store of rocksdb has not been opened at com.google.common.base.Preconditions.checkState(Preconditions.java:199) ~[guava-19.0.jar:?] at com.baidu.hugegraph.util.E.checkState(E.java:68) ~[hugegraph-common-1.6.5.jar:1.6.5.0] at com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore.checkOpened(RocksDBStore.java:444) ~[classes/:?] at com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore.close(RocksDBStore.java:272) ~[classes/:?] at com.baidu.hugegraph.backend.tx.AbstractTransaction.close(AbstractTransaction.java:203) ~[classes/:?] at com.baidu.hugegraph.backend.tx.IndexableTransaction.close(IndexableTransaction.java:83) ~[classes/:?] at com.baidu.hugegraph.backend.cache.CachedGraphTransaction.close(CachedGraphTransaction.java:77) ~[classes/:?] at com.baidu.hugegraph.HugeGraph$Txs.close(HugeGraph.java:785) [classes/:?] at com.baidu.hugegraph.HugeGraph$TinkerpopTransaction.destroyTransaction(HugeGraph.java:753) [classes/:?] at com.baidu.hugegraph.HugeGraph$TinkerpopTransaction.access$2(HugeGraph.java:744) [classes/:?] at com.baidu.hugegraph.HugeGraph.closeTx(HugeGraph.java:488) [classes/:?] at com.baidu.hugegraph.HugeGraph.close(HugeGraph.java:470) [classes/:?] at com.baidu.hugegraph.core.CoreTestSuite.clear(CoreTestSuite.java:77) [test-classes/:?] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_111] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_111] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_111] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_111] at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) [junit-4.12.jar:4.12] at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.12.jar:4.12] at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) [junit-4.12.jar:4.12] at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33) [junit-4.12.jar:4.12] at org.junit.runners.ParentRunner.run(ParentRunner.java:363) [junit-4.12.jar:4.12] at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86) [.cp/:?] at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38) [.cp/:?] at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459) [.cp/:?] at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678) [.cp/:?] at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382) [.cp/:?] at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192) [.cp/:?] ```</body>
		<created>2019-07-01 12:37:13</created>
		<closed>2019-07-09 13:13:59</closed>
	</bug>
	<bug>
		<id>423</id>
		<title>hugegraph-tools-1.2.0  restore时，报"Graph 'hugegraph' does not exist"</title>
		<body>我自己创建的store名称是rocksdbgraph2  ，执行backup和dump没有异常，当我restore时发生了错误。 我试过./hugegraph --graph rocksdbgraph2 --url http://55.29.1.1:8080  graph-mode-set --graph-name rocksdbgraph2 -m RESTORING，没有用。  详细的信息： `./hugegraph --graph rocksdbgraph2  --url http://55.29.1.1:8080  restore -d /home/hugegraph/backup/rocksdbhugegraph/backup -t all` 报错： Exception in thread "main" class javax.ws.rs.NotFoundException: Graph 'hugegraph' does not exist at com.baidu.hugegraph.exception.ServerException.fromResponse(ServerException.java:44) at com.baidu.hugegraph.client.RestClient.checkStatus(RestClient.java:63) at com.baidu.hugegraph.rest.RestClient.get(RestClient.java:177) at com.baidu.hugegraph.api.graphs.GraphsAPI.mode(GraphsAPI.java:65) at com.baidu.hugegraph.driver.GraphsManager.mode(GraphsManager.java:50) at com.baidu.hugegraph.manager.GraphsManager.mode(GraphsManager.java:55) at com.baidu.hugegraph.cmd.HugeGraphCommand.execute(HugeGraphCommand.java:121) at com.baidu.hugegraph.cmd.HugeGraphCommand.main(HugeGraphCommand.java:280) </body>
		<created>2019-03-30 08:15:24</created>
		<closed>2019-04-09 01:34:31</closed>
	</bug>
	<bug>
		<id>377</id>
		<title>hugegraph 无法启动</title>
		<body>之前正常运行，在一次删除schema的时候报了事务过小的错误，于是修改了 properties配置文件     vertex.tx_capacity=1      改成了      vertex.tx_capacity=100     edge.tx_capacity=100 然后 stop hugegraph-server，再次start失败了。 麻烦看下是什么原因导致的，谢谢！！  版本是0.8.0。 以下是启动日志：  2019-02-28 11:32:09 3965  [main] [INFO ] com.baidu.hugegraph.dist.HugeGremlinServer [] -          \,,,/          (o o) -----oOOo-(3)-oOOo-----  2019-02-28 11:32:10 4734  [main] [INFO ] com.baidu.hugegraph.dist.HugeGremlinServer [] - Configuring Gremlin Server from conf/gremlin-server.yaml 2019-02-28 11:32:10 5261  [main] [INFO ] com.baidu.hugegraph.HugeGraph [] - Opening backend store 'cassandra' for graph 'fanqizha' 2019-02-28 11:32:10 5309  [main] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Graph [hugegraph] was successfully configured via [conf/hugegraph.properties]. 2019-02-28 11:32:10 5309  [main] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Graph [hugegraph] was successfully configured via [conf/hugegraph.properties]. 2019-02-28 11:32:10 5309  [main] [INFO ] org.apache.tinkerpop.gremlin.server.util.ServerGremlinExecutor [] - Initialized Gremlin thread pool.  Threads in pool named with pattern gremlin-* 2019-02-28 11:32:10 5309  [main] [INFO ] org.apache.tinkerpop.gremlin.server.util.ServerGremlinExecutor [] - Initialized Gremlin thread pool.  Threads in pool named with pattern gremlin-* 2019-02-28 11:32:11 6495  [main] [INFO ] org.apache.tinkerpop.gremlin.groovy.engine.ScriptEngines [] - Loaded gremlin-groovy ScriptEngine 2019-02-28 11:32:11 6495  [main] [INFO ] org.apache.tinkerpop.gremlin.groovy.engine.ScriptEngines [] - Loaded gremlin-groovy ScriptEngine 2019-02-28 11:32:12 7527  [main] [INFO ] org.apache.tinkerpop.gremlin.groovy.engine.GremlinExecutor [] - Initialized gremlin-groovy ScriptEngine with scripts/empty-sample.groovy 2019-02-28 11:32:12 7527  [main] [INFO ] org.apache.tinkerpop.gremlin.groovy.engine.GremlinExecutor [] - Initialized gremlin-groovy ScriptEngine with scripts/empty-sample.groovy 2019-02-28 11:32:12 7528  [main] [INFO ] org.apache.tinkerpop.gremlin.server.util.ServerGremlinExecutor [] - Initialized GremlinExecutor and preparing GremlinScriptEngines instances. 2019-02-28 11:32:12 7528  [main] [INFO ] org.apache.tinkerpop.gremlin.server.util.ServerGremlinExecutor [] - Initialized GremlinExecutor and preparing GremlinScriptEngines instances. 2019-02-28 11:32:12 7585  [main] [INFO ] org.apache.tinkerpop.gremlin.server.util.ServerGremlinExecutor [] - Initialized gremlin-groovy GremlinScriptEngine and registered metrics 2019-02-28 11:32:12 7585  [main] [INFO ] org.apache.tinkerpop.gremlin.server.util.ServerGremlinExecutor [] - Initialized gremlin-groovy GremlinScriptEngine and registered metrics 2019-02-28 11:32:12 7687  [main] [INFO ] org.apache.tinkerpop.gremlin.server.util.MetricManager [] - Configured Metrics CsvReporter configured with report interval=180000ms to fileName=/tmp/gremlin-server-metrics.csv 2019-02-28 11:32:12 7687  [main] [INFO ] org.apache.tinkerpop.gremlin.server.util.MetricManager [] - Configured Metrics CsvReporter configured with report interval=180000ms to fileName=/tmp/gremlin-server-metrics.csv 2019-02-28 11:32:13 7728  [main] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Executing start up LifeCycleHook 2019-02-28 11:32:13 7728  [main] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Executing start up LifeCycleHook 2019-02-28 11:32:13 7743  [main] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Executed once at startup of Gremlin Server. 2019-02-28 11:32:13 7743  [main] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Executed once at startup of Gremlin Server. 2019-02-28 11:32:13 7855  [main] [INFO ] org.apache.tinkerpop.gremlin.server.AbstractChannelizer [] - Configured application/vnd.gremlin-v1.0+gryo-lite with org.apache.tinkerpop.gremlin.driver.ser.GryoLiteMessageSerializerV1d0 2019-02-28 11:32:13 7855  [main] [INFO ] org.apache.tinkerpop.gremlin.server.AbstractChannelizer [] - Configured application/vnd.gremlin-v1.0+gryo-lite with org.apache.tinkerpop.gremlin.driver.ser.GryoLiteMessageSerializerV1d0 2019-02-28 11:32:13 7855  [main] [INFO ] org.apache.tinkerpop.gremlin.server.AbstractChannelizer [] - Configured application/vnd.gremlin-v1.0+gryo-stringd with org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV1d0 2019-02-28 11:32:13 7855  [main] [INFO ] org.apache.tinkerpop.gremlin.server.AbstractChannelizer [] - Configured application/vnd.gremlin-v1.0+gryo-stringd with org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV1d0 2019-02-28 11:32:13 8223  [main] [INFO ] org.apache.tinkerpop.gremlin.server.AbstractChannelizer [] - Configured application/vnd.gremlin-v1.0+json with org.apache.tinkerpop.gremlin.driver.ser.GraphSONMessageSerializerGremlinV1d0 2019-02-28 11:32:13 8223  [main] [INFO ] org.apache.tinkerpop.gremlin.server.AbstractChannelizer [] - Configured application/vnd.gremlin-v1.0+json with org.apache.tinkerpop.gremlin.driver.ser.GraphSONMessageSerializerGremlinV1d0 2019-02-28 11:32:13 8272  [main] [INFO ] org.apache.tinkerpop.gremlin.server.AbstractChannelizer [] - Configured application/vnd.gremlin-v2.0+json with org.apache.tinkerpop.gremlin.driver.ser.GraphSONMessageSerializerGremlinV2d0 2019-02-28 11:32:13 8272  [main] [INFO ] org.apache.tinkerpop.gremlin.server.AbstractChannelizer [] - Configured application/vnd.gremlin-v2.0+json with org.apache.tinkerpop.gremlin.driver.ser.GraphSONMessageSerializerGremlinV2d0 2019-02-28 11:32:13 8274  [main] [INFO ] org.apache.tinkerpop.gremlin.server.AbstractChannelizer [] - Configured application/json with org.apache.tinkerpop.gremlin.driver.ser.GraphSONMessageSerializerV1d0 2019-02-28 11:32:13 8274  [main] [INFO ] org.apache.tinkerpop.gremlin.server.AbstractChannelizer [] - Configured application/json with org.apache.tinkerpop.gremlin.driver.ser.GraphSONMessageSerializerV1d0 2019-02-28 11:32:13 8467  [gremlin-server-boss-1] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Gremlin Server configured with worker thread pool of 1, gremlin pool of 8 and boss thread pool of 1. 2019-02-28 11:32:13 8467  [gremlin-server-boss-1] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Gremlin Server configured with worker thread pool of 1, gremlin pool of 8 and boss thread pool of 1. 2019-02-28 11:32:13 8467  [gremlin-server-boss-1] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Channel started at port 8182. 2019-02-28 11:32:13 8467  [gremlin-server-boss-1] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Channel started at port 8182. 2019-02-28 11:32:15 9898  [main] [INFO ] com.baidu.hugegraph.server.RestServer [] - RestServer starting... Feb 28, 2019 11:32:40 AM org.glassfish.grizzly.http.server.NetworkListener start INFO: Started listener bound to [10.9.21.155:8081] 2019-02-28 11:32:40 35274 [main] [INFO ] com.baidu.hugegraph.server.RestServer [] - Graph 'hugegraph' was successfully configured via 'conf/hugegraph.properties' 2019-02-28 11:32:42 37140 [main] [ERROR] com.baidu.hugegraph.dist.HugeGraphServer [] - HugeRestServer start error: com.baidu.hugegraph.HugeException: Failed to update/query TaskStore         at com.baidu.hugegraph.task.TaskScheduler.call(TaskScheduler.java:402) ~[hugegraph-core-0.8.0.jar:0.8.0.0]         at com.baidu.hugegraph.task.TaskScheduler.queryTask(TaskScheduler.java:362) ~[hugegraph-core-0.8.0.jar:0.8.0.0]         at com.baidu.hugegraph.task.TaskScheduler.queryTask(TaskScheduler.java:357) ~[hugegraph-core-0.8.0.jar:0.8.0.0]         at com.baidu.hugegraph.task.TaskScheduler.findTask(TaskScheduler.java:275) ~[hugegraph-core-0.8.0.jar:0.8.0.0]         at com.baidu.hugegraph.task.TaskScheduler.restoreTasks(TaskScheduler.java:153) ~[hugegraph-core-0.8.0.jar:0.8.0.0]         at com.baidu.hugegraph.core.GraphManager.restoreUncompletedTasks(GraphManager.java:213) ~[hugegraph-api-0.8.0.jar:0.31.0.0]         at com.baidu.hugegraph.core.GraphManager.&lt;init&gt;(GraphManager.java:77) ~[hugegraph-api-0.8.0.jar:0.31.0.0]         at com.baidu.hugegraph.server.ApplicationConfig$GraphManagerFactory$1.onEvent(ApplicationConfig.java:102) ~[hugegraph-api-0.8.0.jar:0.31.0.0]         at org.glassfish.jersey.server.internal.monitoring.CompositeApplicationEventListener.onEvent(CompositeApplicationEventListener.java:74) ~[jersey-server-2.25.1.jar:?]         at org.glassfish.jersey.server.internal.monitoring.MonitoringContainerListener.onStartup(MonitoringContainerListener.java:81) ~[jersey-server-2.25.1.jar:?]         at org.glassfish.jersey.server.ApplicationHandler.onStartup(ApplicationHandler.java:1180) ~[jersey-server-2.25.1.jar:?]         at org.glassfish.jersey.grizzly2.httpserver.GrizzlyHttpContainer.start(GrizzlyHttpContainer.java:357) ~[jersey-container-grizzly2-http-2.25.1.jar:?]         at org.glassfish.grizzly.http.server.HttpHandlerChain.start(HttpHandlerChain.java:422) ~[grizzly-http-server-2.3.28.jar:2.3.28]         at org.glassfish.grizzly.http.server.HttpServer.setupHttpHandler(HttpServer.java:314) ~[grizzly-http-server-2.3.28.jar:2.3.28]         at org.glassfish.grizzly.http.server.HttpServer.start(HttpServer.java:290) ~[grizzly-http-server-2.3.28.jar:2.3.28]         at org.glassfish.jersey.grizzly2.httpserver.GrizzlyHttpServerFactory.createHttpServer(GrizzlyHttpServerFactory.java:296) ~[jersey-container-grizzly2-http-2.25.1.jar:?]         at org.glassfish.jersey.grizzly2.httpserver.GrizzlyHttpServerFactory.createHttpServer(GrizzlyHttpServerFactory.java:119) ~[jersey-container-grizzly2-http-2.25.1.jar:?]         at com.baidu.hugegraph.server.RestServer.start(RestServer.java:59) ~[hugegraph-api-0.8.0.jar:0.31.0.0]         at com.baidu.hugegraph.server.RestServer.start(RestServer.java:76) ~[hugegraph-api-0.8.0.jar:0.31.0.0]         at com.baidu.hugegraph.dist.HugeRestServer.start(HugeRestServer.java:58) ~[hugegraph-dist-0.8.0.jar:?]         at com.baidu.hugegraph.dist.HugeGraphServer.main(HugeGraphServer.java:60) [hugegraph-dist-0.8.0.jar:?] Caused by: java.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: Undefined property key: '~task_status'         at java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[?:1.8.0_181]         at java.util.concurrent.FutureTask.get(FutureTask.java:192) ~[?:1.8.0_181]         at com.baidu.hugegraph.task.TaskScheduler.call(TaskScheduler.java:400) ~[hugegraph-core-0.8.0.jar:0.8.0.0]         ... 20 more Caused by: java.lang.IllegalArgumentException: Undefined property key: '~task_status'         at com.google.common.base.Preconditions.checkArgument(Preconditions.java:146) ~[guava-19.0.jar:?]         at com.baidu.hugegraph.util.E.checkArgument(E.java:56) ~[hugegraph-common-1.5.3.jar:1.5.3.0]         at com.baidu.hugegraph.HugeGraph.propertyKey(HugeGraph.java:406) ~[hugegraph-core-0.8.0.jar:0.8.0.0]         at com.baidu.hugegraph.task.TaskScheduler.lambda$queryTask$6(TaskScheduler.java:367) ~[hugegraph-core-0.8.0.jar:0.8.0.0]         at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_181]         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_181]         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_181]         at java.lang.Thread.run(Thread.java:748) ~[?:1.8.0_181] 2019-02-28 11:32:42 37154 [main] [INFO ] org.apache.tinkerpop.gremlin.server.op.OpLoader [] - Adding the standard OpProcessor. 2019-02-28 11:32:42 37154 [main] [INFO ] org.apache.tinkerpop.gremlin.server.op.OpLoader [] - Adding the standard OpProcessor. 2019-02-28 11:32:42 37155 [main] [INFO ] org.apache.tinkerpop.gremlin.server.op.OpLoader [] - Adding the control OpProcessor. 2019-02-28 11:32:42 37155 [main] [INFO ] org.apache.tinkerpop.gremlin.server.op.OpLoader [] - Adding the control OpProcessor. 2019-02-28 11:32:42 37158 [main] [INFO ] org.apache.tinkerpop.gremlin.server.op.OpLoader [] - Adding the session OpProcessor. 2019-02-28 11:32:42 37158 [main] [INFO ] org.apache.tinkerpop.gremlin.server.op.OpLoader [] - Adding the session OpProcessor. 2019-02-28 11:32:42 37163 [main] [INFO ] org.apache.tinkerpop.gremlin.server.op.OpLoader [] - Adding the traversal OpProcessor. 2019-02-28 11:32:42 37163 [main] [INFO ] org.apache.tinkerpop.gremlin.server.op.OpLoader [] - Adding the traversal OpProcessor. 2019-02-28 11:32:42 37164 [main] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Shutting down OpProcessor[] 2019-02-28 11:32:42 37164 [main] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Shutting down OpProcessor[] 2019-02-28 11:32:42 37165 [main] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Shutting down OpProcessor[session] 2019-02-28 11:32:42 37165 [main] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Shutting down OpProcessor[session] 2019-02-28 11:32:42 37167 [main] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Shutting down OpProcessor[control] 2019-02-28 11:32:42 37167 [main] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Shutting down OpProcessor[control] 2019-02-28 11:32:42 37167 [main] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Shutting down OpProcessor[traversal] 2019-02-28 11:32:42 37167 [main] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Shutting down OpProcessor[traversal] 2019-02-28 11:32:42 37169 [main] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Shutting down thread pools. 2019-02-28 11:32:42 37169 [main] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Shutting down thread pools. 2019-02-28 11:32:42 37171 [gremlin-server-stop] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Executing shutdown LifeCycleHook 2019-02-28 11:32:42 37171 [gremlin-server-stop] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Executing shutdown LifeCycleHook Exception in thread "main" 2019-02-28 11:32:42 37171 [gremlin-server-stop] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Executed once at shutdown of Gremlin Server. com.baidu.hugegraph.HugeException: Failed to update/query TaskStore 2019-02-28 11:32:42 37171 [gremlin-server-stop] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Executed once at shutdown of Gremlin Server.         at com.baidu.hugegraph.task.TaskScheduler.call(TaskScheduler.java:402)         at com.baidu.hugegraph.task.TaskScheduler.queryTask(TaskScheduler.java:362)         at com.baidu.hugegraph.task.TaskScheduler.queryTask(TaskScheduler.java:357)         at com.baidu.hugegraph.task.TaskScheduler.findTask(TaskScheduler.java:275)         at com.baidu.hugegraph.task.TaskScheduler.restoreTasks(TaskScheduler.java:153)         at com.baidu.hugegraph.core.GraphManager.restoreUncompletedTasks(GraphManager.java:213)         at com.baidu.hugegraph.core.GraphManager.&lt;init&gt;(GraphManager.java:77)         at com.baidu.hugegraph.server.ApplicationConfig$GraphManagerFactory$1.onEvent(ApplicationConfig.java:102)         at org.glassfish.jersey.server.internal.monitoring.CompositeApplicationEventListener.onEvent(CompositeApplicationEventListener.java:74)         at org.glassfish.jersey.server.internal.monitoring.MonitoringContainerListener.onStartup(MonitoringContainerListener.java:81)         at org.glassfish.jersey.server.ApplicationHandler.onStartup(ApplicationHandler.java:1180)         at org.glassfish.jersey.grizzly2.httpserver.GrizzlyHttpContainer.start(GrizzlyHttpContainer.java:357)         at org.glassfish.grizzly.http.server.HttpHandlerChain.start(HttpHandlerChain.java:422)         at org.glassfish.grizzly.http.server.HttpServer.setupHttpHandler(HttpServer.java:314)         at org.glassfish.grizzly.http.server.HttpServer.start(HttpServer.java:290)         at org.glassfish.jersey.grizzly2.httpserver.GrizzlyHttpServerFactory.createHttpServer(GrizzlyHttpServerFactory.java:296)         at org.glassfish.jersey.grizzly2.httpserver.GrizzlyHttpServerFactory.createHttpServer(GrizzlyHttpServerFactory.java:119)         at com.baidu.hugegraph.server.RestServer.start(RestServer.java:59)         at com.baidu.hugegraph.server.RestServer.start(RestServer.java:76)         at com.baidu.hugegraph.dist.HugeRestServer.start(HugeRestServer.java:58)         at com.baidu.hugegraph.dist.HugeGraphServer.main(HugeGraphServer.java:60) Caused by: java.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: Undefined property key: '~task_status'         at java.util.concurrent.FutureTask.report(FutureTask.java:122)         at java.util.concurrent.FutureTask.get(FutureTask.java:192)         at com.baidu.hugegraph.task.TaskScheduler.call(TaskScheduler.java:400)         ... 20 more Caused by: java.lang.IllegalArgumentException: Undefined property key: '~task_status'         at com.google.common.base.Preconditions.checkArgument(Preconditions.java:146)         at com.baidu.hugegraph.util.E.checkArgument(E.java:56)         at com.baidu.hugegraph.HugeGraph.propertyKey(HugeGraph.java:406)         at com.baidu.hugegraph.task.TaskScheduler.lambda$queryTask$6(TaskScheduler.java:367)         at java.util.concurrent.FutureTask.run(FutureTask.java:266)         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)         at java.lang.Thread.run(Thread.java:748) 2019-02-28 11:32:44 39375 [gremlin-server-stop] [WARN ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Exception while closing Graph instance [hugegraph] com.baidu.hugegraph.HugeException: Exception when closing task tx         at com.baidu.hugegraph.task.TaskManager.closeTaskTx(TaskManager.java:110) ~[hugegraph-core-0.8.0.jar:0.8.0.0]         at com.baidu.hugegraph.task.TaskManager.closeScheduler(TaskManager.java:75) ~[hugegraph-core-0.8.0.jar:0.8.0.0]         at com.baidu.hugegraph.HugeGraph.close(HugeGraph.java:453) ~[hugegraph-core-0.8.0.jar:0.8.0.0]         at org.apache.tinkerpop.gremlin.server.GremlinServer.lambda$null$8(GremlinServer.java:307) ~[gremlin-server-3.2.5.jar:3.2.5]         at java.util.concurrent.ConcurrentHashMap$KeySetView.forEach(ConcurrentHashMap.java:4649) ~[?:1.8.0_181]         at org.apache.tinkerpop.gremlin.server.GremlinServer.lambda$stop$9(GremlinServer.java:304) ~[gremlin-server-3.2.5.jar:3.2.5]         at java.lang.Thread.run(Thread.java:748) [?:1.8.0_181] Caused by: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.FutureTask@33802670 rejected from java.util.concurrent.ThreadPoolExecutor@5c622b3b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]         at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063) ~[?:1.8.0_181]         at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830) ~[?:1.8.0_181]         at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379) ~[?:1.8.0_181]         at java.util.concurrent.AbstractExecutorService.invokeAll(AbstractExecutorService.java:238) ~[?:1.8.0_181]         at com.baidu.hugegraph.task.TaskManager.closeTaskTx(TaskManager.java:108) ~[hugegraph-core-0.8.0.jar:0.8.0.0]         ... 6 more 2019-02-28 11:32:44 39375 [gremlin-server-stop] [WARN ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Exception while closing Graph instance [hugegraph] com.baidu.hugegraph.HugeException: Exception when closing task tx         at com.baidu.hugegraph.task.TaskManager.closeTaskTx(TaskManager.java:110) ~[hugegraph-core-0.8.0.jar:0.8.0.0]         at com.baidu.hugegraph.task.TaskManager.closeScheduler(TaskManager.java:75) ~[hugegraph-core-0.8.0.jar:0.8.0.0]         at com.baidu.hugegraph.HugeGraph.close(HugeGraph.java:453) ~[hugegraph-core-0.8.0.jar:0.8.0.0]         at org.apache.tinkerpop.gremlin.server.GremlinServer.lambda$null$8(GremlinServer.java:307) ~[gremlin-server-3.2.5.jar:3.2.5]         at java.util.concurrent.ConcurrentHashMap$KeySetView.forEach(ConcurrentHashMap.java:4649) ~[?:1.8.0_181]         at org.apache.tinkerpop.gremlin.server.GremlinServer.lambda$stop$9(GremlinServer.java:304) ~[gremlin-server-3.2.5.jar:3.2.5]         at java.lang.Thread.run(Thread.java:748) [?:1.8.0_181] Caused by: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.FutureTask@33802670 rejected from java.util.concurrent.ThreadPoolExecutor@5c622b3b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]         at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063) ~[?:1.8.0_181]         at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830) ~[?:1.8.0_181]         at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379) ~[?:1.8.0_181]         at java.util.concurrent.AbstractExecutorService.invokeAll(AbstractExecutorService.java:238) ~[?:1.8.0_181]         at com.baidu.hugegraph.task.TaskManager.closeTaskTx(TaskManager.java:108) ~[hugegraph-core-0.8.0.jar:0.8.0.0]         ... 6 more 2019-02-28 11:32:44 39376 [gremlin-server-stop] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Closed Graph instance [hugegraph] 2019-02-28 11:32:44 39376 [gremlin-server-stop] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Closed Graph instance [hugegraph] 2019-02-28 11:32:44 39378 [gremlin-server-stop] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Gremlin Server - shutdown complete 2019-02-28 11:32:44 39378 [gremlin-server-stop] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Gremlin Server - shutdown complete</body>
		<created>2019-02-28 06:22:51</created>
		<closed>2019-02-28 13:56:09</closed>
	</bug>
	<bug>
		<id>359</id>
		<title>初始化自定义存储后端失败：Not exists BackendStoreProvider</title>
		<body>v0.8.0版本使用HugeGraph Plugin机制扩展自定义后端，执行init-store.sh初始化数据库时，会报如下异常： ``` [root@master hugegraph-0.8.0]# bin/init-store.sh  Initing HugeGraph Store... 2019-02-12 10:51:23 733   [main] [INFO ] com.baidu.hugegraph.cmd.InitStore [] - Init graph with config file: conf/hugegraph.properties 2019-02-12 10:51:23 741   [main] [WARN ] com.baidu.hugegraph.config.HugeConfig [] - The config option 'snappy.driver' is redundant, please ensure it has been registered 2019-02-12 10:51:23 741   [main] [WARN ] com.baidu.hugegraph.config.HugeConfig [] - The config option 'snappy.url' is redundant, please ensure it has been registered 2019-02-12 10:51:23 741   [main] [WARN ] com.baidu.hugegraph.config.HugeConfig [] - The config option 'snappy.username' is redundant, please ensure it has been registered 2019-02-12 10:51:24 835   [main] [INFO ] com.baidu.hugegraph.HugeGraph [] - Opening backend store 'snappydata' for graph 'bigraph' 2019-02-12 10:51:24 836   [main] [ERROR] com.baidu.hugegraph.HugeGraph [] - Failed to init backend store: Not exists BackendStoreProvider: snappydata Exception in thread "main" com.baidu.hugegraph.HugeException: Failed to init backend store at com.baidu.hugegraph.HugeGraph.&lt;init&gt;(HugeGraph.java:140) at com.baidu.hugegraph.HugeFactory.open(HugeFactory.java:44) at com.baidu.hugegraph.HugeFactory.open(HugeFactory.java:56) at com.baidu.hugegraph.cmd.InitStore.initGraph(InitStore.java:95) at com.baidu.hugegraph.cmd.InitStore.main(InitStore.java:87) ```  查看com.baidu.hugegraph.cmd.InitStore源码，没有发现registerPlugins相关代码；在init-store.sh中没有添加hugegraph-0.8.0/plugins目录下的Jar包到CLASSPATH中 ```     public static void main(String[] args)                        throws ConfigurationException, InterruptedException {         E.checkArgument(args.length == 1,                         "Init store only accept one config file.");         E.checkArgument(args[0].endsWith(".yaml"),                         "Init store only accept yaml config file.");          String confFile = args[0];         RegisterUtil.registerBackends();//只注册了内置后端          YamlConfiguration config = new YamlConfiguration();         config.load(confFile);          List&lt;ConfigurationNode&gt; nodes = config.getRootNode()                                               .getChildren(GRAPHS);         E.checkArgument(nodes.size() == 1,                         "Must contain one '%s' in config file '%s'",                         GRAPHS, confFile);          List&lt;ConfigurationNode&gt; graphNames = nodes.get(0).getChildren();          E.checkArgument(!graphNames.isEmpty(),                         "Must contain at least one graph");          for (ConfigurationNode graphName : graphNames) {             String configPath = graphName.getValue().toString();             initGraph(configPath);         }          HugeGraph.shutdown(30L);     } ```  所以目前我的解决方法如下： 1、修改com.baidu.hugegraph.cmd.InitStore源码，在第69行添加RegisterUtil.registerPlugins(); 2、将Plugin Jar包放至hugegraph-0.8.0/lib下，使ClassLoader能够加载到Plugin类  请问该问题有无更好的解决方式，或后续版本能否支持初始化自定义存储后端？谢谢！ </body>
		<created>2019-02-12 02:55:14</created>
		<closed>2019-02-27 08:17:45</closed>
	</bug>
	<bug>
		<id>335</id>
		<title>Could not initialize class org.rocksdb.Options</title>
		<body>Reference link: https://github.com/confluentinc/ksql/issues/1332 &gt; If the user runs into this, the best solution is to set java.io.tmpdir to a directory which is writable by all users.  </body>
		<created>2019-01-15 08:36:41</created>
		<closed>2019-04-09 07:13:31</closed>
	</bug>
	<bug>
		<id>323</id>
		<title>Backend metrics of rocksdb disk usage can't work</title>
		<body></body>
		<created>2019-01-08 13:18:56</created>
		<closed>2019-02-12 11:22:00</closed>
	</bug>
	<bug>
		<id>314</id>
		<title>primitive system id reservation has no effect</title>
		<body></body>
		<created>2019-01-03 12:16:07</created>
		<closed>2019-01-07 04:03:16</closed>
	</bug>
	<bug>
		<id>302</id>
		<title>Bug: query vertices by id with hasId() filter when using number id</title>
		<body>### Expected behavior 期望表现 可以查询出结果   ### Actual behavior 实际表现 结果为空   ### Steps to reproduce the problem 复现步骤 g.V(1, 2, 3).hasId(P.within(2, 3))   ### Specifications of environment 环境信息 - hugegraph version: 0.8  </body>
		<created>2018-12-25 09:08:18</created>
		<closed>2018-12-25 14:12:51</closed>
	</bug>
	<bug>
		<id>291</id>
		<title>index rebuild exceeds 80w limit and 65536 cassandra limit</title>
		<body>### Actual behavior 实际表现 &gt; HugeException: Too many records(must &lt;=800000) for the query: ....  or  &gt; HugeException: Batch statement cannot contain more than 65535 statements...     ### Steps to reproduce the problem 复现步骤 1. insert &gt; 80w vertices 2. create secondary/range index  ### Specifications of environment 环境信息 - hugegraph version: 0.8.0  </body>
		<created>2018-12-19 10:55:32</created>
		<closed>2018-12-25 14:07:49</closed>
	</bug>
	<bug>
		<id>280</id>
		<title>Condition Query has none-flatten condition</title>
		<body>### Actual behavior 实际表现 java.lang.IllegalStateException: Condition Query has none-flatten condition '183 &gt; 45 OR 183 == 35 OR 183 &lt; 29 AND 183 &lt; 20 AND 183 &gt;= 11 OR 183 &gt; 10' at com.google.common.base.Preconditions.checkState(Preconditions.java:199) at com.baidu.hugegraph.util.E.checkState(E.java:68) at com.baidu.hugegraph.backend.query.ConditionQuery.checkFlattened(ConditionQuery.java:396) at com.baidu.hugegraph.backend.query.ConditionQuery.condition(ConditionQuery.java:140) at com.baidu.hugegraph.backend.tx.GraphIndexTransaction.collectMatchedIndexes(GraphIndexTransaction.java:529) at com.baidu.hugegraph.backend.tx.GraphIndexTransaction.processRangeIndexLeft(GraphIndexTransaction.java:103) at com.baidu.hugegraph.backend.tx.GraphIndexTransaction.removeIndexLeft(GraphIndexTransaction.java:93) at com.baidu.hugegraph.backend.tx.GraphTransaction.filterResultFromIndexQuery(GraphTransaction.java:1181) at com.baidu.hugegraph.backend.tx.GraphTransaction.lambda$queryVertices$1(GraphTransaction.java:485) at com.baidu.hugegraph.iterator.FilterIterator.fetch(FilterIterator.java:45) at com.baidu.hugegraph.iterator.WrappedIterator.hasNext(WrappedIterator.java:41) at org.apache.tinkerpop.gremlin.process.traversal.step.map.GraphStep.processNextStart(GraphStep.java:131) at org.apache.tinkerpop.gremlin.process.traversal.step.util.AbstractStep.hasNext(AbstractStep.java:143) at org.apache.tinkerpop.gremlin.process.traversal.step.util.ExpandableStepIterator.next(ExpandableStepIterator.java:50) at org.apache.tinkerpop.gremlin.process.traversal.step.map.FlatMapStep.processNextStart(FlatMapStep.java:48) at org.apache.tinkerpop.gremlin.process.traversal.step.util.AbstractStep.next(AbstractStep.java:128) at org.apache.tinkerpop.gremlin.process.traversal.step.util.AbstractStep.next(AbstractStep.java:38) at org.apache.tinkerpop.gremlin.process.traversal.Traversal.fill(Traversal.java:177) at org.apache.tinkerpop.gremlin.process.traversal.Traversal.toList(Traversal.java:115) at com.baidu.hugegraph.core.VertexCoreTest.testQueryWithMultiLayerConditions(VertexCoreTest.java:1567) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.junit.runners.Suite.runChild(Suite.java:128) at org.junit.runners.Suite.runChild(Suite.java:27) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86) at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)  </body>
		<created>2018-12-13 09:36:11</created>
		<closed>2018-12-17 07:47:01</closed>
	</bug>
	<bug>
		<id>250</id>
		<title>rings 与rays接口查询报错</title>
		<body>### Expected behavior 期望表现 比如这种查询 http://localhost:8080/graphs/gods_relation_2/traversers/rings?source="1:pluto"&amp;direction=OUT&amp;max_depth=5   ### Actual behavior 实际表现 {     "exception": "class java.lang.IllegalArgumentException",     "message": "Paths max depth must be &gt; 0, but got '0'",     "cause": "" }   ### Steps to reproduce the problem 复现步骤 1. {step 1} 2. {step 2} 3. {step 3}   ### Status of loaded data 数据状态  #### Vertex/Edge summary 数据量 - loaded vertices amount: {like 10 million} - loaded edges amount: {like 20 million} - loaded time: {like 200s}  #### Vertex/Edge example 数据示例 {type something here...}  #### Schema(VertexLabel, EdgeLabel, IndexLabel) 元数据结构 {type something here...}   ### Specifications of environment 环境信息 - hugegraph version: {like v0.7.4} - operating system: {like centos 7.4, 32 CPUs, 64G RAM} - hugegraph backend: {like cassandra 3.10, cluster with 20 nodes, 3 x 1TB HDD disk each node} </body>
		<created>2018-11-30 03:35:02</created>
		<closed>2018-12-17 08:52:37</closed>
	</bug>
	<bug>
		<id>245</id>
		<title>init-store can't find main class</title>
		<body>### Actual behavior 实际表现 v0.8.0 tar contains source.jar   </body>
		<created>2018-11-29 07:47:22</created>
		<closed>2018-11-29 08:23:45</closed>
	</bug>
	<bug>
		<id>239</id>
		<title>task index-label id has conflicts with system label index or schema name index</title>
		<body>### Actual behavior 实际表现 {type something here...} ![image](https://user-images.githubusercontent.com/17330028/49158734-cfe1f400-f35d-11e8-808b-83ab6e07a58c.png)  operate tx in other thread exception appears after fix first bug  ![image](https://user-images.githubusercontent.com/17330028/49166551-92d22d80-f36e-11e8-9945-870fe2820e5a.png) </body>
		<created>2018-11-28 14:35:30</created>
		<closed>2018-11-29 08:07:49</closed>
	</bug>
	<bug>
		<id>237</id>
		<title>关于id策略的边连接问题</title>
		<body>@Linary @javeme 各位同学有个问题请教 配置文件如下 执行loader导入报错PROPERTY_KEY with name 'id' does not exist 看报错的内容他是再找叫id的property_key 我的想法是基于id(.useCustomizeStringId())连接边 请问基于id连接边 配置文件是那个地方需要修改吗 1、schema.groovy schema.propertyKey("test_name").asText().ifNotExist().create(); ...省略 // 使用自定义字符策略使用"test_name"作为id schema.vertexLabel("test_person").useCustomizeStringId().properties("test_age", "test_city").ifNotExist().create(); schema.edgeLabel("test_knows").sourceLabel("test_person").targetLabel("test_person").properties("date", "weight").ifNotExist().create();  2、struct.json "vertices": [     {       "label": "test_person",       "input": {         "type": "file",         "path": "example/vertex_person.csv",         "format": "CSV",         "header": [           "id",           "test_age",           "test_city"         ],         "charset": "UTF-8"       },       "id": "id"     }  "edges": [        {        "label": "test_knows",        "source": ["source_name"],        "target": ["target_name"],        "input": {        "type": "file",        "path": "example/edge_knows.json",        "format": "JSON"        },        "mapping": {        "source_name": "id",        "target_name": "id"        }        } 3、vertex_person.csv 顶点文件 marko,29,Beijing vadas,27,Hongkong 4、edge_knows.json 边文件 {"id": "marko", "id": "vadas", "date": "20160110", "weight": 0.5} {"id": "marko", "id": "josh", "date": "20130220", "weight": 1.0} </body>
		<created>2018-11-28 06:36:27</created>
		<closed>2018-11-29 01:00:49</closed>
	</bug>
	<bug>
		<id>223</id>
		<title>graph state is out of control when closing graph</title>
		<body>Failed to update/query TaskStore when closing graph, also throw java.lang.IllegalStateException: Graph 'hugegraph[xx]' has been closed.  ![image](https://user-images.githubusercontent.com/9625821/48953189-e8c66000-ef7f-11e8-8361-da54b717b6cb.png) </body>
		<created>2018-11-23 16:51:46</created>
		<closed>2018-11-27 07:51:09</closed>
	</bug>
	<bug>
		<id>219</id>
		<title>Can't find task with id xx when waitUntilTaskCompleted()</title>
		<body>small probability occurs in HBase backend with travis core-test ![image](https://user-images.githubusercontent.com/9625821/48933144-34561b00-ef3a-11e8-91c8-db197a1156c4.png) </body>
		<created>2018-11-23 08:09:19</created>
		<closed>2018-11-27 08:55:17</closed>
	</bug>
	<bug>
		<id>211</id>
		<title>Bug: dependencies task will be ignored when index-create no need to rebuild </title>
		<body> ### Steps to reproduce the problem 复现步骤 1.  create personByCity indexlabel 2. create personByCityAndName Indexlabel 3. personByCity will be deleted by task A，but when no need to rebuild personByCityAndName(no person vertices exist), task A will be ignored and not returned.  ### Specifications of environment 环境信息 - hugegraph version: v0.8 </body>
		<created>2018-11-21 13:27:11</created>
		<closed>2018-11-22 09:05:40</closed>
	</bug>
	<bug>
		<id>196</id>
		<title>query vertices with limit but results is incomplete</title>
		<body>### Expected behavior 期望表现  Query vertices with limit   ``` curl http://localhost:8080/graphs/hugegraph/graph/vertices?limit=3 ```  Expect three complete vertices.  ### Actual behavior 实际表现  The last vertex missing some properties. ``` {     "vertices":[         {             "id":"3:lop",             "label":"software",             "type":"vertex",             "properties":{                 "price":[                     {                         "id":"3:lop&gt;price",                         "value":328                     }                 ],                 "name":[                     {                         "id":"3:lop&gt;name",                         "value":"lop"                     }                 ],                 "lang":[                     {                         "id":"3:lop&gt;lang",                         "value":"java"                     }                 ]             }         },         {             "id":"2:josh",             "label":"person",             "type":"vertex",             "properties":{                 "city":[                     {                         "id":"2:josh&gt;city",                         "value":"Beijing"                     }                 ],                 "name":[                     {                         "id":"2:josh&gt;name",                         "value":"josh"                     }                 ],                 "age":[                     {                         "id":"2:josh&gt;age",                         "value":32                     }                 ]             }         },         {             "id":"2:marko",             "label":"person",             "type":"vertex",             "properties":{                 "name":[                     {                         "id":"2:marko&gt;name",                         "value":"marko"                     }                 ]             }         }     ] } ```  ### Specifications of environment 环境信息 - hugegraph version: v0.7.4 - operating system: mac os, 8 CPUs, 16G RAM - hugegraph backend: rocksdb </body>
		<created>2018-11-14 09:18:46</created>
		<closed>2018-11-15 06:28:28</closed>
	</bug>
	<bug>
		<id>164</id>
		<title>The last page when pagination should be displayed as null instead of "null"</title>
		<body></body>
		<created>2018-10-31 13:22:42</created>
		<closed>2018-11-05 03:26:24</closed>
	</bug>
	<bug>
		<id>162</id>
		<title>MySQL后端删除的schema其他线程仍可以查到</title>
		<body>### Steps to reproduce the problem 复现步骤 1. 主线程创建Vertex Label person 2. 子线程删除person 3. 主线程查询person，仍可以查到  ### Specifications of environment 环境信息 - hugegraph version:  v0.7.4  </body>
		<created>2018-10-31 12:20:53</created>
		<closed>2018-10-31 13:09:43</closed>
	</bug>
	<bug>
		<id>160</id>
		<title>异步任务返回值问题</title>
		<body>   ### Expected behavior 期望表现 {type something here...} 虽然看到了一个相似的closed的问题，但是有一些新的需求和问题  期望得到**解析的完整**返回值  ### Actual behavior 实际表现 请教一下，比如我想得一个结点的出向点的列表，当出向点的数量非常大时，这时需要用异步执行来查询数据，但是目前查询到的结果并不完整  比如我执行： bin/hugegraph  gremlin-schedule -s 'g.V().hasLabel("person").has("name","xxx").inE().outV().toList()' 可以解析出长度为66150的列表 但是执行： bin/hugegraph  gremlin-schedule -s 'g.V().hasLabel("person").has("name","xxx").inE().outV().count()' 得到结果为956064 两者差别太大，很多结果都没有查询出来  这个是有返回值限制的么？我该如何设置？  另外terminal step我尝试了下，应该只有toList() 和toSet() 两种是么？ 是否有其他的方式呢？     ### Status of loaded data 数据状态  #### Vertex/Edge summary 数据量 - loaded vertices amount: 6千5百万 - loaded edges amount: 7亿 - loaded time: {like 200s}    ### Specifications of environment 环境信息 - hugegraph version: {like v0.7.4} - operating system: {like centos 7.4, 32 CPUs, 64G RAM} - hugegraph backend: {like rocksDB}</body>
		<created>2018-10-31 11:21:08</created>
		<closed>2018-11-01 13:27:11</closed>
	</bug>
	<bug>
		<id>147</id>
		<title>union操作中查询日期类型报错</title>
		<body>### 查询语句 1、`g.E().has("date", P.gte("2016-01-10 10:00:00.000")).count()` 2、`g.E().union(has("date", P.gte("2016-01-10 10:00:00.000"))).count()`   ### Expected behavior 期望表现 结果一样   ### Actual behavior 实际表现 第一条语句成功执行，第二条报错  ``` Exception in thread "main" java.lang.ClassCastException: java.lang.String cannot be cast to java.util.Date at java.util.Date.compareTo(Date.java:131) at org.apache.tinkerpop.gremlin.process.traversal.Compare$5.test(Compare.java:140) at org.apache.tinkerpop.gremlin.process.traversal.Compare$4.test(Compare.java:115) at org.apache.tinkerpop.gremlin.process.traversal.P.test(P.java:71) at org.apache.tinkerpop.gremlin.process.traversal.step.util.HasContainer.testValue(HasContainer.java:113) at org.apache.tinkerpop.gremlin.process.traversal.step.util.HasContainer.test(HasContainer.java:95) at org.apache.tinkerpop.gremlin.process.traversal.step.util.HasContainer.testAll(HasContainer.java:173) at org.apache.tinkerpop.gremlin.process.traversal.step.filter.HasStep.filter(HasStep.java:50) at org.apache.tinkerpop.gremlin.process.traversal.step.filter.FilterStep.processNextStart(FilterStep.java:38) at org.apache.tinkerpop.gremlin.process.traversal.step.util.AbstractStep.hasNext(AbstractStep.java:143) at org.apache.tinkerpop.gremlin.process.traversal.step.util.ExpandableStepIterator.next(ExpandableStepIterator.java:50) at org.apache.tinkerpop.gremlin.process.traversal.step.util.ComputerAwareStep$EndStep.processNextStart(ComputerAwareStep.java:76) at org.apache.tinkerpop.gremlin.process.traversal.step.util.AbstractStep.hasNext(AbstractStep.java:143) at org.apache.tinkerpop.gremlin.process.traversal.util.DefaultTraversal.hasNext(DefaultTraversal.java:192) at org.apache.tinkerpop.gremlin.process.traversal.step.branch.BranchStep.standardAlgorithm(BranchStep.java:94) at org.apache.tinkerpop.gremlin.process.traversal.step.util.ComputerAwareStep.processNextStart(ComputerAwareStep.java:46) at org.apache.tinkerpop.gremlin.process.traversal.step.util.AbstractStep.hasNext(AbstractStep.java:143) at org.apache.tinkerpop.gremlin.process.traversal.step.util.ExpandableStepIterator.hasNext(ExpandableStepIterator.java:42) at org.apache.tinkerpop.gremlin.process.traversal.step.util.ReducingBarrierStep.processAllStarts(ReducingBarrierStep.java:83) at org.apache.tinkerpop.gremlin.process.traversal.step.util.ReducingBarrierStep.processNextStart(ReducingBarrierStep.java:113) at org.apache.tinkerpop.gremlin.process.traversal.step.util.AbstractStep.next(AbstractStep.java:128) at org.apache.tinkerpop.gremlin.process.traversal.step.util.AbstractStep.next(AbstractStep.java:38) at org.apache.tinkerpop.gremlin.process.traversal.util.DefaultTraversal.next(DefaultTraversal.java:200) at com.baidu.hugegraph.example.Example2.traversal(Example2.java:75) at com.baidu.hugegraph.example.Example2.main(Example2.java:50) ``` </body>
		<created>2018-10-30 06:01:35</created>
		<closed>2018-11-19 03:26:39</closed>
	</bug>
	<bug>
		<id>144</id>
		<title>在无索引的数据上建索引是否会发生数据不一致</title>
		<body>后端使用cassandra  1. 向图里添加大量数据 2. 按user的userid创建索引 ``` schema.indexLabel('userById').onV('user').by('userid').secondary().ifNotExist().create(); ``` 3. 继续添加数据  分析了数据库的表结果。建索引前表graph_secondary_indexes为空，表graph_secondary_indexes有3列，分别是 ``` field_values  index_label_id element_ids ``` 建索引后再添加数据，graph_secondary_indexes开始有数据。 通过分析，field_values是属性值,element_ids是属性值对应的顶点id，很显然，有这个表可以快速地通过属性值找到顶点id，通过观察数据发现： 建索引的时候，没有把老数据的相关信息加到表graph_secondary_indexes中。只是建索引后新数据相关信息加到了graph_secondary_indexes中。此时，若要查一个老数据的userid（建索引前添加到cassandra里的），它不在索引中，查询策略是怎么样的？是先查graph_secondary_indexes，查不到再遍历所有？还是查不到直接返回查不到？还是有其他查询方法?</body>
		<created>2018-10-30 02:26:26</created>
		<closed>2018-11-01 06:17:32</closed>
	</bug>
	<bug>
		<id>139</id>
		<title>Make task-list api not return task_input and task_result</title>
		<body>Because their content may be too long (it's just returned by task-get api)</body>
		<created>2018-10-26 17:09:12</created>
		<closed>2018-11-27 08:56:11</closed>
	</bug>
	<bug>
		<id>129</id>
		<title>The config "batch.max_vertices_per_batch" doesn't work</title>
		<body>### Expected behavior 期望表现 Create vertices success with batch size 1000  ### Actual behavior 实际表现 Insert error with exception "Too many counts of vertices for one time post, the maximum number is 500"  ### Steps to reproduce the problem 复现步骤 1. add config "batch.max_vertices_per_batch=1000" in rest-server.properties 2. new ArrayList&lt;&gt;(1000), then fill with vertices 3. post  </body>
		<created>2018-10-25 02:31:23</created>
		<closed>2018-11-01 06:46:52</closed>
	</bug>
	<bug>
		<id>126</id>
		<title>ClassCastException:  HugeGraphAuthProxy cannot be cast to HugeGraph</title>
		<body>### Actual behavior 实际表现 ```log 2018-10-23 20:43:00 73074 [main] [ERROR] com.baidu.hugegraph.dist.HugeGraphServer [] - HugeGraphServer error: java.lang.ClassCastException: com.baidu.hugegraph.auth.HugeGraphAuthProxy cannot be cast to com.baidu.hugegraph.HugeGraph at com.baidu.hugegraph.core.GraphManager.checkBackendVersionOrExit(GraphManager.java:172) ~[classes/:?] at com.baidu.hugegraph.core.GraphManager.&lt;init&gt;(GraphManager.java:67) ~[classes/:?] at com.baidu.hugegraph.server.ApplicationConfig$GraphManagerFactory$1.onEvent(ApplicationConfig.java:102) ~[classes/:?] at org.glassfish.jersey.server.internal.monitoring.CompositeApplicationEventListener.onEvent(CompositeApplicationEventListener.java:74) ~[jersey-server-2.25.1.jar:?] at org.glassfish.jersey.server.internal.monitoring.MonitoringContainerListener.onStartup(MonitoringContainerListener.java:81) ~[jersey-server-2.25.1.jar:?] at org.glassfish.jersey.server.ApplicationHandler.onStartup(ApplicationHandler.java:1180) ~[jersey-server-2.25.1.jar:?] at org.glassfish.jersey.grizzly2.httpserver.GrizzlyHttpContainer.start(GrizzlyHttpContainer.java:357) ~[jersey-container-grizzly2-http-2.25.1.jar:?] at org.glassfish.grizzly.http.server.HttpHandlerChain.start(HttpHandlerChain.java:422) ~[grizzly-http-server-2.3.28.jar:2.3.28] at org.glassfish.grizzly.http.server.HttpServer.setupHttpHandler(HttpServer.java:314) ~[grizzly-http-server-2.3.28.jar:2.3.28] at org.glassfish.grizzly.http.server.HttpServer.start(HttpServer.java:290) ~[grizzly-http-server-2.3.28.jar:2.3.28] at org.glassfish.jersey.grizzly2.httpserver.GrizzlyHttpServerFactory.createHttpServer(GrizzlyHttpServerFactory.java:296) ~[jersey-container-grizzly2-http-2.25.1.jar:?] at org.glassfish.jersey.grizzly2.httpserver.GrizzlyHttpServerFactory.createHttpServer(GrizzlyHttpServerFactory.java:119) ~[jersey-container-grizzly2-http-2.25.1.jar:?] at com.baidu.hugegraph.server.RestServer.start(RestServer.java:59) ~[classes/:?] at com.baidu.hugegraph.server.RestServer.start(RestServer.java:76) ~[classes/:?] at com.baidu.hugegraph.dist.HugeRestServer.start(HugeRestServer.java:54) ~[classes/:?] at com.baidu.hugegraph.dist.HugeGraphServer.main(HugeGraphServer.java:58) [classes/:?] ```  ### Steps to reproduce the problem 复现步骤 1. enable auth feature 2. start server  ### Specifications of environment 环境信息 - hugegraph version: v0.7.4</body>
		<created>2018-10-23 13:18:49</created>
		<closed>2018-10-25 11:51:39</closed>
	</bug>
	<bug>
		<id>122</id>
		<title>Unable to initialize rocksdb graphs in the same data directory</title>
		<body>### Actual behavior 实际表现 Column family not found: xxx You have to open all column families. Column families not opened: xxx  ### Steps to reproduce the problem 复现步骤 1. configure a graph and init the graph by init-store 2. add a new graph to conf and set rocksdb datapath to be the same as before 3. execute init-store again  ### Specifications of environment 环境信息 - hugegraph version: v0.7.4 - operating system: centos6 - hugegraph backend: rocksdb  ![image](https://user-images.githubusercontent.com/9625821/47346196-287afd00-d6df-11e8-8ece-ba5c4622bb76.png) </body>
		<created>2018-10-23 08:25:08</created>
		<closed>2018-11-07 08:03:18</closed>
	</bug>
	<bug>
		<id>112</id>
		<title>Job status has not been updated after running</title>
		<body>### Steps to reproduce the problem 复现步骤 1. Schedule some(&gt;=4) gremlin jobs which may cost a long time 2. Schedule a gremlin job, we assume the task id is `task-5` and status is `queued` 3. The status of `task-5` won't be updated even if task-5 is running, the status is only changed until it's completed.  hugegraph v0.7.4 </body>
		<created>2018-10-15 12:57:29</created>
		<closed>2018-10-16 07:51:16</closed>
	</bug>
	<bug>
		<id>110</id>
		<title>启动HugeGraph提示失败，但线程已经起起来</title>
		<body> ### Expected behavior 期望表现 {type something here...} 启动HugeGraph server的时候，因为配置错误，提示启动失败，预期是程序没有起起来。   ### Actual behavior 实际表现 {type something here...} 实际上线程已经起起来了。但并没有生成pid file。  stop脚本，是根据pid file，但这个时候，pid file还没有，所以stop的时候，说线程没起。 stop失败。 后续使用start脚本也会提示端口已经被占用，启动不起来。  ### Steps to reproduce the problem 复现步骤 1. {step 1} 2. {step 2} 3. {step 3}   ### Status of loaded data 数据状态  #### Vertex/Edge summary 数据量 - loaded vertices amount: {like 10 million} - loaded edges amount: {like 20 million} - loaded time: {like 200s}  #### Vertex/Edge example 数据示例 {type something here...}  #### Schema(VertexLabel, EdgeLabel, IndexLabel) 元数据结构 {type something here...}   ### Specifications of environment 环境信息 - hugegraph version: {like v0.7.4}  0.8.0 - operating system: {like centos 7.4, 32 CPUs, 64G RAM}  centos 7.4 - hugegraph backend: {like cassandra 3.10, cluster with 20 nodes, 3 x 1TB HDD disk each node} Rocksdb </body>
		<created>2018-10-14 16:03:34</created>
		<closed>2018-11-16 04:14:03</closed>
	</bug>
	<bug>
		<id>106</id>
		<title>属性字段定义类型为SET通过json传递导致类型检查失败</title>
		<body>加载的数据文件中一个属性字段定义类型为SET，通过json数据文件得到的是list，所以在验证中提示错误，无法load数据。请问还有什么需要配置的吗？  json数据格式  ｛“address”：[“北京”，“上海”]｝   反馈自Caohh</body>
		<created>2018-10-11 14:18:49</created>
		<closed>2018-10-23 09:20:29</closed>
	</bug>
	<bug>
		<id>99</id>
		<title>以Memory作为后端起服务时，使用Client删除元数据报错 Undefined vertex label: '~task'</title>
		<body>### Expected behavior 期望表现 成功删除元数据  ### Actual behavior 实际表现 报错  ``` Exception in thread "main" class com.baidu.hugegraph.HugeException: Failed to update/query TaskStore at com.baidu.hugegraph.exception.ServerException.fromResponse(ServerException.java:44) at com.baidu.hugegraph.client.RestClient.checkStatus(RestClient.java:63) at com.baidu.hugegraph.rest.RestClient.delete(RestClient.java:198) at com.baidu.hugegraph.api.schema.EdgeLabelAPI.delete(EdgeLabelAPI.java:73) at com.baidu.hugegraph.driver.SchemaManager.removeEdgeLabel(SchemaManager.java:135) at com.baidu.hugegraph.example.SingleExample.lambda$main$4(SingleExample.java:181) at java.util.ArrayList.forEach(ArrayList.java:1249) at com.baidu.hugegraph.example.SingleExample.main(SingleExample.java:180) Caused by: java.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: Undefined vertex label: '~task'  ```  ### Steps to reproduce the problem 复现步骤 1. 以Memory作为后端启动服务 2. 使用HugeClient添加一些数据，比如 SingleExample 的数据 3. 删除元数据，报错  </body>
		<created>2018-10-11 07:20:01</created>
		<closed>2018-10-11 07:45:32</closed>
	</bug>
	<bug>
		<id>94</id>
		<title>hugegraph-loader导入顶点为空</title>
		<body>### schema // Define schema schema.propertyKey("name").asText().ifNotExist().create(); schema.propertyKey("age").asInt().ifNotExist().create(); schema.propertyKey("city").asText().ifNotExist().create();  schema.vertexLabel("person").properties("name", "age", "city").useCustomizeNumberId().ifNotExist().create();  schema.indexLabel("personByName").onV("person").by("name").secondary().ifNotExist().create(); schema.indexLabel("personByAge").onV("person").by("age").range().ifNotExist().create(); schema.indexLabel("personByCity").onV("person").by("city").secondary().ifNotExist().create(); schema.indexLabel("personByAgeAndCity").onV("person").by("age", "city").secondary().ifNotExist().create();   ### struct {   "vertices": [     {       "label": "person",       "input": {         "type": "file",         "path": "example2/vertex_person.csv",         "format": "CSV",         "header": ["id","name", "age", "city"],         "charset": "UTF-8"       },       "id":"id"     }   ] }   ### data 1,marko,29,Beijing 2,vadas,27,Hongkong 3,josh,32,Beijing 4,peter,35,Shanghai 5,"li,nary",26,"Wu,han"                     ### Specifications of environment 环境信息 - hugegraph version: v0.7.4 - operating system: centos 7.4, 32 CPUs, 256G RAM - hugegraph backend: hbase </body>
		<created>2018-10-10 08:56:59</created>
		<closed>2018-10-11 09:13:40</closed>
	</bug>
	<bug>
		<id>88</id>
		<title>Can't operate a tx in other threads</title>
		<body>The error occurred when updating property</body>
		<created>2018-10-10 02:46:50</created>
		<closed>2018-11-27 08:58:32</closed>
	</bug>
	<bug>
		<id>78</id>
		<title>loader工具传输数据问题</title>
		<body>### Expected behavior 期望表现 正确传输 119544个结点 8000000条边  ### Actual behavior 实际表现 插入成功结点：114044 插入成功边：8005500 结点失败和边失败数均为0  ### Steps to reproduce the problem 复现步骤 1. {step 1} 2. {step 2} 3. {step 3}   ### Status of loaded data 数据状态  #### Vertex/Edge summary 数据量 - loaded vertices amount: 119544 - loaded edges amount: 8000000 - loaded time: {like 101s}  #### Vertex/Edge example 数据示例 {type something here...}  #### Schema(VertexLabel, EdgeLabel, IndexLabel) 元数据结构 {type something here...}   ### Specifications of environment 环境信息 - hugegraph version: { v0.7.4} - operating system: {like ubuntu 18.04, 64 CPUs, 64G RAM} - hugegraph backend: {rocksdb} </body>
		<created>2018-10-06 03:19:36</created>
		<closed>2018-10-11 08:43:04</closed>
	</bug>
	<bug>
		<id>76</id>
		<title>内存模式启动失败没有产生日志</title>
		<body>### Expected behavior 期望表现 backend是内存模式时启动失败打印日志   ### Actual behavior 实际表现 backend是内存模式时启动失败没有打印日志   ### Steps to reproduce the problem 复现步骤 1. 下载0.7.4压缩包 2. 解压 3.修改hugegraph.properties为 ``` backend=memory serializer=text ``` 4.执行 bin/start-hugegraph.sh 5. 显示 ``` Starting HugeGraphServer... Connecting to HugeGraphServer (http://127.0.0.1:8080/graphs)................The operation timed out when attempting to connect to http://127.0.0.1:8080/graphs See /root/hugegraph-0.7.4/logs/hugegraph-server.log for HugeGraphServer log output. ``` 但是并没有日志文件产生  ### Specifications of environment 环境信息 - hugegraph version:0.7.4 - operating system: centos 7.4, MacOS Sierra都能重现 - hugegraph backend: memory - java version: 1.8.0_161 </body>
		<created>2018-09-30 00:35:45</created>
		<closed>2018-10-10 02:44:27</closed>
	</bug>
	<bug>
		<id>50</id>
		<title>hasLabel(label...)，多个label时失败</title>
		<body>### Expected behavior 期望表现 正确查询，满足一个label即可返回   ### Actual behavior 实际表现 ` java.lang.ClassCastException: java.lang.String cannot be cast to com.baidu.hugegraph.backend.id.Id         at com.baidu.hugegraph.backend.tx.GraphTransaction.optimizeQuery(GraphTransaction.java:892) ~[hugegraph-core-0.7.4.jar:0.7.4.0]         at com.baidu.hugegraph.backend.tx.GraphTransaction.query(GraphTransaction.java:292) ~[hugegraph-core-0.7.4.jar:0.7.4.0]         at com.baidu.hugegraph.backend.tx.GraphTransaction.queryVerticesFromBackend(GraphTransaction.java:452) ~[hugegraph-core-0.7.4.jar:0.7.4.0]         at com.baidu.hugegraph.backend.tx.GraphTransaction.queryVertices(GraphTransaction.java:443) ~[hugegraph-core-0.7.4.jar:0.7.4.0]         at com.baidu.hugegraph.backend.cache.CachedGraphTransaction.queryVertices(CachedGraphTransaction.java:93) ~[hugegraph-core-0.7.4.jar:0.7.4.0]         at com.baidu.hugegraph.HugeGraph.vertices(HugeGraph.java:337) ~[hugegraph-core-0.7.4.jar:0.7.4.0]         at com.baidu.hugegraph.traversal.optimize.HugeGraphStep.vertices(HugeGraphStep.java:94) ~[hugegraph-core-0.7.4.jar:0.7.4.0]         at com.baidu.hugegraph.traversal.optimize.HugeGraphStep.lambda$new$0(HugeGraphStep.java:66) ~[hugegraph-core-0.7.4.jar:0.7.4.0]         at org.apache.tinkerpop.gremlin.process.traversal.step.map.GraphStep.processNextStart(GraphStep.java:139) ~[gremlin-core-3.2.5.jar:3.2.5]         at org.apache.tinkerpop.gremlin.process.traversal.step.util.AbstractStep.hasNext(AbstractStep.java:143) ~[gremlin-core-3.2.5.jar:3.2.5]         at org.apache.tinkerpop.gremlin.process.traversal.step.util.ExpandableStepIterator.next(ExpandableStepIterator.java:50) ~[gremlin-core-3.2.5.jar:3.2.5]         at org.apache.tinkerpop.gremlin.process.traversal.step.filter.FilterStep.processNextStart(FilterStep.java:37) ~[gremlin-core-3.2.5.jar:3.2.5]         at org.apache.tinkerpop.gremlin.process.traversal.step.util.AbstractStep.hasNext(AbstractStep.java:143) ~[gremlin-core-3.2.5.jar:3.2.5]         at org.apache.tinkerpop.gremlin.process.traversal.util.DefaultTraversal.hasNext(DefaultTraversal.java:192) ~[gremlin-core-3.2.5.jar:3.2.5]         at org.apache.tinkerpop.gremlin.util.iterator.IteratorUtils.fill(IteratorUtils.java:62) ~[gremlin-core-3.2.5.jar:3.2.5]         at org.apache.tinkerpop.gremlin.util.iterator.IteratorUtils.list(IteratorUtils.java:85) ~[gremlin-core-3.2.5.jar:3.2.5]         at org.apache.tinkerpop.gremlin.util.iterator.IteratorUtils.asList(IteratorUtils.java:382) ~[gremlin-core-3.2.5.jar:3.2.5]         at org.apache.tinkerpop.gremlin.server.handler.HttpGremlinEndpointHandler.lambda$channelRead$1(HttpGremlinEndpointHandler.java:239) ~[gremlin-server-3.2.5.jar:3.2.5]         at org.apache.tinkerpop.gremlin.util.function.FunctionUtils.lambda$wrapFunction$0(FunctionUtils.java:36) ~[gremlin-core-3.2.5.jar:3.2.5]         at org.apache.tinkerpop.gremlin.groovy.engine.GremlinExecutor.lambda$eval$2(GremlinExecutor.java:320) ~[gremlin-groovy-3.2.5.jar:3.2.5]         at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_181]         at com.baidu.hugegraph.auth.HugeGraphAuthProxy$ContextTask.run(HugeGraphAuthProxy.java:290) [hugegraph-api-0.7.4.jar:0.27.0.0]         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_181]         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_181]         at java.lang.Thread.run(Thread.java:748) [?:1.8.0_181] `   ### Steps to reproduce the problem 复现步骤  `g.V().hasLabel('person', 'software')`   ### Status of loaded data 数据状态  #### Vertex/Edge summary 数据量  #### Vertex/Edge example 数据示例  #### Schema(VertexLabel, EdgeLabel, IndexLabel) 元数据结构  ### Specifications of environment 环境信息 - hugegraph version: v0.7.4  </body>
		<created>2018-09-10 09:09:29</created>
		<closed>2018-09-20 03:46:55</closed>
	</bug>
	<bug>
		<id>48</id>
		<title>HugeGraph（0.7.4），后端存储用scyllaDB（1.7版本），初始化的失败（“Indexes are not supported yet”）</title>
		<body>### Expected behavior 期望表现 {type something here...}   ### Actual behavior 实际表现 {type something here...}   ### Steps to reproduce the problem 复现步骤 1. {step 1} 2. {step 2} 3. {step 3}   ### Status of loaded data 数据状态  #### Vertex/Edge summary 数据量 - loaded vertices amount: {like 10 million} - loaded edges amount: {like 20 million} - loaded time: {like 200s}  #### Vertex/Edge example 数据示例 {type something here...}  #### Schema(VertexLabel, EdgeLabel, IndexLabel) 元数据结构 {type something here...}   ### Specifications of environment 环境信息 - hugegraph version: {like v0.7.4} - operating system: {like centos 7.4, 32 CPUs, 64G RAM} - hugegraph backend: {like cassandra 3.10, cluster with 20 nodes, 3 x 1TB HDD disk each node} </body>
		<created>2018-09-06 06:46:41</created>
		<closed>2018-09-07 03:41:35</closed>
	</bug>
	<bug>
		<id>36</id>
		<title>添加索引报错 com.baidu.hugegraph.exception.LimitExceedException: Too many records(must &lt;=800000) for the query</title>
		<body>场景：先导入数据，131w左右；发现有些列需要查询，然后创建索引。 版本：hugegraph-0.7.4 + rocksDB 异常栈： 2018-08-27 11:37:29 3702792 [pool-5-thread-1] [WARN ] com.baidu.hugegraph.task.HugeTask [] - An exception occurred when running task: 1 com.baidu.hugegraph.exception.LimitExceedException: Too many records(must &lt;=800000) for the query: Query for VERTEX offset=0, limit=9223372036854775807, order by {} where id in [2:"Doe"!"Anna"!""!"Other"!1/1/1963, 2:"Lam"!"Thi"!""!"Green"!1/11/1956, 2:"Bond"!"Tina"!""!"Green"!3/3/1969, 2:"Guy"!"Alex"!""!"Green"!2/27/1985, 2:"Bean"!"Eric"!"A"!"Green"!7/1... at com.baidu.hugegraph.backend.query.Query.checkCapacity(Query.java:203) ~[hugegraph-core-0.7.4.jar:0.7.4.0] at com.baidu.hugegraph.backend.query.IdQuery.query(IdQuery.java:76) ~[hugegraph-core-0.7.4.jar:0.7.4.0] at com.baidu.hugegraph.backend.query.IdQuery.query(IdQuery.java:82) ~[hugegraph-core-0.7.4.jar:0.7.4.0] at com.baidu.hugegraph.backend.query.IdQuery.&lt;init&gt;(IdQuery.java:61) ~[hugegraph-core-0.7.4.jar:0.7.4.0] at com.baidu.hugegraph.backend.tx.GraphIndexTransaction.query(GraphIndexTransaction.java:360) ~[hugegraph-core-0.7.4.jar:0.7.4.0] at com.baidu.hugegraph.backend.tx.GraphTransaction.optimizeQuery(GraphTransaction.java:961) ~[hugegraph-core-0.7.4.jar:0.7.4.0] at com.baidu.hugegraph.backend.tx.GraphTransaction.query(GraphTransaction.java:292) ~[hugegraph-core-0.7.4.jar:0.7.4.0] at com.baidu.hugegraph.backend.tx.GraphTransaction.queryVerticesFromBackend(GraphTransaction.java:452) ~[hugegraph-core-0.7.4.jar:0.7.4.0] at com.baidu.hugegraph.backend.tx.GraphTransaction.queryVertices(GraphTransaction.java:443) ~[hugegraph-core-0.7.4.jar:0.7.4.0] at com.baidu.hugegraph.backend.cache.CachedGraphTransaction.queryVertices(CachedGraphTransaction.java:93) ~[hugegraph-core-0.7.4.jar:0.7.4.0] at com.baidu.hugegraph.backend.tx.GraphIndexTransaction.rebuildIndex(GraphIndexTransaction.java:1109) ~[hugegraph-core-0.7.4.jar:0.7.4.0] at com.baidu.hugegraph.backend.tx.GraphIndexTransaction.rebuildIndex(GraphIndexTransaction.java:1047) ~[hugegraph-core-0.7.4.jar:0.7.4.0] at com.baidu.hugegraph.backend.tx.GraphTransaction.rebuildIndex(GraphTransaction.java:1237) ~[hugegraph-core-0.7.4.jar:0.7.4.0] at com.baidu.hugegraph.job.schema.RebuildIndexCallable.runTask(RebuildIndexCallable.java:36) ~[hugegraph-core-0.7.4.jar:0.7.4.0] at com.baidu.hugegraph.job.schema.SchemaCallable.call(SchemaCallable.java:18) ~[hugegraph-core-0.7.4.jar:0.7.4.0] at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_181] at com.baidu.hugegraph.task.HugeTask.run(HugeTask.java:198) [hugegraph-core-0.7.4.jar:0.7.4.0] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_181] at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_181] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_181] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_181] at java.lang.Thread.run(Thread.java:748) [?:1.8.0_181] </body>
		<created>2018-08-27 11:14:18</created>
		<closed>2018-10-11 03:04:17</closed>
	</bug>
	<bug>
		<id>35</id>
		<title>初次启动服务会提示“../plugins: No such file or directory”。</title>
		<body>暂时手动建立plugins目录，再次启动则可正常启动。</body>
		<created>2018-08-27 07:25:36</created>
		<closed>2018-09-06 03:08:37</closed>
	</bug>
	<bug>
		<id>34</id>
		<title>启动服务有时候会提示“The operation time out when attempting to connect to http://xxx:port/graphs”</title>
		<body>使用rocksdb存储，启动服务，服务已经启动成功，但是提示“The operation time out when attempting to connect to http://xxx:port/graphs”  </body>
		<created>2018-08-27 07:23:03</created>
		<closed>2018-09-06 03:08:37</closed>
	</bug>
	<bug>
		<id>32</id>
		<title>Lock error thrown when modifying schema and data dynamically</title>
		<body>The schema created at the beginning can't satisfy our requirement, so we have to modify the schema to load data into the database. When we modify the schema and invoke setProperty method, the following exception thrown: ``` com.baidu.hugegraph.exception.ServerException: Lock [il_delete:35] is locked by other operation at com.baidu.hugegraph.exception.ServerException.fromResponse(ServerException.java:44) ~[hugegraph-client-1.5.8.jar:1.5.8.0] at com.baidu.hugegraph.client.RestClient.checkStatus(RestClient.java:63) ~[hugegraph-client-1.5.8.jar:1.5.8.0] at com.baidu.hugegraph.rest.RestClient.put(RestClient.java:142) ~[hugegraph-common-1.4.9.jar:1.4.9.0] at com.baidu.hugegraph.api.graph.VertexAPI.append(VertexAPI.java:70) ~[hugegraph-client-1.5.8.jar:1.5.8.0] at com.baidu.hugegraph.driver.GraphManager.appendVertexProperty(GraphManager.java:143) ~[hugegraph-client-1.5.8.jar:1.5.8.0] at com.baidu.hugegraph.structure.graph.Vertex.setProperty(Vertex.java:73) ~[hugegraph-client-1.5.8.jar:1.5.8.0] at com.baidu.hugegraph.structure.graph.Vertex.property(Vertex.java:63) ~[hugegraph-client-1.5.8.jar:1.5.8.0] at com.baidu.hugegraph.structure.graph.Vertex.property(Vertex.java:30) ~[hugegraph-client-1.5.8.jar:1.5.8.0] at com.baidu.hugedragon.repository.graphdb.hugegraph.HugeGraphElement.setProperty(HugeGraphElement.java:118) ~[classes/:?] ... 19 more ``` ### Steps to reproduce  - Create a vertex label - Add a property key  - Add a property with property key created in last step in the vertex label - Set value for the new created property  ### Environments - hugegraph-client 1.5.8 - hugegraph-core 0.7.4</body>
		<created>2018-08-24 10:47:44</created>
		<closed>2018-11-16 11:30:37</closed>
	</bug>
	<bug>
		<id>22</id>
		<title>init-store failed due to datapath and walpath error for rocksdb backend</title>
		<body>Initing HugeGraph Store... 2018-08-22 16:54:58 718   [main] [INFO ] com.baidu.hugegraph.cmd.InitStore [] - Init graph with config file: conf/hugegraph.properties 2018-08-22 16:54:58 819   [main] [INFO ] com.baidu.hugegraph.HugeGraph [] - Opening backend store 'rocksdb' for graph 'hugegraph' 2018-08-22 16:54:58 865   [main] [INFO ] com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore [] - Opening RocksDB with data path: ./rocksdb-data/schema 2018-08-22 16:54:59 1043  [main] [INFO ] com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore [] - Failed to open RocksDB './rocksdb-data/schema' with database 'hugegraph', try to init CF later 2018-08-22 16:54:59 1160  [main] [INFO ] com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore [] - Opening RocksDB with data path: ./rocksdb-data/system 2018-08-22 16:54:59 1217  [main] [INFO ] com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore [] - Failed to open RocksDB './rocksdb-data/system' with database 'hugegraph', try to init CF later 2018-08-22 16:54:59 1276  [main] [INFO ] com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore [] - Opening RocksDB with data path: ./rocksdb-data/graph 2018-08-22 16:54:59 1325  [main] [INFO ] com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore [] - Failed to open RocksDB './rocksdb-data/graph' with database 'hugegraph', try to init CF later 2018-08-22 16:54:59 1409  [main] [INFO ] com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore [] - Opening RocksDB with data path: ./edge_in/graph 2018-08-22 16:54:59 1411  [main] [ERROR] com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore [] - Failed to open RocksDB './edge_in/graph'         at com.baidu.hugegraph.backend.store.rocksdb.RocksDBStdSessions.&lt;init&gt;(RocksDBStdSessions.java:113) ~[hugegraph-rocksdb-0.7.4.jar:?]         at com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore.openSessionPool(RocksDBStore.java:206) ~[hugegraph-rocksdb-0.7.4.jar:?]         at com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore.open(RocksDBStore.java:154) [hugegraph-rocksdb-0.7.4.jar:?]         at com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore.open(RocksDBStore.java:143) [hugegraph-rocksdb-0.7.4.jar:?]         at com.baidu.hugegraph.HugeGraph.initBackend(HugeGraph.java:187) [hugegraph-core-0.7.4.jar:0.7.4.0]         at com.baidu.hugegraph.cmd.InitStore.initBackend(InitStore.java:115) [hugegraph-dist-0.7.4.jar:?]         at com.baidu.hugegraph.cmd.InitStore.initGraph(InitStore.java:103) [hugegraph-dist-0.7.4.jar:?]         at com.baidu.hugegraph.cmd.InitStore.main(InitStore.java:86) [hugegraph-dist-0.7.4.jar:?] Exception in thread "main" com.baidu.hugegraph.backend.BackendException: Failed to open RocksDB './edge_in/graph'         at com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore.open(RocksDBStore.java:186)         at com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore.open(RocksDBStore.java:143)         at com.baidu.hugegraph.HugeGraph.initBackend(HugeGraph.java:187)         at com.baidu.hugegraph.cmd.InitStore.initBackend(InitStore.java:115)         at com.baidu.hugegraph.cmd.InitStore.initGraph(InitStore.java:103)         at com.baidu.hugegraph.cmd.InitStore.main(InitStore.java:86) Caused by: org.rocksdb.RocksDBException: While lock file: ./rocksdb-data/graph/LOCK: No locks available         at org.rocksdb.RocksDB.open(Native Method)         at org.rocksdb.RocksDB.open(RocksDB.java:286)         at com.baidu.hugegraph.backend.store.rocksdb.RocksDBStdSessions.&lt;init&gt;(RocksDBStdSessions.java:113)         at com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore.openSessionPool(RocksDBStore.java:206)         at com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore.open(RocksDBStore.java:154)         ... 5 more</body>
		<created>2018-08-22 11:35:15</created>
		<closed>2018-08-29 06:36:16</closed>
	</bug>
	<bug>
		<id>15</id>
		<title>Check the predicate of HasContainer can't be null</title>
		<body>![image](https://user-images.githubusercontent.com/9625821/44298673-b9b5a800-a319-11e8-8e3b-5dd7e9382f11.png) </body>
		<created>2018-08-18 04:58:39</created>
		<closed>2018-08-22 09:01:54</closed>
	</bug>
	<bug>
		<id>10</id>
		<title>The travis deployment is run multiple times due to matrix</title>
		<body></body>
		<created>2018-08-17 12:03:51</created>
		<closed>2018-11-20 09:52:27</closed>
	</bug>
	<bug>
		<id>8</id>
		<title>tinkerpop tests fail to find blacklist resource file</title>
		<body>1. can't find blacklist resource file, resulting in NPE 2. TestGraph config xxxTest rather than xxxSuite, resulting in ERROR info 3. Vertex and Edge capacity were set 1000, resulting in tests failed</body>
		<created>2018-08-17 11:06:28</created>
		<closed>2018-08-17 12:32:00</closed>
	</bug>
	<bug>
		<id>7</id>
		<title>init的时候报错：init是报Could not find or load main class .root.hugegraph-0.7.4.lib.hugegraph-dist-0.7.4-javadoc.jar</title>
		<body>sh bin/init-store.sh Initing HugeGraph Store... Error: Could not find or load main class .root.hugegraph-0.7.4.lib.hugegraph-dist-0.7.4-javadoc.jar    可以通过修改 bin/init-store.sh倒数第二行 exec $JAVA -cp $LIB   --&gt;  exec $JAVA -cp $CLASSPATH:$LIB   来解决</body>
		<created>2018-08-17 07:54:05</created>
		<closed>2018-09-06 03:09:36</closed>
	</bug>
	<bug>
		<id>3</id>
		<title>在docker中启动hugegraph-server失败</title>
		<body>###尝试了用memory方式启动 log如下 ``` 2018-08-08 02:24:53 1272  [main] [INFO ] com.baidu.hugegraph.dist.HugeGremlinServer [] -           \,,,/          (o o) -----oOOo-(3)-oOOo-----  2018-08-08 02:24:53 1494  [main] [INFO ] com.baidu.hugegraph.dist.HugeGremlinServer [] - Configuring Gremlin Server from conf/gremlin-server.yaml 2018-08-08 02:24:54 1987  [main] [INFO ] com.baidu.hugegraph.HugeGraph [] - Opening backend store 'memory' for graph 'hugegraph' 2018-08-08 02:24:54 2015  [main] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Graph [hugegraph] was successfully configured via [conf/hugegraph.properties]. 2018-08-08 02:24:54 2015  [main] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Graph [hugegraph] was successfully configured via [conf/hugegraph.properties]. 2018-08-08 02:24:54 2016  [main] [INFO ] org.apache.tinkerpop.gremlin.server.util.ServerGremlinExecutor [] - Initialized Gremlin thread pool.  Threads in pool named with pattern gremlin-* 2018-08-08 02:24:54 2016  [main] [INFO ] org.apache.tinkerpop.gremlin.server.util.ServerGremlinExecutor [] - Initialized Gremlin thread pool.  Threads in pool named with pattern gremlin-* 2018-08-08 02:24:56 3612  [main] [INFO ] org.apache.tinkerpop.gremlin.groovy.engine.ScriptEngines [] - Loaded gremlin-groovy ScriptEngine 2018-08-08 02:24:56 3612  [main] [INFO ] org.apache.tinkerpop.gremlin.groovy.engine.ScriptEngines [] - Loaded gremlin-groovy ScriptEngine 2018-08-08 02:24:57 4945  [main] [INFO ] org.apache.tinkerpop.gremlin.groovy.engine.GremlinExecutor [] - Initialized gremlin-groovy ScriptEngine with scripts/empty-sample.groovy 2018-08-08 02:24:57 4945  [main] [INFO ] org.apache.tinkerpop.gremlin.groovy.engine.GremlinExecutor [] - Initialized gremlin-groovy ScriptEngine with scripts/empty-sample.groovy 2018-08-08 02:24:57 4946  [main] [INFO ] org.apache.tinkerpop.gremlin.server.util.ServerGremlinExecutor [] - Initialized GremlinExecutor and preparing GremlinScriptEngines instances. 2018-08-08 02:24:57 4946  [main] [INFO ] org.apache.tinkerpop.gremlin.server.util.ServerGremlinExecutor [] - Initialized GremlinExecutor and preparing GremlinScriptEngines instances. 2018-08-08 02:24:57 5038  [main] [INFO ] org.apache.tinkerpop.gremlin.server.util.ServerGremlinExecutor [] - Initialized gremlin-groovy GremlinScriptEngine and registered metrics 2018-08-08 02:24:57 5038  [main] [INFO ] org.apache.tinkerpop.gremlin.server.util.ServerGremlinExecutor [] - Initialized gremlin-groovy GremlinScriptEngine and registered metrics 2018-08-08 02:24:57 5052  [main] [INFO ] org.apache.tinkerpop.gremlin.server.util.MetricManager [] - Configured Metrics CsvReporter configured with report interval=180000ms to fileName=/tmp/gremlin-server-metrics.csv 2018-08-08 02:24:57 5052  [main] [INFO ] org.apache.tinkerpop.gremlin.server.util.MetricManager [] - Configured Metrics CsvReporter configured with report interval=180000ms to fileName=/tmp/gremlin-server-metrics.csv 2018-08-08 02:24:57 5149  [main] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Executing start up LifeCycleHook 2018-08-08 02:24:57 5149  [main] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Executing start up LifeCycleHook 2018-08-08 02:24:57 5196  [main] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Executed once at startup of Gremlin Server. 2018-08-08 02:24:57 5196  [main] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Executed once at startup of Gremlin Server. 2018-08-08 02:24:57 5390  [main] [INFO ] org.apache.tinkerpop.gremlin.server.AbstractChannelizer [] - Configured application/vnd.gremlin-v1.0+gryo-lite with org.apache.tinkerpop.gremlin.driver.ser.GryoLiteMessageSerializerV1d0 2018-08-08 02:24:57 5390  [main] [INFO ] org.apache.tinkerpop.gremlin.server.AbstractChannelizer [] - Configured application/vnd.gremlin-v1.0+gryo-lite with org.apache.tinkerpop.gremlin.driver.ser.GryoLiteMessageSerializerV1d0 2018-08-08 02:24:57 5391  [main] [INFO ] org.apache.tinkerpop.gremlin.server.AbstractChannelizer [] - Configured application/vnd.gremlin-v1.0+gryo-stringd with org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV1d0 2018-08-08 02:24:57 5391  [main] [INFO ] org.apache.tinkerpop.gremlin.server.AbstractChannelizer [] - Configured application/vnd.gremlin-v1.0+gryo-stringd with org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV1d0 2018-08-08 02:24:58 5828  [main] [INFO ] org.apache.tinkerpop.gremlin.server.AbstractChannelizer [] - Configured application/vnd.gremlin-v1.0+json with org.apache.tinkerpop.gremlin.driver.ser.GraphSONMessageSerializerGremlinV1d0 2018-08-08 02:24:58 5828  [main] [INFO ] org.apache.tinkerpop.gremlin.server.AbstractChannelizer [] - Configured application/vnd.gremlin-v1.0+json with org.apache.tinkerpop.gremlin.driver.ser.GraphSONMessageSerializerGremlinV1d0 2018-08-08 02:24:58 5969  [main] [INFO ] org.apache.tinkerpop.gremlin.server.AbstractChannelizer [] - Configured application/vnd.gremlin-v2.0+json with org.apache.tinkerpop.gremlin.driver.ser.GraphSONMessageSerializerGremlinV2d0 2018-08-08 02:24:58 5969  [main] [INFO ] org.apache.tinkerpop.gremlin.server.AbstractChannelizer [] - Configured application/vnd.gremlin-v2.0+json with org.apache.tinkerpop.gremlin.driver.ser.GraphSONMessageSerializerGremlinV2d0 2018-08-08 02:24:58 5976  [main] [INFO ] org.apache.tinkerpop.gremlin.server.AbstractChannelizer [] - Configured application/json with org.apache.tinkerpop.gremlin.driver.ser.GraphSONMessageSerializerV1d0 2018-08-08 02:24:58 5976  [main] [INFO ] org.apache.tinkerpop.gremlin.server.AbstractChannelizer [] - Configured application/json with org.apache.tinkerpop.gremlin.driver.ser.GraphSONMessageSerializerV1d0 2018-08-08 02:24:58 6139  [gremlin-server-boss-1] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Gremlin Server configured with worker thread pool of 1, gremlin pool of 1 and boss thread pool of 1. 2018-08-08 02:24:58 6139  [gremlin-server-boss-1] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Gremlin Server configured with worker thread pool of 1, gremlin pool of 1 and boss thread pool of 1. 2018-08-08 02:24:58 6140  [gremlin-server-boss-1] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Channel started at port 8182. 2018-08-08 02:24:58 6140  [gremlin-server-boss-1] [INFO ] org.apache.tinkerpop.gremlin.server.GremlinServer [] - Channel started at port 8182. 2018-08-08 02:24:58 6158  [main] [INFO ] com.baidu.hugegraph.server.RestServer [] - RestServer starting... Aug 08, 2018 2:25:01 AM org.glassfish.grizzly.http.server.NetworkListener start INFO: Started listener bound to [172.17.0.2:8080] 2018-08-08 02:25:01 9102  [main] [INFO ] com.baidu.hugegraph.server.RestServer [] - Graph 'hugegraph' was successfully configured via 'conf/hugegraph.properties' 2018-08-08 02:25:02 9674  [main] [ERROR] com.baidu.hugegraph.server.RestServer [] - The backend store of 'hugegraph' has not been initialized ``` 貌似只是说后端存储初始化失败，memory方式不是不用初始化吗？？  ###尝试用RocksDB方式启动 log如下 ``` Initing HugeGraph Store... 2018-08-08 02:41:11 1166  [main] [INFO ] com.baidu.hugegraph.cmd.InitStore [] - Init graph with config file: conf/hugegraph.properties 2018-08-08 02:41:11 1333  [main] [INFO ] com.baidu.hugegraph.HugeGraph [] - Opening backend store 'rocksdb' for graph 'hugegraph' 2018-08-08 02:41:11 1410  [main] [INFO ] com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore [] - Opening RocksDB with data path: /tmp/schema 2018-08-08 02:41:12 1715  [main] [INFO ] com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore [] - Failed to open RocksDB '/tmp/schema' with database 'hugegraph', try to init CF later 2018-08-08 02:41:12 1788  [main] [INFO ] com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore [] - Opening RocksDB with data path: /tmp/system 2018-08-08 02:41:12 1876  [main] [INFO ] com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore [] - Failed to open RocksDB '/tmp/system' with database 'hugegraph', try to init CF later 2018-08-08 02:41:12 1888  [main] [INFO ] com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore [] - Opening RocksDB with data path: /tmp/graph 2018-08-08 02:41:12 1902  [main] [INFO ] com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore [] - Failed to open RocksDB '/tmp/graph' with database 'hugegraph', try to init CF later 2018-08-08 02:41:12 1966  [main] [INFO ] com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore [] - Store initialized: schema 2018-08-08 02:41:12 2000  [main] [INFO ] com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore [] - Store initialized: system 2018-08-08 02:41:12 2036  [main] [INFO ] com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore [] - Store initialized: graph 2018-08-08 02:41:12 2293  [pool-3-thread-1] [INFO ] com.baidu.hugegraph.backend.Transaction [] - Clear cache on event 'store.init' ``` rocksdb要写的目录我放在tmp目录，应该不会没有权限  然后，我同样的方式在虚拟机中是可以启动的2333333 </body>
		<created>2018-08-08 02:44:21</created>
		<closed>2018-08-23 12:46:42</closed>
	</bug>
</bugs>
