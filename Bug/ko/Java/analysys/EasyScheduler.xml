<?xml version="1.0" encoding="ISO-8859-1"?>

<bugs>
	<bug>
		<id>3751</id>
		<title>[Bug][dolphinscheduler-server] Time custom parameters conver error</title>
		<body>`current time : 2020-09-15 15:15:13` `custom parameter : echo $[yyyy-MM-dd HH:mm:ss-1/24]` `But the result is : 2020-09-15 15:15:13-54913523000000/24` `The desired result is : 2020-09-15 14:15:13`</body>
		<created>2020-09-15 11:46:35</created>
		<closed>2020-09-16 02:03:54</closed>
	</bug>
	<bug>
		<id>3745</id>
		<title>[Bug][server] server get tasktype NPE exception</title>
		<body>**Describe the bug**  ``` switch (EnumUtils.getEnum(TaskType.class,taskExecutionContext.getTaskType())) ``` When the task type does not exist in the enumeration class TaskType, EnumUtils.getEnum() returns null, and switch will report a null pointer exception  **Expected behavior** Null processing of parameter values in switch  **Which version of Dolphin Scheduler:**  -[dev]  ---  **描述错误** ``` switch (EnumUtils.getEnum(TaskType.class,taskExecutionContext.getTaskType())) ``` 当任务类型在枚举类中TaskType不存在时，EnumUtils.getEnum()返回null,switch 会报空指针异常  **预期行为** switch 内参数值判空处理  **哪个版本的Dolphin Scheduler：**   -[dev]  </body>
		<created>2020-09-15 04:35:58</created>
		<closed>2020-09-17 08:29:03</closed>
	</bug>
	<bug>
		<id>3739</id>
		<title>[Bug][service] sql result set is converted to json, there is data loss</title>
		<body>**Describe the bug** sql result set is converted to json, there is data loss  **To Reproduce**  1. sqlscript:  `select DBS.NAME  as 'DB_NAME', PARTITIONS.PART_ID, TBLS.TBL_NAME, PARTITIONS.PART_NAME, SDS.LOCATION, PARTITION_FILENUM.PARAM_VALUE AS FILE_NUM, PARTITION_TOTAL_Size.PARAM_VALUE AS FILE_SIZE,  CEILING(PARTITION_TOTAL_Size.PARAM_VALUE/(128*1024*1024)) AS CLAC_FILE_NUM from  DBS,SDS,TBLS,PARTITIONS, (select * from PARTITION_PARAMS where PARAM_KEY='numFiles') as PARTITION_FILENUM, (select * from PARTITION_PARAMS where PARAM_KEY='totalSize') as PARTITION_TOTAL_Size where DBS.DB_ID = TBLS.DB_ID and PARTITIONS.SD_ID = SDS.SD_ID and TBLS.TBL_ID=PARTITIONS.TBL_ID and PARTITIONS.PART_ID =PARTITION_FILENUM.PART_ID and PARTITIONS.PART_ID =PARTITION_TOTAL_Size.PART_ID AND PARTITION_FILENUM.PARAM_VALUE&gt;CEILING(PARTITION_TOTAL_Size.PARAM_VALUE/(128*1024*1024))  limit 1 ` result:  ![image](https://user-images.githubusercontent.com/10862577/93058748-5e924300-f6a2-11ea-9eb5-9da43fdecf9b.png)   2. Code location ： class[SqlTask]-Method [resultProcess] ![image](https://user-images.githubusercontent.com/10862577/93058544-1f63f200-f6a2-11ea-9a3d-23230ffc02ec.png)  Generated json result： [{ "NAME": "ods", "PART_ID": 28980, "TBL_NAME": "xxxxx", "PART_NAME": "partition_col=201511", "LOCATION": "hdfs://cdh1:8020/user/hive/warehouse/ods.db/xxxxx/partition_col=201511", "PARAM_VALUE": "6320486", "CLAC_FILE_NUM": 1.0 }]  **Expected behavior** The comparison result found: 1. First of all, the data field alias fails to have any effect 2. Take the original name of the database, there are missing fields in FILE_NUM and FILE_SIZE  **Which version of Dolphin Scheduler:**  -[1.3.1-preview]  **Requirement or improvement**  1.Modify the code to take the database field alias instead of the original name。  I think it should be changed to this： ![image](https://user-images.githubusercontent.com/10862577/93058671-428ea180-f6a2-11ea-81cb-d36e33c332b9.png)  2.Add new features to save the execution results of the previous task node, which can be passed as a parameter to the next task node. This scenario is very common </body>
		<created>2020-09-14 07:59:41</created>
		<closed>2020-09-17 03:42:51</closed>
	</bug>
	<bug>
		<id>3722</id>
		<title>[Bug][dolphinscheduler-ui] cannot modify password on dev branch </title>
		<body>**Describe the bug** I deployed a dev branch development environment. After I changed the password in the environment and submitted it, the page reported an updated user error message.  **Expected behavior** java.lang.IllegalStateException: Optional int parameter 'state' is present but cannot be translated into a null value due to being declared as a primitive type. Consider declaring it as object wrapper for the corresponding primitive type. at org.springframework.web.method.annotation.AbstractNamedValueMethodArgumentResolver.handleNullValue(AbstractNamedValueMethodArgumentResolver.java:245) ~[spring-web-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.web.method.annotation.AbstractNamedValueMethodArgumentResolver.resolveArgument(AbstractNamedValueMethodArgumentResolver.java:115) ~[spring-web-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.web.method.support.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:126) ~[spring-web-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.web.method.support.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:166) ~[spring-web-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:134) ~[spring-web-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102) ~[spring-webmvc-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895) ~[spring-webmvc-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:800) ~[spring-webmvc-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1038) ~[spring-webmvc-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942) ~[spring-webmvc-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1005) [spring-webmvc-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:908) [spring-webmvc-5.1.5.RELEASE.jar:5.1.5.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:707) [javax.servlet-api-3.1.0.jar:3.1.0] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:882) [spring-webmvc-5.1.5.RELEASE.jar:5.1.5.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) [javax.servlet-api-3.1.0.jar:3.1.0] at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:867) [jetty-servlet-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1623) [jetty-servlet-9.4.14.v20181114.jar:9.4.14.v20181114] at com.github.xiaoymin.swaggerbootstrapui.filter.SecurityBasicAuthFilter.doFilter(SecurityBasicAuthFilter.java:84) [swagger-bootstrap-ui-1.9.3.jar:na] at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1610) [jetty-servlet-9.4.14.v20181114.jar:9.4.14.v20181114] at com.github.xiaoymin.swaggerbootstrapui.filter.ProductionSecurityFilter.doFilter(ProductionSecurityFilter.java:53) [swagger-bootstrap-ui-1.9.3.jar:na] at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1610) [jetty-servlet-9.4.14.v20181114.jar:9.4.14.v20181114] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) [spring-web-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1610) [jetty-servlet-9.4.14.v20181114.jar:9.4.14.v20181114] at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:92) [spring-web-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1610) [jetty-servlet-9.4.14.v20181114.jar:9.4.14.v20181114] at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) [spring-web-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1610) [jetty-servlet-9.4.14.v20181114.jar:9.4.14.v20181114] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) [spring-web-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1610) [jetty-servlet-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:540) [jetty-servlet-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:146) [jetty-server-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548) [jetty-security-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132) [jetty-server-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:257) [jetty-server-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1588) [jetty-server-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255) [jetty-server-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1345) [jetty-server-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203) [jetty-server-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:480) [jetty-servlet-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1557) [jetty-server-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201) [jetty-server-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1247) [jetty-server-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144) [jetty-server-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132) [jetty-server-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.server.Server.handle(Server.java:502) [jetty-server-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:364) [jetty-server-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260) [jetty-server-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:305) [jetty-io-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103) [jetty-io-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118) [jetty-io-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333) [jetty-util-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310) [jetty-util-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168) [jetty-util-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126) [jetty-util-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366) [jetty-util-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:765) [jetty-util-9.4.14.v20181114.jar:9.4.14.v20181114] at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:683) [jetty-util-9.4.14.v20181114.jar:9.4.14.v20181114] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_265]   **Screenshots** ![image](https://user-images.githubusercontent.com/26177232/92882887-e9750280-f442-11ea-8d42-0f09de7e60df.png)   **Which version of Dolphin Scheduler:**  -[dev-branch]   **Requirement or improvement** I guessed from the exception that it was a UI problem, so I looked for the source code of the UI. I found a problem in dolphinscheduler-ui-&gt;src-&gt;js-&gt;conf-&gt;home-&gt;pages-&gt;user-&gt;pages-&gt;password-&gt; _source-&gt; info.vue. ![image](https://user-images.githubusercontent.com/26177232/92883879-e1699280-f443-11ea-84bb-74fcd74c2953.png) Add "state: this.userinfo.state" to this code param, and after redeploying the UI, you can successfully submit the request to change the password. ![image](https://user-images.githubusercontent.com/26177232/92884217-386f6780-f444-11ea-992b-921dd27da427.png) ![image](https://user-images.githubusercontent.com/26177232/92884353-59d05380-f444-11ea-9349-1cf022576364.png)  </body>
		<created>2020-09-11 07:36:06</created>
		<closed>2020-09-13 15:52:20</closed>
	</bug>
	<bug>
		<id>3713</id>
		<title>[Bug][HadoopUtils] catfile method  Stream not closed </title>
		<body>  The catfile method did not close the data stream, resulting in too many open files   ![image](https://user-images.githubusercontent.com/39816903/92694030-02b17c80-f379-11ea-843c-bac4aee4c778.png)   </body>
		<created>2020-09-10 07:36:42</created>
		<closed>2020-09-12 15:42:41</closed>
	</bug>
	<bug>
		<id>3675</id>
		<title>shell run sqoop miss DB2 driver</title>
		<body>I have configured the DB2 driver in /sqoop/lib/db2jcc4.jar , the sqoop command can be executed correctly in the command  but the execution of the same command failed .in the dolphin's shell .   the error log is "20/09/04 15:40:58 ERROR sqoop.Sqoop: Got exception running Sqoop: java.lang.RuntimeException: Could not load db driver class: com.ibm.db2.jcc.DB2Driver"   Only the DB2 data source has this problem, the sqoop commands of other data sources can be executed directly in the dolphin's shell   ![image](https://user-images.githubusercontent.com/34772948/92230237-60f3e080-eedd-11ea-889b-29a99fb4b69f.png) </body>
		<created>2020-09-04 10:41:57</created>
		<closed>2020-09-07 04:47:36</closed>
	</bug>
	<bug>
		<id>3645</id>
		<title>[Bug][worker]  get yarn applications status from yarn server,http code return 404, get yarn applications status cause NullPointerException </title>
		<body>*For better global communication, please give priority to using English description, thx! *  *Please review https://dolphinscheduler.apache.org/en-us/docs/development/issue.html when describe an issue.*  **Describe the bug** [ERROR] 2020-09-02 15:37:27.040 org.apache.dolphinscheduler.common.utils.HttpUtils:[70] - http get:404 response status code is not 200! [ERROR] 2020-09-02 15:37:27.043  - [taskAppId=TASK-5-185-263]:[388] - yarn applications: [application_1598594304061_22447]  status failed java.lang.NullPointerException: null         at org.apache.dolphinscheduler.common.utils.HadoopUtils.getApplicationStatus(HadoopUtils.java:415)         at org.apache.dolphinscheduler.server.worker.task.AbstractCommandExecutor.isSuccessOfYarnState(AbstractCommandExecutor.java:374)         at org.apache.dolphinscheduler.server.worker.task.AbstractCommandExecutor.run(AbstractCommandExecutor.java:218)         at org.apache.dolphinscheduler.server.worker.task.AbstractYarnTask.handle(AbstractYarnTask.java:57)         at org.apache.dolphinscheduler.server.worker.runner.TaskExecuteThread.run(TaskExecuteThread.java:129)         at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)         at java.util.concurrent.FutureTask.run(FutureTask.java:266)         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)         at java.lang.Thread.run(Thread.java:745) **Which version of Dolphin Scheduler:**  -[1.3.2]   </body>
		<created>2020-09-02 08:23:00</created>
		<closed>2020-09-02 09:56:51</closed>
	</bug>
	<bug>
		<id>3638</id>
		<title>[Bug]单独执行工作流里的作业时默认工作组错误 Default workgroup error when executing a job</title>
		<body>在一个工作流(已上线)里单独执行某个作业时，默认的工作组不对，而且不能选择 When a job is executed separately in a workflow (online), the default working group is not correct and cannot be selected  **Which version of Dolphin Scheduler:**  -[1.3.2-release]  ![image](https://user-images.githubusercontent.com/57620584/91861607-9d39fd80-ec9f-11ea-8e3e-36981b41889f.png) ![image](https://user-images.githubusercontent.com/57620584/91861623-a1661b00-ec9f-11ea-9309-30bd4ce9d8e0.png) ![image](https://user-images.githubusercontent.com/57620584/91861639-a5923880-ec9f-11ea-99d1-52d31fd1e346.png) ![image](https://user-images.githubusercontent.com/57620584/91861825-d6726d80-ec9f-11ea-84a5-bc0846fdb2e2.png) </body>
		<created>2020-09-01 14:09:48</created>
		<closed>2020-09-02 03:41:24</closed>
	</bug>
	<bug>
		<id>3637</id>
		<title>[Bug]The date shows the problem on the safari browser</title>
		<body>&lt;img width="810" alt="屏幕快照 2020-09-01 下午4 56 02" src="https://user-images.githubusercontent.com/21189049/91829952-acf01c80-ec74-11ea-9627-2a0e428e2f66.png"&gt; Time is displayed as Invalid Date in the safari browser.</body>
		<created>2020-09-01 09:01:38</created>
		<closed>2020-09-01 11:43:21</closed>
	</bug>
	<bug>
		<id>3628</id>
		<title>[Bug]一个worker不能属于多个工作组 one worker can’t belong different worker groups</title>
		<body>1.3.2版本一个新的功能是一个worker能属于多个工作组 https://github.com/apache/incubator-dolphinscheduler/pull/3277 但我实际测试，在worker.properties里设置worker.groups=default,group1 在页面上还是只有default这个工作组  A new feature of version 1.3.2 is that a worker can belong to multiple working groups https://github.com/apache/incubator-dolphinscheduler/pull/3277 But I actually tested that in config file worker.properties Setting in worker.groups=default,group1 On the UI, only default worder groups  worker.properties ![image](https://user-images.githubusercontent.com/57620584/91709265-1577c480-ebb5-11ea-8126-7897883de500.png) install_config.conf ![image](https://user-images.githubusercontent.com/57620584/91709187-f842f600-ebb4-11ea-85d3-e86ac96c6991.png) WEB UI ![image](https://user-images.githubusercontent.com/57620584/91708263-ad74ae80-ebb3-11ea-9a67-f8ab9230ca79.png)   **Which version of Dolphin Scheduler:**  -[1.3.2-release]  </body>
		<created>2020-08-31 09:54:06</created>
		<closed>2020-09-01 02:30:56</closed>
	</bug>
	<bug>
		<id>3607</id>
		<title>[Bug][Workflow version] ProcessDefinition version can delete and save with releaseState=ONLINE</title>
		<body>**Describe the bug** ProcessDefinition version can delete and save with releaseState=ONLINE  **To Reproduce** Steps to reproduce the behavior, for example: 1. set processdefinition online 2. click processdefinition name 3. click save `[bug]should disabeld` 4. click version info,delete/switch version `[bug]shoudld disabeld`  **Which version of Dolphin Scheduler:**  -[dev] @yangyichao-mango </body>
		<created>2020-08-27 02:16:10</created>
		<closed>2020-08-27 05:00:19</closed>
	</bug>
	<bug>
		<id>3599</id>
		<title>[Bug][首页] 页面滚动遮挡顶部菜单</title>
		<body>首页页面向上滚动时遮挡了顶部菜单栏！ The top menu bar is obscured when the home page scrolls up！ ![WX20200826-155559](https://user-images.githubusercontent.com/15725862/91277410-5b97e700-e7b5-11ea-887c-025851657218.png) </body>
		<created>2020-08-26 08:01:52</created>
		<closed>2020-08-26 08:43:42</closed>
	</bug>
	<bug>
		<id>3584</id>
		<title>[Bug][API] The Spark task runs in Cluster mode, executes successfully but the status of the task is shown to fail</title>
		<body>use version 1.3.1 of Dolphinscheduler：  **Describe the bug** The Spark task runs in Cluster mode, executes successfully but the status of the task is shown to fail.  **To Reproduce** 1. Run a Spark task in Cluster mode. 2. view the status fo the task,failed. ![image](https://user-images.githubusercontent.com/32183971/91116113-37a5aa00-e6be-11ea-9a71-ab9d6e6300b2.png) 3. View the task log and the end of the log shows that the Spark task executed successfully. ![image](https://user-images.githubusercontent.com/32183971/91116069-20ff5300-e6be-11ea-99dc-a1a4f37059f5.png)  **Expected behavior** The Spark task runs in Cluster mode, executes successfully then the status of the task is shown to success. </body>
		<created>2020-08-25 02:39:22</created>
		<closed>2020-08-25 08:31:17</closed>
	</bug>
	<bug>
		<id>3583</id>
		<title>[Bug][dolphinscheduler-server] serialization error when presto-jdbc resultset contains object 'PrestoArray'</title>
		<body>**Which version of Dolphin Scheduler:**   - [branch: dev ; commitId:836e86dca50ac636f66e0b2a881b183b322329e8]  **Describe the bug** serialization error when presto-jdbc resultset contains object 'PrestoArray'  ERROR] 2020-08-24 23:41:51.262  - [taskAppId=TASK-1-21-31]:[242] - execute sql error java.lang.IllegalArgumentException: getResultSet not supported (through reference chain: com.facebook.presto.jdbc.PrestoArray["resultSet"]) at com.fasterxml.jackson.databind.ObjectMapper.valueToTree(ObjectMapper.java:2802) at org.apache.dolphinscheduler.common.utils.JSONUtils.toJsonNode(JSONUtils.java:67) at org.apache.dolphinscheduler.server.worker.task.sql.SqlTask.resultProcess(SqlTask.java:265) at org.apache.dolphinscheduler.server.worker.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:232) at org.apache.dolphinscheduler.server.worker.task.sql.SqlTask.handle(SqlTask.java:138) at org.apache.dolphinscheduler.server.worker.runner.TaskExecuteThread.run(TaskExecuteThread.java:149) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745) Caused by: com.fasterxml.jackson.databind.JsonMappingException: getResultSet not supported (through reference chain: com.facebook.presto.jdbc.PrestoArray["resultSet"]) at com.fasterxml.jackson.databind.JsonMappingException.wrapWithPath(JsonMappingException.java:394) at com.fasterxml.jackson.databind.JsonMappingException.wrapWithPath(JsonMappingException.java:353) at com.fasterxml.jackson.databind.ser.std.StdSerializer.wrapAndThrow(StdSerializer.java:316) at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:727) at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:155) at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider._serialize(DefaultSerializerProvider.java:480) at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:319) at com.fasterxml.jackson.databind.ObjectMapper.writeValue(ObjectMapper.java:2655) at com.fasterxml.jackson.databind.ObjectMapper.valueToTree(ObjectMapper.java:2797) ... 10 common frames omitted Caused by: java.sql.SQLFeatureNotSupportedException: getResultSet not supported at com.facebook.presto.jdbc.PrestoArray.getResultSet(PrestoArray.java:89) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:688) at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:719) ... 15 common frames omitted [ERROR] 2020-08-24 23:41:51.281  - [taskAppId=TASK-1-21-31]:[144] - sql task error java.lang.RuntimeException: execute sql error at org.apache.dolphinscheduler.server.worker.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:243) at org.apache.dolphinscheduler.server.worker.task.sql.SqlTask.handle(SqlTask.java:138) at org.apache.dolphinscheduler.server.worker.runner.TaskExecuteThread.run(TaskExecuteThread.java:149) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745)  **To Reproduce** using sql node execute "select array['a','b','c']"  on presto datasource   - Please describe about your requirements or improvement suggestions. </body>
		<created>2020-08-25 02:25:28</created>
		<closed>2020-08-25 08:12:17</closed>
	</bug>
	<bug>
		<id>3570</id>
		<title>ApiApplicationServer failed to start, but other Server started normally.</title>
		<body> **Describe the bug** ApiApplicationServer failed to start. And the dolphinscheduler-api-server-pgsrv2.out logs have following error,   ERROR org.springframework.boot.SpringApplication - Application run failed org.springframework.boot.web.server.WebServerException: Unable to start embedded Jetty server  [postgres@pgsrv2 logs]$ jps 18609 LoggerServer 18657 AlertServer 18564 WorkerServer 22789 AlertServer 22742 LoggerServer 18519 MasterServer 22697 WorkerServer 9964 QuorumPeerMain 22652 MasterServer 23359 Jps  ![image](https://user-images.githubusercontent.com/34437466/90869107-5825e980-e3ca-11ea-95d7-58f4e6e93a0c.png)  ### The log in dolphinscheduler-api-server-pgsrv2.out is here `Java HotSpot(TM) 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.    .   ____          _            __ _ _  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \ ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )   '  |____| .__|_| |_|_| |_\__, | / / / /  =========|_|==============|___/=/_/_/_/  :: Spring Boot ::        (v2.1.3.RELEASE)  [INFO] 2020-08-21 15:04:15.978 org.eclipse.jetty.util.log:[193] - Logging initialized @18007ms to org.eclipse.jetty.util.log.Slf4jLog [INFO] 2020-08-21 15:04:16.419 org.eclipse.jetty.server.Server:[370] - jetty-9.4.14.v20181114; built: 2018-11-14T21:20:31.478Z; git: c4550056e785fb5665914545889f21dc136ad9e6; jvm 11.0.8+10-LTS [INFO] 2020-08-21 15:04:16.501 org.eclipse.jetty.server.handler.ContextHandler.application:[2345] - Initializing Spring embedded WebApplicationContext [INFO] 2020-08-21 15:04:16.616 org.eclipse.jetty.server.session:[365] - DefaultSessionIdManager workerName=node0 [INFO] 2020-08-21 15:04:16.617 org.eclipse.jetty.server.session:[370] - No SessionScavenger set, using defaults [INFO] 2020-08-21 15:04:16.623 org.eclipse.jetty.server.session:[149] - node0 Scavenging every 600000ms [INFO] 2020-08-21 15:04:16.637 org.eclipse.jetty.server.handler.ContextHandler:[855] - Started o.s.b.w.e.j.JettyEmbeddedWebAppContext@5ffd35dd{application,/dolphinscheduler,[file:///tmp/jetty-docbase.1884328835880379741.12345/, jar:file:/usr/local/dolphinscheduler-1.3.1/dolphinscheduler-data/bin/../lib/springfox-swagger-ui-2.9.2.jar!/META-INF/resources, jar:file:/usr/local/dolphinscheduler-1.3.1/dolphinscheduler-data/bin/../lib/swagger-bootstrap-ui-1.9.3.jar!/META-INF/resources],AVAILABLE} [INFO] 2020-08-21 15:04:16.639 org.eclipse.jetty.server.Server:[407] - Started @18682ms  _ _   |_  _ _|_. ___ _ |    _  | | |\/|_)(_| | |_\  |_)||_|_\       /               |                                  3.2.0  [INFO] 2020-08-21 15:04:20.370 org.apache.dolphinscheduler.service.zk.ZookeeperOperator:[82] - zookeeper registry center init, server lists is: pgsrv2:2181. [INFO] 2020-08-21 15:04:20.460 org.apache.curator.utils.Compatibility:[48] - Running in ZooKeeper 3.4.x compatibility mode [INFO] 2020-08-21 15:04:20.465 org.apache.curator.utils.Compatibility:[61] - Using emulated InjectSessionExpiration [INFO] 2020-08-21 15:04:20.519 org.apache.curator.framework.imps.CuratorFrameworkImpl:[308] - Starting [INFO] 2020-08-21 15:04:20.565 org.apache.curator.framework.imps.CuratorFrameworkImpl:[356] - Default schema [INFO] 2020-08-21 15:04:20.597 org.apache.curator.framework.state.ConnectionStateManager:[251] - State change: CONNECTED [INFO] 2020-08-21 15:04:20.607 org.apache.dolphinscheduler.service.zk.ZookeeperOperator:[82] - zookeeper registry center init, server lists is: pgsrv2:2181. [INFO] 2020-08-21 15:04:20.608 org.apache.curator.framework.imps.CuratorFrameworkImpl:[308] - Starting [INFO] 2020-08-21 15:04:20.612 org.apache.curator.framework.imps.CuratorFrameworkImpl:[356] - Default schema [INFO] 2020-08-21 15:04:20.614 org.apache.curator.framework.state.ConnectionStateManager:[251] - State change: CONNECTED [INFO] 2020-08-21 15:04:20.626 org.apache.dolphinscheduler.service.zk.ZookeeperCachedOperator:[43] - add listener to zk path: /dolphinscheduler [INFO] 2020-08-21 15:04:20.830 org.apache.dolphinscheduler.service.zk.ZookeeperOperator:[82] - zookeeper registry center init, server lists is: pgsrv2:2181. [INFO] 2020-08-21 15:04:20.831 org.apache.curator.framework.imps.CuratorFrameworkImpl:[308] - Starting [INFO] 2020-08-21 15:04:20.834 org.apache.curator.framework.imps.CuratorFrameworkImpl:[356] - Default schema [INFO] 2020-08-21 15:04:20.839 org.apache.curator.framework.state.ConnectionStateManager:[251] - State change: CONNECTED [INFO] 2020-08-21 15:04:20.840 org.apache.dolphinscheduler.service.zk.ZookeeperCachedOperator:[43] - add listener to zk path: /dolphinscheduler [INFO] 2020-08-21 15:04:23.361 springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper:[160] - Context refreshed [INFO] 2020-08-21 15:04:23.441 springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper:[163] - Found 1 custom documentation plugin(s) [INFO] 2020-08-21 15:04:23.627 springfox.documentation.spring.web.scanners.ApiListingReferenceScanner:[41] - Scanning for api listing references [INFO] 2020-08-21 15:04:24.323 springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator:[40] - Generating unique operation named: viewTreeUsingGET_1 [INFO] 2020-08-21 15:04:24.457 springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator:[40] - Generating unique operation named: queryResourceListUsingGET_1 [INFO] 2020-08-21 15:04:24.657 org.eclipse.jetty.server.handler.ContextHandler.application:[2345] - Initializing Spring DispatcherServlet 'dispatcherServlet' [INFO] 2020-08-21 15:04:24.688 org.mortbay.log:[67] - Logging to Logger[org.mortbay.log] via org.mortbay.log.Slf4jLog [WARN] 2020-08-21 15:04:24.715 org.eclipse.jetty.server.handler.ContextHandler.application:[2355] - unavailable java.lang.ClassCastException: class jdk.internal.loader.ClassLoaders$AppClassLoader cannot be cast to class java.net.URLClassLoader (jdk.internal.loader.ClassLoaders$AppClassLoader and java.net.URLClassLoader are in module java.base of loader 'bootstrap')         at org.apache.jasper.compiler.JspRuntimeContext.&lt;init&gt;(JspRuntimeContext.java:174)         at org.apache.jasper.servlet.JspServlet.init(JspServlet.java:150)         at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:672)         at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:429)         at org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:750)         at java.base/java.util.stream.SortedOps$SizedRefSortingSink.end(SortedOps.java:357)         at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:485)         at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)         at java.base/java.util.stream.StreamSpliterators$WrappingSpliterator.forEachRemaining(StreamSpliterators.java:312)         at java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:735)         at java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734)         at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658)         at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:744)         at org.springframework.boot.web.embedded.jetty.JettyEmbeddedWebAppContext$JettyEmbeddedServletHandler.deferredInitialize(JettyEmbeddedWebAppContext.java:46)         at org.springframework.boot.web.embedded.jetty.JettyEmbeddedWebAppContext.deferredInitialize(JettyEmbeddedWebAppContext.java:36)         at org.springframework.boot.web.embedded.jetty.JettyWebServer.handleDeferredInitialize(JettyWebServer.java:221)         at org.springframework.boot.web.embedded.jetty.JettyWebServer.start(JettyWebServer.java:142)         at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.startWebServer(ServletWebServerApplicationContext.java:311)         at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.finishRefresh(ServletWebServerApplicationContext.java:164)         at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:552)         at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142)         at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775)         at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397)         at org.springframework.boot.SpringApplication.run(SpringApplication.java:316)         at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260)         at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248)         at org.apache.dolphinscheduler.api.ApiApplicationServer.main(ApiApplicationServer.java:36) [INFO] 2020-08-21 15:04:24.717 org.eclipse.jetty.server.session:[167] - node0 Stopped scavenging [INFO] 2020-08-21 15:04:24.719 org.eclipse.jetty.server.handler.ContextHandler.application:[2345] - Destroying Spring FrameworkServlet 'dispatcherServlet' [INFO] 2020-08-21 15:04:24.720 org.eclipse.jetty.server.handler.ContextHandler:[1045] - Stopped o.s.b.w.e.j.JettyEmbeddedWebAppContext@5ffd35dd{application,/dolphinscheduler,[file:///tmp/jetty-docbase.1884328835880379741.12345/, jar:file:/usr/local/dolphinscheduler-1.3.1/dolphinscheduler-data/bin/../lib/springfox-swagger-ui-2.9.2.jar!/META-INF/resources, jar:file:/usr/local/dolphinscheduler-1.3.1/dolphinscheduler-data/bin/../lib/swagger-bootstrap-ui-1.9.3.jar!/META-INF/resources],UNAVAILABLE} 15:04:24.730 [main] ERROR org.springframework.boot.SpringApplication - Application run failed org.springframework.boot.web.server.WebServerException: Unable to start embedded Jetty server         at org.springframework.boot.web.embedded.jetty.JettyWebServer.start(JettyWebServer.java:168) ~[spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.startWebServer(ServletWebServerApplicationContext.java:311) ~[spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.finishRefresh(ServletWebServerApplicationContext.java:164) ~[spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:552) ~[spring-context-5.1.5.RELEASE.jar:5.1.5.RELEASE]         at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) ~[spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) [spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) [spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) [spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) [spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) [spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.apache.dolphinscheduler.api.ApiApplicationServer.main(ApiApplicationServer.java:36) [dolphinscheduler-api-1.3.1.jar:1.3.1] Caused by: javax.servlet.ServletException: jsp@19c47==org.apache.jasper.servlet.JspServlet,jsp=null,order=3,inst=false,async=true         at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:693) ~[jetty-servlet-9.4.14.v20181114.jar:9.4.14.v20181114]         at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:429) ~[jetty-servlet-9.4.14.v20181114.jar:9.4.14.v20181114]         at org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:750) ~[jetty-servlet-9.4.14.v20181114.jar:9.4.14.v20181114]         at java.util.stream.SortedOps$SizedRefSortingSink.end(SortedOps.java:357) ~[?:?]         at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:485) ~[?:?]         at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ~[?:?]         at java.util.stream.StreamSpliterators$WrappingSpliterator.forEachRemaining(StreamSpliterators.java:312) ~[?:?]         at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:735) ~[?:?]         at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734) ~[?:?]         at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658) ~[?:?]         at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:744) ~[jetty-servlet-9.4.14.v20181114.jar:9.4.14.v20181114]         at org.springframework.boot.web.embedded.jetty.JettyEmbeddedWebAppContext$JettyEmbeddedServletHandler.deferredInitialize(JettyEmbeddedWebAppContext.java:46) ~[spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.springframework.boot.web.embedded.jetty.JettyEmbeddedWebAppContext.deferredInitialize(JettyEmbeddedWebAppContext.java:36) ~[spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.springframework.boot.web.embedded.jetty.JettyWebServer.handleDeferredInitialize(JettyWebServer.java:221) ~[spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.springframework.boot.web.embedded.jetty.JettyWebServer.start(JettyWebServer.java:142) ~[spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         ... 10 more Caused by: java.lang.ClassCastException: class jdk.internal.loader.ClassLoaders$AppClassLoader cannot be cast to class java.net.URLClassLoader (jdk.internal.loader.ClassLoaders$AppClassLoader and java.net.URLClassLoader are in module java.base of loader 'bootstrap')         at org.apache.jasper.compiler.JspRuntimeContext.&lt;init&gt;(JspRuntimeContext.java:174) ~[jsp-2.1-6.1.14.jar:6.1.14]         at org.apache.jasper.servlet.JspServlet.init(JspServlet.java:150) ~[jsp-2.1-6.1.14.jar:6.1.14]         at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:672) ~[jetty-servlet-9.4.14.v20181114.jar:9.4.14.v20181114]         at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:429) ~[jetty-servlet-9.4.14.v20181114.jar:9.4.14.v20181114]         at org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:750) ~[jetty-servlet-9.4.14.v20181114.jar:9.4.14.v20181114]         at java.util.stream.SortedOps$SizedRefSortingSink.end(SortedOps.java:357) ~[?:?]         at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:485) ~[?:?]         at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ~[?:?]         at java.util.stream.StreamSpliterators$WrappingSpliterator.forEachRemaining(StreamSpliterators.java:312) ~[?:?]         at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:735) ~[?:?]         at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734) ~[?:?]         at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658) ~[?:?]         at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:744) ~[jetty-servlet-9.4.14.v20181114.jar:9.4.14.v20181114]         at org.springframework.boot.web.embedded.jetty.JettyEmbeddedWebAppContext$JettyEmbeddedServletHandler.deferredInitialize(JettyEmbeddedWebAppContext.java:46) ~[spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.springframework.boot.web.embedded.jetty.JettyEmbeddedWebAppContext.deferredInitialize(JettyEmbeddedWebAppContext.java:36) ~[spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.springframework.boot.web.embedded.jetty.JettyWebServer.handleDeferredInitialize(JettyWebServer.java:221) ~[spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.springframework.boot.web.embedded.jetty.JettyWebServer.start(JettyWebServer.java:142) ~[spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         ... 10 more [INFO] 2020-08-21 15:04:24.774 org.apache.dolphinscheduler.remote.NettyRemotingClient:[376] - netty client closed [INFO] 2020-08-21 15:04:24.775 org.apache.dolphinscheduler.service.log.LogClientService:[59] - logger client closed`   **Which version of Dolphin Scheduler:**  -[1.3.1]  **Which version of JDK:** [postgres@pgsrv2 logs]$ java --version java 11.0.8 2020-07-14 LTS Java(TM) SE Runtime Environment 18.9 (build 11.0.8+10-LTS) Java HotSpot(TM) 64-Bit Server VM 18.9 (build 11.0.8+10-LTS, mixed mode)  I have no idea with it, please tell how to fix it. If you need anyting more ,please let me know ,Thanks! </body>
		<created>2020-08-21 08:28:40</created>
		<closed>2020-09-15 13:58:38</closed>
	</bug>
	<bug>
		<id>3569</id>
		<title>[Bug][Module Name] sqoop任务中途退出，exit before timeout, exit value:127</title>
		<body>使用调度： java -jar ds-sqoop.jar --spring.profiles.active=test --jobs.active=TaskRunnerJob 361 报错信息： 2020-08-21 11:11:18 [INFO] [main] [com.fenbi.ds.sqoop.service.CmdLineRunner] commands:cd /home/shared/ds-sqoop/tmp; sqoop --options-file /home/shared/ds-sqoop/config/pipe_sqoop_task_config &gt; /home/shared/ds-sqoop/log/sqoop/pipe_sqoop_task_log 2&gt;&amp;1 **2020-08-21 11:11:18 [INFO] [main] [com.fenbi.ds.sqoop.service.CmdLineRunner] exit before timeout, exit value:127** 但是： 直接执行jar包，不会中途退出。 2020-08-21 14:38:10 [INFO] [main] [com.fenbi.ds.sqoop.service.CmdLineRunner] cmd:sqoop --options-file /home/shared/ds-sqoop/config/pipe_sqoop_task_config 2020-08-21 14:38:10 [INFO] [main] [com.fenbi.ds.sqoop.service.CmdLineRunner] commands:cd /home/shared/ds-sqoop/tmp; sqoop --options-file /home/shared/ds-sqoop/config/pipe_sqoop_task_config &gt; /home/shared/ds-sqoop/log/sqoop/pipe_sqoop_task_log 2&gt;&amp;1 **2020-08-21 14:41:00 [INFO] [main] [com.fenbi.ds.sqoop.service.CmdLineRunner] exit before timeout, exit value:0** </body>
		<created>2020-08-21 07:48:28</created>
		<closed>2020-08-25 02:59:56</closed>
	</bug>
	<bug>
		<id>3536</id>
		<title>[Bug][API] If user didn't have tenant,create resource will NPE.</title>
		<body>**Describe the bug** [Bug][API] If user didn't have tenant,create resource will NPE.  **Expected behavior** A clear and concise description of what you expected to happen.  **Screenshots** If applicable, add screenshots to help explain your problem.   **Which version of Dolphin Scheduler:**  -[1.3.2-release]  </body>
		<created>2020-08-18 05:23:28</created>
		<closed>2020-08-18 09:06:18</closed>
	</bug>
	<bug>
		<id>3529</id>
		<title>spark任务 程序获取命令行参数中文乱码</title>
		<body>**Describe the bug** spark任务 命令行参数 在程序中获取到时乱码  **To Reproduce** Steps to reproduce the behavior, for example: 1. 新建spark任务 2. 填写spark命令行参数 3. 程序打印main方法的args 4. 中文是乱码 数字可以正常显示  **Expected behavior** 中文正常显示  **Screenshots** ![image](https://user-images.githubusercontent.com/64292411/90375556-b049ac80-e0a7-11ea-84ac-3deecb7d770f.png) ![image](https://user-images.githubusercontent.com/64292411/90376246-bab87600-e0a8-11ea-918a-cfaf0c8733d7.png) ![image](https://user-images.githubusercontent.com/64292411/90376911-c7899980-e0a9-11ea-9864-dd7f1b12942d.png)    **Which version of Dolphin Scheduler:** -[1.3.1-release]</body>
		<created>2020-08-17 08:54:38</created>
		<closed>2020-08-18 07:59:31</closed>
	</bug>
	<bug>
		<id>3528</id>
		<title>[Bug][工作流] 编辑工作流，点进去以后，编辑页面经常空白。</title>
		<body> chrome浏览器版本 84.0.4147.125（正式版本），经测试，编辑工作流，点进去以后，编辑页面经常空白。 火狐浏览器没有这个问题。 ![image](https://user-images.githubusercontent.com/29685418/90365868-1a0e8a00-e099-11ea-8f11-932f58389f30.png)   </body>
		<created>2020-08-17 06:51:37</created>
		<closed>2020-08-26 03:50:35</closed>
	</bug>
	<bug>
		<id>3510</id>
		<title>[Bug][Workflow 面板] 定义工作流流程</title>
		<body>* DAG ![image](https://user-images.githubusercontent.com/13701232/90306175-13e3a680-defd-11ea-986a-843773c1c503.png) * Tree ![image](https://user-images.githubusercontent.com/13701232/90306178-1fcf6880-defd-11ea-8e3f-bad1537cac60.png)  最后一个节点的perTask为空,不为mr9. 经常出现这种问题.</body>
		<created>2020-08-15 05:43:08</created>
		<closed>2020-08-15 05:48:01</closed>
	</bug>
	<bug>
		<id>3495</id>
		<title>[Bug][Master] The same scheduling task runs twice, causing data duplication</title>
		<body>**Describe the bug** The same scheduling task runs twice, causing data duplication **To Reproduce** 1. The cluster has two workers and two masters 2. set up a scheduled task 3. run by time  **Expected behavior** duplicate tasks  **Screenshots** If applicable, add screenshots to help explain your problem. ![image](https://user-images.githubusercontent.com/18513424/90220906-b5a2bf00-de3b-11ea-8794-d6d03b4b5da7.png)   **Which version of Dolphin Scheduler:**  -[1.2.0-preview]  **Additional context** ![image](https://user-images.githubusercontent.com/18513424/90221838-7d03e500-de3d-11ea-8704-a711c234af88.png)   **improvement** does this problem exist in 1.3.1 ?   thx  </body>
		<created>2020-08-14 06:40:45</created>
		<closed>2020-08-20 06:34:46</closed>
	</bug>
	<bug>
		<id>3480</id>
		<title>[Bug][Server] zookeeper multi directories, tasks cannot be assigned</title>
		<body>**Describe the bug** zookeeper多级目录场景下任务无法分配worker  **To Reproduce** Steps to reproduce the behavior, for example: 1. 修改配置文件zookeeper.properties zookeeper.dolphinscheduler.root=/path/to/dolphinscheduler 2. 正常启动master, worker 3. 新建工作流定义, 新建shell节点, echo "hello world"  **Expected behavior** 1.控制台正常显示已注册的master, worker 2.启动任务后, master报错: "fail to execute : xxx due to no suitable worker, current task need to yyy worker group execute"  **Which version of Dolphin Scheduler:**  -[1.3.1.release]  **Additional context** 1.ExecutorDispatcher#dispatch //hostManager.select 根据已经注册的worker, 通过group找到允许执行的worker 2.ZookeeperNodeManager$WorkerGroupNodeListener#dataChanged 监听worker变化 3.错误代码部分  &gt; `          if (event.getType() == TreeCacheEvent.Type.NODE_ADDED) {           logger.info("worker group node : {} added.", path);           String group = parseGroup(path); //格式化获取group出错, 导致无法刷新syncWorkerGroupNodes           Set&lt;String&gt; workerNodes = workerGroupNodes.getOrDefault(group, new HashSet&lt;&gt;());           Set&lt;String&gt; previousNodes = new HashSet&lt;&gt;(workerNodes);           Set&lt;String&gt; currentNodes = registryCenter.getWorkerGroupNodesDirectly(group);           logger.info("currentNodes : {}", currentNodes);           syncWorkerGroupNodes(group, currentNodes);        } `   &gt; `      private String parseGroup(String path){     String[] parts = path.split("\\/");     if(parts.length != 6){       throw new IllegalArgumentException(String.format("worker group path : %s is not valid, ignore", path));     }     String group = parts[4]; // /dolphinscheduler/nodes/worker/default, 这段代码符合的路径     return group;   } `   4. 临时修改 `String group = parts[parts.length-2];// 临时修改`   5.问题原因: workerGroupNodes保存worker信息, workerGroupNodes通过dataChange刷新, parseGroup错误导致变量一直无法更新, 最终ExecutorDispatcher#dispatch无法获取worker, 任务无法继续  </body>
		<created>2020-08-13 06:13:48</created>
		<closed>2020-08-15 03:16:43</closed>
	</bug>
	<bug>
		<id>3469</id>
		<title>[Bug] The program type of spark node is selected as PYTHON, how should the main jar package be selected?</title>
		<body>**Describe the question** ![image](https://user-images.githubusercontent.com/45786444/89966662-459d0900-dc82-11ea-9299-910c9b1745d0.png)  **Which version of DolphinScheduler:**  -[1.3.0]  **Additional context** The program type of spark node is selected as PYTHON, how should the main jar package be selected? Because on a linux machine, this command "spark-sumbit *.py" can run spark to run python files.  **Requirement or improvement** no </body>
		<created>2020-08-12 02:09:30</created>
		<closed>2020-08-15 02:39:26</closed>
	</bug>
	<bug>
		<id>3466</id>
		<title>[Bug][Worker] ZooKeeper path must not end with / character</title>
		<body>**Describe the bug** worker registry path end with / character, so it throws exeption  **To Reproduce**  **Expected behavior**  **Screenshots** ![image](https://user-images.githubusercontent.com/10829956/89892178-de8f3e00-dc08-11ea-9e60-20eaf7dd2273.png)   **Which version of Dolphin Scheduler:**  -[dev] </body>
		<created>2020-08-11 11:49:59</created>
		<closed>2020-08-12 14:01:23</closed>
	</bug>
	<bug>
		<id>3463</id>
		<title>[Bug][api] rename the udf resource file associated with the udf function, Failed to execute hive task</title>
		<body>1. Rename the udf resource file associated with the udf function ![image](https://user-images.githubusercontent.com/55787491/89854573-ceef0580-dbc6-11ea-90d4-2b4587d37f0f.png) ![image](https://user-images.githubusercontent.com/55787491/89854587-d9a99a80-dbc6-11ea-8b1a-f0b189824287.png)  2. Executing hive task is fail ![image](https://user-images.githubusercontent.com/55787491/89854496-9bac7680-dbc6-11ea-8ab4-e6ab2bd08ed2.png)  **Which version of Dolphin Scheduler:**  -[1.3.2-release]</body>
		<created>2020-08-11 03:37:09</created>
		<closed>2020-08-15 02:26:35</closed>
	</bug>
	<bug>
		<id>3462</id>
		<title>[Bug][api] The admin user cannot view the UDF functions created by ordinary users in the workflow definition</title>
		<body>1. Ordinarily use xhh to create udf functions ![image](https://user-images.githubusercontent.com/55787491/89853531-38214980-dbc4-11ea-8c4b-e6b159f8a732.png)  2. The admin user enters the workflow definition page and creates a hive task. The udf function drop-down box does not display the udf function created by xhh ![image](https://user-images.githubusercontent.com/55787491/89853598-5edf8000-dbc4-11ea-9685-094ccbbcc088.png)  **Which version of Dolphin Scheduler:**  -[1.3.2-release] </body>
		<created>2020-08-11 03:18:38</created>
		<closed>2020-08-12 07:51:05</closed>
	</bug>
	<bug>
		<id>3461</id>
		<title>[Bug][Worker] In version 1.2.0, the process execution error, but it shows success</title>
		<body>![1597114106(1)](https://user-images.githubusercontent.com/18513424/89851900-3a81a480-dbc0-11ea-9f38-4c0aba8d7cd6.jpg) ![1597113877(1)](https://user-images.githubusercontent.com/18513424/89851738-cf37d280-dbbf-11ea-8177-cf48ad28dc8a.jpg) 在高版本这个问题有解决吗？ </body>
		<created>2020-08-11 02:47:37</created>
		<closed>2020-08-20 06:35:20</closed>
	</bug>
	<bug>
		<id>3446</id>
		<title>[Bug][ui] 工作流定义时使用鼠标滚轮时显示不正确</title>
		<body>编辑工作流时，使用滚轮放大，相应的连接线位置不会移动，而节点会移动，造成错位</body>
		<created>2020-08-09 07:30:57</created>
		<closed>2020-08-31 02:13:00</closed>
	</bug>
	<bug>
		<id>3436</id>
		<title>[Bug][server] if resultset  has null value of some column, fastxml.jackson may ocurr exception</title>
		<body>### MyCase:        1.  use sql task node, sql type is query;        2. (db is oracle )config a sql, such as select *from table_t;                 table_t has two  columns, one's name is comment, type is VARCHAR2(50),                 another is last_updated_time , timestamp;        3. excute the job.  ![image](https://user-images.githubusercontent.com/7147384/89647035-7205fd80-d8ef-11ea-9d07-f8e6dbc6a9d1.png)   ### version: 1.3.1  ### Exception:   java.lang.IllegalArgumentException: No serializer found for class java.io.ByteArrayInputStream and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS) (through reference chain: oracle.sql.TIMESTAMP["stream"])         at com.fasterxml.jackson.databind.ObjectMapper.valueToTree(ObjectMapper.java:2802)         at org.apache.dolphinscheduler.common.utils.JSONUtils.toJsonNode(JSONUtils.java:67)         at org.apache.dolphinscheduler.server.worker.task.sql.SqlTask.resultProcess(SqlTask.java:265)         at org.apache.dolphinscheduler.server.worker.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:232)         at org.apache.dolphinscheduler.server.worker.task.sql.SqlTask.handle(SqlTask.java:138)         at org.apache.dolphinscheduler.server.worker.runner.TaskExecuteThread.run(TaskExecuteThread.java:129)         at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)         at java.util.concurrent.FutureTask.run(FutureTask.java:266)         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)         at java.lang.Thread.run(Thread.java:748)  ### My  Solution: modifiy the declare ObjectMapper in  the Class "JSONUtils"  as following:            `new ObjectMapper().configure(FAIL_ON_EMPTY_BEANS, false)          `  </body>
		<created>2020-08-07 12:51:15</created>
		<closed>2020-09-18 07:55:00</closed>
	</bug>
	<bug>
		<id>3433</id>
		<title>[Bug][api] Release the imported process definition which version is below 1.3.0 will be failure</title>
		<body>**Describe the bug** [Bug][api] Release the imported process definition which version is below 1.3.0 will be failure  **To Reproduce** Steps to reproduce the behavior, for example: 1. Import the process definition which vesion is below 1.3.0 2. Rlease the above process definiton. 3. See error ![image](https://user-images.githubusercontent.com/15651066/89617172-4c133580-d8bc-11ea-839e-2acd3ca53304.png)     **Which version of Dolphin Scheduler:**  -[1.3.2-release]</body>
		<created>2020-08-07 06:43:45</created>
		<closed>2020-08-08 09:19:20</closed>
	</bug>
	<bug>
		<id>3432</id>
		<title>[Bug][style] install checkstyle to IDEA failed</title>
		<body>I pull the code of branch dev and install the checkstyle to IDEA.   ![image](https://user-images.githubusercontent.com/32193458/89615598-8fb87000-d8b9-11ea-979c-7cbedceb8e65.png)  ![image](https://user-images.githubusercontent.com/32193458/89615628-9a730500-d8b9-11ea-9e3d-e33accb5ba6a.png)  And then it`s failed !  com.puppycrawl.tools.checkstyle.api.CheckstyleException: cannot initialize module TreeWalker - TreeWalker is not allowed as a parent of LineLength Please review 'Parent Module' section for this Check in web documentation if Check is standard. at com.puppycrawl.tools.checkstyle.Checker.setupChild(Checker.java:473) at com.puppycrawl.tools.checkstyle.api.AutomaticBean.configure(AutomaticBean.java:198) at org.infernus.idea.checkstyle.service.cmd.OpCreateChecker.execute(OpCreateChecker.java:61) at org.infernus.idea.checkstyle.service.cmd.OpCreateChecker.execute(OpCreateChecker.java:26) at org.infernus.idea.checkstyle.service.CheckstyleActionsImpl.executeCommand(CheckstyleActionsImpl.java:130) at org.infernus.idea.checkstyle.service.CheckstyleActionsImpl.createChecker(CheckstyleActionsImpl.java:60) at org.infernus.idea.checkstyle.service.CheckstyleActionsImpl.createChecker(CheckstyleActionsImpl.java:51) at org.infernus.idea.checkstyle.checker.CheckerFactoryWorker.run(CheckerFactoryWorker.java:46) Caused by: com.puppycrawl.tools.checkstyle.api.CheckstyleException: TreeWalker is not allowed as a parent of LineLength Please review 'Parent Module' section for this Check in web documentation if Check is standard. at com.puppycrawl.tools.checkstyle.TreeWalker.setupChild(TreeWalker.java:147) at com.puppycrawl.tools.checkstyle.api.AutomaticBean.configure(AutomaticBean.java:198) at com.puppycrawl.tools.checkstyle.Checker.setupChild(Checker.java:468) ... 7 more  ![image](https://user-images.githubusercontent.com/32193458/89615661-ae1e6b80-d8b9-11ea-8028-2bf84a8c9f0d.png)  My OS is macos 10.15.6  My IDEA version is 2018.2.6  </body>
		<created>2020-08-07 06:25:58</created>
		<closed>2020-08-07 07:16:18</closed>
	</bug>
	<bug>
		<id>3431</id>
		<title>[Bug][api] After the resource is re-uploaded, the deleted resource directory displayed in the workflow definition is incorrect</title>
		<body>1.Upgrade from 1.2.0 to 1.3.2， Re-upload the file in the resource center ![image](https://user-images.githubusercontent.com/55787491/89607356-eb2c3300-d8a4-11ea-9f1d-e1c41e09ba75.png) 2. View the task resources of the workflow definition，display multiple deleted resources directories  ![image](https://user-images.githubusercontent.com/55787491/89607195-7eb13400-d8a4-11ea-9667-d46b51cb2678.png)  **Which version of Dolphin Scheduler:**  -[1.3.2-release]</body>
		<created>2020-08-07 03:58:50</created>
		<closed>2020-08-15 02:29:53</closed>
	</bug>
	<bug>
		<id>3423</id>
		<title>[Bug][api] 1.2.0 upgrade to 1.3.2, rename the resource file, view the resource in workflow definition, the file cannot be found</title>
		<body>1.Upgrade from 1.2.0 to 1.3.2 2. rename the resource file, rename bigdata-1.0-SNAPSHOT.jar to bigdata-1.0-SNAPSHOT_1.jar ![image](https://user-images.githubusercontent.com/55787491/89502841-34727900-d7f8-11ea-9fe9-995d46174d2e.png)  3.view the resource in workflow definition, the file cannot be found ![image](https://user-images.githubusercontent.com/55787491/89502812-2886b700-d7f8-11ea-82f8-308e4da45f40.png) ![image](https://user-images.githubusercontent.com/55787491/89502821-2cb2d480-d7f8-11ea-8f55-aa32ec25d401.png)   **Which version of Dolphin Scheduler:**  -[1.3.2] </body>
		<created>2020-08-06 07:20:38</created>
		<closed>2020-08-15 02:18:04</closed>
	</bug>
	<bug>
		<id>3413</id>
		<title>[Bug][ui] shell setting form display error</title>
		<body>*For better global communication, please give priority to using English description, thx! *  *Please review https://dolphinscheduler.apache.org/en-us/docs/development/issue.html when describe an issue.*  **Describe the bug** double click D, and double click B. the shell content cannot display.   ![image](https://user-images.githubusercontent.com/29528966/89375397-1f2a1b80-d720-11ea-9b81-88ef5b567679.png)   **To Reproduce** Steps to reproduce the behavior, for example: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error  **Expected behavior** A clear and concise description of what you expected to happen.  **Screenshots** If applicable, add screenshots to help explain your problem.   **Which version of Dolphin Scheduler:**  -[1.1.0-preview]  **Additional context** Add any other context about the problem here.  **Requirement or improvement** - Please describe about your requirements or improvement suggestions. </body>
		<created>2020-08-05 05:34:43</created>
		<closed>2020-08-06 03:20:52</closed>
	</bug>
	<bug>
		<id>3399</id>
		<title>[Bug]定时任务没有正常跑</title>
		<body>问题: &lt;img width="714" alt="屏幕快照 2020-08-04 下午4 21 55" src="https://user-images.githubusercontent.com/21189049/89270998-b3d44100-d66e-11ea-99d6-57b7f5b6857a.png"&gt;  定时为每天小时的任务，缺了22点的定时任务，没有正常启动  查看dolphinscheduler-worker.2020-08-03_22.0.log日志发现服务连接zookpeer服务  using SASL (unknown error) [WARN] 2020-08-03 22:00:52.649 org.apache.zookeeper.ClientCnxn:[1164] - Session 0x0 for server xxxxxx/xxxxx:2181, unexpected error, closing socket connection a nd attempting reconnect java.io.IOException: Connection reset by peer at sun.nio.ch.FileDispatcherImpl.read0(Native Method) at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39) at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223) at sun.nio.ch.IOUtil.read(IOUtil.java:192) at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380) at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68) at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366) at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141) [INFO] 2020-08-03 22:00:53.488 org.apache.zookeeper.ClientCnxn:[1025] - Opening socket connection to server xxxxxx/xxxxx:2181. Will not attempt to authenticate  using SASL (unknown error) [INFO] 2020-08-03</body>
		<created>2020-08-04 08:24:04</created>
		<closed>2020-08-04 08:37:50</closed>
	</bug>
	<bug>
		<id>3397</id>
		<title>[Bug][api] Upgrade from 1.2.0 to 1.3.0,Run the spark task, the error is "spark task params is not valid"</title>
		<body>1.Upgrade from 1.2.0 to 1.3.0 2.Run the spark task, the error is "spark task params is not valid" ![image](https://user-images.githubusercontent.com/55787491/89267697-27278400-d66a-11ea-9e58-67587827c75a.png)  The error message is as follows：  [INFO] 2020-08-04 15:54:20.988  - [taskAppId=TASK-2-31-42]:[72] - spark task params {"mainArgs":"/chenxingchun/words.txt  /chenxingchun/out_c","driverMemory":"512M","executorMemory":"2G","programType":"SCALA","mainClass":"com.journey.spark.WordCount","driverCores":1,"deployMode":"cluster","executorCores":2,"mainJar":{"res":"bigdata-1.0-SNAPSHOT.jar"},"numExecutors":2,"localParams":[],"others":"","resourceList":[{"res":"test.sh"},{"res":"udf-demo-SNAPSHOT.jar"}]} [ERROR] 2020-08-04 15:54:20.989 org.apache.dolphinscheduler.server.worker.runner.TaskExecuteThread:[140] - task scheduler failure java.lang.RuntimeException: spark task params is not valid         at org.apache.dolphinscheduler.server.worker.task.spark.SparkTask.init(SparkTask.java:77)         at org.apache.dolphinscheduler.server.worker.runner.TaskExecuteThread.run(TaskExecuteThread.java:126)         at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)         at java.util.concurrent.FutureTask.run(FutureTask.java:266)         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)         at java.lang.Thread.run(Thread.java:748) [INFO] 2020-08-04 15:54:21.996 org.apache.dolphinscheduler.service.log.LogClientService:[100] - view log path /data1/dolphinscheduler_1.3.2/logs/2/31/42.log   **Which version of Dolphin Scheduler:**  -[1.3.2-release]  </body>
		<created>2020-08-04 07:53:25</created>
		<closed>2020-08-05 06:15:08</closed>
	</bug>
	<bug>
		<id>3393</id>
		<title>[Bug][api] view the log of the subtask, prompt "task instance does not exist"</title>
		<body>Click "View Log" of the subtask,  prompt "The task instance does not exist" ![image](https://user-images.githubusercontent.com/55787491/89242261-b36a8480-d633-11ea-82de-ca2988c41d2e.png)  **Which version of Dolphin Scheduler:**  -[1.3.2-release]  </body>
		<created>2020-08-04 01:22:02</created>
		<closed>2020-08-04 08:00:04</closed>
	</bug>
	<bug>
		<id>3390</id>
		<title>[Bug][api] Run hive task, udf resource path is incorrect</title>
		<body>1. Run hive task 2.Find the udf resource path of d is incorrect,As shown in the figure below, a "/" is missing after udfs ![image](https://user-images.githubusercontent.com/55787491/89169944-8bd2d800-d5b1-11ea-9dd3-20c55d66b5f4.png) ![image](https://user-images.githubusercontent.com/55787491/89169963-91c8b900-d5b1-11ea-9b9d-1c93081060ba.png)    **Which version of Dolphin Scheduler:**  -[1.3.2-release]   </body>
		<created>2020-08-03 09:49:42</created>
		<closed>2020-08-04 08:00:50</closed>
	</bug>
	<bug>
		<id>3386</id>
		<title>[Bug][Module Name] Bug title 突然停止调度了所有任务</title>
		<body>1.2.1，all scheduler tasks do not start, no alter, no error, just do not start scheduler： [ERROR] 2020-07-31 08:08:57.297 io.grpc.internal.ManagedChannelImpl:[1116] - *~*~*~ Channel io.grpc.internal.ManagedChannelImpl-9309 for target 192.168.13.22:50051  was not shutdown properly!!! ~*~*~*     Make sure to call shutdown()/shutdownNow() and awaitTermination(). java.lang.RuntimeException: ManagedChannel allocation site         at io.grpc.internal.ManagedChannelImpl$ManagedChannelReference.&lt;init&gt;(ManagedChannelImpl.java:1065)         at io.grpc.internal.ManagedChannelImpl.&lt;init&gt;(ManagedChannelImpl.java:485)         at io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:349)         at org.apache.dolphinscheduler.api.log.LogClient.&lt;init&gt;(LogClient.java:60)         at org.apache.dolphinscheduler.api.log.LogClient.&lt;init&gt;(LogClient.java:45)         at org.apache.dolphinscheduler.api.service.LoggerService.queryLog(LoggerService.java:71)         at org.apache.dolphinscheduler.api.service.ProcessInstanceService.AddDependResultForTaskList(ProcessInstanceService.java:252)         at org.apache.dolphinscheduler.api.service.ProcessInstanceService.queryTaskListByProcessId(ProcessInstanceService.java:235)         at org.apache.dolphinscheduler.api.service.ProcessInstanceService$$FastClassBySpringCGLIB$$da33359.invoke(&lt;generated&gt;)         at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)         at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684)         at org.apache.dolphinscheduler.api.service.ProcessInstanceService$$EnhancerBySpringCGLIB$$389dd9ea.queryTaskListByProcessId(&lt;generated&gt;)         at org.apache.dolphinscheduler.api.controller.ProcessInstanceController.queryTaskListByProcessId(ProcessInstanceController.java:133)         at sun.reflect.GeneratedMethodAccessor564.invoke(Unknown Source)         at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)         at java.lang.reflect.Method.invoke(Method.java:498)         at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:189)         at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138)         at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102)         at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)         at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:800)         at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)         at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1038)         at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942)         at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1005)         at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:897)         at javax.servlet.http.HttpServlet.service(HttpServlet.java:687)         at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:882)         at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)         at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:867)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1623)         at com.github.xiaoymin.swaggerbootstrapui.filter.SecurityBasicAuthFilter.doFilter(SecurityBasicAuthFilter.java:84)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1610)         at com.github.xiaoymin.swaggerbootstrapui.filter.ProductionSecurityFilter.doFilter(ProductionSecurityFilter.java:53)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1610)         at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1610)         at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:92)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1610)         at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1610)         at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1610)         at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:540)         at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:146)         at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)         at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)         at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:257)         at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1588)         at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)         at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1345)         at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)         at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:480)         at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1557)         at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)         at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1247)         at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)         at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)         at org.eclipse.jetty.server.Server.handle(Server.java:502)         at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:364)         at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260)         at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:305)         at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)         at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)         at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)         at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)         at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)         at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)         at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)         at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:765)         at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:683)         at java.lang.Thread.run(Thread.java:748)  之前一直没出问题，大意了，看来还是得每天检查调度才行</body>
		<created>2020-08-03 01:57:42</created>
		<closed>2020-09-02 10:05:59</closed>
	</bug>
	<bug>
		<id>3366</id>
		<title>工作流实例中可以编辑上线的工作流</title>
		<body>![image](https://user-images.githubusercontent.com/61308609/89017904-9c831400-d34d-11ea-9a11-c4d8122f5a23.png) 上线了的工作流,从工作流实例中进入查看日志,可以进行工作流的编辑保存</body>
		<created>2020-07-31 08:48:43</created>
		<closed>2020-08-03 02:50:53</closed>
	</bug>
	<bug>
		<id>3364</id>
		<title>After update the version from 1.2.0 to 1.3.1,running the spark task fail because the can't find the jar</title>
		<body>*For better global communication, please give priority to using English description, thx! *  *Please review https://dolphinscheduler.apache.org/en-us/docs/development/issue.html when describe an issue.*  **Describe the question** 1.2.0升级1.3.1 由于任务Json格式变更导致Spark任务找不到Jar包 任务报错 ClassNotFound 即便应用了升级Mysql脚本 Json格式也没有变成1.3可以识别的Json格式 升级脚本是否没有对Spark任务 做升级变更处理？？？  又或者是1.3.1没有兼容1.2.0的任务？？？？  导致我必须 把所有Spark类型的任务 都要重新编辑一下 保存 刷新成1.3.1的Json格式才可以执行。。。  **Which version of DolphinScheduler:**  -[1.3.1-preview]  **Additional context**    **Requirement or improvement** - Please describe about your requirements or improvement suggestions. </body>
		<created>2020-07-31 03:56:02</created>
		<closed>2020-08-10 07:42:12</closed>
	</bug>
	<bug>
		<id>3357</id>
		<title>[Bug][front end] Select the dag connection to pop up the label edit box</title>
		<body>**Describe the bug** Normally select the dag connection, the label edit box should not pop up   **Which version of Dolphin Scheduler:**  -[1.3.2-release]  </body>
		<created>2020-07-30 05:35:02</created>
		<closed>2020-07-30 08:02:16</closed>
	</bug>
	<bug>
		<id>3340</id>
		<title>dolphinscheduler 1.3.1版本部署 登录不上</title>
		<body>我按照官方文档，部署出来，在登录页面输入用户名密码点击登录，闪了一下，又出现了登录页面，有没有遇到过得，该怎么解决呢</body>
		<created>2020-07-29 02:46:37</created>
		<closed>2020-08-03 03:28:06</closed>
	</bug>
	<bug>
		<id>3339</id>
		<title>执行任务 ssh Host key verification failed   出个大佬远程解决一哈。compensation</title>
		<body>![image](https://user-images.githubusercontent.com/58324759/88748532-d56f8d00-d183-11ea-81a8-de59a524b482.png) 如果用ds部署用户创建一个租户 就会一直在执行</body>
		<created>2020-07-29 02:12:07</created>
		<closed>2020-08-03 03:32:49</closed>
	</bug>
	<bug>
		<id>3299</id>
		<title>[Bug][Alert] when master or worker shutdown, alert cannot notify</title>
		<body>This error log: `[ERROR] 2020-07-22 11:00:22.209 org.apache.dolphinscheduler.common.utils.JSONUtils:[145] - parse list exception! com.fasterxml.jackson.databind.JsonMappingException: Unexpected character (''' (code 39)): was expecting double-quote to start field name  at [Source: (String)"[{'type':'WORKER','host':'/dolphinscheduler/nodes/worker/hadoop/192.168.0.3:5678','event':'server down','warning level':'serious'}]"; line: 1, column: 2] (through reference chain: java.util.ArrayList[0])         at com.fasterxml.jackson.databind.JsonMappingException.wrapWithPath(JsonMappingException.java:394)         at com.fasterxml.jackson.databind.JsonMappingException.wrapWithPath(JsonMappingException.java:365)         at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:302)         at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:245)         at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:27)         at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4013)         at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3042)         at org.apache.dolphinscheduler.common.utils.JSONUtils.toList(JSONUtils.java:143)`  I think the reason for this is that Jackson can't parse JSON fields with single quotes.</body>
		<created>2020-07-24 06:06:25</created>
		<closed>2020-08-19 08:27:40</closed>
	</bug>
	<bug>
		<id>3295</id>
		<title>When I create a scheduler directly through the api, a NullPointerException will appear when the processInstancePriority field is not passed. he is @RequestParam(value = "processInstancePriority", required = false)</title>
		<body> ![image](https://user-images.githubusercontent.com/34977303/88355113-e1c7a480-cd95-11ea-8cfa-9d34d866cb08.png)  error line  ![image](https://user-images.githubusercontent.com/34977303/88355156-10457f80-cd96-11ea-8e3f-31170d6fdff6.png)  Do you need to modify it to @RequestParam(value = "processInstancePriority", required = true)</body>
		<created>2020-07-24 02:12:26</created>
		<closed>2020-07-29 11:03:25</closed>
	</bug>
	<bug>
		<id>3273</id>
		<title>[Bug][Module Name] Bug title dolphinscheduler keytab认证bug</title>
		<body>[INFO] 2020-07-22 13:59:04.784  - [taskAppId=TASK-22-93-102]:[415] - find app id: application_1595373507922_23374 [ERROR] 2020-07-22 13:59:04.942 org.apache.dolphinscheduler.common.utils.HadoopUtils:[172] - Can't get Kerberos realm java.lang.IllegalArgumentException: Can't get Kerberos realm at org.apache.hadoop.security.HadoopKerberosName.setConfiguration(HadoopKerberosName.java:65) at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:276) at org.apache.hadoop.security.UserGroupInformation.setConfiguration(UserGroupInformation.java:312) at org.apache.dolphinscheduler.common.utils.HadoopUtils.init(HadoopUtils.java:123) at org.apache.dolphinscheduler.common.utils.HadoopUtils.&lt;init&gt;(HadoopUtils.java:81) at org.apache.dolphinscheduler.common.utils.HadoopUtils.&lt;init&gt;(HadoopUtils.java:54) at org.apache.dolphinscheduler.common.utils.HadoopUtils$1.load(HadoopUtils.java:71) at org.apache.dolphinscheduler.common.utils.HadoopUtils$1.load(HadoopUtils.java:68) at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3628) at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2336) at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2295) at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2208) at com.google.common.cache.LocalCache.get(LocalCache.java:4053) at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:4057) at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4986) at com.google.common.cache.LocalCache$LocalLoadingCache.getUnchecked(LocalCache.java:4992) at org.apache.dolphinscheduler.common.utils.HadoopUtils.getInstance(HadoopUtils.java:87) at org.apache.dolphinscheduler.server.worker.task.AbstractCommandExecutor.isSuccessOfYarnState(AbstractCommandExecutor.java:374) at org.apache.dolphinscheduler.server.worker.task.AbstractCommandExecutor.run(AbstractCommandExecutor.java:218) at org.apache.dolphinscheduler.server.worker.task.shell.ShellTask.handle(ShellTask.java:95) at org.apache.dolphinscheduler.server.worker.runner.TaskExecuteThread.run(TaskExecuteThread.java:129) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Caused by: java.lang.reflect.InvocationTargetException: null at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.hadoop.security.authentication.util.KerberosUtil.getDefaultRealm(KerberosUtil.java:84) at org.apache.hadoop.security.HadoopKerberosName.setConfiguration(HadoopKerberosName.java:63) ... 25 common frames omitted Caused by: sun.security.krb5.KrbException: Cannot locate default realm at sun.security.krb5.Config.getDefaultRealm(Config.java:1029) ... 31 common frames omitted [ERROR] 2020-07-22 13:59:04.944 org.apache.dolphinscheduler.common.utils.HadoopUtils:[102] - null java.lang.NullPointerException: null at org.apache.dolphinscheduler.common.utils.HadoopUtils.initHdfsPath(HadoopUtils.java:98) at org.apache.dolphinscheduler.common.utils.HadoopUtils.&lt;init&gt;(HadoopUtils.java:82) at org.apache.dolphinscheduler.common.utils.HadoopUtils.&lt;init&gt;(HadoopUtils.java:54) at org.apache.dolphinscheduler.common.utils.HadoopUtils$1.load(HadoopUtils.java:71) at org.apache.dolphinscheduler.common.utils.HadoopUtils$1.load(HadoopUtils.java:68) at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3628) at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2336) at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2295) at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2208) at com.google.common.cache.LocalCache.get(LocalCache.java:4053) at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:4057) at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4986) at com.google.common.cache.LocalCache$LocalLoadingCache.getUnchecked(LocalCache.java:4992) at org.apache.dolphinscheduler.common.utils.HadoopUtils.getInstance(HadoopUtils.java:87) at org.apache.dolphinscheduler.server.worker.task.AbstractCommandExecutor.isSuccessOfYarnState(AbstractCommandExecutor.java:374) at org.apache.dolphinscheduler.server.worker.task.AbstractCommandExecutor.run(AbstractCommandExecutor.java:218) at org.apache.dolphinscheduler.server.worker.task.shell.ShellTask.handle(ShellTask.java:95) at org.apache.dolphinscheduler.server.worker.runner.TaskExecuteThread.run(TaskExecuteThread.java:129) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)</body>
		<created>2020-07-22 06:40:39</created>
		<closed>2020-09-02 09:29:41</closed>
	</bug>
	<bug>
		<id>3266</id>
		<title>[Bug][User Login] Lower version chrome can't access login page </title>
		<body>If you access dophin index use chrome which version is less than 40.x，you will can't access the log page, always loading! ![image](https://user-images.githubusercontent.com/13913085/88068063-4a4e3000-cba2-11ea-8f08-43a99518ef4f.png) througth the linux  background log，you can get the message :"user does not exist" and "session info is null" ![image](https://user-images.githubusercontent.com/13913085/88068265-8e413500-cba2-11ea-82d8-f6f19ddd9a6d.png)  for solving the problem，you can use upgrade the chrome to 70.x , or use firefox. but you can't use IE，becuase It still have some problem.  so think if dolphinscheduler check the browser version，and tip user，It will  save lots of time to debug!  </body>
		<created>2020-07-21 14:42:35</created>
		<closed>2020-07-22 06:19:32</closed>
	</bug>
	<bug>
		<id>3262</id>
		<title>[Bug][dolphinscheduler-common]  When you request the URL through applicationID to get the application status, you cannot get it if Kerberos authentication is enabled</title>
		<body>When you request the URL through applicationID to get the application status, you cannot get it if Kerberos authentication is enabled eg: ![image](https://user-images.githubusercontent.com/59079269/88059613-b0818580-cb97-11ea-892b-3c3f94c32652.png)  yarn.application.status.address=http://ark1:8088/ws/v1/cluster/apps/%s  </body>
		<created>2020-07-21 13:20:54</created>
		<closed>2020-08-10 07:18:01</closed>
	</bug>
	<bug>
		<id>3258</id>
		<title>[Bug][Security][Worker group manage] Connot get create time and update time,report DateTimeParseException</title>
		<body>`[ERROR] 2020-07-21 15:04:34.683 org.apache.dolphinscheduler.common.utils.DateUtils:[122] - error while parse date:25.83 java.time.format.DateTimeParseException: Text '25.83' could not be parsed at index 0         at java.time.format.DateTimeFormatter.parseResolved0(DateTimeFormatter.java:1949)         at java.time.format.DateTimeFormatter.parse(DateTimeFormatter.java:1851)         at java.time.LocalDateTime.parse(LocalDateTime.java:492)         at org.apache.dolphinscheduler.common.utils.DateUtils.parse(DateUtils.java:119)         at org.apache.dolphinscheduler.common.utils.DateUtils.stringToDate(DateUtils.java:135)         at org.apache.dolphinscheduler.api.service.WorkerGroupService.getWorkerGroups(WorkerGroupService.java:152)         at org.apache.dolphinscheduler.api.service.WorkerGroupService.queryAllGroupPaging(WorkerGroupService.java:74)         at org.apache.dolphinscheduler.api.controller.WorkerGroupController.queryAllWorkerGroupsPaging(WorkerGroupController.java:84)`  Please see image ![image](https://user-images.githubusercontent.com/42576980/88023872-6337f080-cb64-11ea-8a55-a74f37e65250.png) </body>
		<created>2020-07-21 07:11:19</created>
		<closed>2020-07-22 03:50:20</closed>
	</bug>
	<bug>
		<id>3240</id>
		<title>[Bug][worker] Cannot find a (Map) Key deserializer for type</title>
		<body>When I execute SQL query task, JSON parsing error   error info : ````  com.fasterxml.jackson.databind.exc.InvalidDefinitionException:  Cannot find a (Map) Key deserializer for type [simple type, class org.apache.dolphinscheduler.dao.entity.UdfFunc]     `````   ![image](https://user-images.githubusercontent.com/39816903/87851699-ecb1ad80-c92d-11ea-8c3d-820f38f5d68d.png)     show code :    TaskExecutionContext taskExecutionContext = JSONUtils.parseObject(contextJson, TaskExecutionContext.class); ![image](https://user-images.githubusercontent.com/39816903/87851753-69448c00-c92e-11ea-94e0-36b45135e533.png)   contextJson:   ```  {     "taskInstanceId":2,     "taskName":"SQL-QUERY",     "startTime":"2020-07-18 19:18:58",     "taskType":"SQL",     "host":null,     "executePath":"/tmp/dolphinscheduler/exec/process/2/17/2/2",     "logPath":null,     "taskJson":"{"id":"tasks-5736","name":"SQL-QUERY","desc":null,"type":"SQL","runFlag":"NORMAL","loc":null,"maxRetryTimes":0,"retryInterval":1,"params":{"type":"MYSQL","datasource":3,"sql":"SELECT * FROM person","udfs":"","sqlType":"0","title":"SQL-QUERY","receivers":"zhangboyi_mx@163.com","receiversCc":"","showType":"TABLE","localParams":[],"connParams":"","preStatements":[],"postStatements":[]},"preTasks":[],"extras":null,"depList":[],"dependence":{},"conditionResult":{"successNode":[""],"failedNode":[""]},"taskInstancePriority":"MEDIUM","workerGroup":"default","workerGroupId":null,"timeout":{"strategy":"","interval":null,"enable":false},"conditionsTask":false,"forbidden":false,"taskTimeoutParameter":{"enable":false,"strategy":null,"interval":0}}",     "processId":0,     "appIds":null,     "processInstanceId":2,     "scheduleTime":null,     "globalParams":null,     "executorId":2,     "cmdTypeIfComplement":0,     "tenantCode":"sysadmin",     "queue":"default",     "processDefineId":17,     "projectId":2,     "taskParams":null,     "envFile":null,     "definedParams":null,     "taskAppId":null,     "taskTimeoutStrategy":0,     "taskTimeout":0,     "workerGroup":"default",     "resources":{      },     "sqlTaskExecutionContext":{         "warningGroupId":0,         "connectionParams":"{"type":null,"address":"jdbc:mysql://127.0.0.1:3306","database":"test","jdbcUrl":"jdbc:mysql://127.0.0.1:3306/test","user":"root","password":"IUAjJCVeJipyb290"}",         "udfFuncTenantCodeMap":null     },     "dataxTaskExecutionContext":{         "dataSourceId":0,         "sourcetype":0,         "sourceConnectionParams":null,         "dataTargetId":0,         "targetType":0,         "targetConnectionParams":null     },     "dependenceTaskExecutionContext":null,     "sqoopTaskExecutionContext":{         "dataSourceId":0,         "sourcetype":0,         "sourceConnectionParams":null,         "dataTargetId":0,         "targetType":0,         "targetConnectionParams":null     },     "procedureTaskExecutionContext":{         "connectionParams":null     } }   ```     test  unit :  ```   public class TaskExecuteProcessorTest {      @Test     public void testJson(){         String contextJson = "{\n" +                 "    \"taskInstanceId\":2,\n" +                 "    \"taskName\":\"SQL-QUERY\",\n" +                 "    \"startTime\":\"2020-07-18 19:18:58\",\n" +                 "    \"taskType\":\"SQL\",\n" +                 "    \"host\":null,\n" +                 "    \"executePath\":\"/tmp/dolphinscheduler/exec/process/2/17/2/2\",\n" +                 "    \"logPath\":null,\n" +                 "    \"taskJson\":\"{\"id\":\"tasks-5736\",\"name\":\"SQL-QUERY\",\"desc\":null,\"type\":\"SQL\",\"runFlag\":\"NORMAL\",\"loc\":null,\"maxRetryTimes\":0,\"retryInterval\":1,\"params\":{\"type\":\"MYSQL\",\"datasource\":3,\"sql\":\"SELECT * FROM person\",\"udfs\":\"\",\"sqlType\":\"0\",\"title\":\"SQL-QUERY\",\"receivers\":\"zhangboyi_mx@163.com\",\"receiversCc\":\"\",\"showType\":\"TABLE\",\"localParams\":[],\"connParams\":\"\",\"preStatements\":[],\"postStatements\":[]},\"preTasks\":[],\"extras\":null,\"depList\":[],\"dependence\":{},\"conditionResult\":{\"successNode\":[\"\"],\"failedNode\":[\"\"]},\"taskInstancePriority\":\"MEDIUM\",\"workerGroup\":\"default\",\"workerGroupId\":null,\"timeout\":{\"strategy\":\"\",\"interval\":null,\"enable\":false},\"conditionsTask\":false,\"forbidden\":false,\"taskTimeoutParameter\":{\"enable\":false,\"strategy\":null,\"interval\":0}}\",\n" +                 "    \"processId\":0,\n" +                 "    \"appIds\":null,\n" +                 "    \"processInstanceId\":2,\n" +                 "    \"scheduleTime\":null,\n" +                 "    \"globalParams\":null,\n" +                 "    \"executorId\":2,\n" +                 "    \"cmdTypeIfComplement\":0,\n" +                 "    \"tenantCode\":\"sysadmin\",\n" +                 "    \"queue\":\"default\",\n" +                 "    \"processDefineId\":17,\n" +                 "    \"projectId\":2,\n" +                 "    \"taskParams\":null,\n" +                 "    \"envFile\":null,\n" +                 "    \"definedParams\":null,\n" +                 "    \"taskAppId\":null,\n" +                 "    \"taskTimeoutStrategy\":0,\n" +                 "    \"taskTimeout\":0,\n" +                 "    \"workerGroup\":\"default\",\n" +                 "    \"resources\":{\n" +                 "\n" +                 "    },\n" +                 "    \"sqlTaskExecutionContext\":{\n" +                 "        \"warningGroupId\":0,\n" +                 "        \"connectionParams\":\"{\"type\":null,\"address\":\"jdbc:mysql://127.0.0.1:3306\",\"database\":\"test\",\"jdbcUrl\":\"jdbc:mysql://127.0.0.1:3306/test\",\"user\":\"root\",\"password\":\"IUAjJCVeJipyb290\"}\",\n" +                 "        \"udfFuncTenantCodeMap\":null\n" +                 "    },\n" +                 "    \"dataxTaskExecutionContext\":{\n" +                 "        \"dataSourceId\":0,\n" +                 "        \"sourcetype\":0,\n" +                 "        \"sourceConnectionParams\":null,\n" +                 "        \"dataTargetId\":0,\n" +                 "        \"targetType\":0,\n" +                 "        \"targetConnectionParams\":null\n" +                 "    },\n" +                 "    \"dependenceTaskExecutionContext\":null,\n" +                 "    \"sqoopTaskExecutionContext\":{\n" +                 "        \"dataSourceId\":0,\n" +                 "        \"sourcetype\":0,\n" +                 "        \"sourceConnectionParams\":null,\n" +                 "        \"dataTargetId\":0,\n" +                 "        \"targetType\":0,\n" +                 "        \"targetConnectionParams\":null\n" +                 "    },\n" +                 "    \"procedureTaskExecutionContext\":{\n" +                 "        \"connectionParams\":null\n" +                 "    }\n" +                 "}" ;          TaskExecutionContext taskExecutionContext = JSONUtils.parseObject(contextJson, TaskExecutionContext.class);          assertTrue(taskExecutionContext != null);     } } ```  error info : ``` Connected to the target VM, address: '127.0.0.1:53429', transport: 'socket' 19:43:31.405 [main] ERROR org.apache.dolphinscheduler.common.utils.JSONUtils - parse object exception! com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Cannot find a (Map) Key deserializer for type [simple type, class org.apache.dolphinscheduler.dao.entity.UdfFunc]  at [Source: (String)"{     "taskInstanceId":2,     "taskName":"SQL-QUERY",     "startTime":"2020-07-18 19:18:58",     "taskType":"SQL",     "host":null,     "executePath":"/tmp/dolphinscheduler/exec/process/2/17/2/2",     "logPath":null,     "taskJson":"{"id":"tasks-5736","name":"SQL-QUERY","desc":null,"type":"SQL","runFlag":"NORMAL","loc":null,"maxRetryTimes":0,"retryInterval":1,"params":{"type":"MYSQL","datasource":3,"sql":"SELECT * FROM person","udfs":"","sqlType":"0","title":"SQL-QUERY","receivers":"zhangboyi_mx"[truncated 1787 chars]; line: 1, column: 1] at com.fasterxml.jackson.databind.exc.InvalidDefinitionException.from(InvalidDefinitionException.java:67) at com.fasterxml.jackson.databind.DeserializationContext.reportBadDefinition(DeserializationContext.java:1452) at com.fasterxml.jackson.databind.deser.DeserializerCache._handleUnknownKeyDeserializer(DeserializerCache.java:599) at com.fasterxml.jackson.databind.deser.DeserializerCache.findKeyDeserializer(DeserializerCache.java:168) at com.fasterxml.jackson.databind.DeserializationContext.findKeyDeserializer(DeserializationContext.java:500) at com.fasterxml.jackson.databind.deser.std.MapDeserializer.createContextual(MapDeserializer.java:248) at com.fasterxml.jackson.databind.DeserializationContext.handlePrimaryContextualization(DeserializationContext.java:651) at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.resolve(BeanDeserializerBase.java:484) at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:293) at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244) at com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142) at com.fasterxml.jackson.databind.DeserializationContext.findNonContextualValueDeserializer(DeserializationContext.java:467) at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.resolve(BeanDeserializerBase.java:473) at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:293) at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244) at com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142) at com.fasterxml.jackson.databind.DeserializationContext.findRootValueDeserializer(DeserializationContext.java:477) at com.fasterxml.jackson.databind.ObjectMapper._findRootDeserializer(ObjectMapper.java:4190) at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4009) at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3004) at org.apache.dolphinscheduler.common.utils.JSONUtils.parseObject(JSONUtils.java:108) at org.apache.dolphinscheduler.server.worker.processor.TaskExecuteProcessorTest.testJson(TaskExecuteProcessorTest.java:71) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33) at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:230) at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:58) Disconnected from the target VM, address: '127.0.0.1:53429', transport: 'socket'  java.lang.AssertionError at org.junit.Assert.fail(Assert.java:86) at org.junit.Assert.assertTrue(Assert.java:41) at org.junit.Assert.assertTrue(Assert.java:52) at org.apache.dolphinscheduler.server.worker.processor.TaskExecuteProcessorTest.testJson(TaskExecuteProcessorTest.java:73) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33) at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:230) at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:58)  ``` </body>
		<created>2020-07-18 11:39:43</created>
		<closed>2020-07-21 10:54:08</closed>
	</bug>
	<bug>
		<id>3238</id>
		<title>[Bug][Resource Center] Can not create folder in docker with standalone mode</title>
		<body>Creating a folder in the Resource Center failed.  1. build docker images by default Dockerfile 2. run docker with args ALL 3. open resource center, and create a folder 4. See error  **Which version of Dolphin Scheduler:**  -[1.3.1]  **Additional context** The error info in logs is :  NulPointer Error in createDirecortry(ResourceService.java:484) It seems to be a HDFS error. but in DOC, the local fs is supported.  And then，I modify the common config file, change the storage.type from NONE to HDFS, but still failed.  i want to evaluate dolphinscheduler quickly, but it's not very easy -_-b Please consider being able to quickly evaluate the software through docker. </body>
		<created>2020-07-18 09:25:05</created>
		<closed>2020-09-21 09:14:06</closed>
	</bug>
	<bug>
		<id>3236</id>
		<title>[Bug][DagHelper] Time complexity is O(N^N)</title>
		<body>function  getFlowNodeListPost's  time complexity is O(N^N) </body>
		<created>2020-07-18 08:09:25</created>
		<closed>2020-07-22 06:27:06</closed>
	</bug>
	<bug>
		<id>3217</id>
		<title>[Bug][worker] There are no worker groups generated in zk, and task instances are not executed</title>
		<body>1. Configure worker group cxc, execute sh install.sh, check the worker group in zk, no cxc group is generated ![image](https://user-images.githubusercontent.com/55787491/87510643-86ffc000-c6a6-11ea-93eb-72cf6a98ac66.png) ![image](https://user-images.githubusercontent.com/55787491/87510656-8d8e3780-c6a6-11ea-9790-09440583bccc.png)  2. Run the workflow, the task is not executed ![image](https://user-images.githubusercontent.com/55787491/87510696-9ed74400-c6a6-11ea-9db7-b94243f0ee96.png)  **Which version of Dolphin Scheduler:**  -[dev]</body>
		<created>2020-07-15 06:25:06</created>
		<closed>2020-08-27 01:45:04</closed>
	</bug>
	<bug>
		<id>3213</id>
		<title>shell脚本ssh root@host 出现主机秘钥验证失败</title>
		<body>![image](https://user-images.githubusercontent.com/58324759/87498100-9f151680-c689-11ea-9b5a-a20fa6b27cda.png)  ![image](https://user-images.githubusercontent.com/58324759/87498155-b522d700-c689-11ea-9075-1592341b7246.png) 会报错这样的信息。主机用户各种免密已经做了。在liunx上进行操作没有问题。就是在ds上会报错。找不到问题在哪里   </body>
		<created>2020-07-15 02:56:24</created>
		<closed>2020-07-15 04:33:21</closed>
	</bug>
	<bug>
		<id>3211</id>
		<title>[Bug][api] Error enMsg zhMsg in Status.PROCESS_NODE_S_PARAMETER_INVALID</title>
		<body>**Describe the bug** When build the error message, it will show `流程节点[%s]参数无效` or `process node %s parameter invalid`, do not fill the `%s` parameter.  **Screenshots** 1.3.1-release ![image](https://user-images.githubusercontent.com/29545877/87495265-84d83a00-c683-11ea-8332-81ed4760e29d.png) 1.2.1-release ![image](https://user-images.githubusercontent.com/29545877/87523102-09917b00-c6b9-11ea-9245-e5052c7404ed.png) 1.2.0-release ![image](https://user-images.githubusercontent.com/29545877/87523355-6a20b800-c6b9-11ea-9543-96058b07dbac.png)  **Which version of Dolphin Scheduler:**  -[1.3.1-release]  -[1.2.1-release]  -[1.2.0-release]  **Requirement or improvement** - Change `%s` to `{0}` </body>
		<created>2020-07-15 02:13:31</created>
		<closed>2020-07-15 11:39:58</closed>
	</bug>
	<bug>
		<id>3204</id>
		<title>[Bug][Module Name] Bug title </title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** A clear and concise description of what the bug is.  **To Reproduce** Steps to reproduce the behavior, for example: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error  **Expected behavior** A clear and concise description of what you expected to happen.  **Screenshots** If applicable, add screenshots to help explain your problem.   **Which version of Dolphin Scheduler:**  -[1.1.0-preview]  **Additional context** Add any other context about the problem here.  **Requirement or improvement** - Please describe about your requirements or improvement suggestions. </body>
		<created>2020-07-13 11:09:43</created>
		<closed>2020-07-13 11:09:50</closed>
	</bug>
	<bug>
		<id>3198</id>
		<title>[Bug]default JVM parameter bug</title>
		<body>dolphinscheduler-daemon.sh    Setting '-XX:+DisableExplicitGC ' causes netty memory leaks   in addition    Set '- xms1g' but '- XX: largepagesizeinbytes = 128M'   It is recommended that "-XX:LargePageSizeInBytes" be set to 10m or remove this parameter     If the problem exists, I will fix it    </body>
		<created>2020-07-12 16:50:33</created>
		<closed>2020-07-23 03:01:18</closed>
	</bug>
	<bug>
		<id>3187</id>
		<title>[BUG] Heartbeat thread pool does not shutdown when MasterRegistry unRegistry</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** look at the method of MasterRegistry ```java     public void unRegistry() {         String address = getLocalAddress();         String localNodePath = getMasterPath();         zookeeperRegistryCenter.getZookeeperCachedOperator().remove(localNodePath);         logger.info("master node : {} unRegistry to ZK.", address);     } ``` The method, which is invoke when close the MasterServer, does not shutdown the Heartbeat thread pool.</body>
		<created>2020-07-10 17:28:52</created>
		<closed>2020-07-13 06:27:39</closed>
	</bug>
	<bug>
		<id>3181</id>
		<title>[BUG] get http code 400 bad request with AWS S3 as resource storage type</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** when you use AWS S3 as the resource storage backend you will get a error like:  ``` log Status Code: 400,  AWS Service: Amazon S3, AWS Request ID: xxxxxxx, AWS Error Code: null, AWS Error Message: Bad Request ```  **To Reproduce** Steps to reproduce the behavior, for example: just set `resource.storage.type=S3` in common.properties and also keep other configuration correct.  **Expected behavior** the resource centre work fine.  **Screenshots** when you try to upload a file at resource centre, you will get a error.   **Which version of Dolphin Scheduler:**  -[1.3.1-release]  **Additional context** it is because of the version of AWS S3 encryption method.  **Requirement or improvement** I will make a PR for this later. </body>
		<created>2020-07-10 11:30:13</created>
		<closed>2020-07-16 05:43:49</closed>
	</bug>
	<bug>
		<id>3179</id>
		<title>[BUG] cache  bug</title>
		<body> **Describe the bug**  ![image](https://user-images.githubusercontent.com/7700151/87138506-1a18ae80-c2d1-11ea-8a75-98af77b07589.png)  When I go to use it  ![image](https://user-images.githubusercontent.com/7700151/87138427-fd7c7680-c2d0-11ea-971d-02800505ba9b.png) </body>
		<created>2020-07-10 09:17:26</created>
		<closed>2020-07-15 01:58:51</closed>
	</bug>
	<bug>
		<id>3176</id>
		<title>[BUG] optimize #3165  Gets the value of this property “resource.storage.type”， Comparison with enumerated types </title>
		<body>By looking at the ResourcesService  code, I found a potential problem.  Enumeration type comparisons are used in both classes ：HadoopUtils.java ,CommonUtils.java  I don't think this [submission](https://github.com/apache/incubator-dolphinscheduler/pull/3166)  is perfect  All comparisons of ResUploadType need to be optimized.  I'm going to modify this part   中文：  通过阅读ResourcesService代码，发现了潜在隐患。  在HadoopUtils和CommonUtils,资源中心类型，都是通过枚举类型比较。  所以感觉到[submission](https://github.com/apache/incubator-dolphinscheduler/pull/3166) 这个提交是不完备的。   需要优化所有的ResUploadType类型比较部分的代码。 </body>
		<created>2020-07-10 06:05:07</created>
		<closed>2020-07-10 07:21:43</closed>
	</bug>
	<bug>
		<id>3165</id>
		<title>config resource.storage.type=hdfs throw exception need config  resource.storage.type=HDFS</title>
		<body>when i config common.properties , resource.storage.type=hdfs  will throw exception   ![image](https://user-images.githubusercontent.com/59079269/86872565-3cfb6500-c10f-11ea-802b-21fdf1003db7.png)  because Enumerated type comparisons do not ignore case。</body>
		<created>2020-07-08 03:37:44</created>
		<closed>2020-07-09 10:28:05</closed>
	</bug>
	<bug>
		<id>3157</id>
		<title>[BUG] netty server may start multiple times if multiple threads execute the start method</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** look at the code of NettyRemotingServer ```java     public void start(){          if(this.isStarted.get()){             return;         }          this.serverBootstrap                 .group(this.bossGroup, this.workGroup)                 .channel(NioServerSocketChannel.class)                 .option(ChannelOption.SO_REUSEADDR, true)                 .option(ChannelOption.SO_BACKLOG, serverConfig.getSoBacklog())                 .childOption(ChannelOption.SO_KEEPALIVE, serverConfig.isSoKeepalive())                 .childOption(ChannelOption.TCP_NODELAY, serverConfig.isTcpNoDelay())                 .childOption(ChannelOption.SO_SNDBUF, serverConfig.getSendBufferSize())                 .childOption(ChannelOption.SO_RCVBUF, serverConfig.getReceiveBufferSize())                 .childHandler(new ChannelInitializer&lt;NioSocketChannel&gt;() {                      @Override                     protected void initChannel(NioSocketChannel ch) throws Exception {                         initNettyChannel(ch);                     }                 });          ChannelFuture future;         try {             future = serverBootstrap.bind(serverConfig.getListenPort()).sync();         } catch (Exception e) {             logger.error("NettyRemotingServer bind fail {}, exit",e.getMessage(), e);             throw new RuntimeException(String.format("NettyRemotingServer bind %s fail", serverConfig.getListenPort()));         }         if (future.isSuccess()) {             logger.info("NettyRemotingServer bind success at port : {}", serverConfig.getListenPort());         } else if (future.cause() != null) {             throw new RuntimeException(String.format("NettyRemotingServer bind %s fail", serverConfig.getListenPort()), future.cause());         } else {             throw new RuntimeException(String.format("NettyRemotingServer bind %s fail", serverConfig.getListenPort()));         }         //         isStarted.compareAndSet(false, true);     } ``` If multiple threads execute the method at a time, it may start the netty server multiple times. **To Reproduce** Steps to reproduce the behavior, for example: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error  **Expected behavior** A clear and concise description of what you expected to happen.  **Screenshots** If applicable, add screenshots to help explain your problem.   **Which version of Dolphin Scheduler:**  -[1.1.0-preview]  **Additional context** Add any other context about the problem here.  **Requirement or improvement - Please describe about your requirements or improvement suggestions. </body>
		<created>2020-07-06 12:12:29</created>
		<closed>2020-07-07 10:45:21</closed>
	</bug>
	<bug>
		<id>3148</id>
		<title>[BUG] resource download error</title>
		<body>when resource file is under sub dir ,download goes error.</body>
		<created>2020-07-06 07:37:02</created>
		<closed>2020-07-16 12:42:03</closed>
	</bug>
	<bug>
		<id>3144</id>
		<title>[BUG]Batch scheduling sql tasks,  occasionally fail to send mail</title>
		<body>Occasionally this error occurs when sending mail concurrently ![image](https://user-images.githubusercontent.com/55787491/86552006-4fdc3100-bf79-11ea-8aad-b9c8509a4c15.png) ![image](https://user-images.githubusercontent.com/55787491/86552027-5d91b680-bf79-11ea-8440-4faa47a8740b.png) ![image](https://user-images.githubusercontent.com/55787491/86552031-61bdd400-bf79-11ea-8721-02c5e7f5b823.png) ![image](https://user-images.githubusercontent.com/55787491/86552170-c5480180-bf79-11ea-8f7a-abf200bfea98.png)  **Which version of Dolphin Scheduler:**  -[1.3.0] </body>
		<created>2020-07-06 03:11:31</created>
		<closed>2020-07-28 03:16:17</closed>
	</bug>
	<bug>
		<id>3140</id>
		<title>[BUG] Embed zookeeper server 'ZKServer' has deadlock problem</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** look at the code snippet ```java     private static synchronized void startLocalZkServer(final int port, final String dataDirPath,final int tickTime,String maxClientCnxns) {         if (zkServer != null) {             throw new RuntimeException("Zookeeper server is already started!");         }         zkServer = new PublicZooKeeperServerMain();         logger.info("Zookeeper data path : {} ", dataDirPath);         dataDir = dataDirPath;         final String[] args = new String[]{Integer.toString(port), dataDirPath, Integer.toString(tickTime), maxClientCnxns};          try {             logger.info("Zookeeper server started ");             isStarted.compareAndSet(false, true);              zkServer.initializeAndRun(args);         } catch (QuorumPeerConfig.ConfigException e) {             logger.warn("Caught exception while starting ZK", e);         } catch (IOException e) {             logger.warn("Caught exception while starting ZK", e);         }     } ``` The above start method will acquire the lock of the ZKServer class. But the line "zkServer.initializeAndRun(args);" will block until the application exit. So it will never release the lock. ```java     private static synchronized void stopLocalZkServer(final boolean deleteDataDir) {         // 省略     } ``` The above stop method try to acquire the lock of the ZKServer class, but it will never succeed. **To Reproduce** Steps to reproduce the behavior, for example: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error  **Expected behavior** A clear and concise description of what you expected to happen.  **Screenshots** If applicable, add screenshots to help explain your problem.   **Which version of Dolphin Scheduler:**  -[1.1.0-preview]  **Additional context** Add any other context about the problem here.  **Requirement or improvement - Please describe about your requirements or improvement suggestions. </body>
		<created>2020-07-05 15:26:02</created>
		<closed>2020-07-13 10:52:34</closed>
	</bug>
	<bug>
		<id>3138</id>
		<title>[BUG] The app will try to reconnect the zookeeper server when it fails to initiate the connection.</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** If the app fails to initiate the connection to zookeeper server, the app will try to reconnect infinitely. The better practice is to fail fast.  **To Reproduce** Steps to reproduce the behavior, for example: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error  **Expected behavior** A clear and concise description of what you expected to happen.  **Screenshots** If applicable, add screenshots to help explain your problem.   **Which version of Dolphin Scheduler:**  -[1.1.0-preview]  **Additional context** Add any other context about the problem here.  **Requirement or improvement - Please describe about your requirements or improvement suggestions. </body>
		<created>2020-07-05 10:52:53</created>
		<closed>2020-07-09 12:27:42</closed>
	</bug>
	<bug>
		<id>3131</id>
		<title>[BUG] When the new tenant already exists, the prompt is incorrect</title>
		<body>1. Tenant cxc exists 2. When adding a tenant, fill in the tenant code cxc, the prompt is incorrect, as shown in the figure ![image](https://user-images.githubusercontent.com/55787491/86510027-ffe95700-be1e-11ea-9f2a-c4308243202b.png)  It should be reminded that the tenant already exists  **Which version of Dolphin Scheduler:**  -[1.3.1-release]  </body>
		<created>2020-07-04 09:54:11</created>
		<closed>2020-07-13 00:48:51</closed>
	</bug>
	<bug>
		<id>3125</id>
		<title>[BUG] Permission denied if not found dolphinscheder-env.sh</title>
		<body>when worker server execute the task , if not found dolphinscheder-env.sh, will get `System.getProperty("user.home") + File.separator + ".bash_profile"` , and it will lead to Permission denied error, something like ` [INFO] 2020-07-04 12:43:12.640  - [taskAppId=TASK-3-58-65]:[121] -  -&gt; /tmp/dolphinscheduler/exec/process/1/3/58/65/3_58_65.command: line 4: /Users/stone/.bash_profile: Permission denied`  the related code in CommonUtils.java ``` public static String getSystemEnvPath() {     String envPath = PropertyUtils.getString(Constants.DOLPHINSCHEDULER_ENV_PATH);     if (StringUtils.isEmpty(envPath)) {       URL envDefaultPath = CommonUtils.class.getClassLoader().getResource(Constants.ENV_PATH);        if (envDefaultPath != null){         envPath = envDefaultPath.getPath();         logger.debug("env path :{}", envPath);       }else{         envPath = System.getProperty("user.home") + File.separator + ".bash_profile";       }     }      return envPath;   }  ``` </body>
		<created>2020-07-04 05:16:41</created>
		<closed>2020-07-05 13:50:43</closed>
	</bug>
	<bug>
		<id>3121</id>
		<title>[BUG] Fix all the bug reported by Sonar</title>
		<body>**Describe the bug**  Fix all the bug report by sonar(https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;resolved=false&amp;types=BUG) </body>
		<created>2020-07-03 08:42:32</created>
		<closed>2020-07-13 04:44:14</closed>
	</bug>
	<bug>
		<id>3120</id>
		<title>[BUG] Format DAG bug [ the connection line disappears ]</title>
		<body>Format DAG bug [ the connection line disappears ]  1、click： ![image](https://user-images.githubusercontent.com/7700151/86439291-e373ee80-bd3a-11ea-9a5b-b178818e988a.png)  2、copy： ![image](https://user-images.githubusercontent.com/7700151/86439940-18cd0c00-bd3c-11ea-9324-566c609a7e36.png)   3、connect、format： ![image](https://user-images.githubusercontent.com/7700151/86440052-647fb580-bd3c-11ea-9b19-d29db13cfe9b.png)   4、line is gone： ![image](https://user-images.githubusercontent.com/7700151/86440078-6e091d80-bd3c-11ea-897c-912ff5d59875.png)  </body>
		<created>2020-07-03 06:44:13</created>
		<closed>2020-09-02 09:44:35</closed>
	</bug>
	<bug>
		<id>3116</id>
		<title>[BUG] Clicking the cancel button of the dag popup box triggers the event that the text input box loses focus</title>
		<body>*For better global communication, please give priority to using English description, thx! *  Describe the bug Clicking the cancel button of the dag popup box triggers the event that the text input box loses focus  To Reproduce 1. Double-click a node, and leave the node name blank 2. Then click the Cancel button  Which version of Dolphin Scheduler: -[dev]</body>
		<created>2020-07-02 09:57:51</created>
		<closed>2020-07-13 00:51:08</closed>
	</bug>
	<bug>
		<id>3112</id>
		<title>[BUG] Executing authorized sql-hive, UDF function resource path is incorrect</title>
		<body>1. Authorize the UDF resource and UDF function of the tenant cxc to the user A 2. The user A selects tenant cxc2 to execute sql-hive, the UDF resource to be searched is tenant cxc2,  the tenant should be searched to be cxc ![image](https://user-images.githubusercontent.com/55787491/86310585-04601500-bc51-11ea-9436-63fa78e4ed50.png)  **Which version of Dolphin Scheduler:**  -[1.3.1-release]  **Additional context** Add any other context about the problem here.  **Requirement or improvement - Please describe about your requirements or improvement suggestions. </body>
		<created>2020-07-02 02:44:56</created>
		<closed>2020-07-02 07:12:20</closed>
	</bug>
	<bug>
		<id>3111</id>
		<title>[BUG] Edit the node, after clicking Cancel, the node information is saved</title>
		<body>1. Edit the node information and click the cancel button 2. Check the node information, the node information is changed successfully ![image](https://user-images.githubusercontent.com/55787491/86308498-fd82d380-bc4b-11ea-840d-853a3816faed.png)  **Which version of Dolphin Scheduler:**  -[1.3.0]  **Additional context** Add any other context about the problem here.  **Requirement or improvement - Please describe about your requirements or improvement suggestions. </body>
		<created>2020-07-02 02:10:31</created>
		<closed>2020-07-02 07:13:10</closed>
	</bug>
	<bug>
		<id>3104</id>
		<title>[BUG] Wrong deletion of token</title>
		<body>For example:  The admin user sets a long-term valid token in token manage for API interface    But after logging in to the web page with admin  According to the following code, because there is no type distinction, the created token may be deleted by mistake   `    if (sessionList.size() &gt; 1){         for (int i=1 ; i &lt; sessionList.size();i++){           sessionMapper.deleteById(sessionList.get(i).getId());         }       }`   -----------------------------------   The complete code is as follows:  org.apache.dolphinscheduler.api.service.SessionService#createSession ` @Transactional(rollbackFor = Exception.class) public String createSession(User user, String ip) {     Session session = null;      // logined     List&lt;Session&gt; sessionList = sessionMapper.queryByUserId(user.getId());      Date now = new Date();      /**      * if you have logged in and are still valid, return directly      */     if (CollectionUtils.isNotEmpty(sessionList)) {       // is session list greater 1 ， delete other ，get one       if (sessionList.size() &gt; 1){         for (int i=1 ; i &lt; sessionList.size();i++){           sessionMapper.deleteById(sessionList.get(i).getId());         }       }       session = sessionList.get(0);       if (now.getTime() - session.getLastLoginTime().getTime() &lt;= Constants.SESSION_TIME_OUT * 1000) {         /**          * updateProcessInstance the latest login time          */         session.setLastLoginTime(now);         sessionMapper.updateById(session);          return session.getId();        } else {         /**          * session expired, then delete this session first          */         sessionMapper.deleteById(session.getId());       }     }      // assign new session     session = new Session();      session.setId(UUID.randomUUID().toString());     session.setIp(ip);     session.setUserId(user.getId());     session.setLastLoginTime(now);      sessionMapper.insert(session);      return session.getId(); } ` ------------------------------------  It is suggested to add a field to distinguish token management  The token created by the function. And the token generated by normal login operation       </body>
		<created>2020-07-01 02:58:38</created>
		<closed>2020-07-01 09:53:54</closed>
	</bug>
	<bug>
		<id>3096</id>
		<title>[BUG] In ambari plugin  the config options which has unit  doesn`t write unit into config file</title>
		<body>In ambari plugin  the config options which has unit  doesn`t write unit into config file。Parameters such as spring.servlet.multipart.max-file-size and spring.servlet.multipart.max-request-size, which are shown in units of MB on the Ambari interface, have no units when writing to the configuration file and are identified as KB</body>
		<created>2020-06-30 08:59:46</created>
		<closed>2020-07-14 08:11:59</closed>
	</bug>
	<bug>
		<id>3086</id>
		<title>[BUG] spark.vue 前端无法传到后台 主jar包 参数的名字</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** 使用spark task组件，主jar包名称在后台无法获取值  **To Reproduce** Steps to reproduce the behavior, for example: 1. 使用spark task 组件，输入各种参数，包括选择主jar包 2. 点击提交，前端发现只有id，没有jar包名称 3. 后台无法接收到主jar包名称，会在TaskScheduleThread类的copyHdfsToLocal()方法里面的File resFile = new File(execLocalPath, res);该出代码报空指针，res为null，res为主jar包的名称，前端传不过来，因此报空指针  **Screenshots** ![image](https://user-images.githubusercontent.com/52660126/86090008-e45b1500-badb-11ea-985b-a002430b12f6.png)  ![image](https://user-images.githubusercontent.com/52660126/86090341-7a8f3b00-badc-11ea-875a-19fa0b4fc248.png)  ![image](https://user-images.githubusercontent.com/52660126/86090752-436d5980-badd-11ea-9dcc-a4cbe865bacd.png)    **Which version of Dolphin Scheduler:**  -[1.3.0-preview] 我们的dolphinscheduler1.2.0的代码也有，1.3.0的代码也有，但是spark.vue用的是1.3.0的 </body>
		<created>2020-06-30 06:23:50</created>
		<closed>2020-06-30 14:27:03</closed>
	</bug>
	<bug>
		<id>3085</id>
		<title>[BUG] after zoom or drag the dag view, cant plcae node correctly and may be disappear</title>
		<body>**Describe the bug** After zoom or drag the dag view, cant plcae node correctly and may be disappear  **To Reproduce** 1. Go to 'project detail dag' 2. Scroll middle mouse button, zoom nodes 3. Drag new node into contaiment. (close to sidebar ) 4. See error, the new node diappear, or it cant place what we want.  **Expected behavior** When we drag new node into contaiment, it should not disappear. Because we do the correct thing, but something wrong happen.  **Screenshots**  ![no zoom](https://user-images.githubusercontent.com/40662353/86087052-d0acb000-bad5-11ea-827e-de9316d989a1.png) ![after zoom](https://user-images.githubusercontent.com/40662353/86087169-1a959600-bad6-11ea-858a-b9fc00cc74f0.png)   **Which version of Dolphin Scheduler:**  -[1.2.0 to latest version ]  **Additional context** After zooming (or drag #canvas element), the area of ​​the canvas and the outer area do not fit, causing the drag to fail. I try to fix this problem. There has two ways. 1. use jsplumb nativie method to support zoom. 2. modify dragZoom.js code, change the zoom beahavior.  I choose 2, I think this way lead to increased code complexity. Any suggetions? Should I create a PR? </body>
		<created>2020-06-30 05:34:19</created>
		<closed>2020-07-02 06:19:06</closed>
	</bug>
	<bug>
		<id>3077</id>
		<title>[BUG] repeated task name in one flow</title>
		<body>first add two different tasks,then rename one and keep both has a some name ,you will find you can save the flow with same name tasks.</body>
		<created>2020-06-29 11:37:26</created>
		<closed>2020-09-02 09:45:22</closed>
	</bug>
	<bug>
		<id>3070</id>
		<title>[BUG] have not enough thread when I just run one workflow</title>
		<body>1. when I'm running a workflow that contain  three flume task，I start other workflow，It stay in "waiting for thread" ![image](https://user-images.githubusercontent.com/13913085/85966119-5d317280-b9f1-11ea-896a-0e856c9a80be.png)  2. I check the linux Server, I found a lot of threads running by the MasterServer   ![image](https://user-images.githubusercontent.com/13913085/85966131-67ec0780-b9f1-11ea-95b8-0bf95e531b63.png)  3. The master log also show "have not enough thread" ![image](https://user-images.githubusercontent.com/13913085/85966867-9539b500-b9f3-11ea-90fc-150fed84ad4e.png) </body>
		<created>2020-06-29 02:15:16</created>
		<closed>2020-06-29 02:44:45</closed>
	</bug>
	<bug>
		<id>3067</id>
		<title>[BUG]  DEPENDENT node type is not supported since version 1.2.1-SNAPSHOT</title>
		<body>version 【1.2.1 】  When choosing to use the dependent node task, an error is reported during execution  `[ERROR] 2020-06-28 15:27:22.118-[taskAppId=TASK-341-240188-431977]:[75]-unsupport task type: DEPENDENT`  See below  &lt;img width="687" alt="微信图片_20200628175138" src="https://user-images.githubusercontent.com/38177161/85944264-0fbcf300-b968-11ea-89db-010d44850418.png"&gt;   code show as below  &lt;img width="647" alt="微信图片_20200628174034" src="https://user-images.githubusercontent.com/38177161/85944027-7fca7980-b966-11ea-8d13-e60f4cd3d5c0.png"&gt;  ==》https://github.com/apache/incubator-dolphinscheduler/blob/4946e88872ef943b5d0a739f213831daca3facd8/dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/task/TaskManager.java  </body>
		<created>2020-06-28 09:42:28</created>
		<closed>2020-06-29 02:47:44</closed>
	</bug>
	<bug>
		<id>3065</id>
		<title>why use the tenant configuration of the workflow in the downloadResource method of taskExecuteThread</title>
		<body>version:1.3.0 Why use the tenant configuration of the workflow in the downloadResource method of TaskExecuteThread. If a user is given resource permissions in user management, but the tenant of the running workflow is not a tenant of the resource, an error is reported that the resource file is not retrieved ============================== TaskExecuteThread的downloadResource 方法中使用工作流的租户配置。如果在用户管理中给用户分配了资源权限，但是运行的工作流的租户并不是资源上传用户的租户，那么就会报获取不到资源文件的错误 </body>
		<created>2020-06-28 08:26:18</created>
		<closed>2020-07-02 07:23:05</closed>
	</bug>
	<bug>
		<id>3059</id>
		<title>[BUG] Workflow definition display exception</title>
		<body> ![image](https://user-images.githubusercontent.com/39816903/85936097-cc439400-b929-11ea-86d8-5645cca34bcf.png) </body>
		<created>2020-06-28 02:26:55</created>
		<closed>2020-07-02 13:00:20</closed>
	</bug>
	<bug>
		<id>3058</id>
		<title>[BUG] 1.3.0 branch The task running order in the process instance does not follow the topological order in the process definition</title>
		<body>1. process definition ![1593309494(1)](https://user-images.githubusercontent.com/9334358/85935770-d9ab4f00-b926-11ea-9f69-52a9e11ad699.jpg) 2. task instance order in database ![72423ea1aafbee8b832e4798046dff7](https://user-images.githubusercontent.com/9334358/85935784-fa73a480-b926-11ea-93a2-aa89f2718f29.png) 3. task instance order in web ui ![image](https://user-images.githubusercontent.com/9334358/85935791-0b241a80-b927-11ea-9288-a61e66d0486b.png) 4.task instance order in process instance ![image](https://user-images.githubusercontent.com/9334358/85935795-1aa36380-b927-11ea-9532-99462048e24c.png)  The task running order in the process instance does not follow the topological order in the process definition, Why? </body>
		<created>2020-06-28 02:07:54</created>
		<closed>2020-08-15 02:18:39</closed>
	</bug>
	<bug>
		<id>3056</id>
		<title>[BUG] 1.20 branch, sometimes the login step will throw 502 bad gateway at first time.</title>
		<body>workaround: 1.reset the nginx export port 8888-&gt;xxxx 2.reload nginx config</body>
		<created>2020-06-27 11:43:18</created>
		<closed>2020-09-02 09:46:59</closed>
	</bug>
	<bug>
		<id>3045</id>
		<title>[Bug][ui] Define the port or pid of webUI monitor</title>
		<body>**Describe the bug** ![image](https://user-images.githubusercontent.com/29545877/85410356-91440800-b599-11ea-8836-407af5e0a47e.png)   **Which version of Dolphin Scheduler:**  -[dev] </body>
		<created>2020-06-23 13:36:34</created>
		<closed>2020-07-28 05:08:58</closed>
	</bug>
	<bug>
		<id>3039</id>
		<title>ds在运行过程中，经常出现某个节点长时间呈现灰色状态，无法启动的问题</title>
		<body>ds在运行过程中，经常出现某个工作节点无法启动，一直呈灰色圆圈状态。 ![微信图片_20200622204951](https://user-images.githubusercontent.com/32675415/85289463-12cc6500-b4ca-11ea-84e3-ce4d1c8118ee.png) ![微信图片_20200622205323](https://user-images.githubusercontent.com/32675415/85289704-7060b180-b4ca-11ea-9172-be1e3a9a9293.png) 最后只能kill掉，并重新启动。</body>
		<created>2020-06-22 12:52:16</created>
		<closed>2020-09-02 09:51:08</closed>
	</bug>
	<bug>
		<id>3036</id>
		<title>[BUG] I downloaded 1.3.0 and modified the configuration for installation after compiling. Then I found that the API service failed to start. The log is below</title>
		<body>[INFO] 2020-06-22 15:26:13.902 springfox.documentation.spring.web.scanners.ApiListingReferenceScanner:[41] - Scanning for api listing references [INFO] 2020-06-22 15:26:14.448 springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator:[40] - Generating unique operation named: viewTreeUsingGET_1 [INFO] 2020-06-22 15:26:14.526 springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator:[40] - Generating unique operation named: queryResourceListUsingGET_1 [INFO] 2020-06-22 15:26:14.718 org.eclipse.jetty.server.handler.ContextHandler.application:[2345] - Initializing Spring DispatcherServlet 'dispatcherServlet' 15:26:14.747 [main] ERROR org.springframework.boot.SpringApplication - Application run failed java.lang.NoClassDefFoundError: org/mortbay/log/Log         at com.sun.org.apache.commons.logging.JettyLog.&lt;init&gt;(JettyLog.java:36) ~[jsp-2.1-6.1.14.jar:6.1.14]         at com.sun.org.apache.commons.logging.LogFactory.getLog(LogFactory.java:35) ~[jsp-2.1-6.1.14.jar:6.1.14]         at org.apache.jasper.servlet.JspServlet.&lt;clinit&gt;(JspServlet.java:116) ~[jsp-2.1-6.1.14.jar:6.1.14]         at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_162]         at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_162]         at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_162]         at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_162]         at org.eclipse.jetty.server.handler.ContextHandler$Context.createInstance(ContextHandler.java:2649) ~[jetty-server-9.4.14.v20181114.jar:9.4.14.v20181114]         at org.eclipse.jetty.servlet.ServletContextHandler$Context.createServlet(ServletContextHandler.java:1366) ~[jetty-servlet-9.4.14.v20181114.jar:9.4.14.v20181114]         at org.eclipse.jetty.servlet.ServletHolder.newInstance(ServletHolder.java:1299) ~[jetty-servlet-9.4.14.v20181114.jar:9.4.14.v20181114]         at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:649) ~[jetty-servlet-9.4.14.v20181114.jar:9.4.14.v20181114]         at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:429) ~[jetty-servlet-9.4.14.v20181114.jar:9.4.14.v20181114]         at org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:750) ~[jetty-servlet-9.4.14.v20181114.jar:9.4.14.v20181114]         at java.util.stream.SortedOps$SizedRefSortingSink.end(SortedOps.java:352) ~[?:1.8.0_162]         at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) ~[?:1.8.0_162]         at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ~[?:1.8.0_162]         at java.util.stream.StreamSpliterators$WrappingSpliterator.forEachRemaining(StreamSpliterators.java:312) ~[?:1.8.0_162]         at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:743) ~[?:1.8.0_162]         at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) ~[?:1.8.0_162]         at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) ~[?:1.8.0_162]         at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:744) ~[jetty-servlet-9.4.14.v20181114.jar:9.4.14.v20181114]         at org.springframework.boot.web.embedded.jetty.JettyEmbeddedWebAppContext$JettyEmbeddedServletHandler.deferredInitialize(JettyEmbeddedWebAppContext.java:46) ~[spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.springframework.boot.web.embedded.jetty.JettyEmbeddedWebAppContext.deferredInitialize(JettyEmbeddedWebAppContext.java:36) ~[spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.springframework.boot.web.embedded.jetty.JettyWebServer.handleDeferredInitialize(JettyWebServer.java:221) ~[spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.springframework.boot.web.embedded.jetty.JettyWebServer.start(JettyWebServer.java:142) ~[spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.startWebServer(ServletWebServerApplicationContext.java:311) ~[spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.finishRefresh(ServletWebServerApplicationContext.java:164) ~[spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:552) ~[spring-context-5.1.5.RELEASE.jar:5.1.5.RELEASE]         at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) ~[spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) [spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) [spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) [spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) [spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) [spring-boot-2.1.3.RELEASE.jar:2.1.3.RELEASE]         at org.apache.dolphinscheduler.api.ApiApplicationServer.main(ApiApplicationServer.java:36) [dolphinscheduler-api-1.3.0.jar:1.3.0] Caused by: java.lang.ClassNotFoundException: org.mortbay.log.Log         at java.net.URLClassLoader.findClass(URLClassLoader.java:381) ~[?:1.8.0_162]         at java.lang.ClassLoader.loadClass(ClassLoader.java:424) ~[?:1.8.0_162]         at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:338) ~[?:1.8.0_162]         at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ~[?:1.8.0_162]         ... 35 more [INFO] 2020-06-22 15:26:14.776 org.apache.dolphinscheduler.remote.NettyRemotingClient:[376] - netty client closed [INFO] 2020-06-22 15:26:14.777 org.apache.dolphinscheduler.service.log.LogClientService:[59] - logger client closed [INFO] 2020-06-22 15:26:14.782 org.eclipse.jetty.server.session:[167] - node0 Stopped scavenging [INFO] 2020-06-22 15:26:14.785 org.eclipse.jetty.server.handler.ContextHandler.application:[2345] - Destroying Spring FrameworkServlet 'dispatcherServlet' [INFO] 2020-06-22 15:26:14.786 org.eclipse.jetty.server.handler.ContextHandler:[1045] - Stopped o.s.b.w.e.j.JettyEmbeddedWebAppContext@373052b5{application,/dolphinscheduler,[file:///tmp/jetty-docbase.5362881742322523107.12345/, jar:file:/apps/xinsight/tss/backend/lib/springfox-swagger-ui-2.9.2.jar!/META-INF/resources, jar:file:/apps/xinsight/tss/backend/lib/swagger-bootstrap-ui-1.9.3.jar!/META-INF/resources],UNAVAILABLE} </body>
		<created>2020-06-22 08:25:28</created>
		<closed>2020-06-24 05:45:40</closed>
	</bug>
	<bug>
		<id>3028</id>
		<title>[BUG] Front-end post wrong `strategy` value in timeout params</title>
		<body>**Describe the bug** Front-end post empty string `strategy` value in timeout params, and the master and worker will produce the `com.fasterxml.jackson.databind.exc.InvalidFormatException` because of the enum type of `strategy`.  **To Reproduce** 1. Create a new simple shell process definition in front-end. 2. I just fill the name and code of shell node, do not fill or select the other options. 3. Save the process definition and your will find out the front-end post the wrong empty string `strategy` in `timeout` of `processDefinitionJson`. 4.When you run the process definition, then master and worker will serde the processDefinitionJson to object, it will produce `com.fasterxml.jackson.databind.exc.InvalidFormatException` because of the enum type of `strategy`.  **Expected behavior** Front-end post empty string `strategy` value in timeout params.  **Screenshots** ![image](https://user-images.githubusercontent.com/29545877/85226686-72177000-b40b-11ea-98df-d8c7ef23940d.png) ![image](https://user-images.githubusercontent.com/29545877/85226754-c3276400-b40b-11ea-882e-3b1b420c739f.png) ![image](https://user-images.githubusercontent.com/29545877/85226933-a17aac80-b40c-11ea-9665-bb18bac8b14c.png)    **Which version of Dolphin Scheduler:**  -[dev]  **Requirement or improvement - Fix the timeout strategy value when front-end post to the back-end or change enum serde of `strategy`. </body>
		<created>2020-06-21 14:14:29</created>
		<closed>2020-07-13 04:44:36</closed>
	</bug>
	<bug>
		<id>3026</id>
		<title>[BUG] 1.3.0 Document exception</title>
		<body>     In version 1.3.0  The function of workgroup has changed. The current code does not support adding and modifying functions  So in 1.3.0, it also supports the new editing function of workgroup ??   ![image](https://user-images.githubusercontent.com/39816903/85206551-90bb2f80-b355-11ea-81b8-0aca1ab4cce2.png)          </body>
		<created>2020-06-20 16:27:40</created>
		<closed>2020-06-21 15:14:07</closed>
	</bug>
	<bug>
		<id>3018</id>
		<title>[BUG] i18n incomplete</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** In User page, the user type is not in i18n;  **To Reproduce** Steps to reproduce the behavior, for example: 1. In file '\dolphinscheduler-ui\src\js\conf\home\pages\security\pages\users\_source\list.vue' 2. In line 29  3. the '用户类型' should be '{{$t('User Type')}}' 4. and the i18n file should be update  **Expected behavior** modify the page without i18n  **Screenshots** None  **Which version of Dolphin Scheduler:**  -[1.3.0]  **Additional context** None  **Requirement or improvement None </body>
		<created>2020-06-19 03:43:13</created>
		<closed>2020-06-20 14:22:56</closed>
	</bug>
	<bug>
		<id>3017</id>
		<title>[BUG] Comment ERROR</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** The comment error in source code  **To Reproduce** Steps to reproduce the behavior, for example: 1. In 'dolphinscheduler-api\src\main\java\org\apache\dolphinscheduler\api\controller\ResourcesController.java' 2. lines 66 3. the comment title ‘create resource’ should be 'create directory'  **Expected behavior** pls correct this error  **Screenshots** ![image](https://user-images.githubusercontent.com/9511636/85093441-e0e3a600-b21e-11ea-8044-1265ae138a88.png)    **Which version of Dolphin Scheduler:**  -[1.3.0]  **Additional context** None  **Requirement or improvement None </body>
		<created>2020-06-19 03:20:52</created>
		<closed>2020-06-22 02:28:14</closed>
	</bug>
	<bug>
		<id>3016</id>
		<title>Task Online  The master node log appears:  BeanCreationException</title>
		<body>[INFO] 2036-06-19 09:45:04.886 org.apache.dolphinscheduler.server.master.runner.MasterSchedulerService:[132] - find one command: id: 1, type: START_PROCESS [ERROR] 2036-06-19 09:45:04.918 org.apache.dolphinscheduler.server.master.runner.MasterSchedulerService:[144] - scan command error org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'transactionManager' defined in class path resource [org/apache/dolphinscheduler/dao/datasource/SpringConnectio nFactory.class]: BeanPostProcessor before instantiation of bean failed; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframewor k.transaction.annotation.ProxyTransactionManagementConfiguration': Initialization of bean failed; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named ' org.springframework.context.annotation.ConfigurationClassPostProcessor.importRegistry' available</body>
		<created>2020-06-19 02:27:08</created>
		<closed>2020-06-19 09:21:32</closed>
	</bug>
	<bug>
		<id>3012</id>
		<title>[BUG] Workflow dependency definition does not work, tasks are executed in parallel, pretask field is empty (工作流依赖定义不工作，任务并行执行 pretask字段为空)</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** A clear and concise description of what the bug is.  **To Reproduce** Steps to reproduce the behavior, for example: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error  **Expected behavior** A clear and concise description of what you expected to happen.  **Screenshots** If applicable, add screenshots to help explain your problem. ![image](https://user-images.githubusercontent.com/33834062/84989841-dcfc4900-b176-11ea-8449-91fb0d2c85be.png) ![image](https://user-images.githubusercontent.com/33834062/84989852-e2599380-b176-11ea-943f-aefb0b56fd46.png) ![image](https://user-images.githubusercontent.com/33834062/84989868-e7b6de00-b176-11ea-89be-e2759a4fb8bd.png)   **Which version of Dolphin Scheduler:**  -[1.3.1-preview]  **Additional context** Add any other context about the problem here.  **Requirement or improvement - Please describe about your requirements or improvement suggestions. </body>
		<created>2020-06-18 07:18:15</created>
		<closed>2020-06-22 02:31:29</closed>
	</bug>
	<bug>
		<id>3004</id>
		<title>Send the hive query result as an attachment or table, and report an error</title>
		<body>Configure the SQL node to use hive as the data source, and send the query results as attachments to report errors as follows. ![image](https://user-images.githubusercontent.com/63348491/84850553-9c270600-b08a-11ea-9400-ee2a3ee912f4.png) Worker node log ![image](https://user-images.githubusercontent.com/63348491/84850644-d1cbef00-b08a-11ea-9fb2-4cdfeb1ff64e.png) My dolphin scheduler version is 1.2.1. I hope someone can help me solve this problem.</body>
		<created>2020-06-17 03:09:51</created>
		<closed>2020-07-09 03:31:25</closed>
	</bug>
	<bug>
		<id>3001</id>
		<title>[BUG] API interface return time exception ???</title>
		<body>API interface return time will be 8 hours later than normal time  However, the web page displays normally  Where do I need to set????  ![image](https://user-images.githubusercontent.com/39816903/84846417-587bce80-b081-11ea-9e72-6b64b1b6ab23.png)   </body>
		<created>2020-06-17 01:58:28</created>
		<closed>2020-06-17 02:31:14</closed>
	</bug>
	<bug>
		<id>3000</id>
		<title>[BUG] This may cause inconsistent behavior</title>
		<body> version 1.3.0 delpoy two master log:  ''' [WARN] 2020-06-17 01:30:48.985 org.quartz.impl.jdbcjobstore.JobStoreTX:[3350] - This scheduler instance (dataMiddle-801592328643959) is still active but was recovered by another instance in the cluster.  This may cause inconsistent behavior. [WARN] 2020-06-17 01:30:53.988 org.quartz.impl.jdbcjobstore.JobStoreTX:[3350] - This scheduler instance (dataMiddle-801592328643959) is still active but was recovered by another instance in the cluster.  This may cause inconsistent behavior. [WARN] 2020-06-17 01:30:58.991 org.quartz.impl.jdbcjobstore.JobStoreTX:[3350] - This scheduler instance (dataMiddle-801592328643959) is still active but was recovered by another instance in the cluster.  This may cause inconsistent behavior. [WARN] 2020-06-17 01:31:03.992 org.quartz.impl.jdbcjobstore.JobStoreTX:[3350] - This scheduler instance (dataMiddle-801592328643959) is still active but was recovered by another instance in the cluster.  This may cause inconsistent behavior. [WARN] 2020-06-17 01:31:08.996 org.quartz.impl.jdbcjobstore.JobStoreTX:[3350] - This scheduler instance (dataMiddle-801592328643959) is still active but was recovered by another instance in the cluster.  This may cause inconsistent behavior. [WARN] 2020-06-17 01:31:13.998 org.quartz.impl.jdbcjobstore.JobStoreTX:[3350] - This scheduler instance (dataMiddle-801592328643959) is still active but was recovered by another instance in the cluster.  This may cause inconsistent behavior. [WARN] 2020-06-17 01:31:19.000 org.quartz.impl.jdbcjobstore.JobStoreTX:[3350] - This scheduler instance (dataMiddle-801592328643959) is still active but was recovered by another instance in the cluster.  This may cause inconsistent behavior. [WARN] 2020-06-17 01:31:24.004 org.quartz.impl.jdbcjobstore.JobStoreTX:[3350] - This scheduler instance (dataMiddle-801592328643959) is still active but was recovered by another instance in the cluster.  This may cause inconsistent behavior. [WARN] 2020-06-17 01:31:29.006 org.quartz.impl.jdbcjobstore.JobStoreTX:[3350] - This scheduler instance (dataMiddle-801592328643959) is still active but was recovered by another instance in the cluster.  This may cause inconsistent behavior. [WARN] 2020-06-17 01:31:34.009 org.quartz.impl.jdbcjobstore.JobStoreTX:[3350] - This scheduler instance (dataMiddle-801592328643959) is still active but was recovered by another instance in the cluster.  This may cause inconsistent behavior. [WARN] 2020-06-17 01:31:39.012 org.quartz.impl.jdbcjobstore.JobStoreTX:[3350] - This scheduler instance (dataMiddle-801592328643959) is still active but was recovered by another instance in the cluster.  This may cause inconsistent behavior.  ''''    </body>
		<created>2020-06-16 17:33:26</created>
		<closed>2020-06-20 16:17:06</closed>
	</bug>
	<bug>
		<id>2999</id>
		<title>[BUG] After configuring a task, the subtasks of the task are all submitted at once to be executed in parallel</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** After configuring a task, the subtasks of the task are all submitted at once to be executed in parallel.  This question is very strange, but not every task will be like this, some tasks are normal, some tasks are abnormal  ![image](https://user-images.githubusercontent.com/10054719/84797778-c6e27180-b02c-11ea-945a-75ab18f7c8b6.png)  ![image](https://user-images.githubusercontent.com/10054719/84797624-9e5a7780-b02c-11ea-8bb9-32b65d2573c5.png)  ![image](https://user-images.githubusercontent.com/10054719/84797576-90a4f200-b02c-11ea-9d9c-f1c0ad8c6c27.png)  ![image](https://user-images.githubusercontent.com/10054719/84797855-de215f00-b02c-11ea-857a-49adf72dd19f.png)   **Which version of Dolphin Scheduler:**  -1.3.0 - Distributed deployment      </body>
		<created>2020-06-16 15:56:51</created>
		<closed>2020-06-19 09:58:41</closed>
	</bug>
	<bug>
		<id>2991</id>
		<title>[BUG] Restart Ambari report an error: duplicate key: DOLPHIN_ALERT</title>
		<body>Description： After I replaced the common-service file in Ambari, restarting Ambari failed and the log showed: ``` 2020-06-06 09:57:26,984 ERROR [main] AmbariServer:1116 - Failed to run the Ambari Server org.apache.ambari.server.AmbariException: Could not read the alert definition file at org.apache.ambari.server.state.alert.AlertDefinitionFactory.getAlertDefinitions(AlertDefinitionFactory.java:103) at org.apache.ambari.server.api.services.AmbariMetaInfo.getAlertDefinitions(AmbariMetaInfo.java:1036) at org.apache.ambari.server.api.services.AmbariMetaInfo.reconcileAlertDefinitions(AmbariMetaInfo.java:1133) at org.apache.ambari.server.api.services.AmbariMetaInfo.reconcileAlertDefinitions(AmbariMetaInfo.java:1086) at org.apache.ambari.server.controller.AmbariServer.run(AmbariServer.java:538) at org.apache.ambari.server.controller.AmbariServer.main(AmbariServer.java:1110) Cased by: org.apache.ambari.server.AmbariException: Could not read alert definitions at org.apache.ambari.server.state.alert.AlertDefinitionFactory.getAlertDefinitions(AlertDefinitionFactory.java:137) at org.apache.ambari.server.state.alert.AlertDefinitionFactory.getAlertDefinitions(AlertDefinitionFactory.java:99) ... 5 more Caused by: com.google.gson.JsonSyntaxException: duplicate key: DOLPHIN_ALERT at com.google.gson.internal.bind.MapTypeAdapterFactory$Adapter.read(MapTypeAdapterFactory.java:191) at com.google.gson.internal.bind.MapTypeAdapterFactory$Adapter.read(MapTypeAdapterFactory.java:146) at com.google.gson.internal.bind.TypeAdapterRuntimeTypeWrapper.read(TypeAdapterRuntimeTypeWrapper.java:40) at com.google.gson.internal.bind.MapTypeAdapterFactory$Adapter.read(MapTypeAdapterFactory.java:188) at com.google.gson.internal.bind.MapTypeAdapterFactory$Adapter.read(MapTypeAdapterFactory.java:146) at com.google.gson.Gson.fromJson(Gson.java:795) at com.google.gson.Gson.fromJson(Gson.java:761) at org.apache.ambari.server.state.alert.AlertDefinitionFactory.getAlertDefinitions(AlertDefinitionFactory.java:134) ... 6 more ```  version:  1.3.0-release  </body>
		<created>2020-06-16 06:38:32</created>
		<closed>2020-06-17 08:59:33</closed>
	</bug>
	<bug>
		<id>2988</id>
		<title>[BUG] Can't see logs when performing tasks</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** Can't see logs when performing tasks. Then found that the server's logs are not synchronized, resulting in no logs. I think the log is not synchronized.  # ui error info ![image](https://user-images.githubusercontent.com/10054719/84726339-3c175d80-afbf-11ea-9b74-f8b162e086d6.png) # dc-ds-02 error info ![image](https://user-images.githubusercontent.com/10054719/84726349-43d70200-afbf-11ea-9f43-4c97368bf1bf.png)  # dc-ds-01， logs,  ![image](https://user-images.githubusercontent.com/10054719/84726237-05d9de00-afbf-11ea-81a8-940e904a87c4.png)  # dc-ds-02, logs: ![image](https://user-images.githubusercontent.com/10054719/84726302-273aca00-afbf-11ea-937a-44424a824e95.png)  **Which version of Dolphin Scheduler:**  -1.3.0 - Use distributed deployment - nodeis : dc-ds-01,  dc-ds-02 - dc-ds-01 process 16449 LoggerServer 16403 WorkerServer 16836 Jps 16357 MasterServer 16501 AlertServer 24344 SecondaryNameNode 22970 QuorumPeerMain 23805 NameNode 23934 DataNode  - dc-ds-02 process 13120 Jps 12851 ApiApplicationServer 12804 LoggerServer 12759 WorkerServer 493 QuorumPeerMain     </body>
		<created>2020-06-16 02:53:37</created>
		<closed>2020-06-16 07:24:25</closed>
	</bug>
	<bug>
		<id>2987</id>
		<title>[BUG] workflow instance don't update status even if the task has been executed successfully</title>
		<body>*description* Hi there, I've got several shell scripts ( task ) in a workflow instance, when I directly run the entire workflow, after a few minutes, when I check the status of the workflow, it's showing `executing` while all of the tasks have been executed successfully and there are no remaining processes at the server, the task logs also indicates that the task calling is a success. please help to give some advice!  job log ( the end of a sqoop import log): ```         Time taken: 9.072 seconds [INFO] 2020-06-15 18:57:30.635  - [taskAppId=TASK-11-44-111]:[106] -  -&gt; 20/06/15 18:57:29 INFO CliDriver: Time taken: 9.072 seconds         20/06/15 18:57:29 INFO conf.HiveConf: Using the default value passed in for log id: a8909031-313f-4755-9572-96f35a102049         20/06/15 18:57:29 INFO session.SessionState: Resetting thread name to  main         20/06/15 18:57:29 INFO conf.HiveConf: Using the default value passed in for log id: a8909031-313f-4755-9572-96f35a102049         20/06/15 18:57:29 INFO session.SessionState: Deleted directory: /tmp/hive/hive/a8909031-313f-4755-9572-96f35a102049 on fs with scheme hdfs         20/06/15 18:57:29 INFO session.SessionState: Deleted directory: /tmp/hive/a8909031-313f-4755-9572-96f35a102049 on fs with scheme file         20/06/15 18:57:29 INFO hive.metastore: Closed a connection to metastore, current connections: 0         20/06/15 18:57:29 INFO hive.HiveImport: Hive import complete.         20/06/15 18:57:29 INFO imps.CuratorFrameworkImpl: backgroundOperationsLoop exiting         20/06/15 18:57:30 INFO zookeeper.ZooKeeper: Session: 0x172310c034fc245 closed         20/06/15 18:57:30 INFO CuratorFrameworkSingleton: Closing ZooKeeper client.         20/06/15 18:57:30 INFO zookeeper.ClientCnxn: EventThread shut down ``` worker log ( task id is 111 ): ``` /tmp/dolphinscheduler/exec/process/3/11/44/113/11_44_113_node.sh [INFO] 2020-06-15 18:55:26.797  - [taskAppId=TASK-11-44-113]:[329] - task run command: sudo -u hive sh /tmp/dolphinscheduler/exec/process/3/11/44/113/11_44_113.command [INFO] 2020-06-15 18:55:26.897  - [taskAppId=TASK-11-44-112]:[158] - process start, process id is: 46878 [INFO] 2020-06-15 18:55:26.994  - [taskAppId=TASK-11-44-113]:[158] - process start, process id is: 46902 [INFO] 2020-06-15 18:57:30.132  - [taskAppId=TASK-11-44-112]:[168] - process has exited, work dir:/tmp/dolphinscheduler/exec/process/3/11/44/112, pid:46878 ,exitStatusCode:0 [INFO] 2020-06-15 18:57:30.139  - [taskAppId=TASK-11-44-112]:[231] - process id is 46878 [INFO] 2020-06-15 18:57:30.140  - [taskAppId=TASK-11-44-112]:[432] - find app id: application_1591693349720_0153 [INFO] 2020-06-15 18:57:30.141  - [taskAppId=TASK-11-44-112]:[236] - yarn log url:application_1591693349720_0153 [INFO] 2020-06-15 18:57:30.636  - [taskAppId=TASK-11-44-111]:[168] - process has exited, work dir:/tmp/dolphinscheduler/exec/process/3/11/44/111, pid:46853 ,exitStatusCode:0 [INFO] 2020-06-15 18:57:30.643  - [taskAppId=TASK-11-44-111]:[231] - process id is 46853 [INFO] 2020-06-15 18:57:30.644  - [taskAppId=TASK-11-44-111]:[432] - find app id: application_1591693349720_0152 [INFO] 2020-06-15 18:57:30.645  - [taskAppId=TASK-11-44-111]:[236] - yarn log url:application_1591693349720_0152 [INFO] 2020-06-15 18:57:33.458  - [taskAppId=TASK-11-44-113]:[168] - process has exited, work dir:/tmp/dolphinscheduler/exec/process/3/11/44/113, pid:46902 ,exitStatusCode:0 [INFO] 2020-06-15 18:57:33.464  - [taskAppId=TASK-11-44-113]:[231] - process id is 46902 [INFO] 2020-06-15 18:57:33.465  - [taskAppId=TASK-11-44-113]:[432] - find app id: application_1591693349720_0154 [INFO] 2020-06-15 18:57:33.466  - [taskAppId=TASK-11-44-113]:[236] - yarn log url:application_1591693349720_0154 ``` </body>
		<created>2020-06-16 01:56:24</created>
		<closed>2020-06-22 07:57:05</closed>
	</bug>
	<bug>
		<id>2983</id>
		<title>[BUG] no email sent when query SQL has no result</title>
		<body>**Describe the bug**  no email sent when query SQL has no result  **To Reproduce**  - Create an email task to execute Query SQL which return empty result.  **Expected behavior**  An email with empty body should be sent.  **Which version of Dolphin Scheduler:**  - [1.2.0, ]   **Requirement or improvement** - An email should be sent for Query SQL ,no matter whether it has result or not .</body>
		<created>2020-06-15 13:09:20</created>
		<closed>2020-06-19 06:50:11</closed>
	</bug>
	<bug>
		<id>2975</id>
		<title>[BUG] Workflow reference authorization file error</title>
		<body>1. The associated tenant of the admin user is hdfs, the associated tenant of the chenxingchun user is cxc, and the files of the admin user are authorized to the chenxingchun user. 2. The chenxingchun user refers to the authorization file in the workflow. When the workflow is executed, the tenant who looks for the file is cxc, which results in the execution workflow to find the resource does not exist.  1.admin用户关联租户为hdfs，chenxingchun用户关联租户为cxc，将admin用户的文件授权给chenxingchun用户， 2.chenxingchun用户在工作流中引用授权文件，执行工作流时，查找文件的租户为cxc，导致执行工作流查找资源不存在  ![image](https://user-images.githubusercontent.com/55787491/84615123-a74b2c00-aefa-11ea-81c7-45c0bc787ac8.png) ![image](https://user-images.githubusercontent.com/55787491/84615145-bfbb4680-aefa-11ea-9604-01d138e7466a.png) ![image](https://user-images.githubusercontent.com/55787491/84615442-9d75f880-aefb-11ea-991b-bb7b96c48a63.png) ![image](https://user-images.githubusercontent.com/55787491/84615645-25f49900-aefc-11ea-99b1-d696948d8f6b.png)     **Which version of Dolphin Scheduler:**  -[dev_1.3.0]  </body>
		<created>2020-06-15 03:31:22</created>
		<closed>2020-07-02 07:20:55</closed>
	</bug>
	<bug>
		<id>2974</id>
		<title>[BUG] Download the file  of directory  is error</title>
		<body>When downloading a file, only the file is transferred, there is no upper directory of the file ![image](https://user-images.githubusercontent.com/55787491/84614753-a8c82480-aef9-11ea-8eda-52ba6680e83c.png) ![image](https://user-images.githubusercontent.com/55787491/84614798-cbf2d400-aef9-11ea-8204-4c61eca9aae7.png) ![image](https://user-images.githubusercontent.com/55787491/84614845-e7f67580-aef9-11ea-8ad4-15f4012133e1.png)    **Which version of Dolphin Scheduler:**  -[dev_1.3.0]   </body>
		<created>2020-06-15 03:20:00</created>
		<closed>2020-06-17 09:46:57</closed>
	</bug>
	<bug>
		<id>2959</id>
		<title>[BUG] 1.3.0版本没有创建工作组按钮</title>
		<body></body>
		<created>2020-06-13 01:35:44</created>
		<closed>2020-06-17 09:44:59</closed>
	</bug>
	<bug>
		<id>2951</id>
		<title>[BUG] java.util.NoSuchElementException: 'task.record.flag' doesn't map to an existing object</title>
		<body>使用1.2.1官方提供的tar包直接进行安装，运行调度任务后，经常出现任务运行失败，但是日志显示正常的问题，查看数据也都正常落库。work报错如下：[ERROR] 2020-06-09 15:58:43.995 org.apache.dolphinscheduler.server.worker.runner.TaskScheduleThread:[153] - task scheduler failure java.util.NoSuchElementException: 'task.record.flag' doesn't map to an existing object at org.apache.commons.configuration.AbstractConfiguration.getBoolean(AbstractConfiguration.java:644) at org.apache.dolphinscheduler.dao.TaskRecordDao.getTaskRecordFlag(TaskRecordDao.java:64) at org.apache.dolphinscheduler.server.worker.task.AbstractTask.after(AbstractTask.java:134) at org.apache.dolphinscheduler.server.worker.runner.TaskScheduleThread.run(TaskScheduleThread.java:150) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) [INFO] 2020-06-09 15:58:43.995 - [taskAppId=TASK-4-330-5535]:[262] - cancel process: 17728 [INFO] 2020-06-09 15:58:44.000 org.apache.dolphinscheduler.server.worker.runner.TaskScheduleThread:[161] - task instance id : 5535,task final status : SUCCESS</body>
		<created>2020-06-10 07:46:32</created>
		<closed>2020-06-10 10:52:46</closed>
	</bug>
	<bug>
		<id>2950</id>
		<title>[BUG] bug title </title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** A clear and concise description of what the bug is.  **To Reproduce** Steps to reproduce the behavior, for example: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error  **Expected behavior** A clear and concise description of what you expected to happen.  **Screenshots** If applicable, add screenshots to help explain your problem.   **Which version of Dolphin Scheduler:**  -[1.1.0-preview]  **Additional context** Add any other context about the problem here.  **Requirement or improvement - Please describe about your requirements or improvement suggestions. </body>
		<created>2020-06-10 07:42:33</created>
		<closed>2020-06-10 07:45:00</closed>
	</bug>
	<bug>
		<id>2928</id>
		<title>[BUG] bug title 1.3.0的api服务启动失败</title>
		<body>我下载了1.3.0然后编译之后修改配置进行安装，然后发现啊皮服务启动失败，报了空指针异常，请问这个1.3.0是还不能使用吗？  下面是错误信息 [INFO] 2020-06-09 10:40:35.131 org.eclipse.jetty.server.handler.ContextHandler.application:[2345] - Initializing Spring DispatcherServlet 'dispatcherServlet' [INFO] 2020-06-09 10:40:35.152 org.mortbay.log:[67] - Logging to Logger[org.mortbay.log] via org.mortbay.log.Slf4jLog [INFO] 2020-06-09 10:40:35.221 org.apache.dolphinscheduler.remote.NettyRemotingClient:[376] - netty client closed [INFO] 2020-06-09 10:40:35.222 org.apache.dolphinscheduler.service.log.LogClientService:[59] - logger client closed [INFO] 2020-06-09 10:40:35.226 org.eclipse.jetty.server.session:[167] - node0 Stopped scavenging [INFO] 2020-06-09 10:40:35.228 org.eclipse.jetty.server.handler.ContextHandler.application:[2345] - Destroying Spring FrameworkServlet 'dispatcherServlet' [WARN] 2020-06-09 10:40:35.230 org.eclipse.jetty.servlet.ServletHolder:[461] -  java.lang.NullPointerException: null         at org.apache.jasper.servlet.JspServlet.destroy(JspServlet.java:410)         at org.eclipse.jetty.servlet.ServletHolder.destroyInstance(ServletHolder.java:486)         at org.eclipse.jetty.servlet.ServletHolder.doStop(ServletHolder.java:457)         at org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:89)         at org.eclipse.jetty.servlet.ServletHandler.doStop(ServletHandler.java:288)         at org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:89)         at org.eclipse.jetty.util.component.ContainerLifeCycle.stop(ContainerLifeCycle.java:149)         at org.eclipse.jetty.util.component.ContainerLifeCycle.doStop(ContainerLifeCycle.java:170)         at org.eclipse.jetty.server.handler.AbstractHandler.doStop(AbstractHandler.java:124)         at org.eclipse.jetty.security.SecurityHandler.doStop(SecurityHandler.java:381)         at org.eclipse.jetty.security.ConstraintSecurityHandler.doStop(ConstraintSecurityHandler.java:457)         at org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:89)         at org.eclipse.jetty.util.component.ContainerLifeCycle.stop(ContainerLifeCycle.java:149)  at org.eclipse.jetty.util.component.ContainerLifeCycle.doStop(ContainerLifeCycle.java:170)         at org.eclipse.jetty.server.handler.AbstractHandler.doStop(AbstractHandler.java:124)         at org.eclipse.jetty.server.session.SessionHandler.doStop(SessionHandler.java:512)         at org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:89)         at org.eclipse.jetty.util.component.ContainerLifeCycle.stop(ContainerLifeCycle.java:149)         at org.eclipse.jetty.util.component.ContainerLifeCycle.doStop(ContainerLifeCycle.java:170)         at org.eclipse.jetty.server.handler.AbstractHandler.doStop(AbstractHandler.java:124)         at org.eclipse.jetty.server.handler.ContextHandler.stopContext(ContextHandler.java:932)         at org.eclipse.jetty.servlet.ServletContextHandler.stopContext(ServletContextHandler.java:375)         at org.eclipse.jetty.webapp.WebAppContext.stopWebapp(WebAppContext.java:1503)         at org.eclipse.jetty.webapp.WebAppContext.stopContext(WebAppContext.java:1467)         at org.eclipse.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:1009)         at org.eclipse.jetty.servlet.ServletContextHandler.doStop(ServletContextHandler.java:288)         at org.eclipse.jetty.webapp.WebAppContext.doStop(WebAppContext.java:569)         at org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:89)         at org.eclipse.jetty.util.component.ContainerLifeCycle.stop(ContainerLifeCycle.java:149)         at org.eclipse.jetty.util.component.ContainerLifeCycle.doStop(ContainerLifeCycle.java:170)         at org.eclipse.jetty.server.handler.AbstractHandler.doStop(AbstractHandler.java:124)         at org.eclipse.jetty.server.Server.doStop(Server.java:461)         at org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:89)         at org.springframework.boot.web.embedded.jetty.JettyWebServer.stop(JettyWebServer.java:237)         at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.stopAndReleaseWebServer(ServletWebServerApplicationContext.java:320) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onClose(ServletWebServerApplicationContext.java:173)         at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:1032)         at org.springframework.context.support.AbstractApplicationContext.close(AbstractApplicationContext.java:975)         at org.springframework.boot.SpringApplication.handleRunFailure(SpringApplication.java:834)         at org.springframework.boot.SpringApplication.run(SpringApplication.java:327)         at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260)         at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248)         at org.apache.dolphinscheduler.api.ApiApplicationServer.main(ApiApplicationServer.java:36) [INFO] 2020-06-09 10:40:35.231 org.eclipse.jetty.server.handler.ContextHandler:[1045] - Stopped o.s.b.w.e.j.JettyEmbeddedWebAppContext@422ad5e2{application,/dolphinscheduler,[file:///tmp/jetty-docbase.6503539574314088320.12345/, jar:file:/opt/dolphinscheduler/lib/swagger-bootstrap-ui-1.9.3.jar!/META-INF/resources, jar:file:/opt/dolphinscheduler/lib/springfox-swagger-ui-2.9.2.jar!/META-INF/resources],UNAVAILABLE} </body>
		<created>2020-06-09 02:51:59</created>
		<closed>2020-06-13 01:59:19</closed>
	</bug>
	<bug>
		<id>2927</id>
		<title>[BUG] NEF when get info from OSUtils</title>
		<body>**Describe the bug** `OSUtils.cpuUsage()` function will produce NumberFormatException if cpuUsage() function returns `0.0 / 0.0 = NaN`.  **To Reproduce** When I start my WorkerServer in my MacOS, it will schedule to produce a heartbeat signal to zk, and it will produce NFE when get `cpuUsage()` result equals `NaN`(0.0 / 0.0) from `oshi.AbstractCentralProcessor#getSystemCpuLoad()`.  **Screenshots** ![image](https://user-images.githubusercontent.com/29545877/84022235-8180cd00-a9b8-11ea-8f9b-f4b593c69f05.png)  **Which version of Dolphin Scheduler:**  -[dev]  **Requirement or improvement - Use `Double#isNaN()` to judge the result although it returns double type, it will not throw NFE when the result is NaN(0.0 / 0.0). - Judge every place that use the double type in OSUtils and add `Double#isNaN()` judgement. ![image](https://user-images.githubusercontent.com/29545877/84023209-42ec1200-a9ba-11ea-9f6b-756486f724cc.png)  </body>
		<created>2020-06-08 11:01:08</created>
		<closed>2020-06-12 03:12:33</closed>
	</bug>
	<bug>
		<id>2925</id>
		<title>[BUG] There is no exitVal judge in OSUtils.exeCmd function</title>
		<body>**Describe the bug** There is no exitVal judge in OSUtils.exeCmd function. So when I run cmd in this function in MacOS and this cmd fail, there is no log or exception thrown.  **To Reproduce** 1.Make sure `sudo sysadminctl -addUser 1 -password 1` will produce error when you execute in your shell. 2. Run OSUtils.exeCmd with `sudo sysadminctl -addUser 1 -password 1` params. 3. Judge the `p.waitFor()`'s result, it will be `1` that means failed.  **Expected behavior** Judge the `p.waitFor()`'s result, it will be `1` that means failed.  **Screenshots** ![image](https://user-images.githubusercontent.com/29545877/84001665-ad408a80-a999-11ea-9e1a-d9f57232e9fa.png)   **Which version of Dolphin Scheduler:**  -[dev]   **Requirement or improvement - Judge the result of `Process.waitFor()` or record the creating working dir and user detail log by `TaskLogger` - Remove the exeCmd from OSUtils, and use the `ShellExecutor.execCommand(command)` function. </body>
		<created>2020-06-08 07:08:17</created>
		<closed>2020-06-28 09:43:14</closed>
	</bug>
	<bug>
		<id>2923</id>
		<title>[BUG] Hive JDBC connection parameter ignored</title>
		<body>**Describe the bug** The jdbc connection parameter of Hive datasource, should append after the question mark when building jdbc url, like `jdbc:hive2://host:port/default?mapred.job.queue.name=root.users.a`. But actually, it append after the semicolon, so the result is `jdbc:hive2://host:port/default;mapred.job.queue.name=root.users.a`, which make the parameter being ignored  ![image](https://user-images.githubusercontent.com/16650282/83969066-3efbb980-a900-11ea-8c83-ffa899d7a65b.png)  For testing, I set the parameter in this way `{"?mapred.job.queue.name":"root.user.a"}`, and now it can be set correctly    **Which version of Dolphin Scheduler:**  - [1.2.1-release] </body>
		<created>2020-06-07 12:52:13</created>
		<closed>2020-07-13 05:58:02</closed>
	</bug>
	<bug>
		<id>2922</id>
		<title>[BUG] Jackson UDSerde error</title>
		<body>**Describe the bug**  There is a Serde Exception in `TaskNode`, because we use Jackson UDSerde `JSONUtils.JsonDataSerializer` and `JSONUtils.JsonDataDeserializer` in `TaskNode` fields.  The UDSerde can convert "[]" to ""[]"" because the `JsonDataDeserializer` node.toString() implement.  **To Reproduce** Steps to reproduce the behavior, for example:  `public static void main(String[] args) {         String a = "{\"conditionResult\":\"{\\\"successNode\\\":[\\\"\\\"],\\\"failedNode\\\":[\\\"\\\"]}\","                 + "\"conditionsTask\":false,\"depList\":[],\"dependence\":\"{}\",\"forbidden\":false,"                 + "\"id\":\"tasks-86823\",\"maxRetryTimes\":1,\"name\":\"shell test\","                 + "\"params\":\"{\\\"resourceList\\\":[],\\\"localParams\\\":[],\\\"rawScript\\\":\\\"echo "                 + "'yyc'\\\"}\",\"preTasks\":\"[]\",\"retryInterval\":1,\"runFlag\":\"NORMAL\","                 + "\"taskInstancePriority\":\"HIGHEST\",\"taskTimeoutParameter\":{\"enable\":false,\"interval\":0},"                 + "\"timeout\":\"{}\",\"type\":\"SHELL\",\"workerGroup\":\"default\"}";         TaskNode taskNode = JSONUtils.parseObject(a, TaskNode.class);     }`   **Expected behavior** `com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot deserialize instance of `java.util.ArrayList` out of VALUE_STRING token  at [Source: (String)""[]""; line: 1, column: 1]`  **Screenshots** ![image](https://user-images.githubusercontent.com/29545877/83968921-f98abc80-a8fe-11ea-8765-94829ce5dedd.png)   **Which version of Dolphin Scheduler:**  -[dev]  **Requirement or improvement - We can remove the UDSerde `JSONUtils.JsonDataSerializer` and `JSONUtils.JsonDataDeserializer` in JSONUtils. </body>
		<created>2020-06-07 12:42:16</created>
		<closed>2020-06-17 03:33:42</closed>
	</bug>
	<bug>
		<id>2919</id>
		<title>[BUG] Start master or worker can not load logback-xx.xml</title>
		<body>**Describe the bug** When I set `System.setProperty("spring.profiles.active", "worker")` and `System.setProperty("spring.profiles.active", "master")` configuration and start master and worker in MacOS, the spring container can not load logback-master.xml or logback-worker.xml automatically.  I've to set `System.setProperty("logging.config", "classpath:logback-worker.xml")` to load the logback-worker.xml.  **To Reproduce** Steps to reproduce the behavior, for example: 1. Go to 'org.apache.dolphinscheduler.server.worker.WorkerServer' and set `System.setProperty("spring.profiles.active", "worker")` in `main()` function , run the `main()` function. 1. Go to 'org.apache.dolphinscheduler.server.master.MasterServer' and set `System.setProperty("spring.profiles.active", "master")` in `main()` function, run the `main()` function. 2. Submit a Shell task and run it manually. 3. There is a `NPE`.  **Expected behavior** There is a `NPE` when the `org.apache.dolphinscheduler.server.worker.processor.TaskExecuteProcessor.getTaskLogPath()` try to get `TASKLOGFILE`, but it can not get `TASKLOGFILE` defined in `logback-worker.xml` in this function, because the Spring container does not load the `logback-worker.xml`.  **Screenshots** ![image](https://user-images.githubusercontent.com/29545877/83962637-920a4800-a8d1-11ea-9199-ad56073a3d0f.png)  **Which version of Dolphin Scheduler:**  -[1.3.0]  **Requirement or improvement - We need to set System.setProperty("logging.config", "classpath:logback-worker.xml") in worker main function and set System.setProperty("logging.config", "classpath:logback-master.xml") in master main function. </body>
		<created>2020-06-07 07:25:52</created>
		<closed>2020-06-07 10:34:57</closed>
	</bug>
	<bug>
		<id>2910</id>
		<title>[BUG] master server  will show exception for some time when master server restart, it's just dispatching task</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** [ERROR] 2020-06-06 15:46:22.683 org.apache.dolphinscheduler.server.master.consumer.TaskPriorityQueueConsumer:[152] - dispatch error org.apache.dolphinscheduler.server.master.dispatch.exceptions.ExecuteException: fail to execute : Command [type=TASK_EXECUTE_REQUEST, opaque=1, bodyLen=1619] due to no suitable worker , current task need to default worker group execute at org.apache.dolphinscheduler.server.master.dispatch.ExecutorDispatcher.dispatch(ExecutorDispatcher.java:87) at org.apache.dolphinscheduler.server.master.consumer.TaskPriorityQueueConsumer.dispatch(TaskPriorityQueueConsumer.java:149) at org.apache.dolphinscheduler.server.master.consumer.TaskPriorityQueueConsumer.run(TaskPriorityQueueConsumer.java:118)  **To Reproduce** 1、worker server runs normally,  click `start workflow` ,  2、then restart master server , master server runtime log will show the following exception for some time(about 30 seconds), then master will go  works normally  **Which version of Dolphin Scheduler:**  -[ dev-1.3.0 ] </body>
		<created>2020-06-06 07:57:47</created>
		<closed>2020-06-06 10:24:52</closed>
	</bug>
	<bug>
		<id>2903</id>
		<title>[BUG] When a process called by the scheduler is re-run, the tasks in the sub-process is not executed.</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** When I rerun a process called by the scheduler, the tasks of the sub-processes in the process are not executed  &lt;img width="1212" alt="image" src="https://user-images.githubusercontent.com/20351485/83841663-e5469400-a733-11ea-9a0c-be760a5d1e52.png"&gt;  The arrows represent tasks in the sub-process, in the next two re-runs, there was no such task.  **Which version of Dolphin Scheduler:**  -[1.2.1]  -[1.3.0] </body>
		<created>2020-06-05 05:56:43</created>
		<closed>2020-06-08 03:16:15</closed>
	</bug>
	<bug>
		<id>2893</id>
		<title>[BUG] dev-1.3.0 sqoop task params set error</title>
		<body>**Describe the bug** Sqoop task params :  --map-column-hive &amp; --map-column-java params set error,  if set multi-params only the last param effect  **To Reproduce** 1. In Sqoop task set two hive-map fields like， item_id String, parent_id String  2. worker log show that only --map-column-hive parent_id=String, not --map-column-hive item_id=String, parent_id=String  **Expected behavior** --map-column-hive &amp; --map-column-java params set success  **Which version of Dolphin Scheduler:**  -[dev-1.3.0]  **Requirement or improvement** - Modify sqoop-MysqlSourceGenerator </body>
		<created>2020-06-04 07:46:40</created>
		<closed>2020-06-05 02:41:43</closed>
	</bug>
	<bug>
		<id>2892</id>
		<title>[BUG] When editing user information, clear the phone number, the database table t_ds_user.phone is not cleared</title>
		<body> ![image](https://user-images.githubusercontent.com/55787491/83727354-7f94d200-a677-11ea-9937-70d96123137e.png) ![image](https://user-images.githubusercontent.com/55787491/83727493-ba970580-a677-11ea-8dd4-6e1a40201d05.png)   **Which version of Dolphin Scheduler:**  -[dev-1.3.0]  </body>
		<created>2020-06-04 07:26:35</created>
		<closed>2020-06-04 09:13:09</closed>
	</bug>
	<bug>
		<id>2891</id>
		<title>[BUG] bug title   Easyscheduler 1.1.0 task flow cannot be displayed on a web page when the log is large. Where can I adjust the log file size display?</title>
		<body> Easyscheduler 1.1.0 task flow cannot be displayed on a web page when the log is large. Where can I adjust the log file size display?  ![image](https://user-images.githubusercontent.com/11416812/83722510-af3fdc00-a66f-11ea-9426-61ca2679f354.png)  But the file only has 179K  </body>
		<created>2020-06-04 06:30:27</created>
		<closed>2020-06-08 07:16:30</closed>
	</bug>
	<bug>
		<id>2890</id>
		<title>[BUG] When saving workflow, the default tenant of admin and the Default display of the drop-down list are inconsistent</title>
		<body>1.When saving workflow, the default tenant of admin and the Default display of the drop-down list are inconsistent 2.After entering the workflow name, the default value is cleared ![image](https://user-images.githubusercontent.com/55787491/83709791-d5ef1a00-a651-11ea-9930-17fc22e4bee0.png)  ![image](https://user-images.githubusercontent.com/55787491/83709770-c96ac180-a651-11ea-94b1-982012016375.png)   **Which version of Dolphin Scheduler:**  -[dev_1.3.0]  </body>
		<created>2020-06-04 02:55:10</created>
		<closed>2020-06-08 03:16:49</closed>
	</bug>
	<bug>
		<id>2889</id>
		<title>Why the task was judged error</title>
		<body>1.2.0 ![2020-06-03 16-14-02屏幕截图](https://user-images.githubusercontent.com/31722412/83612922-a4c10c00-a5b5-11ea-8ef4-d45e24a8b7ad.png) q: There is no error in running shell task. Why DS thinks the task is error </body>
		<created>2020-06-03 08:16:26</created>
		<closed>2020-06-17 01:43:46</closed>
	</bug>
	<bug>
		<id>2888</id>
		<title>[BUG] can not use hive udf</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** 1、upload a hive udf in resource center successfully 2、create a work flow , Select UDF function, confirm to add, and enter editing state again.，UDF function is not saved.use this udf to query , return error。 3、dolphin version is 1.2.0 release,hive version is 1.2.1 and 2.7.3 both test failed 4、we test the udf in the hive cli, query successfully,so the jar is good  **To Reproduce** Steps to reproduce the behavior, for example: 1. upload a hive udf in resource center 2. create a work flow , use this udf to query 3. See error，error info : [INFO] 2020-06-03 15:03:54.560  - [taskAppId=TASK-8-133-287]:[109] - SqlParameters{type='HIVE', datasource=2, sql='select name,id,idcardcheck(id) as result from ods_people', sqlType=0, udfs='', showType='TABLE', connParams='', title='test', receivers='fsdfs@asiainfo.com', receiversCc='', preStatements=[], postStatements=[]} [INFO] 2020-06-03 15:03:54.567  - [taskAppId=TASK-8-133-287]:[110] - sql type : HIVE, datasource : 2, sql : select name,id,idcardcheck(id) as result from ods_people , localParams : [],udfs : ,showType : TABLE,connParams :  [INFO] 2020-06-03 15:03:54.570  - [taskAppId=TASK-8-133-287]:[127] - datasource name : hivetest2 , type : HIVE , desc :   , user_id : 2 , parameter : {"address":"jdbc:hive2://10.19.83.39:10000","database":"default","jdbcUrl":"jdbc:hive2://10.19.83.39:10000/default","user":"hadoop","password":"hadoop"} [INFO] 2020-06-03 15:03:54.571  - [taskAppId=TASK-8-133-287]:[214] - SQL tile : test [INFO] 2020-06-03 15:03:54.572  - [taskAppId=TASK-8-133-287]:[448] - after replace sql , preparing : select name,id,idcardcheck(id) as result from ods_people [INFO] 2020-06-03 15:03:54.572  - [taskAppId=TASK-8-133-287]:[453] - replaced sql , parameters: [INFO] 2020-06-03 15:03:54.904  - [taskAppId=TASK-8-133-287]:[364] - prepare statement replace sql : org.apache.hive.jdbc.HivePreparedStatement@67d16b19  [ERROR] 2020-06-03 15:03:54.977  - [taskAppId=TASK-8-133-287]:[336] - Error while compiling statement: FAILED: SemanticException [Error 10011]: Line 1:15 Invalid function 'idcardcheck' org.apache.hive.service.cli.HiveSQLException: Error while compiling statement: FAILED: SemanticException [Error 10011]: Line 1:15 Invalid function 'idcardcheck' at org.apache.hive.jdbc.Utils.verifySuccess(Utils.java:264) at org.apache.hive.jdbc.Utils.verifySuccessWithInfo(Utils.java:250) at org.apache.hive.jdbc.HiveStatement.runAsyncOnServer(HiveStatement.java:309) at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:250) at org.apache.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:434) at org.apache.hive.jdbc.HivePreparedStatement.executeQuery(HivePreparedStatement.java:109) at org.apache.dolphinscheduler.server.worker.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:295) at org.apache.dolphinscheduler.server.worker.task.sql.SqlTask.handle(SqlTask.java:176) at org.apache.dolphinscheduler.server.worker.runner.TaskScheduleThread.run(TaskScheduleThread.java:142) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Caused by: org.apache.hive.service.cli.HiveSQLException: Error while compiling statement: FAILED: SemanticException [Error 10011]: Line 1:15 Invalid function 'idcardcheck' at org.apache.hive.service.cli.operation.Operation.toSQLException(Operation.java:315) at org.apache.hive.service.cli.operation.SQLOperation.prepare(SQLOperation.java:112) at org.apache.hive.service.cli.operation.SQLOperation.runInternal(SQLOperation.java:181) at org.apache.hive.service.cli.operation.Operation.run(Operation.java:257) at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:388) at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementAsync(HiveSessionImpl.java:375) at sun.reflect.GeneratedMethodAccessor51.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:78) at org.apache.hive.service.cli.session.HiveSessionProxy.access$000(HiveSessionProxy.java:36) at org.apache.hive.service.cli.session.HiveSessionProxy$1.run(HiveSessionProxy.java:63) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:422) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762) at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:59) at com.sun.proxy.$Proxy20.executeStatementAsync(Unknown Source) at org.apache.hive.service.cli.CLIService.executeStatementAsync(CLIService.java:274) at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:486) at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1313) at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1298) at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39) at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:56) at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:285) ... 3 common frames omitted Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.parse.SemanticException:Line 1:15 Invalid function 'idcardcheck' at org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory$DefaultExprProcessor.getXpathOrFuncExprNodeDesc(TypeCheckProcFactory.java:925) at org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory$DefaultExprProcessor.process(TypeCheckProcFactory.java:1265) at org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher.dispatch(DefaultRuleDispatcher.java:90) at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatchAndReturn(DefaultGraphWalker.java:95) at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatch(DefaultGraphWalker.java:79) at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.walk(DefaultGraphWalker.java:133) at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.startWalking(DefaultGraphWalker.java:110) at org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory.genExprNode(TypeCheckProcFactory.java:205) at org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory.genExprNode(TypeCheckProcFactory.java:149) at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genAllExprNodeDesc(SemanticAnalyzer.java:10512) at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genExprNodeDesc(SemanticAnalyzer.java:10468) at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genSelectPlan(SemanticAnalyzer.java:3840) at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genSelectPlan(SemanticAnalyzer.java:3619) at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPostGroupByBodyPlan(SemanticAnalyzer.java:8956) at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:8911) at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:9756) at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:9649) at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genOPTree(SemanticAnalyzer.java:10122) at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:325) at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10133) at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:209) at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:227) at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:424) at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:308) at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1122) at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:1116) at org.apache.hive.service.cli.operation.SQLOperation.prepare(SQLOperation.java:110) ... 26 common frames omitted    </body>
		<created>2020-06-03 07:23:28</created>
		<closed>2020-06-05 06:35:20</closed>
	</bug>
	<bug>
		<id>2883</id>
		<title>CONDITIONS task is not work </title>
		<body>version dev-1.3.0  ![image](https://user-images.githubusercontent.com/39816903/83594162-19358400-a591-11ea-85c0-71540d44fffc.png)          </body>
		<created>2020-06-03 03:55:28</created>
		<closed>2020-06-04 15:03:22</closed>
	</bug>
	<bug>
		<id>2875</id>
		<title>[BUG] After the workers group, specify a group. The task cannot view the log, but can only download and view it</title>
		<body>**Describe the bug** After grouping, the task cannot view the log, but if the default grouping is used, the log will be displayed  **To Reproduce** Steps to reproduce the behavior, for example: 1. Create a workers group 2. Create a test project 3. run the project 4. after look the log is '暂无更多'  **Expected behavior** i think the log is show the background  **Screenshots**  ![image](https://user-images.githubusercontent.com/66063598/83507902-c1990900-a4fb-11ea-839f-b264c4648136.png)    **Which version of Dolphin Scheduler:**  -1.2.1  **Additional context** Add any other context about the problem here.  **Requirement or improvement - i want look the log</body>
		<created>2020-06-02 10:07:10</created>
		<closed>2020-09-02 09:57:10</closed>
	</bug>
	<bug>
		<id>2860</id>
		<title>[BUG] When a user has a resource directory tree, update the user's tenant to report an error</title>
		<body> ![image](https://user-images.githubusercontent.com/55787491/83390197-03ef1700-a424-11ea-8894-674e758cd92d.png) ![image](https://user-images.githubusercontent.com/55787491/83390230-10736f80-a424-11ea-8fd7-c7b9acf27a20.png)  **Which version of Dolphin Scheduler:**  -[dev_1.3.0]  **Additional context** Add any other context about the problem here.  **Requirement or improvement - Please describe about your requirements or improvement suggestions. </body>
		<created>2020-06-01 08:22:32</created>
		<closed>2020-06-04 01:49:17</closed>
	</bug>
	<bug>
		<id>2841</id>
		<title>[BUG] report an error when use python-plugin run as Debug on win10</title>
		<body>**Describe the bug** report an error when use python-plugin run as Debug on win10 See below for details. **Which version of Dolphin Scheduler:**  -[dev-1.3]  **Additional context** error-log:  [taskAppId=TASK-7-8-11]:[97] - python task failure java.io.IOException: Cannot run program "sudo" (in directory "\tmp\dolphinscheduler\exec\process\2\7\8\11"): CreateProcess error=2, 系统找不到指定的文件。 at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048) at org.apache.dolphinscheduler.server.worker.task.AbstractCommandExecutor.buildProcess(AbstractCommandExecutor.java:118) at org.apache.dolphinscheduler.server.worker.task.AbstractCommandExecutor.run(AbstractCommandExecutor.java:146) at org.apache.dolphinscheduler.server.worker.task.python.PythonTask.handle(PythonTask.java:90) at org.apache.dolphinscheduler.server.worker.runner.TaskExecuteThread.run(TaskExecuteThread.java:118) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266) at java.util.concurrent.FutureTask.run(FutureTask.java) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Caused by: java.io.IOException: CreateProcess error=2, 系统找不到指定的文件。  @liwenhe1993 </body>
		<created>2020-05-29 06:23:26</created>
		<closed>2020-05-29 08:02:53</closed>
	</bug>
	<bug>
		<id>2836</id>
		<title>[BUG] After the task is executed, after the master restarts, the task execution status is not obtained.  </title>
		<body>1. After running the workflow, stop the master service 2. After the worker task is successfully executed, start the master service  Actual result: the master service can not get the status of the worker execution success, the workflow and task status have been running  1.运行工作流后，停止master服务 2.worker任务执行成功后，启动master服务  实际结果：master服务拿不到worker执行成功的状态，工作流和任务状态一直在运行中 ![image](https://user-images.githubusercontent.com/55787491/83111407-1f41e580-a0f7-11ea-946c-3cdb445e53ac.png) ![image](https://user-images.githubusercontent.com/55787491/83111432-28cb4d80-a0f7-11ea-8ab5-cf07f495d282.png)  **Which version of Dolphin Scheduler:**  -[dev_1.3.0]   </body>
		<created>2020-05-28 07:23:28</created>
		<closed>2020-06-01 01:06:28</closed>
	</bug>
	<bug>
		<id>2835</id>
		<title>[BUG] Table 't_ds_worker_group' doesn't exist when init ds-1.3.0 db metadata</title>
		<body>**Describe the bug** dev-1.3.0 exec CreateDolphinScheduler to init db metadata will report the error:  Table 'dolphinscheduler.t_ds_worker_group' doesn't exist   **To Reproduce** the error :  12:51:03.091 [main] ERROR org.apache.dolphinscheduler.dao.upgrade.WorkerGroupDao -  com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Table 'dolphinscheduler.t_ds_worker_group' doesn't exist at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:423) at com.mysql.jdbc.Util.handleNewInstance(Util.java:377) at com.mysql.jdbc.Util.getInstance(Util.java:360) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:978) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3887) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3823) at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2435) at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2582) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2530) at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1907) at com.mysql.jdbc.PreparedStatement.executeQuery(PreparedStatement.java:2030) at com.alibaba.druid.pool.DruidPooledPreparedStatement.executeQuery(DruidPooledPreparedStatement.java:227) at org.apache.dolphinscheduler.dao.upgrade.WorkerGroupDao.queryAllOldWorkerGroup(WorkerGroupDao.java:48) at org.apache.dolphinscheduler.dao.upgrade.UpgradeDao.updateProcessDefinitionJsonWorkerGroup(UpgradeDao.java:275) at org.apache.dolphinscheduler.dao.upgrade.UpgradeDao.upgradeDolphinScheduler(UpgradeDao.java:262) at org.apache.dolphinscheduler.dao.upgrade.DolphinSchedulerManager.upgradeDolphinScheduler(DolphinSchedulerManager.java:119) at org.apache.dolphinscheduler.dao.upgrade.shell.CreateDolphinScheduler.main(CreateDolphinScheduler.java:40)  **Which version of Dolphin Scheduler:**  -[dev-1.3.0]  </body>
		<created>2020-05-28 07:17:03</created>
		<closed>2020-05-29 15:44:09</closed>
	</bug>
	<bug>
		<id>2830</id>
		<title>[BUG] bug title Use escheduler-1.1.0 to schedule the hive task. Stopping the workflow will lock the table</title>
		<body>Use escheduler-1.1.0 to schedule the hive task. Stopping the workflow will lock the table. You need to manually delete the record of the lock table in hive metadata. Is there any way to avoid this problem? Thank you.  使用escheduler-1.1.0版本调度hive任务，停止工作流会锁表 </body>
		<created>2020-05-27 10:19:43</created>
		<closed>2020-06-04 06:24:00</closed>
	</bug>
	<bug>
		<id>2828</id>
		<title>[BUG] 工作流启动，界面上无法看到工作流实例和任务实例</title>
		<body> **Describe the bug** 工作流启动，界面上无法看到工作流实例和任务实例，重启所有服务可以看到。  **To Reproduce** 引起的原因是我重启了ZOOKPER服务，WORK自动恢复链接，我看日志WORK是自动重启了，就没有管；这个时候启动的工作流，界面上无法看到工作流实例和任务实例，之后重启DS所有服务可以看到了   **Which version of Dolphin Scheduler:**  -[1.2.1] </body>
		<created>2020-05-27 09:32:28</created>
		<closed>2020-06-18 07:24:33</closed>
	</bug>
	<bug>
		<id>2822</id>
		<title>[BUG] Downloading the dag graph will refresh the page, causing the created data to disappear</title>
		<body>As shown below, after clicking the download button, the task 1 is gone  ![image](https://user-images.githubusercontent.com/55787491/82886269-e0862100-9f78-11ea-999c-97e16773b4b2.png) ![image](https://user-images.githubusercontent.com/55787491/82886294-eb40b600-9f78-11ea-9d44-b68e26455596.png)    **Which version of Dolphin Scheduler:**  -[dev_1.3.0]  </body>
		<created>2020-05-26 09:48:05</created>
		<closed>2020-05-27 09:36:00</closed>
	</bug>
	<bug>
		<id>2820</id>
		<title>[BUG] the button of multi delete do not display </title>
		<body> **Describe the bug** the button of multi delete do not display anymore.  ![image](https://user-images.githubusercontent.com/29528966/82883493-16c1a180-9f75-11ea-8c13-ed4d0c7535a8.png)  [version] dev-1.3.0</body>
		<created>2020-05-26 09:20:29</created>
		<closed>2020-05-27 09:37:32</closed>
	</bug>
	<bug>
		<id>2805</id>
		<title>[BUG] Execute multiple statements in a sql node</title>
		<body>Execute multiple statements in a sql node, I use a semicolon to separate, the execution reports a syntax error</body>
		<created>2020-05-25 03:17:29</created>
		<closed>2020-06-13 13:27:33</closed>
	</bug>
	<bug>
		<id>2799</id>
		<title>[BUG] After the master is fault-tolerant, it cannot resume operation</title>
		<body>1. Run the workflow, the workflow runs on master1 2. Stop the workflow and stop the master1 service 3. After master2 is fault-tolerant, the workflow stops, click "Resume" again, the workflow is not running 1.运行工作流，工作流在master1运行 2.停止工作流，停掉master1服务 3.master2容错后，工作流停止，再次点击“恢复运行”，工作流没有运行  **Which version of Dolphin Scheduler:**  -[dev_1.3.0]  </body>
		<created>2020-05-22 09:36:08</created>
		<closed>2020-05-27 09:37:54</closed>
	</bug>
	<bug>
		<id>2798</id>
		<title>[BUG] Restart the worker service again, the previously submitted successful tasks are not executed</title>
		<body>1. Shell_2 worker group selection cxc_189 2. Stop the worker service of 189, run the workflow, and shell_2 is in the successful submission state 3. Restart the worker service of 189, the shell_2 task is not executed again 1.shell2的worker分组选择cxc_189 2.停掉189的worker服务，运行工作流，shell_2为提交成功状态 3.重启189的worker服务，shell_2任务没有再次执行 ![image](https://user-images.githubusercontent.com/55787491/82653071-3d1fce00-9c51-11ea-97a9-91a43871d92f.png)    **Which version of Dolphin Scheduler:**  -[dev_1.3.0]  **Additional context** Add any other context about the problem here.  **Requirement or improvement - Please describe about your requirements or improvement suggestions. </body>
		<created>2020-05-22 09:33:34</created>
		<closed>2020-05-25 06:47:47</closed>
	</bug>
	<bug>
		<id>2797</id>
		<title>[BUG] ${map[${host}]} run error using host ip</title>
		<body>scp-hosts.sh  # if worker in workersGroup     if [[ "${map[${host}]}" ]] &amp;&amp; [[ "${dsDir}" -eq "conf" ]]; then       sed -i ${txt} "s#worker.group.*#worker.group=${map[${host}]}#g" $workDir/../conf/worker.properties     fi</body>
		<created>2020-05-22 07:13:14</created>
		<closed>2020-05-22 09:52:42</closed>
	</bug>
	<bug>
		<id>2796</id>
		<title>[BUG] Where is defined workersGroup using in start-all.sh and stop-all.sh</title>
		<body>no worker is running because workersGroup is not defined ? ``` for worker in ${!workersGroup[*]} do   echo "$worker worker server is starting"    ssh -p $sshPort $worker  "cd $installPath/; sh bin/dolphinscheduler-daemon.sh start worker-server;"   ssh -p $sshPort $worker  "cd $installPath/; sh bin/dolphinscheduler-daemon.sh start logger-server;" done ```</body>
		<created>2020-05-22 07:10:08</created>
		<closed>2020-05-22 09:52:58</closed>
	</bug>
	<bug>
		<id>2794</id>
		<title>[BUG] upgrade 1.3.0 worker group adapter</title>
		<body>1，process definition json worker group convert 2，process instance worker group convert 3，task instance worker group convert 4，scheduler cron table worker group convert</body>
		<created>2020-05-22 06:49:36</created>
		<closed>2020-06-16 15:16:37</closed>
	</bug>
	<bug>
		<id>2791</id>
		<title>[BUG] The data source center reported an error when creating an Oracle data source:Invalid connection string format</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** The data source center reported an error when creating an Oracle data source: org.apache.dolphinscheduler.api.service.DataSourceService:[421] - Invalid connection string format, a valid format is: "//host[:port][/service_name]"  The original question is here:#2632  **To Reproduce** When creating an Oracle data source in the data source center, according to the API logs, you can see the error, whether it is using the service name or SID.  **Which version of Dolphin Scheduler:**  -[dev]  **Requirement or improvement - The data source center normally adds Oracle data sources</body>
		<created>2020-05-22 03:13:08</created>
		<closed>2020-06-15 07:03:25</closed>
	</bug>
	<bug>
		<id>2788</id>
		<title>The RPM package made under the dev-1.3.0 branch will have dependency detection exceptions during installation</title>
		<body>The RPM package made under the dev-1.3.0 branch will have dependency detection exceptions during installation。 Like that: $ rpm -ivh apache-dolphinscheduler-incubating-1.2.1-1.noarch.rpm 错误：依赖检测失败：  osgi(org.eclipse.core.resources) 被 apache-dolphinscheduler-incubating-1.2.1-1.noarch 需要  osgi(org.eclipse.core.runtime) 被 apache-dolphinscheduler-incubating-1.2.1-1.noarch 需要  osgi(org.eclipse.text) 被 apache-dolphinscheduler-incubating-1.2.1-1.noarch 需要  </body>
		<created>2020-05-21 10:28:01</created>
		<closed>2020-06-30 07:23:41</closed>
	</bug>
	<bug>
		<id>2782</id>
		<title>[BUG]Delete the selected worker_group in zk, after running the workflow, the workflow instance and task run successfully</title>
		<body>1. There are 2 workgroups of cxc_188 and cxc_189 2. Click the run button of the workflow, select cxc_189 for the workgroup 3. Delete cxc_189 in zookeeper 4. Click the run button, the workflow instance and task are successfully run ![image](https://user-images.githubusercontent.com/55787491/82529936-b0044880-9b6e-11ea-9c65-dd1e0518bdc2.png)   **Which version of Dolphin Scheduler:**  -[dev_1.3.0]  </body>
		<created>2020-05-21 06:28:07</created>
		<closed>2020-05-25 06:49:51</closed>
	</bug>
	<bug>
		<id>2781</id>
		<title>[BUG] cannot pause work flow when task state is "submit success"</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** cannot pause the work flow when some tasks state is "submit success"   **To Reproduce** 1. worker down, only master is running 2. start a work flow 3. pause the work flow from site result: work flow cannot be operated all the time  **Which version of Dolphin Scheduler:**  -[dev-1.3.0] </body>
		<created>2020-05-21 06:26:10</created>
		<closed>2020-07-27 05:45:14</closed>
	</bug>
	<bug>
		<id>2763</id>
		<title>[BUG] Sqoop task type can not read custom parameters</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** The custom parameters of the Sqoop task do not work, and the user's custom parameters cannot be read, for example: --verbose. Such parameters cannot be found in the Sqoop command.Currently displayed on the page, but there is no corresponding analysis on the back.  **To Reproduce** Create a Sqoop type task, add any parameters in the bottom custom parameters, the custom added parameters do not take effect when the sqoop task is executed, the worker log shows that the generated sqoop command script has no custom added parameters.  **Expected behavior** The custom added parameters of sqoop node should take effect  **Screenshots** worker-log: ![image](https://user-images.githubusercontent.com/41327198/82398348-42302200-9a85-11ea-9949-40781893a6c6.png) [INFO] 2020-05-21 10:30:30.185  - [taskAppId=TASK-41-1345-2808]:[51] - sqoop task params {"sourceType":"MYSQL","targetType":"HDFS","targetParams":"{\"targetPath\":\"/tmp/sqooptest518\",\"deleteTargetDir\":true,\"fileType\":\"--as-textfile\",\"compressionCodec\":\"\",\"fieldsTerminated\":\"\",\"linesTerminated\":\"\"}","modelType":"import","sourceParams":"{\"srcType\":\"MYSQL\",\"srcDatasource\":10,\"srcTable\":\"im\",\"srcQueryType\":\"0\",\"srcQuerySql\":\"\",\"srcColumnType\":\"0\",\"srcColumns\":\"\",\"srcConditionList\":[],\"mapColumnHive\":[],\"mapColumnJava\":[]}","localParams":[{"prop":"--verbose","direct":"IN","type":"VARCHAR","value":""},{"prop":"--validate","direct":"IN","type":"VARCHAR","value":""}],"concurrency":1} [INFO] 2020-05-21 10:30:30.231  - [taskAppId=TASK-41-1345-2808]:[74] - sqoop script: sqoop import -m 1 --connect jdbc:mysql://10.180.210.143:3306/test --username root --password bigdata --table im --target-dir /tmp/sqooptest518 --as-textfile --delete-target-dir --null-non-string 'NULL' --null-string 'NULL' [INFO] 2020-05-21 10:30:30.231  - [taskAppId=TASK-41-1345-2808]:[84] - tenantCode user:hdfs, task dir:41_1345_2808 [INFO] 2020-05-21 10:30:30.232  - [taskAppId=TASK-41-1345-2808]:[89] - create command file:/tmp/dolphinscheduler/exec/process/11/41/1345/2808/41_1345_2808.command [INFO] 2020-05-21 10:30:30.232  - [taskAppId=TASK-41-1345-2808]:[108] - command : #!/bin/sh BASEDIR=$(cd `dirname $0`; pwd) cd $BASEDIR source /opt/dolphinscheduler/conf/env/dolphinscheduler_env.sh sqoop import -m 1 --connect jdbc:mysql://10.180.210.143:3306/test --username root --password bigdata --table im --target-dir /tmp/sqooptest518 --as-textfile --delete-target-dir --null-non-string 'NULL' --null-string 'NULL'   The two parameters I added: --verbose，--validateare not displayed in the generated sqoop command script  **Which version of Dolphin Scheduler:**  -[dev-1.3.0]，[dev]  **Requirement or improvement For the sqoop command, because there are too many command parameters, I think it is not appropriate to directly remove the interface used for custom parameters. Hope to be able to solve this problem. </body>
		<created>2020-05-20 02:38:00</created>
		<closed>2020-06-11 03:49:02</closed>
	</bug>
	<bug>
		<id>2762</id>
		<title>[BUG]the master would be blocked when worker group not exists</title>
		<body>**Is your feature request related to a problem? Please describe.**  i create a task with a special worker group,  master would be blocked when the worker group does not exists,  In this case, other tasks would not run anymore.   version: [dev-1.3.0]</body>
		<created>2020-05-20 02:17:55</created>
		<closed>2020-06-11 02:43:01</closed>
	</bug>
	<bug>
		<id>2759</id>
		<title>branch 1.3.0 The front-end log output is inconsistent</title>
		<body>![图片](https://user-images.githubusercontent.com/37201886/82313114-80ccca80-99fa-11ea-8845-7d835f44707a.png) ![图片](https://user-images.githubusercontent.com/37201886/82313127-84f8e800-99fa-11ea-87fb-adc7ef71265f.png) My task ran for about 20 minutes. In the last time, I found that the front-end log was inconsistent with the output log of the background log. May I ask what happened?No error was reported in the log. Finally, the program was executed successfully, but the foreground still shows that it is running.</body>
		<created>2020-05-19 10:03:17</created>
		<closed>2020-05-20 10:10:30</closed>
	</bug>
	<bug>
		<id>2758</id>
		<title>T_ds_process_definition table, some fields are not long enough to cause an error</title>
		<body>t_ds_task_instance table fields is app_link  ，The field is too short and I recommend changing varchar (255) to longtext， or  varchar（2550） ![图片](https://user-images.githubusercontent.com/37201886/82307584-24b27800-99f3-11ea-86c4-6596a97cedd7.png) ![图片](https://user-images.githubusercontent.com/37201886/82307634-34ca5780-99f3-11ea-975d-645851f24f20.png) </body>
		<created>2020-05-19 09:07:29</created>
		<closed>2020-06-01 14:14:34</closed>
	</bug>
	<bug>
		<id>2745</id>
		<title>[BUG] TaskExecutionContextCacheManagerImpl Do not execute removeByTaskInstanceId</title>
		<body>**Describe the bug** worker  TaskExecutionContextCacheManagerImpl Do not execute removeByTaskInstanceId  Causing the map to gradually become larger  ![image](https://user-images.githubusercontent.com/42244568/82195487-f1a4b180-992a-11ea-8855-7bce03b5839a.png)   **Which version of Dolphin Scheduler:**  -[dev]  </body>
		<created>2020-05-18 09:15:04</created>
		<closed>2020-06-03 16:32:58</closed>
	</bug>
	<bug>
		<id>2739</id>
		<title>[BUG] SQLTask replace the ${} of the SQL statement to "?" does not work</title>
		<body>**Describe the bug** In the SqlTask the function ParameterUtils.replaceScheduleTime(sql, taskExecutionContext.getScheduleTime(), paramsMap) replaces all $ {} to real value, so the function setSqlParamsMap(sql, rgex, sqlParamsMap, paramsMap); does not work  **Screenshots** ![image](https://user-images.githubusercontent.com/10829956/82187951-bb156980-991f-11ea-9f69-bf978ae83429.png)  **Which version of Dolphin Scheduler:**  -[dev-1.3.0]  </body>
		<created>2020-05-18 07:56:57</created>
		<closed>2020-05-22 02:07:37</closed>
	</bug>
	<bug>
		<id>2735</id>
		<title>[BUG]The IP and process pid of the master and worker in the monitoring center are not displayed  </title>
		<body> ![image](https://user-images.githubusercontent.com/55787491/82179785-c06bb780-9911-11ea-996a-ec3aad68bf41.png)  ![image](https://user-images.githubusercontent.com/55787491/82179769-b5188c00-9911-11ea-8e31-699b85b3a304.png)    **Which version of Dolphin Scheduler:**  -[dev_1.3.0]  </body>
		<created>2020-05-18 06:14:37</created>
		<closed>2020-05-22 03:43:08</closed>
	</bug>
	<bug>
		<id>2720</id>
		<title>[BUG] After executing the workflow, the master reports an error</title>
		<body> ![image](https://user-images.githubusercontent.com/55787491/82007234-5696a800-969c-11ea-9eb0-1d9536e65252.png)  **Which version of Dolphin Scheduler:**  -[dev_1.3.0]   </body>
		<created>2020-05-15 03:08:55</created>
		<closed>2020-05-22 02:10:09</closed>
	</bug>
	<bug>
		<id>2714</id>
		<title>[BUG] [Worker group manage]  No buttons added</title>
		<body>Worker group manage  No buttons added  ![image](https://user-images.githubusercontent.com/39816903/81903776-d8cb9180-95f4-11ea-98cb-94ca1e6a1db5.png)      </body>
		<created>2020-05-14 07:09:53</created>
		<closed>2020-05-18 06:34:32</closed>
	</bug>
	<bug>
		<id>2691</id>
		<title>In the workflow DAG editing page, the dependency relationship (line with arrow) does not follow the movement when the page is dragged</title>
		<body>RT</body>
		<created>2020-05-12 08:02:32</created>
		<closed>2020-06-18 06:56:52</closed>
	</bug>
	<bug>
		<id>2690</id>
		<title>打rpm包报错</title>
		<body>[ERROR] Failed to execute goal org.codehaus.mojo:rpm-maven-plugin:2.2.0:attached-rpm (default) on project dolphinscheduler-dist: Unable to copy files for packaging: You must set at least one file. -&gt; [Help 1] org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.codehaus.mojo:rpm-maven-plugin:2.2.0:attached-rpm (default) on project dolphinscheduler-dist: Unable to copy files for packaging: You must set at least one file. at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:217) at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153) at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145) at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:84) at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:59) at org.apache.maven.lifecycle.internal.LifecycleStarter.singleThreadedBuild(LifecycleStarter.java:183) at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:161) at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:320) at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:156) at org.apache.maven.cli.MavenCli.execute(MavenCli.java:537) at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:196) at org.apache.maven.cli.MavenCli.main(MavenCli.java:141) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:290) at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:230) at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:414) at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:357) Caused by: org.apache.maven.plugin.MojoExecutionException: Unable to copy files for packaging: You must set at least one file. at org.codehaus.mojo.rpm.FileHelper.copySource(FileHelper.java:272) at org.codehaus.mojo.rpm.FileHelper.processSources(FileHelper.java:485) at org.codehaus.mojo.rpm.FileHelper.installFiles(FileHelper.java:133) at org.codehaus.mojo.rpm.AbstractRPMMojo.execute(AbstractRPMMojo.java:768) at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:101) at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:209) ... 19 more Caused by: org.codehaus.plexus.archiver.ArchiverException: You must set at least one file. at org.codehaus.plexus.archiver.dir.DirectoryArchiver.execute(DirectoryArchiver.java:52) at org.codehaus.plexus.archiver.AbstractArchiver.createArchive(AbstractArchiver.java:965) at org.codehaus.mojo.rpm.FileHelper.copySource(FileHelper.java:254) ... 24 more </body>
		<created>2020-05-12 07:22:14</created>
		<closed>2020-09-02 10:09:26</closed>
	</bug>
	<bug>
		<id>2686</id>
		<title>[BUG] jobs with "kill" status will not be execute when recovery failed</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** Job A have a sub job B in it. When I  run the job A at first time, a node "mytask" In job B has not any responses,so I killed the process on server by using "kill -9 ###".Then "mytask" was changed it's status to "kill". I stopped the Job A and recovery failed and then I get into the instance job B ,I found "my task" was not runing and was still with status "kill",but at that moment the status of job B is success and the job A was go on running.  我有一个”任务A“，里面有一个子任务”任务B“。 当我第一次运行任务A时，在子任务B中有个名为"mytask"的节点执行没有反应，于是我在服务器上使用kill -9 ###命令将其执行的进程杀掉了。此时"mytask"节点的状态被自动变为kill。于是我停止了任务A的运行，开始执行恢复错误，这时我进到任务B中查看mytask，状态还是kill，但任务B的状态居然变成了success，然后任务A认为任务B成功了，继续往后执行 </body>
		<created>2020-05-12 05:31:53</created>
		<closed>2020-06-18 07:08:49</closed>
	</bug>
	<bug>
		<id>2664</id>
		<title>[BUG] Python script variable has "processDefinitionId" is error</title>
		<body>1.Python script variable has "processDefinitionId" error 2.Changing "processDefinitionId" to "processdefinitionid" will not report an error    ![image](https://user-images.githubusercontent.com/55787491/81469209-60d92200-9216-11ea-82ca-dc32e0a9e439.png)  ![image](https://user-images.githubusercontent.com/55787491/81469159-1657a580-9216-11ea-8cb7-17880a1220a7.png) ![image](https://user-images.githubusercontent.com/55787491/81469200-50c14280-9216-11ea-83c0-4c16edb2ec78.png)   **Which version of Dolphin Scheduler:**  -[dev-1.3.0]  </body>
		<created>2020-05-09 09:02:03</created>
		<closed>2020-05-09 10:40:51</closed>
	</bug>
	<bug>
		<id>2663</id>
		<title>[BUG]  When I modify the workflow definition, the flowchart can pull multiple lines</title>
		<body>**Describe the bug** ![image](https://user-images.githubusercontent.com/42244568/81468920-f1166780-9214-11ea-9147-4af546e74e3d.png)   When I modify the workflow definition, the flowchart can pull multiple lines  **Which version of Dolphin Scheduler:**  -[1.3.0-dev] </body>
		<created>2020-05-09 08:50:47</created>
		<closed>2020-05-19 03:15:02</closed>
	</bug>
	<bug>
		<id>2659</id>
		<title>[BUG] After running the workflow, the master cannot connect to the worker</title>
		<body> ![image](https://user-images.githubusercontent.com/55787491/81466926-d38ed100-9207-11ea-8673-66a1cda74656.png) ![image](https://user-images.githubusercontent.com/55787491/81466936-e0132980-9207-11ea-95f0-2e1fc93107d4.png) ![image](https://user-images.githubusercontent.com/55787491/81466938-e73a3780-9207-11ea-99e2-91b331da7beb.png)    **Which version of Dolphin Scheduler:**  -[dev_1.3.0]   </body>
		<created>2020-05-09 07:15:42</created>
		<closed>2020-05-09 07:46:30</closed>
	</bug>
	<bug>
		<id>2653</id>
		<title>[BUG] the log file size rise rapidly when start DS service</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** When I start the DS service, the logs size in logs directory rises rapidly to almost 20G, so I can't start DS, because this must not be normal.  The error info shows that there is a JDBC Connection exception with druid, as I know so far, the druid setting in DS is default, I don't know the reason result in this problem. Thanks!  **To Reproduce** Steps to reproduce the behavior, for example:  `sh ./bin/start-all.sh`  **Screenshots**  ![image](https://user-images.githubusercontent.com/14816130/81462121-cd3a2e00-91e2-11ea-884c-1191262785c6.png)  **Which version of Dolphin Scheduler:**  -[1.2]</body>
		<created>2020-05-09 02:51:48</created>
		<closed>2020-05-09 06:18:27</closed>
	</bug>
	<bug>
		<id>2650</id>
		<title>[BUG] Workflow definition cannot be deleted  </title>
		<body> ![image](https://user-images.githubusercontent.com/55787491/81461406-0fad3c00-91de-11ea-8df6-63481f7a4e6e.png)   **Which version of Dolphin Scheduler:**  -[dev-1.3.0]   </body>
		<created>2020-05-09 02:16:22</created>
		<closed>2020-05-09 09:43:48</closed>
	</bug>
	<bug>
		<id>2649</id>
		<title>[BUG] After deleting the condition node, the save workflow prompts an error</title>
		<body> ![image](https://user-images.githubusercontent.com/55787491/81461307-741bcb80-91dd-11ea-8037-69f257c3f8e8.png)    **Which version of Dolphin Scheduler:**  -[dev-1.3.0]   </body>
		<created>2020-05-09 02:12:39</created>
		<closed>2020-05-09 09:44:06</closed>
	</bug>
	<bug>
		<id>2648</id>
		<title>[BUG] dev 1.3.0 branch log to dolphinscheduler-alert-server-xx.out is not split ??</title>
		<body>Log output file, found no redirection to the specified file，dolphinscheduler-alert.log file is empty。 ？？ ![图片](https://user-images.githubusercontent.com/37201886/81461259-2dc66c80-91dd-11ea-8b68-6241bcbf67e2.png) </body>
		<created>2020-05-09 02:11:31</created>
		<closed>2020-05-11 06:37:15</closed>
	</bug>
	<bug>
		<id>2644</id>
		<title>[BUG]Unrecognized VM option 'UseFastAccessorMethods'</title>
		<body>**Describe the bug** When do `sh create-dolphinscheduler.sh` in openjdk 11.0.7, Program will exit.   ``` [dolphinscheduler@root script]$ sh create-dolphinscheduler.sh  OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.    Unrecognized VM option 'UseFastAccessorMethods'    Error: Could not create the Java Virtual Machine.    Error: A fatal exception has occurred. Program will exit.    ```  **To Reproduce** Steps to reproduce the behavior, for example: run `sh script/create-dolphinscheduler.sh`  **Which version of Dolphin Scheduler:**  1.2.1 </body>
		<created>2020-05-08 12:49:32</created>
		<closed>2020-05-31 14:27:09</closed>
	</bug>
	<bug>
		<id>2640</id>
		<title>[BUG] The dev branch is started using the docker-compose default configuration and displays zookeeper errors（dev 分支使用docker-compose默认配置启动，显示zookeeper 错误）</title>
		<body>*For better global communication, please give priority to using English description, thx! *   **Describe the bug** The screenshot below ![image](https://user-images.githubusercontent.com/37896380/81392539-6ae51d00-9151-11ea-8a44-689e482b6fcd.png)  The default configuration is used   The startup log is as follows   `zookeeper 17:18:20.12 Welcome to the Bitnami zookeeper container zookeeper 17:18:20.12 Subscribe to project updates by watching https://github.com/bitnami/bitnami-docker-zookeeper zookeeper 17:18:20.12 Submit issues and feature requests at https://github.com/bitnami/bitnami-docker-zookeeper/issues zookeeper 17:18:20.12  zookeeper 17:18:20.12 INFO  ==&gt; ** Starting ZooKeeper setup ** zookeeper 17:18:20.14 WARN  ==&gt; You have set the environment variable ALLOW_ANONYMOUS_LOGIN=yes. For safety reasons, do not use this flag in a production environment. zookeeper 17:18:20.15 INFO  ==&gt; Initializing ZooKeeper... zookeeper 17:18:20.15 INFO  ==&gt; User injected custom configuration detected! zookeeper 17:18:20.15 INFO  ==&gt; Deploying ZooKeeper with persisted data... zookeeper 17:18:20.15 INFO  ==&gt; ** ZooKeeper setup finished! **  zookeeper 17:18:20.17 INFO  ==&gt; ** Starting ZooKeeper ** /opt/bitnami/java/bin/java ZooKeeper JMX enabled by default Using config: /opt/bitnami/zookeeper/bin/../conf/zoo.cfg 2020-05-08 17:18:20,805 [myid:] - INFO  [main:QuorumPeerConfig@173] - Reading configuration from: /opt/bitnami/zookeeper/bin/../conf/zoo.cfg 2020-05-08 17:18:20,821 [myid:] - INFO  [main:QuorumPeerConfig@459] - clientPortAddress is 0.0.0.0:2181 2020-05-08 17:18:20,821 [myid:] - INFO  [main:QuorumPeerConfig@463] - secureClientPort is not set 2020-05-08 17:18:20,821 [myid:] - INFO  [main:QuorumPeerConfig@479] - observerMasterPort is not set 2020-05-08 17:18:20,822 [myid:] - INFO  [main:QuorumPeerConfig@496] - metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider 2020-05-08 17:18:20,828 [myid:1] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3 2020-05-08 17:18:20,828 [myid:1] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 0 2020-05-08 17:18:20,828 [myid:1] - INFO  [main:DatadirCleanupManager@101] - Purge task is not scheduled. 2020-05-08 17:18:20,828 [myid:1] - WARN  [main:QuorumPeerMain@138] - Either no config or no quorum defined in config, running in standalone mode 2020-05-08 17:18:20,835 [myid:1] - INFO  [main:ManagedUtil@44] - Log4j 1.2 jmx support found and enabled. 2020-05-08 17:18:20,856 [myid:1] - INFO  [main:QuorumPeerConfig@173] - Reading configuration from: /opt/bitnami/zookeeper/bin/../conf/zoo.cfg 2020-05-08 17:18:20,857 [myid:1] - INFO  [main:QuorumPeerConfig@459] - clientPortAddress is 0.0.0.0:2181 2020-05-08 17:18:20,857 [myid:1] - INFO  [main:QuorumPeerConfig@463] - secureClientPort is not set 2020-05-08 17:18:20,857 [myid:1] - INFO  [main:QuorumPeerConfig@479] - observerMasterPort is not set 2020-05-08 17:18:20,857 [myid:1] - INFO  [main:QuorumPeerConfig@496] - metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider 2020-05-08 17:18:20,857 [myid:1] - INFO  [main:ZooKeeperServerMain@122] - Starting server 2020-05-08 17:18:20,877 [myid:1] - INFO  [main:ServerMetrics@62] - ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@1018bde2 2020-05-08 17:18:20,882 [myid:1] - INFO  [main:FileTxnSnapLog@124] - zookeeper.snapshot.trust.empty : false 2020-05-08 17:18:20,891 [myid:1] - INFO  [main:ZookeeperBanner@42] -  2020-05-08 17:18:20,892 [myid:1] - INFO  [main:ZookeeperBanner@42] -   ______                  _                                           2020-05-08 17:18:20,892 [myid:1] - INFO  [main:ZookeeperBanner@42] -  |___  /                 | |                                          2020-05-08 17:18:20,892 [myid:1] - INFO  [main:ZookeeperBanner@42] -     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    2020-05-08 17:18:20,892 [myid:1] - INFO  [main:ZookeeperBanner@42] -    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| 2020-05-08 17:18:20,892 [myid:1] - INFO  [main:ZookeeperBanner@42] -   / /__  | (_) | | (_) | |   &lt;  |  __/ |  __/ | |_) | |  __/ | |     2020-05-08 17:18:20,893 [myid:1] - INFO  [main:ZookeeperBanner@42] -  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| 2020-05-08 17:18:20,893 [myid:1] - INFO  [main:ZookeeperBanner@42] -                                               | |                      2020-05-08 17:18:20,893 [myid:1] - INFO  [main:ZookeeperBanner@42] -                                               |_|                      2020-05-08 17:18:20,893 [myid:1] - INFO  [main:ZookeeperBanner@42] -  2020-05-08 17:18:20,894 [myid:1] - INFO  [main:Environment@98] - Server environment:zookeeper.version=3.6.1--104dcb3e3fb464b30c5186d229e00af9f332524b, built on 04/21/2020 15:01 GMT 2020-05-08 17:18:20,894 [myid:1] - INFO  [main:Environment@98] - Server environment:host.name=6d9a31a8232e 2020-05-08 17:18:20,895 [myid:1] - INFO  [main:Environment@98] - Server environment:java.version=11.0.7 2020-05-08 17:18:20,895 [myid:1] - INFO  [main:Environment@98] - Server environment:java.vendor=BellSoft 2020-05-08 17:18:20,895 [myid:1] - INFO  [main:Environment@98] - Server environment:java.home=/opt/bitnami/java 2020-05-08 17:18:20,895 [myid:1] - INFO  [main:Environment@98] - Server environment:java.class.path=/opt/bitnami/zookeeper/bin/../zookeeper-server/target/classes:/opt/bitnami/zookeeper/bin/../build/classes:/opt/bitnami/zookeeper/bin/../zookeeper-server/target/lib/*.jar:/opt/bitnami/zookeeper/bin/../build/lib/*.jar:/opt/bitnami/zookeeper/bin/../lib/zookeeper-prometheus-metrics-3.6.1.jar:/opt/bitnami/zookeeper/bin/../lib/zookeeper-jute-3.6.1.jar:/opt/bitnami/zookeeper/bin/../lib/zookeeper-3.6.1.jar:/opt/bitnami/zookeeper/bin/../lib/snappy-java-1.1.7.jar:/opt/bitnami/zookeeper/bin/../lib/slf4j-log4j12-1.7.25.jar:/opt/bitnami/zookeeper/bin/../lib/slf4j-api-1.7.25.jar:/opt/bitnami/zookeeper/bin/../lib/simpleclient_servlet-0.6.0.jar:/opt/bitnami/zookeeper/bin/../lib/simpleclient_hotspot-0.6.0.jar:/opt/bitnami/zookeeper/bin/../lib/simpleclient_common-0.6.0.jar:/opt/bitnami/zookeeper/bin/../lib/simpleclient-0.6.0.jar:/opt/bitnami/zookeeper/bin/../lib/netty-transport-native-unix-common-4.1.48.Final.jar:/opt/bitnami/zookeeper/bin/../lib/netty-transport-native-epoll-4.1.48.Final.jar:/opt/bitnami/zookeeper/bin/../lib/netty-transport-4.1.48.Final.jar:/opt/bitnami/zookeeper/bin/../lib/netty-resolver-4.1.48.Final.jar:/opt/bitnami/zookeeper/bin/../lib/netty-handler-4.1.48.Final.jar:/opt/bitnami/zookeeper/bin/../lib/netty-common-4.1.48.Final.jar:/opt/bitnami/zookeeper/bin/../lib/netty-codec-4.1.48.Final.jar:/opt/bitnami/zookeeper/bin/../lib/netty-buffer-4.1.48.Final.jar:/opt/bitnami/zookeeper/bin/../lib/metrics-core-3.2.5.jar:/opt/bitnami/zookeeper/bin/../lib/log4j-1.2.17.jar:/opt/bitnami/zookeeper/bin/../lib/json-simple-1.1.1.jar:/opt/bitnami/zookeeper/bin/../lib/jline-2.11.jar:/opt/bitnami/zookeeper/bin/../lib/jetty-util-9.4.24.v20191120.jar:/opt/bitnami/zookeeper/bin/../lib/jetty-servlet-9.4.24.v20191120.jar:/opt/bitnami/zookeeper/bin/../lib/jetty-server-9.4.24.v20191120.jar:/opt/bitnami/zookeeper/bin/../lib/jetty-security-9.4.24.v20191120.jar:/opt/bitnami/zookeeper/bin/../lib/jetty-io-9.4.24.v20191120.jar:/opt/bitnami/zookeeper/bin/../lib/jetty-http-9.4.24.v20191120.jar:/opt/bitnami/zookeeper/bin/../lib/javax.servlet-api-3.1.0.jar:/opt/bitnami/zookeeper/bin/../lib/jackson-databind-2.10.3.jar:/opt/bitnami/zookeeper/bin/../lib/jackson-core-2.10.3.jar:/opt/bitnami/zookeeper/bin/../lib/jackson-annotations-2.10.3.jar:/opt/bitnami/zookeeper/bin/../lib/commons-lang-2.6.jar:/opt/bitnami/zookeeper/bin/../lib/commons-cli-1.2.jar:/opt/bitnami/zookeeper/bin/../lib/audience-annotations-0.5.0.jar:/opt/bitnami/zookeeper/bin/../zookeeper-*.jar:/opt/bitnami/zookeeper/bin/../zookeeper-server/src/main/resources/lib/*.jar:/opt/bitnami/zookeeper/bin/../conf: 2020-05-08 17:18:20,895 [myid:1] - INFO  [main:Environment@98] - Server environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib 2020-05-08 17:18:20,895 [myid:1] - INFO  [main:Environment@98] - Server environment:java.io.tmpdir=/tmp 2020-05-08 17:18:20,895 [myid:1] - INFO  [main:Environment@98] - Server environment:java.compiler=&lt;NA&gt; 2020-05-08 17:18:20,895 [myid:1] - INFO  [main:Environment@98] - Server environment:os.name=Linux 2020-05-08 17:18:20,896 [myid:1] - INFO  [main:Environment@98] - Server environment:os.arch=amd64 2020-05-08 17:18:20,896 [myid:1] - INFO  [main:Environment@98] - Server environment:os.version=4.4.0-148-generic 2020-05-08 17:18:20,896 [myid:1] - INFO  [main:Environment@98] - Server environment:user.name=? 2020-05-08 17:18:20,896 [myid:1] - INFO  [main:Environment@98] - Server environment:user.home=? 2020-05-08 17:18:20,896 [myid:1] - INFO  [main:Environment@98] - Server environment:user.dir=/ 2020-05-08 17:18:20,896 [myid:1] - INFO  [main:Environment@98] - Server environment:os.memory.free=1009MB 2020-05-08 17:18:20,896 [myid:1] - INFO  [main:Environment@98] - Server environment:os.memory.max=1024MB 2020-05-08 17:18:20,896 [myid:1] - INFO  [main:Environment@98] - Server environment:os.memory.total=1024MB 2020-05-08 17:18:20,896 [myid:1] - INFO  [main:ZooKeeperServer@128] - zookeeper.enableEagerACLCheck = false 2020-05-08 17:18:20,897 [myid:1] - INFO  [main:ZooKeeperServer@136] - zookeeper.digest.enabled = true 2020-05-08 17:18:20,897 [myid:1] - INFO  [main:ZooKeeperServer@140] - zookeeper.closeSessionTxn.enabled = true 2020-05-08 17:18:20,897 [myid:1] - INFO  [main:ZooKeeperServer@1434] - zookeeper.flushDelay=0 2020-05-08 17:18:20,897 [myid:1] - INFO  [main:ZooKeeperServer@1443] - zookeeper.maxWriteQueuePollTime=0 2020-05-08 17:18:20,897 [myid:1] - INFO  [main:ZooKeeperServer@1452] - zookeeper.maxBatchSize=1000 2020-05-08 17:18:20,897 [myid:1] - INFO  [main:ZooKeeperServer@241] - zookeeper.intBufferStartingSizeBytes = 1024 2020-05-08 17:18:20,898 [myid:1] - INFO  [main:BlueThrottle@141] - Weighed connection throttling is disabled 2020-05-08 17:18:20,899 [myid:1] - INFO  [main:ZooKeeperServer@1246] - minSessionTimeout set to 4000 2020-05-08 17:18:20,899 [myid:1] - INFO  [main:ZooKeeperServer@1255] - maxSessionTimeout set to 40000 2020-05-08 17:18:20,901 [myid:1] - INFO  [main:ResponseCache@45] - Response cache size is initialized with value 400. 2020-05-08 17:18:20,901 [myid:1] - INFO  [main:ResponseCache@45] - Response cache size is initialized with value 400. 2020-05-08 17:18:20,902 [myid:1] - INFO  [main:RequestPathMetricsCollector@111] - zookeeper.pathStats.slotCapacity = 60 2020-05-08 17:18:20,902 [myid:1] - INFO  [main:RequestPathMetricsCollector@112] - zookeeper.pathStats.slotDuration = 15 2020-05-08 17:18:20,902 [myid:1] - INFO  [main:RequestPathMetricsCollector@113] - zookeeper.pathStats.maxDepth = 6 2020-05-08 17:18:20,902 [myid:1] - INFO  [main:RequestPathMetricsCollector@114] - zookeeper.pathStats.initialDelay = 5 2020-05-08 17:18:20,902 [myid:1] - INFO  [main:RequestPathMetricsCollector@115] - zookeeper.pathStats.delay = 5 2020-05-08 17:18:20,903 [myid:1] - INFO  [main:RequestPathMetricsCollector@116] - zookeeper.pathStats.enabled = false 2020-05-08 17:18:20,905 [myid:1] - INFO  [main:ZooKeeperServer@1471] - The max bytes for all large requests are set to 104857600 2020-05-08 17:18:20,905 [myid:1] - INFO  [main:ZooKeeperServer@1485] - The large request threshold is set to -1 2020-05-08 17:18:20,906 [myid:1] - INFO  [main:ZooKeeperServer@329] - Created server with tickTime 2000 minSessionTimeout 4000 maxSessionTimeout 40000 clientPortListenBacklog -1 datadir /bitnami/zookeeper/data/version-2 snapdir /bitnami/zookeeper/data/version-2 2020-05-08 17:18:20,933 [myid:1] - INFO  [main:Log@169] - Logging initialized @736ms to org.eclipse.jetty.util.log.Slf4jLog 2020-05-08 17:18:21,034 [myid:1] - WARN  [main:ContextHandler@1520] - o.e.j.s.ServletContextHandler@5b38c1ec{/,null,UNAVAILABLE} contextPath ends with /* 2020-05-08 17:18:21,034 [myid:1] - WARN  [main:ContextHandler@1531] - Empty contextPath 2020-05-08 17:18:21,053 [myid:1] - INFO  [main:Server@359] - jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 11.0.7+10-LTS 2020-05-08 17:18:21,090 [myid:1] - INFO  [main:DefaultSessionIdManager@333] - DefaultSessionIdManager workerName=node0 2020-05-08 17:18:21,090 [myid:1] - INFO  [main:DefaultSessionIdManager@338] - No SessionScavenger set, using defaults 2020-05-08 17:18:21,092 [myid:1] - INFO  [main:HouseKeeper@140] - node0 Scavenging every 600000ms 2020-05-08 17:18:21,101 [myid:1] - INFO  [main:ContextHandler@825] - Started o.e.j.s.ServletContextHandler@5b38c1ec{/,null,AVAILABLE} 2020-05-08 17:18:21,127 [myid:1] - INFO  [main:AbstractConnector@330] - Started ServerConnector@7161d8d1{HTTP/1.1,[http/1.1]}{0.0.0.0:8080} 2020-05-08 17:18:21,127 [myid:1] - INFO  [main:Server@399] - Started @930ms 2020-05-08 17:18:21,128 [myid:1] - INFO  [main:JettyAdminServer@178] - Started AdminServer on address 0.0.0.0, port 8080 and command URL /commands 2020-05-08 17:18:21,133 [myid:1] - INFO  [main:ServerCnxnFactory@169] - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory 2020-05-08 17:18:21,134 [myid:1] - WARN  [main:ServerCnxnFactory@309] - maxCnxns is not configured, using default value 0. 2020-05-08 17:18:21,136 [myid:1] - INFO  [main:NIOServerCnxnFactory@666] - Configuring NIO connection handler with 10s sessionless connection timeout, 1 selector thread(s), 8 worker threads, and 64 kB direct buffers. 2020-05-08 17:18:21,137 [myid:1] - INFO  [main:NIOServerCnxnFactory@674] - binding to port 0.0.0.0/0.0.0.0:2181 2020-05-08 17:18:21,153 [myid:1] - INFO  [main:WatchManagerFactory@42] - Using org.apache.zookeeper.server.watch.WatchManager as watch manager 2020-05-08 17:18:21,153 [myid:1] - INFO  [main:WatchManagerFactory@42] - Using org.apache.zookeeper.server.watch.WatchManager as watch manager 2020-05-08 17:18:21,154 [myid:1] - INFO  [main:ZKDatabase@132] - zookeeper.snapshotSizeFactor = 0.33 2020-05-08 17:18:21,154 [myid:1] - INFO  [main:ZKDatabase@152] - zookeeper.commitLogCount=500 2020-05-08 17:18:21,158 [myid:1] - INFO  [main:SnapStream@61] - zookeeper.snapshot.compression.method = CHECKED 2020-05-08 17:18:21,159 [myid:1] - INFO  [main:FileSnap@85] - Reading snapshot /bitnami/zookeeper/data/version-2/snapshot.0 2020-05-08 17:18:21,161 [myid:1] - INFO  [main:DataTree@1737] - The digest value is empty in snapshot 2020-05-08 17:18:21,427 [myid:1] - INFO  [main:FileTxnSnapLog@363] - 6869 txns loaded in 262 ms 2020-05-08 17:18:21,428 [myid:1] - INFO  [main:ZKDatabase@289] - Snapshot loaded in 273 ms, highest zxid is 0x1ad5, digest is 28899694010 2020-05-08 17:18:21,428 [myid:1] - INFO  [main:FileTxnSnapLog@470] - Snapshotting: 0x1ad5 to /bitnami/zookeeper/data/version-2/snapshot.1ad5 2020-05-08 17:18:21,430 [myid:1] - INFO  [main:ZooKeeperServer@519] - Snapshot taken in 2 ms 2020-05-08 17:18:21,440 [myid:1] - INFO  [main:RequestThrottler@74] - zookeeper.request_throttler.shutdownTimeout = 10000 2020-05-08 17:18:21,470 [myid:1] - INFO  [main:ContainerManager@83] - Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 2020-05-08 17:18:21,471 [myid:1] - INFO  [main:ZKAuditProvider@42] - ZooKeeper audit is disabled. 2020-05-08 17:18:21,789 [myid:1] - INFO  [SyncThread:0:FileTxnLog@284] - Creating new log file: log.1ad6 2020-05-08 17:18:24,382 [myid:1] - INFO  [NIOWorkerThread-1:FourLetterCommands@223] - The list of known four letter word commands is : [{1936881266=srvr, 1937006964=stat, 2003003491=wchc, 1685417328=dump, 1668445044=crst, 1936880500=srst, 1701738089=envi, 1668247142=conf, -720899=telnet close, 1751217000=hash, 2003003507=wchs, 2003003504=wchp, 1684632179=dirs, 1668247155=cons, 1835955314=mntr, 1769173615=isro, 1920298859=ruok, 1735683435=gtmk, 1937010027=stmk}] 2020-05-08 17:18:24,383 [myid:1] - INFO  [NIOWorkerThread-1:FourLetterCommands@224] - The list of enabled four letter word commands is : [[mntr, srvr]]`   </body>
		<created>2020-05-08 09:30:48</created>
		<closed>2020-05-12 02:15:45</closed>
	</bug>
	<bug>
		<id>2639</id>
		<title>[BUG] Upgrade from 1.2.0 to 1.3.0, Timing does not take effect  </title>
		<body>1.Scheduled to execute once every five minutes 2.The last scheduled execution in version 1.2.0 is 2020-05-08 16:43:00 3.The success of the upgrade service in version 1.3.0 is 2020-05-08 16:48:49 4.The timing is still online, but 5 minutes later， there is no scheduled execution  ![image](https://user-images.githubusercontent.com/55787491/81390493-2015d600-914e-11ea-86a3-7741e5283e44.png)  ![image](https://user-images.githubusercontent.com/55787491/81390461-155b4100-914e-11ea-8e8a-4a921f02f8aa.png)  ![image](https://user-images.githubusercontent.com/55787491/81391127-2789af00-914f-11ea-876c-1d87a54900de.png)   **Which version of Dolphin Scheduler:**  -[dev]  </body>
		<created>2020-05-08 09:13:03</created>
		<closed>2020-05-14 09:42:20</closed>
	</bug>
	<bug>
		<id>2637</id>
		<title>[BUG] Upgrade from 1.2.0 to 1.3.0, rerun, restore failed, resume operation in process instance is error</title>
		<body> ![image](https://user-images.githubusercontent.com/55787491/81380612-c4435100-913d-11ea-875e-37d6d4fb8e78.png)   **Which version of Dolphin Scheduler:**  -[dev]  </body>
		<created>2020-05-08 07:08:54</created>
		<closed>2020-05-14 09:42:46</closed>
	</bug>
	<bug>
		<id>2636</id>
		<title>[BUG] Upgrade from 1.2.0 to 1.3.0, resource files cannot be found when performing tasks</title>
		<body> ![image](https://user-images.githubusercontent.com/55787491/81380019-b6d99700-913c-11ea-8000-0dd7728c1761.png)   ![image](https://user-images.githubusercontent.com/55787491/81380019-b6d99700-913c-11ea-8000-0dd7728c1761.png)    **Which version of Dolphin Scheduler:**  -[dev]  </body>
		<created>2020-05-08 07:02:47</created>
		<closed>2020-05-14 09:43:05</closed>
	</bug>
	<bug>
		<id>2634</id>
		<title>Process shows success,when the task of the process is killed in the terminal</title>
		<body>重现步骤： 1、有两个工作流AA和BB，BB依赖AA。 2、AA中有test1和test2任务，test2任务依赖test1。 3、BB中有dependent和test3任务，dependent配置AA的test2，test3依赖dependent。 4、现在手工运行AA，（test1任务可以配置shell，shell中运行一个test1.sh文件，该文件中可以写个sleep 60s），在执行worker的终端kill掉该任务（这种情况是手工kill，实际生产中服务器压力大时很有可能被其他服务kill掉）。 5、此时显示工作流AA运行成功，AA中test1任务kill状态，test2任务没有运行。 6、手工运行BB，可以看到BB中dependent和test3任务都运行成功。  正确的场景是AA中test1被kill后，AA应该是失败状态而不是成功状态，BB因dependent失败而失败 -------------------------------------------------------------------------------------- Reproduction steps:  1. There are two workflows AA and BB, and BB depends on AA. 2. There are test1 and test2 tasks in AA, and test2 tasks depend on test1. 3. There are DEPENDENCT and test3 tasks in BB. DEPENDENCT configures test2 of AA, and test3 depends on the DEPENDENCT. 4. Now run AA manually (test1 task can configure the shell, and a test1.sh file can be run in the shell, and a sleep 60s can be written in the file). Kill the task at the terminal executing the worker (in this case, kill manually. In actual production, when the server is under great pressure, it is likely to be killed by other services). 5. At this time, the workflow AA runs successfully, the test1 task in AA is in kill status, and the test2 task is not running. 6. Run BB manually, and you can see that the DEPENDENCT and test3 tasks in BB run successfully.  I think the correct scenario is that after test1 in AA is killed, AA should be in failure state instead of success state. BB fails due to the DEPENDENCT failure</body>
		<created>2020-05-08 06:20:02</created>
		<closed>2020-05-11 06:56:20</closed>
	</bug>
	<bug>
		<id>2629</id>
		<title>[BUG] The reference failed after the udf was added</title>
		<body>**Describe the bug** The reference failed after the udf was added. Occurs in DAG, add HiveSql  **Which version of Dolphin Scheduler:** 1.2.0.release  </body>
		<created>2020-05-08 03:02:51</created>
		<closed>2020-07-14 09:25:04</closed>
	</bug>
	<bug>
		<id>2624</id>
		<title>[BUG] allways fail when a task instance submit multiple yarn application</title>
		<body>ds will write all yarn app_ids at table **t_ds_task_instance**, **app_link** column.  If is over 255 charters(limit of this varchar column) , mysql driver will throw com.mysql.cj.jdbc.exceptions.MysqlDataTruncation: Data truncation: Data too long for column 'app_link' at row 1 And treat this task instance as a failure ![image](https://user-images.githubusercontent.com/16174111/81312485-476e9380-90b9-11ea-9aad-ed009db899b1.png) ![image](https://user-images.githubusercontent.com/16174111/81312517-4ccbde00-90b9-11ea-8c07-e9bdb878a0c3.png)  </body>
		<created>2020-05-07 15:20:18</created>
		<closed>2020-05-09 03:13:33</closed>
	</bug>
	<bug>
		<id>2623</id>
		<title>[BUG] run shell task error in worker server use idea</title>
		<body>*For better global communication, please give priority to using English description, thx! *  i use apple as startup user, hdfs as tenant when  running a shell task, there are  some permission error:  ``` [root@node2 dev]#  sudo -u hdfs sh /tmp/dolphinscheduler/exec/process/1/1/111/206/1_111_206.command /tmp/dolphinscheduler/exec/process/1/1/111/206/1_111_206.command: line 4: /home/apple/.bash_profile: Permission denied ```  version：dev </body>
		<created>2020-05-07 09:58:23</created>
		<closed>2020-07-14 09:29:14</closed>
	</bug>
	<bug>
		<id>2619</id>
		<title>[BUG]  /dolphinscheduler/projects/create doesn't return project ID when create successfuly</title>
		<body> **Describe the bug** V1.2.0, when  invoke /dolphinscheduler/projects/create, it doesn't return project ID when create successfuly just return  {     "code": 0,     "msg": "success",     "data": null }  **Expected behavior** it should return project ID, otherwise, how can I build relationship between dolphin and my system.  **Which version of Dolphin Scheduler:**  -[1.2.0]  **Additional context** Add any other context about the problem here.  **Requirement or improvement - Please fix this or tell me how to get project ID for newly created project. </body>
		<created>2020-05-07 08:17:58</created>
		<closed>2020-05-30 04:45:40</closed>
	</bug>
	<bug>
		<id>2616</id>
		<title>[BUG] version1.1 When a large text is modified (&gt;300KB), click Submit and find that the document is truncated to upload</title>
		<body>BUG位置：资源中心&gt;&gt;文件管理&gt;&gt;修改文件 BUG复现： 1、创建原始文档300kb 2、展示没有问题 3、修改其中一行，点击提交 4、发现文档被截断了，只剩（100kb）  初步判断是资源文件更新接口问题</body>
		<created>2020-05-07 03:38:48</created>
		<closed>2020-05-08 01:29:13</closed>
	</bug>
	<bug>
		<id>2603</id>
		<title>[BUG] code annotation error</title>
		<body>incubator-dolphinscheduler-dev/dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/WorkerServer.java Source code： /**      * master server startup      *      * master server not use web service      * @param args arguments      */     public static void main(String[] args) {         Thread.currentThread().setName(Constants.THREAD_NAME_WORKER_SERVER);         new SpringApplicationBuilder(WorkerServer.class).web(WebApplicationType.NONE).run(args);     }  The master in the annotation on lines 74 and 76 should be changed to worker.  </body>
		<created>2020-05-06 07:20:42</created>
		<closed>2020-05-11 01:30:31</closed>
	</bug>
	<bug>
		<id>2598</id>
		<title>[BUG] After renaming the file, downloading the file gives an error</title>
		<body>1. create file is test_1.sh 2. The file is renamed to test_1.txt, and the file name displayed on the page is "test_1.txt.sh" 3. Download file, prompt "error downloading resource file" 4. Check the hdfs resource file is "test_1.txt" ![image](https://user-images.githubusercontent.com/55787491/81133105-3d4a7900-8f83-11ea-9ce6-d36fa2f38a43.png)  ![image](https://user-images.githubusercontent.com/55787491/81132928-a7aee980-8f82-11ea-8b0a-e3ed7231e560.png) ![image](https://user-images.githubusercontent.com/55787491/81133119-48050e00-8f83-11ea-84a5-83bc3f9f84d3.png)    **Which version of Dolphin Scheduler:**  -[dev]  </body>
		<created>2020-05-06 02:17:35</created>
		<closed>2020-05-22 03:52:28</closed>
	</bug>
	<bug>
		<id>2596</id>
		<title>[BUG] the file name is not correct after rename the HDFS resource file</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** The file name is not correct after rename the HDFS resource file via [Resources -&gt; File Manager -&gt; [pick a item and click]"Rename" Button]  **To Reproduce** Steps to reproduce the behavior, for example: 1. prepare a log file ![0](https://user-images.githubusercontent.com/22143753/80987937-5bba5280-8e65-11ea-91a0-273eb7ba5e99.png)  2. upload the file test.log ![image](https://user-images.githubusercontent.com/22143753/80987814-31689500-8e65-11ea-8997-e6247f9d4936.png)  3. rename test.log to test.txt ![2](https://user-images.githubusercontent.com/22143753/80988066-89070080-8e65-11ea-93e0-4e40165f1ef7.png)  4. See error: the file name is not change to test.txt, and can not open in file details ![3](https://user-images.githubusercontent.com/22143753/80988104-958b5900-8e65-11ea-96b8-18425ba527d6.png)  ![3_2](https://user-images.githubusercontent.com/22143753/80988379-03d01b80-8e66-11ea-81f9-c8d008ec00a0.png)   **Expected behavior** The file name should be change to test.txt, and can open it in file detail page  **Which version of Dolphin Scheduler:**  -[1.2.1-realease]  </body>
		<created>2020-05-04 16:22:21</created>
		<closed>2020-06-18 07:45:06</closed>
	</bug>
	<bug>
		<id>2581</id>
		<title>[BUG] When the process involves sub-processes, the complement operation will only take the start time, and will repeat the number of days to perform the complement</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** When the process involves sub-processes, the complement operation will only take the start time, and will repeat the number of days to perform the complement.  **To Reproduce** Steps to reproduce the behavior, for example: 1. Create a simple sub-process, such as a shell 2. Create another main process and associate sub-processes 3. For complement operation, you can also make up only two days  The specific operation is as follows： 1. Create subprocess，  ![image](https://user-images.githubusercontent.com/10054719/80662237-5e165880-8ac3-11ea-9e47-ea97af1179ab.png) 2. Save subprocess and setting variables ![image](https://user-images.githubusercontent.com/10054719/80662384-b6e5f100-8ac3-11ea-84f5-a307acc79f88.png) 3. Create the main process and create sub node as in main process ![image](https://user-images.githubusercontent.com/10054719/80662453-d715b000-8ac3-11ea-8186-b7a92a709c79.png) ![image](https://user-images.githubusercontent.com/10054719/80662492-f0b6f780-8ac3-11ea-9c0c-ed628b82772c.png) 4. Save main process and setting variables ![image](https://user-images.githubusercontent.com/10054719/80662523-07f5e500-8ac4-11ea-8b15-8df097cc5c76.png) 5. As follow. ![image](https://user-images.githubusercontent.com/10054719/80662545-193ef180-8ac4-11ea-8343-802808ad278f.png) 6. Then complement ![image](https://user-images.githubusercontent.com/10054719/80662594-3b387400-8ac4-11ea-96b1-75fa364ca167.png) 7. The result is as follows, the date printed is only the start date ![image](https://user-images.githubusercontent.com/10054719/80662665-67ec8b80-8ac4-11ea-9ae2-d082087efe6b.png) ![image](https://user-images.githubusercontent.com/10054719/80662670-6d49d600-8ac4-11ea-8487-608327a30654.png) ![image](https://user-images.githubusercontent.com/10054719/80662674-70dd5d00-8ac4-11ea-914d-096c12cbfb9c.png)  8. The timing of the main process is correct ![image](https://user-images.githubusercontent.com/10054719/80662741-9bc7b100-8ac4-11ea-9d4d-e05c54ca5a86.png)   **Which version of Dolphin Scheduler:**  -[1.2.1] - Stand-alone deployment  </body>
		<created>2020-04-30 01:27:32</created>
		<closed>2020-05-16 10:38:41</closed>
	</bug>
	<bug>
		<id>2578</id>
		<title>[BUG]wrong description of work flow copy tips</title>
		<body>![image](https://user-images.githubusercontent.com/29528966/80588031-28815900-8a4a-11ea-8c41-595890f0c529.png)  version: dev  i think the tips should be "work flow copy"</body>
		<created>2020-04-29 10:50:58</created>
		<closed>2020-05-11 01:35:21</closed>
	</bug>
	<bug>
		<id>2571</id>
		<title>[BUG] After killing the process instance,  can't rerun and Resume run</title>
		<body>1.run workflow 2.stop master 3.kill process instance 4.start master,The process instance is in the kill state, but the task is in the successful state 5.rerun process instance or Resume run  process instance,No process instance and task instance are generated   ![image](https://user-images.githubusercontent.com/55787491/80558479-21882580-8a0d-11ea-8e4d-07542ff3c520.png) ![image](https://user-images.githubusercontent.com/55787491/80558513-3a90d680-8a0d-11ea-89f6-5ba220747ead.png) ![image](https://user-images.githubusercontent.com/55787491/80558605-8a6f9d80-8a0d-11ea-8b6b-fb4e18b18806.png)     **Which version of Dolphin Scheduler:**  -[dev]  </body>
		<created>2020-04-29 03:36:38</created>
		<closed>2020-05-09 07:53:35</closed>
	</bug>
	<bug>
		<id>2568</id>
		<title>After the sub process ends, the main process task status is not updated.</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** After the sub process ends, the main process task status is not updated.  **To Reproduce** Steps to reproduce the behavior, for example: 1. Create the main process and sub-process as shown in the figure 2. Then make up data two days  **Expected behavior** 1. After 12 hours of execution there is still no update. 2. After the service restarts, the task will be automatically re-executed（In fact, I just want to end this task, and later modify the database table to temporarily end the task.） 3. This problem does not always appear.(This step was successful again just after I executed)  **Which version of Dolphin Scheduler:**  -[1.2.1] - Stand-alone deployment  **Additional context** Add any other context about the problem here.  ![image](https://user-images.githubusercontent.com/10054719/80553181-7d49b300-89fb-11ea-905e-42ff3650978d.png)  ![image](https://user-images.githubusercontent.com/10054719/80553200-86d31b00-89fb-11ea-86d5-3eb34fb15776.png)  ![image](https://user-images.githubusercontent.com/10054719/80553208-8dfa2900-89fb-11ea-93c5-0d994346658c.png)  </body>
		<created>2020-04-29 01:29:06</created>
		<closed>2020-06-18 07:57:07</closed>
	</bug>
	<bug>
		<id>2567</id>
		<title>After the sub process ends, the main process task status is not updated</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** After the sub process ends, the main process task status is not updated.  **To Reproduce** Steps to reproduce the behavior, for example: 1. Create the main process and sub-process as shown in the figure 2. Then make up two days  **Expected behavior** 1. After 12 hours of execution there is still no update. 2. After the service restarts, the task will be automatically re-executed（In fact, I just want to end this task, and later modify the database table to the task status.）  **Which version of Dolphin Scheduler:**  -[1.2.1]  **Additional context** Add any other context about the problem here.  **Requirement or improvement - 1.2.1 - Stand-alone deployment  ![image](https://user-images.githubusercontent.com/10054719/80553181-7d49b300-89fb-11ea-905e-42ff3650978d.png)  ![image](https://user-images.githubusercontent.com/10054719/80553200-86d31b00-89fb-11ea-86d5-3eb34fb15776.png)  ![image](https://user-images.githubusercontent.com/10054719/80553208-8dfa2900-89fb-11ea-93c5-0d994346658c.png)  </body>
		<created>2020-04-29 01:27:23</created>
		<closed>2020-04-29 01:45:27</closed>
	</bug>
	<bug>
		<id>2565</id>
		<title>[BUG] 配置了告警策略，没有收到告警邮件和查到相关输出日志</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** 任务流配置了通知策略：成功或失败都发，执行任务流没有告警邮件收到和相关日志输出 **To Reproduce** 点击运行任务流，在弹出的窗口中配置通知策略:成功或失败都发，选择通知组，点击运行按钮 **Expected behavior** 收到告警邮件和后台查看到告警日志输出 **Screenshots** If applicable, add screenshots to help explain your problem. [](url)  **Which version of Dolphin Scheduler:**  -[1.1.0-preview]  **Additional context** Add any other context about the problem here.  **Requirement or improvement - Please describe about your requirements or improvement suggestions. </body>
		<created>2020-04-28 14:28:40</created>
		<closed>2020-04-28 14:30:22</closed>
	</bug>
	<bug>
		<id>2563</id>
		<title>[BUG] the license about org.codehaus.janino</title>
		<body>the license about janino maybe not compatiable with Apache v2  https://github.com/janino-compiler/janino/blob/3.1.12/LICENSE</body>
		<created>2020-04-28 12:38:09</created>
		<closed>2020-05-18 10:33:43</closed>
	</bug>
	<bug>
		<id>2557</id>
		<title>[BUG] After the success or failure of the conditions node, the icon is not displayed</title>
		<body>  ![image](https://user-images.githubusercontent.com/55787491/80473534-df150900-8978-11ea-9e5c-9c3b1b913e51.png)  **Which version of Dolphin Scheduler:**  -[dev]  </body>
		<created>2020-04-28 09:52:58</created>
		<closed>2020-05-06 01:35:01</closed>
	</bug>
	<bug>
		<id>2554</id>
		<title>[BUG] The options overlap. It is recommended to add a scroll bar</title>
		<body> **Describe the bug** The options overlap. It is recommended to add a scroll bar  **Screenshots** ![image](https://user-images.githubusercontent.com/7700151/80467330-3cf12300-8970-11ea-9ac0-85e7150a55d7.png)   **Which version of Dolphin Scheduler:**  -[dev branch] </body>
		<created>2020-04-28 08:53:03</created>
		<closed>2020-05-11 01:49:33</closed>
	</bug>
	<bug>
		<id>2547</id>
		<title>Zookeeper management interface in monitoring center displays abnormal</title>
		<body>  **Describe the bug** Zookeeper management interface in monitoring center displays abnormal。In fact, zookeepeer is running normally, both master and worker are successfully registered in zookeeper  **To Reproduce** 1、After normal installation and deployment, log in to the dolphinscheduler web interface 2、Check the zookeeper management interface of the monitoring center, you can find this problem  **Expected behavior** It can display various monitoring indicators of zookeeper normally  **Screenshots** ![image](https://user-images.githubusercontent.com/42579056/80374318-13c98780-88c9-11ea-8d5f-53448b957f02.png)    **Which version of Dolphin Scheduler:**  -[1.2.0]   </body>
		<created>2020-04-27 12:53:48</created>
		<closed>2020-05-06 05:56:06</closed>
	</bug>
	<bug>
		<id>2545</id>
		<title>[BUG] The create user is always loading when the queue does not select any value</title>
		<body>**The create user is always loading when the queue does not select any value**  Prerequisite: queue is not required to fill **Steps to reproduce the issue** 1. Click create user 2. User name, password, tenant, email mobile phone number are filled in correctly 3. Only the queue is empty () 4. submit 5. error: Display "loading" all the time  **expected result** Successfully create the user when the queue is empty, so I can use the tenant's queue, because the priority of the user's queue is higher than that of the tenant's queue.  **DolphinScheduler1.2.0** **Screenshots**  ![1587983909(1)](https://user-images.githubusercontent.com/51871547/80363158-63eb1e80-88b6-11ea-83cc-dc37183f4a76.jpg)  </body>
		<created>2020-04-27 10:39:35</created>
		<closed>2020-04-28 10:22:37</closed>
	</bug>
	<bug>
		<id>2538</id>
		<title>[BUG] Importing the workflow concurrently has the same name, resulting in an error when importing the workflow again  </title>
		<body>1. Import the same workflow concurrently 2. The imported workflow names are the same 3. Import workflow error again  ![image](https://user-images.githubusercontent.com/55787491/80343905-4d829a00-8899-11ea-81d2-beb67050ad92.png) ![image](https://user-images.githubusercontent.com/55787491/80343966-5ffcd380-8899-11ea-8b78-1e913864a301.png)   **Which version of Dolphin Scheduler:**  -[dev]   </body>
		<created>2020-04-27 07:13:32</created>
		<closed>2020-05-22 03:55:58</closed>
	</bug>
	<bug>
		<id>2533</id>
		<title>[dev branch]   Use docker-compose for deployment .   Failed to execute python script(使用docker-compose部署，执行python脚本错误,所使用的docker-compose文件在swarm目录下)</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** start command: docker-compose up -d  description:  Failed to execute python script  the log show    sudo: /opt/soft/python: command not found  However, I have changed the dolphinscheduler_env.sh file   `export HADOOP_HOME=/opt/soft/hadoop export HADOOP_CONF_DIR=/opt/soft/hadoop/etc/hadoop export SPARK_HOME1=/opt/soft/spark1 export SPARK_HOME2=/opt/soft/spark2 export PYTHON_HOME=/usr/bin/python export JAVA_HOME=/opt/soft/java export HIVE_HOME=/opt/soft/hive export FLINK_HOME=/opt/soft/flink export PATH=$HADOOP_HOME/bin:$SPARK_HOME1/bin:$SPARK_HOME2/bin:$PYTHON_HOME:$JAVA_HOME/bin:$HIVE_HOME/bin:$FLINK_HOME/bin:$PATH`    *Screenshots** ![image](https://user-images.githubusercontent.com/37896380/80326017-05984e80-886a-11ea-8015-b843c7979584.png)  **Requirement or improvement Even better, the built-in python version of the container is python3   Hard you      </body>
		<created>2020-04-27 01:35:11</created>
		<closed>2020-04-27 08:20:58</closed>
	</bug>
	<bug>
		<id>2529</id>
		<title>why task instance is null</title>
		<body> **Describe the question** I have a workflow that is executed once every hour. Some tasks started at the time node cannot be completed normally and have been running all the time. The worker log finds errors:【[ERROR] 2020-04-26 13:10:03.627 org.apache.dolphinscheduler.server.worker.runner.FetchTaskThread:[261] - task instance is null. task id : 245 】  **version1.2.0 of DolphinScheduler:**  **dolphinscheduler-master.log** [INFO] 2020-04-26 13:10:03.269 org.apache.dolphinscheduler.server.master.runner.MasterSchedulerThread:[114] - find one command: id: 68, type: SCHEDULER [INFO] 2020-04-26 13:10:03.461 org.apache.dolphinscheduler.server.master.runner.MasterSchedulerThread:[119] - start master exec thread , split DAG ... [INFO] 2020-04-26 13:10:03.465 org.apache.dolphinscheduler.server.master.runner.MasterExecThread:[296] - prepare process :158 end [INFO] 2020-04-26 13:10:03.468 org.apache.dolphinscheduler.server.master.runner.MasterExecThread:[792] - add task to stand by list: sparkPi [INFO] 2020-04-26 13:10:03.468 org.apache.dolphinscheduler.common.queue.TaskQueueFactory:[45] - task queue impl use zookeeper  [INFO] 2020-04-26 13:10:03.468 org.apache.dolphinscheduler.server.master.runner.MasterExecThread:[801] - remove task from stand by list: sparkPi [INFO] 2020-04-26 13:10:03.470 org.apache.dolphinscheduler.dao.ProcessDao:[769] - start submit task : sparkPi, instance id:158, state: RUNNING_EXEUTION,  [INFO] 2020-04-26 13:10:03.474 org.apache.dolphinscheduler.common.queue.TaskQueueZkImpl:[99] - check task:2_158_2_0_-1 not exist in task queue [INFO] 2020-04-26 13:10:03.628 org.apache.dolphinscheduler.common.queue.TaskQueueZkImpl:[99] - check task:2_158_2_245_-1 not exist in task queue [INFO] 2020-04-26 13:10:03.628 org.apache.dolphinscheduler.dao.ProcessDao:[973] - task ready to queue: TaskInstance{id=245, name='sparkPi', taskType='SHELL', processDefinitionId=9, processInstanceId=158, processInstanceName='null', taskJson='{"depList":[],"dependence":"{}","forbidden":false,"id":"tasks-36923","maxRetryTimes":0,"name":"sparkPi","params":"{\"rawScript\":\"sshpass -p  hadoop ssh -o StrictHostKeyChecking=no hadoop@192.168.12.59 \\\"sh /data/hadoop/liucf/dsTest/sparkPi.sh\\\"\",\"localParams\":[],\"resourceList\":[]}","preTasks":"[]","retryInterval":1,"runFlag":"NORMAL","taskInstancePriority":"MEDIUM","taskTimeoutParameter":{"enable":false,"interval":0},"timeout":"{\"enable\":false,\"strategy\":\"\"}","type":"SHELL","workerGroupId":-1}', state=SUBMITTED_SUCCESS, submitTime=Sun Apr 26 13:10:03 CST 2020, startTime=Sun Apr 26 13:10:03 CST 2020, endTime=null, host='null', executePath='null', logPath='null', retryTimes=0, alertFlag=NO, flag=YES, processInstance=null, processDefine=null, pid=0, appLink='null', flag=YES, dependency=null, duration=null, maxRetryTimes=0, retryInterval=1, taskInstancePriority=MEDIUM, processInstancePriority=MEDIUM, workGroupId=-1} [INFO] 2020-04-26 13:10:03.628 org.apache.dolphinscheduler.common.queue.TaskQueueZkImpl:[126] - add task : /dolphinscheduler/tasks_queue/2_158_2_245_-1 to tasks queue , result success [INFO] 2020-04-26 13:10:03.628 org.apache.dolphinscheduler.dao.ProcessDao:[975] - master insert into queue success, task : sparkPi [INFO] 2020-04-26 13:10:03.629 org.apache.dolphinscheduler.dao.ProcessDao:[786] - submit task :sparkPi state:SUBMITTED_SUCCESS complete, instance id:158 state: RUNNING_EXEUTION   **dolphinscheduler-worker.log** [INFO] 2020-04-26 13:10:03.607 org.apache.dolphinscheduler.common.queue.TaskQueueZkImpl:[211] - consume tasks: [2_158_2_245_-1],there still have 0 tasks need to be executed [ERROR] 2020-04-26 13:10:03.627 org.apache.dolphinscheduler.server.worker.runner.FetchTaskThread:[261] - task instance is null. task id : 245  [WARN] 2020-04-26 13:10:03.627 org.apache.dolphinscheduler.server.worker.runner.FetchTaskThread:[188] - remove task queue : 2_158_2_245_-1 due to taskInstance is null [INFO] 2020-04-26 13:10:03.627 org.apache.dolphinscheduler.common.queue.TaskQueueZkImpl:[278] - consume task /dolphinscheduler/tasks_queue/2_158_2_245_-1  **Workflow instance screenshot**  ![1587890842(1)](https://user-images.githubusercontent.com/51871547/80302626-b1478d00-87dd-11ea-97d4-08aa2244a6d0.jpg) What is the cause of this? How to avoid it?   </body>
		<created>2020-04-26 08:52:01</created>
		<closed>2020-04-26 10:08:22</closed>
	</bug>
	<bug>
		<id>2526</id>
		<title>[BUG] sql task node failed to run</title>
		<body>![image](https://user-images.githubusercontent.com/55787491/80299661-b9e19880-87c8-11ea-8410-98d1b78a6944.png) ![image](https://user-images.githubusercontent.com/55787491/80299666-cb2aa500-87c8-11ea-8e43-1db209a8f0c1.png) </body>
		<created>2020-04-26 06:12:57</created>
		<closed>2020-05-14 09:00:27</closed>
	</bug>
	<bug>
		<id>2523</id>
		<title>[BUG] The number of worker threads does't take effect</title>
		<body>1.set worker.exec.threads=2 in conf/worker.properties  2.restart worker service 3.run workflow，Number of tasks greater than 2，The task does not wait for the thread, but runs all tasks，as shown below:  ![image](https://user-images.githubusercontent.com/55787491/80296294-33b75900-87ac-11ea-8117-80f9adccce32.png) ![image](https://user-images.githubusercontent.com/55787491/80296356-da035e80-87ac-11ea-9828-284188df5dca.png)   **Which version of Dolphin Scheduler:**  -[dev]  </body>
		<created>2020-04-26 02:59:11</created>
		<closed>2020-04-30 06:46:01</closed>
	</bug>
	<bug>
		<id>2517</id>
		<title>[BUG] worker_group is not configurable in conf/config/install_config.conf</title>
		<body>Currently worker_group is not configurable in conf/config/install_config.conf，Need to be manually configured in worker.properties ![image](https://user-images.githubusercontent.com/55787491/80188331-97724280-8643-11ea-8293-e860d3782537.png)   **Which version of Dolphin Scheduler:**  -[dev]  </body>
		<created>2020-04-24 07:52:45</created>
		<closed>2020-05-20 11:10:18</closed>
	</bug>
	<bug>
		<id>2515</id>
		<title>[BUG] When double-clicking two sql execution tasks alternately for editing, the sql statement will display an error</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** When double-clicking two sql execution tasks alternately for editing, the sql statement will display an error.  **To Reproduce** Steps to reproduce the behavior, for example: 1. Create workflow 2. Then create two sql scheduling tasks in succession（eq. one is create table sql, and other is insert sql） 3. Save&amp;quit the workflow 4. Edit the two sql scheduling tasks alternately, this time you will find an error when displaying the statement  **Expected behavior** no  **Screenshots** 1. Create the first sql task ![image](https://user-images.githubusercontent.com/10054719/80185982-de5e3900-863f-11ea-920a-5a5f25da0da5.png) 2. create the second sql task ![image](https://user-images.githubusercontent.com/10054719/80186081-051c6f80-8640-11ea-9ad3-84705b7f5225.png) 3. create connect ![image](https://user-images.githubusercontent.com/10054719/80186119-149bb880-8640-11ea-97f7-d0d1a08d3c8f.png) 4.Edit after saving ![image](https://user-images.githubusercontent.com/10054719/80186215-3b59ef00-8640-11ea-8a1f-926c750ccb8a.png) 5. Click two sql tasks alternately， then and look the error! ![image](https://user-images.githubusercontent.com/10054719/80186427-8e33a680-8640-11ea-86a6-b31e6a08644a.png)    **Which version of Dolphin Scheduler:**  -[1.2.1]  **Additional context** no  **Requirement or improvement - Should be a front-end bug        </body>
		<created>2020-04-24 07:32:57</created>
		<closed>2020-05-11 01:59:32</closed>
	</bug>
	<bug>
		<id>2500</id>
		<title>[BUG] Abnormal return jar data</title>
		<body>![image](https://user-images.githubusercontent.com/55787491/80062728-f6ae5500-8566-11ea-9c75-7a37d2f61166.png) ![image](https://user-images.githubusercontent.com/55787491/80062785-1fcee580-8567-11ea-8561-aeb163e39994.png) </body>
		<created>2020-04-23 05:32:32</created>
		<closed>2020-04-24 03:14:01</closed>
	</bug>
	<bug>
		<id>2499</id>
		<title>[BUG]The task is in progress, the master and worker hang up , start the master and worker again, the process instance and task are not fault-tolerant</title>
		<body>1.The task is in progress 2. Worker hangs first, then hangs master 3.start the master and worker again, the process instance and task are not fault-tolerant,Status has been in progress    ![image](https://user-images.githubusercontent.com/55787491/80054593-3e76b180-8552-11ea-9779-b243169b6e44.png)  ![image](https://user-images.githubusercontent.com/55787491/80054556-299a1e00-8552-11ea-998c-9696719264a4.png)  **Which version of Dolphin Scheduler:**  -[dev]  </body>
		<created>2020-04-23 03:05:33</created>
		<closed>2020-04-26 10:07:25</closed>
	</bug>
	<bug>
		<id>2492</id>
		<title>[BUG] sh stop-all.sh,  the master service is not killed  </title>
		<body>1. sh stop-all.sh 2. Check the master service，the master service is not killed       **Which version of Dolphin Scheduler:**  -[dev]  </body>
		<created>2020-04-22 03:20:31</created>
		<closed>2020-04-23 09:12:16</closed>
	</bug>
	<bug>
		<id>2486</id>
		<title>[BUG] The worker cannot connect to the new master service</title>
		<body>1. Run the workflow, the task is in the execution state 2. stop master service 3. Restart the master service, as shown in the figure below, after the task is executed, the worker cannot connect to the master service, and the workflow is fault-tolerant  ![image](https://user-images.githubusercontent.com/55787491/79852239-fc862800-83f8-11ea-83e3-08dc978f4b75.png) ![image](https://user-images.githubusercontent.com/55787491/79852270-0576f980-83f9-11ea-8f97-42543cdd19b7.png) ![image](https://user-images.githubusercontent.com/55787491/79852297-0f98f800-83f9-11ea-87c4-6706c37ba73c.png)    **Which version of Dolphin Scheduler:**  -[dev]  </body>
		<created>2020-04-21 09:55:09</created>
		<closed>2020-04-23 01:10:09</closed>
	</bug>
	<bug>
		<id>2485</id>
		<title>[BUG] The time display on web interface and database is inconsistent</title>
		<body>process_instance： schedule_time、start_time、end_time task_instance：submit_time、start_time、end_time  ![image](https://user-images.githubusercontent.com/62231347/79850265-399ceb00-83f6-11ea-8544-8f7df8a79f9a.png) </body>
		<created>2020-04-21 09:27:29</created>
		<closed>2020-04-21 12:19:30</closed>
	</bug>
	<bug>
		<id>2484</id>
		<title>[BUG] The zookeeper.quorum configuration in install.sh is error</title>
		<body>sed -i ${txt} "s#zookeeper.quorum.*#zookeeper.quorum=${zkQuorum}#g" conf/common.properties  conf/common.properties should be changed to conf/zookeeper.properties  ![image](https://user-images.githubusercontent.com/55787491/79832764-b327df80-83dc-11ea-95ad-d2591eb886f2.png)  **Which version of Dolphin Scheduler:**  -[dev]  </body>
		<created>2020-04-21 06:34:11</created>
		<closed>2020-04-22 10:57:53</closed>
	</bug>
	<bug>
		<id>2481</id>
		<title>[BUG] the Mysql needs to configure with“allowMultiQueries = true”,</title>
		<body>1.Since MYSQL does not support batch upload, the data source needs to be configured with“allowMultiQueries = true”, otherwise an error will be occurred when deleting resource files。mysql configuration is as follows： spring.datasource.url=jdbc:mysql://192.168.xx.xx:3306/dolphinscheduler?useUnicode=true&amp;characterEncoding=UTF-8&amp;allowMultiQueries=true  2.It is recommended to change the database name to configurable  **Which version of Dolphin Scheduler:**  -[dev]  </body>
		<created>2020-04-21 03:57:53</created>
		<closed>2020-05-06 02:06:28</closed>
	</bug>
	<bug>
		<id>2478</id>
		<title>[BUG] The professional vocabulary is misspelled </title>
		<body>The professional vocabulary is misspelled on the Official website of dolphinscheduler.For example, MySQL is written as Mysql,ZooKeeper is writtern as zookeeper. ![image](https://user-images.githubusercontent.com/12154864/79764414-e96f4b80-8357-11ea-8650-de5901b6e6ba.png) </body>
		<created>2020-04-20 14:41:35</created>
		<closed>2020-05-20 15:09:21</closed>
	</bug>
	<bug>
		<id>2473</id>
		<title>In the dev branch, the RPM package  printed under the dist module does not contain configuration files: master.properties, worker.properties</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** A clear and concise description of what the bug is.  **To Reproduce** Steps to reproduce the behavior, for example: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error  **Expected behavior** A clear and concise description of what you expected to happen.  **Screenshots** If applicable, add screenshots to help explain your problem.   **Which version of Dolphin Scheduler:**  -[1.1.0-preview]  **Additional context** Add any other context about the problem here.  **Requirement or improvement - Please describe about your requirements or improvement suggestions. </body>
		<created>2020-04-20 11:37:54</created>
		<closed>2020-04-20 11:38:08</closed>
	</bug>
	<bug>
		<id>2466</id>
		<title>[BUG] run the workflow , failed to send mail</title>
		<body>1.run the workflow 2.see the alert.log , failed to send mail  ![image](https://user-images.githubusercontent.com/55787491/79720077-6ed00d00-8312-11ea-8aeb-82314d0f72d7.png)  ![image](https://user-images.githubusercontent.com/55787491/79719961-3cbeab00-8312-11ea-817c-2350ed7bc923.png)   **Which version of Dolphin Scheduler:**  -[dev]  </body>
		<created>2020-04-20 06:24:30</created>
		<closed>2020-04-23 01:16:35</closed>
	</bug>
	<bug>
		<id>2464</id>
		<title>[BUG] dependent task failed when conditions task exists</title>
		<body>![image](https://user-images.githubusercontent.com/29528966/79708968-8ba91800-82f3-11ea-8bfb-ee1757bb2d80.png)  description: 1. work flow A have a  conditions task.  2. work flow B have a dependent task that depend work A  3. work flow B would failed always. </body>
		<created>2020-04-20 02:48:35</created>
		<closed>2020-05-21 05:47:05</closed>
	</bug>
	<bug>
		<id>2462</id>
		<title>[BUG] Download log file is wrong when log is too large</title>
		<body> </body>
		<created>2020-04-19 05:10:42</created>
		<closed>2020-04-19 06:32:42</closed>
	</bug>
	<bug>
		<id>2461</id>
		<title>[BUG]can not view large log in task instance page</title>
		<body> </body>
		<created>2020-04-19 05:09:54</created>
		<closed>2020-04-19 06:33:25</closed>
	</bug>
	<bug>
		<id>2457</id>
		<title>[BUG] Process defintion - Current node settings - SQL Statement </title>
		<body>SQL Statement's value is not correct, When a process has multiple nodes, The SQL Statement's value is random at value of all nodes' values when i doubleclick a node</body>
		<created>2020-04-18 01:30:38</created>
		<closed>2020-05-11 02:41:05</closed>
	</bug>
	<bug>
		<id>2451</id>
		<title>dev final state and running state run flag display</title>
		<body>![终态](https://user-images.githubusercontent.com/23756105/79553605-51f7c780-80cf-11ea-9a81-1521845c992d.png) ![运行中](https://user-images.githubusercontent.com/23756105/79553611-53c18b00-80cf-11ea-9a04-3349614f0b08.png) </body>
		<created>2020-04-17 09:18:02</created>
		<closed>2020-05-11 02:42:09</closed>
	</bug>
	<bug>
		<id>2450</id>
		<title>[BUG] cannot complement data for one day</title>
		<body> cannot complement data for one day.  ![image](https://user-images.githubusercontent.com/29528966/79549206-443f4380-80c9-11ea-9ec9-678b65095969.png) </body>
		<created>2020-04-17 08:35:59</created>
		<closed>2020-04-23 02:23:33</closed>
	</bug>
	<bug>
		<id>2449</id>
		<title>[BUG]  Cancel authorization file error  </title>
		<body>1.admin authorizes user A's resource file to user B 2. User A refers to the resource file in the workflow definition and goes online 3.admin cancels user B's authorization file, prompting that the resource file is online ============================================================= 1.admin将用户A的资源文件授权给用户B 2.用户A在工作流定义中引用该资源文件且上线 3.admin取消用户B的授权文件，提示该资源文件已上线 ![image](https://user-images.githubusercontent.com/55787491/79538925-d8081400-80b7-11ea-96d8-4051e2b3bcc4.png)   **Which version of Dolphin Scheduler:**  -[dev]  </body>
		<created>2020-04-17 06:30:56</created>
		<closed>2020-05-18 06:48:40</closed>
	</bug>
	<bug>
		<id>2448</id>
		<title>[BUG] run hive task , failed to send mail</title>
		<body>1.run sql-hive task ， Failed to send mail  2.The alert service does not print logs   ![image](https://user-images.githubusercontent.com/55787491/79537198-5bc00180-80b4-11ea-9680-73446446d758.png) ![image](https://user-images.githubusercontent.com/55787491/79537267-7eeab100-80b4-11ea-8698-17150693024e.png)   **Which version of Dolphin Scheduler:**  -[dev] </body>
		<created>2020-04-17 06:08:26</created>
		<closed>2020-04-20 05:56:17</closed>
	</bug>
	<bug>
		<id>2442</id>
		<title>[BUG] update  the  directory  of resource  is error</title>
		<body>  update the  directory occasionally appears the resource file does't exist, and the actual update directory is successful  ![image](https://user-images.githubusercontent.com/55787491/79429815-9feecb80-7ffa-11ea-9c00-41e88eed05e9.png) ![image](https://user-images.githubusercontent.com/55787491/79429960-cd3b7980-7ffa-11ea-958e-32cefebfeffe.png) ![image](https://user-images.githubusercontent.com/55787491/79430009-e17f7680-7ffa-11ea-91ea-87c9d91237b1.png)   **Which version of Dolphin Scheduler:**  -[dev]  </body>
		<created>2020-04-16 08:01:56</created>
		<closed>2020-04-27 06:16:22</closed>
	</bug>
	<bug>
		<id>2439</id>
		<title>[BUG] When exist many retry tasks, Gantt chart bug</title>
		<body>fix before: ![image](https://user-images.githubusercontent.com/39549317/79425027-a9c10080-7ff3-11ea-9e0b-80162a187d4b.png)  fix end: ![image](https://user-images.githubusercontent.com/39549317/79425047-b5acc280-7ff3-11ea-8ce7-371349bec618.png)  </body>
		<created>2020-04-16 07:05:50</created>
		<closed>2020-04-17 09:51:55</closed>
	</bug>
	<bug>
		<id>2437</id>
		<title>[BUG] Instance must be started before calling this method</title>
		<body>**Describe the bug** WorkerServer was shutdown with the following error:  ```  [INFO] 2020-04-16 13:50:59.804 org.apache.dolphinscheduler.common.zk.ZookeeperCachedOperator:[47] - add listener to zk path: /dolphinscheduler [INFO] 2020-04-16 13:51:01.102 org.apache.dolphinscheduler.server.worker.WorkerServer:[59] - Started WorkerServer in 11978.928 seconds (JVM running for 11979.34) [ERROR] 2020-04-16 13:51:01.112 org.apache.dolphinscheduler.common.zk.ZookeeperOperator:[156] - isExisted key : /dolphinscheduler/masters java.lang.IllegalStateException: instance must be started before calling this method at org.apache.curator.shaded.com.google.common.base.Preconditions.checkState(Preconditions.java:176) at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:367) at org.apache.dolphinscheduler.common.zk.ZookeeperOperator.isExisted(ZookeeperOperator.java:154) at org.apache.dolphinscheduler.common.zk.AbstractZKClient.getActiveMasterNum(AbstractZKClient.java:216) at org.apache.dolphinscheduler.server.worker.WorkerServer$1.run(WorkerServer.java:185) at java.lang.Thread.run(Thread.java:748) [INFO] 2020-04-16 13:51:01.179 com.alibaba.druid.pool.DruidDataSource:[1928] - {dataSource-1} closed Exception in thread "Thread-2" org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.PersistenceException:  ### Error updating database.  Cause: org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection; nested exception is com.alibaba.druid.pool.DataSourceDisableException ### The error may exist in org/apache/dolphinscheduler/dao/mapper/AlertMapper.java (best guess) ### The error may involve org.apache.dolphinscheduler.dao.mapper.AlertMapper.insert ### The error occurred while executing an update ### Cause: org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection; nested exception is com.alibaba.druid.pool.DataSourceDisableException at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:78) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:440) at com.sun.proxy.$Proxy79.insert(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:271) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.execute(MybatisMapperMethod.java:58) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy.invoke(MybatisMapperProxy.java:61) at com.sun.proxy.$Proxy95.insert(Unknown Source) at org.apache.dolphinscheduler.dao.AlertDao.sendServerStopedAlert(AlertDao.java:108) at org.apache.dolphinscheduler.server.worker.WorkerServer$1.run(WorkerServer.java:186) at java.lang.Thread.run(Thread.java:748) Caused by: org.apache.ibatis.exceptions.PersistenceException:  ### Error updating database.  Cause: org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection; nested exception is com.alibaba.druid.pool.DataSourceDisableException ### The error may exist in org/apache/dolphinscheduler/dao/mapper/AlertMapper.java (best guess) ### The error may involve org.apache.dolphinscheduler.dao.mapper.AlertMapper.insert ### The error occurred while executing an update ### Cause: org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection; nested exception is com.alibaba.druid.pool.DataSourceDisableException at org.apache.ibatis.exceptions.ExceptionFactory.wrapException(ExceptionFactory.java:30) at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:199) at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:184) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:426) ... 8 more Caused by: org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection; nested exception is com.alibaba.druid.pool.DataSourceDisableException at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:81) at org.mybatis.spring.transaction.SpringManagedTransaction.openConnection(SpringManagedTransaction.java:80) at org.mybatis.spring.transaction.SpringManagedTransaction.getConnection(SpringManagedTransaction.java:67) at org.apache.ibatis.executor.BaseExecutor.getConnection(BaseExecutor.java:336) at com.baomidou.mybatisplus.core.executor.MybatisSimpleExecutor.prepareStatement(MybatisSimpleExecutor.java:93) at com.baomidou.mybatisplus.core.executor.MybatisSimpleExecutor.doUpdate(MybatisSimpleExecutor.java:53) at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117) at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76) at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:197) ... 14 more Caused by: com.alibaba.druid.pool.DataSourceDisableException at com.alibaba.druid.pool.DruidDataSource.pollLast(DruidDataSource.java:2057) at com.alibaba.druid.pool.DruidDataSource.getConnectionInternal(DruidDataSource.java:1537) at com.alibaba.druid.pool.DruidDataSource.getConnectionDirect(DruidDataSource.java:1326) at com.alibaba.druid.pool.DruidDataSource.getConnection(DruidDataSource.java:1306) at com.alibaba.druid.pool.DruidDataSource.getConnection(DruidDataSource.java:1296) at com.alibaba.druid.pool.DruidDataSource.getConnection(DruidDataSource.java:109) at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:157) at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:115) at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:78) ... 22 more ```  **To Reproduce** Zookeeper 3.4.14 version.  **Expected behavior** Worker server should not be shutdown.  **Which version of Dolphin Scheduler:**  -[1.2.1]   </body>
		<created>2020-04-16 06:06:03</created>
		<closed>2020-04-17 08:05:56</closed>
	</bug>
	<bug>
		<id>2435</id>
		<title>UDF函数功能无法使用</title>
		<body>1，创建通过hive数据源，查询数据时，选择UDF函数，确认添加以后，重新进入编辑状态，udf函数并没有保存上， 2，请问创建udf函数后，是否会将函数“临时”或“永久”增加到hive函数库中吗？</body>
		<created>2020-04-15 11:14:03</created>
		<closed>2020-04-24 03:49:43</closed>
	</bug>
	<bug>
		<id>2417</id>
		<title>[BUG] download the file of resource is error</title>
		<body> ![image](https://user-images.githubusercontent.com/55787491/79181234-8c970100-7e3e-11ea-8a27-49b7893b6515.png) ![image](https://user-images.githubusercontent.com/55787491/79181261-991b5980-7e3e-11ea-8bd0-f35a2cb0102c.png)   **Which version of Dolphin Scheduler:**  -[dev] </body>
		<created>2020-04-14 02:56:55</created>
		<closed>2020-04-16 09:08:15</closed>
	</bug>
	<bug>
		<id>2415</id>
		<title>[BUG] update the directory of resources is error</title>
		<body> ![image](https://user-images.githubusercontent.com/55787491/79179095-6f136880-7e39-11ea-96db-c34cf9ef09b0.png)  ![image](https://user-images.githubusercontent.com/55787491/79178911-0af0a480-7e39-11ea-9cee-07ecd033637a.png)   **Which version of Dolphin Scheduler:**  -[dev]  </body>
		<created>2020-04-14 02:18:50</created>
		<closed>2020-04-14 09:13:46</closed>
	</bug>
	<bug>
		<id>2406</id>
		<title>[BUG] Failed to run workflow  </title>
		<body> ![image](https://user-images.githubusercontent.com/55787491/79193332-ffaf7000-7e5c-11ea-9fc2-f735f3d3fcbc.png)   **Which version of Dolphin Scheduler:**  -[dev]  </body>
		<created>2020-04-13 06:18:05</created>
		<closed>2020-04-16 09:07:46</closed>
	</bug>
	<bug>
		<id>2379</id>
		<title>[BUG] If the workflow start notification policy fails or succeeds, the execution succeeds, but the workflow instance fails</title>
		<body>**Describe the bug**   The workflow start notification policy selection fails or succeeds, and the execution succeeds, but the workflow instance shows failure, and the task instance and mail show success   **To Reproduce** 1. login 2. Project management - &gt; select a project 3. Workflow definition - &gt; create a successful workflow 4. Save - &gt; go online - &gt; start 5. Send all successful or failed notification policies, select the email alarm group to receive - &gt; start 6. Failed to view workflow instance 7. View the task instance and mail, and the display is successfu  **Expected behavior** A successful workflow should show success  **Screenshots** ![工作流实例显示信息](https://user-images.githubusercontent.com/39124011/78744799-17868000-7995-11ea-962d-f4c2ea66c272.png) ![节点信息](https://user-images.githubusercontent.com/39124011/78744801-19e8da00-7995-11ea-81d9-931e8e4d8d7e.png) ![任务实例显示信息](https://user-images.githubusercontent.com/39124011/78744804-1a817080-7995-11ea-975d-5a529dc1f1f3.png) ![邮件信息](https://user-images.githubusercontent.com/39124011/78744806-1bb29d80-7995-11ea-884d-939801fab823.png)  </body>
		<created>2020-04-08 04:33:44</created>
		<closed>2020-04-08 05:54:15</closed>
	</bug>
	<bug>
		<id>2368</id>
		<title>[BUG] multiple browser tab cause cron scheduler trigger duplicate</title>
		<body>**Describe the bug** We found some workflow will schedule two instance at the same time every day. Because it has set two Quartz Trigger, see the screenshots below ![image](https://user-images.githubusercontent.com/16650282/78329404-327f7b80-75b4-11ea-92d9-ec958adfd46c.png) Since we can see that the difference is trigger group, the suffix means project id, so it indicate this workflow belong to difference project, which suppose to be wrong. After review the code, the project id comes from the set-scheduler-online-or-offline request, the value is pass by frontend ![image](https://user-images.githubusercontent.com/16650282/78329999-90f92980-75b5-11ea-9036-9efe0857d22d.png)   **To Reproduce** key operations: open two or more tabs, offline and online scheduler Assume we have to project: project-1, project-2, and workflow-A belong to project-1 1. Open the cron scheduler page of workflow-A 2. New a tab, and open another workflow of project-2 3. Refresh the cron scheduler page of workflow-A 4. Offline scheduler of workflow-A 5. Online scheduler of workflow-A After these step, the old cron trigger did not remove, but a new one was added, and the trigger group was difference  **Which version of Dolphin Scheduler:**  -[1.1.0]  **Additional context** Using DolphinScheduler within only one tab can avoid this bug, but it's more convenience for developer if them open one more tab, so this bug may be trigger. </body>
		<created>2020-04-03 06:34:03</created>
		<closed>2020-04-09 10:19:22</closed>
	</bug>
	<bug>
		<id>2359</id>
		<title>[BUG]The attachment name in excel Chinese is too long, and the attachment name in the received email becomes a string of characters</title>
		<body>The attachment name in excel Chinese is too long, and the attachment name in the received email becomes a string of characters</body>
		<created>2020-04-02 02:59:34</created>
		<closed>2020-07-14 15:22:43</closed>
	</bug>
	<bug>
		<id>2358</id>
		<title>[BUG] Scheduled task execution time error</title>
		<body>**Describe the bug** In the task timing scheduling, if the task time interval spans months, the first execution time of the task in each month is No. 1, which does not meet the timing scheduling cycle.  **To Reproduce** Steps to reproduce the behavior, for example: 1. Set task execution time range：2020-04-02 00:00:00 - 2020-06-013 00:00:00 2. Set timed expression：Set timed expression 3. Then,click the execution-time button  **Screenshots** If applicable, add screenshots to help explain your problem. ![image](https://user-images.githubusercontent.com/59900649/78205228-35a03c00-74ce-11ea-9455-c0a1fad311b3.png)   **Which version of Dolphin Scheduler:**  -[1.2.0]  </body>
		<created>2020-04-02 02:40:44</created>
		<closed>2020-04-03 05:47:35</closed>
	</bug>
	<bug>
		<id>2357</id>
		<title>[BUG] When task status statistics and process status statistics are empty, pie charts are not displayed on the homepage and project homepage</title>
		<body> ![image](https://user-images.githubusercontent.com/55787491/78202013-b60e6f00-74c5-11ea-8632-a6b5f8d03fa2.png) ![image](https://user-images.githubusercontent.com/55787491/78202027-c0c90400-74c5-11ea-89b5-099e85775d72.png)    **Which version of Dolphin Scheduler:**  -[refactor-worker , dev]  </body>
		<created>2020-04-02 01:42:28</created>
		<closed>2020-04-17 02:42:57</closed>
	</bug>
	<bug>
		<id>2355</id>
		<title>[BUG] The worker service is not started before running the workflow, and the task is in the "submission successful" state. After starting the worker service, the task is not executed</title>
		<body>1. Do not start the worker service, run the workflow, and the task is in the "submission successful" state; 2. Start the worker service ,but the task is not executed. ================================================= 1.不启动worker服务，运行工作流，任务处于“提交成功”状态； 2.启动worker服务，任务没执行。 ![image](https://user-images.githubusercontent.com/55787491/78123504-d3e5c080-7440-11ea-935b-5348d9c2fa23.png) ![image](https://user-images.githubusercontent.com/55787491/78123602-fc6dba80-7440-11ea-99b0-72b5d982ca0b.png)  **Which version of Dolphin Scheduler:**  -[refactor-worker]  </body>
		<created>2020-04-01 09:50:12</created>
		<closed>2020-04-24 02:58:15</closed>
	</bug>
	<bug>
		<id>2350</id>
		<title>[BUG] master fault tolerance error</title>
		<body>1. Start one master1 and two workers 2. Task setting timing, executed once every 1 minute, online timing 3. There are 3 workflow instances running on the master1 service, and the task shell_task_1 of the workflow instance is also in the "running" state. 4. Start the master2 service, the host of the workflow instance changes from master1 to master2, and the task shell_task_1 also starts fault-tolerant processing, as shown in the following figure, and finally shell_task_1 is executed 3 times: =============================================== 1.启动一台master1 ， 2台worker 2.任务设置定时，1分钟执行一次，上线定时 3.有3个工作流实例在master1服务上运行，其中工作流实例的任务shell_task_1也处于“正在运行”状态 4.启动master2服务，工作流实例的host从master1变为master2，任务shell_task_1也开始容错处理，如下图所示，最终shell_task_1被执行3次： =============================================== ![image](https://user-images.githubusercontent.com/55787491/78106433-f4545180-7425-11ea-8bc6-ebcf916236f8.png) ![image](https://user-images.githubusercontent.com/55787491/78106449-fe765000-7425-11ea-8dd8-3c14ec90d4fb.png) ![image](https://user-images.githubusercontent.com/55787491/78106564-3d0c0a80-7426-11ea-956e-42b2b19a01cd.png)  **Which version of Dolphin Scheduler:**  -[refactor-worker] </body>
		<created>2020-04-01 06:38:43</created>
		<closed>2020-04-10 02:42:56</closed>
	</bug>
	<bug>
		<id>2349</id>
		<title>[BUG]Visit the worker page of the monitoring center, a null pointer occur</title>
		<body> ![image](https://user-images.githubusercontent.com/55787491/78097549-2a3a0b80-740f-11ea-8302-5c63fa1b79dc.png) ![image](https://user-images.githubusercontent.com/55787491/78097589-3faf3580-740f-11ea-82d2-4249cef0e876.png)  **Which version of Dolphin Scheduler:**  -[refactor-worker]  </body>
		<created>2020-04-01 03:53:07</created>
		<closed>2020-04-10 02:43:13</closed>
	</bug>
	<bug>
		<id>2345</id>
		<title>[BUG] mail send fail</title>
		<body>**Describe the bug** alert.properties `xls.file.path=/tmp/xls`  In Linux, tmp directory will be cleaned up automatically.</body>
		<created>2020-03-31 09:48:40</created>
		<closed>2020-03-31 13:58:16</closed>
	</bug>
	<bug>
		<id>2334</id>
		<title>[BUG] sql task, query type, use column label</title>
		<body>`select a as '列1' from t;`  Mail table header display '列1', not 'a'.</body>
		<created>2020-03-30 03:17:41</created>
		<closed>2020-03-30 08:22:45</closed>
	</bug>
	<bug>
		<id>2317</id>
		<title>[BUG] Import workflow</title>
		<body>![image](https://user-images.githubusercontent.com/54257101/77626243-0a729580-6f80-11ea-81d7-d1255ebc03f7.png) I want to copy the workflow from project a to b，when i import the json profile , display success ,but not found the workflow and i have found this question  in the json profile ,'projectname'  limit the project name, need to modify the value</body>
		<created>2020-03-26 08:50:17</created>
		<closed>2020-03-31 03:15:25</closed>
	</bug>
	<bug>
		<id>2308</id>
		<title>调度无法使用</title>
		<body>部署完成发现调度无法使用，经过较长时间的排查，发现是mysql驱动包的问题。建议使用官方文档上的驱动版本。  同时希望能够改进一下日志，server里面quartz包下的日志无法打印到master.log，需要开启STDOUT。排查问题不方便</body>
		<created>2020-03-25 10:34:29</created>
		<closed>2020-03-28 09:50:58</closed>
	</bug>
	<bug>
		<id>2301</id>
		<title>[BUG] After deleting the  resource file, there was an error uploading the file again</title>
		<body> ![image](https://user-images.githubusercontent.com/55787491/77401293-9dc49300-6de7-11ea-9eb4-ecc6b83145d1.png)   **Which version of Dolphin Scheduler:** -[dev-resource-tree]  </body>
		<created>2020-03-24 07:55:16</created>
		<closed>2020-03-25 07:05:12</closed>
	</bug>
	<bug>
		<id>2300</id>
		<title>.gitignore should not add "dolphinscheduler-ui/src/js/conf/home/pages/projects/pages/taskInstance/index.vue"</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** after deployed,we can see the "任务实例" page is wrong!  **To Reproduce** Steps to reproduce the behavior, for example: 1. deployed 2. Click on '任务实例' 3. See wrong page  **Expected behavior** A clear and concise description of what you expected to happen.  **Screenshots** If applicable, add screenshots to help explain your problem.  **Which version of Dolphin Scheduler:**  -[1.2.1-release/1.2.0-release/dev]  **Additional context** Add any other context about the problem here.  **Requirement or improvement - Please describe about your requirements or improvement suggestions. </body>
		<created>2020-03-24 07:54:13</created>
		<closed>2020-04-16 11:36:54</closed>
	</bug>
	<bug>
		<id>2289</id>
		<title>[BUG] if not use hadoop yarn resourcemanager will show exception when upload resource file to HDFS</title>
		<body>when File Manage module been used, DS will check the hadoop resource manager ip, if keep default value(because we may be not use resource manager, we just need to store resource file to HDFS): yarn.resourcemanager.ha.rm.ids=192.168.xx.xx,192.168.xx.xx  DS will show exception, not valid host  **Which version of Dolphin Scheduler:**  -[ 1.2.0 ] may affect &lt;= 1.2.1 version   ** Suggestion ** we should add some logic for resource manager is enabled or not  </body>
		<created>2020-03-23 15:38:43</created>
		<closed>2020-06-30 02:29:43</closed>
	</bug>
	<bug>
		<id>2282</id>
		<title>this workflow is bug , I think it's a very serious problem</title>
		<body>Is I also found a problem, it is a bug, is I have two workflow of a and b, then a workflow Riga, a1 node b work new b1 task dependent nodes, type selection, the chosen today, relying on a1, my situation is such, a workflow, I have the day before the creation of a1 run through a process, and then I run b process, theory should be run failed, but in fact was a success.I am also drunk, similarly I choose the type of b1 yesterday also can run successfully, but the first three days before the election run failed.That logo is faild</body>
		<created>2020-03-23 08:00:51</created>
		<closed>2020-04-02 16:16:02</closed>
	</bug>
	<bug>
		<id>2281</id>
		<title>[BUG] Authorize files in multi-level directories, the resource center only returns the first-level directories  </title>
		<body>Authorized resources are as follows  ![image](https://user-images.githubusercontent.com/55787491/77293205-d64b6a80-6d1c-11ea-89cc-4813bef4fdda.png)  The user views the authorized file in the resource center, as shown below, the data is empty  ![image](https://user-images.githubusercontent.com/55787491/77293337-127ecb00-6d1d-11ea-9b7e-e5fa6d9f9a00.png)    **Which version of Dolphin Scheduler:**  -[dev-resource-tree]  </body>
		<created>2020-03-23 07:48:22</created>
		<closed>2020-04-20 02:01:27</closed>
	</bug>
	<bug>
		<id>2280</id>
		<title>[BUG] hive, spark fail to run  </title>
		<body>hive failure logs ![image](https://user-images.githubusercontent.com/55787491/77291604-93d45e80-6d19-11ea-9426-360e074c3eec.png) spark failure logs ![image](https://user-images.githubusercontent.com/55787491/77291806-e7df4300-6d19-11ea-8916-559c4f299f15.png) ![image](https://user-images.githubusercontent.com/55787491/77291844-f75e8c00-6d19-11ea-8ade-e1fcdae07f55.png)    **Which version of Dolphin Scheduler:**  -[dev-resource-tree]  </body>
		<created>2020-03-23 07:21:48</created>
		<closed>2020-04-16 09:44:47</closed>
	</bug>
	<bug>
		<id>2274</id>
		<title>[BUG] get error attribute value and logger content</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** Wrong attribute is referenced in class 'WorkerConfig' and error log is described in 'checkResource ()' method of class 'OSUtils'  **Expected behavior** Use correct attribute values and log descriptions  **Which version of Dolphin Scheduler:** dev  </body>
		<created>2020-03-23 02:03:05</created>
		<closed>2020-03-28 02:33:37</closed>
	</bug>
	<bug>
		<id>2272</id>
		<title>[BUG] No operations allowed after statement closed when running sql task</title>
		<body>When running the sql task it reports an error: "No operations allowed after statement closed". After the change, the sql task can run normally. </body>
		<created>2020-03-22 14:21:06</created>
		<closed>2020-03-22 14:32:21</closed>
	</bug>
	<bug>
		<id>2268</id>
		<title>[BUG] when running windows bat script, the handle is invalid in win7</title>
		<body>when running windows bat script, the handle is invalid in win7.  ![微信图片_20200322205047](https://user-images.githubusercontent.com/32166572/77249849-d5fc9200-6c7e-11ea-9aff-3b242f4707d1.png)  I will solve this bug.</body>
		<created>2020-03-22 12:51:52</created>
		<closed>2020-03-22 14:57:27</closed>
	</bug>
	<bug>
		<id>2255</id>
		<title>[BUG] taskProps.getScheduleTime() may be null, but there is no check if it is null or not</title>
		<body>```java     if (paramsMap != null) {       String dateTime = DateUtils.format(taskProps.getScheduleTime(), Constants.PARAMETER_FORMAT_TIME);       Property p = new Property();       p.setValue(dateTime);       p.setProp(Constants.PARAMETER_SHECDULE_TIME);       paramsMap.put(Constants.PARAMETER_SHECDULE_TIME, p);       script = ParameterUtils.convertParameterPlaceholders2(script, ParamUtils.convert(paramsMap));     } ```  `taskProps.getScheduleTime()` may be `null`, so we need to check if it is null or not.  I will change as follows: ```java     // new     // replace variable TIME with $[YYYYmmddd...] in shell file when history run job and batch complement job     if (paramsMap != null) {       if (taskProps.getScheduleTime() != null) {         String dateTime = DateUtils.format(taskProps.getScheduleTime(), Constants.PARAMETER_FORMAT_TIME);         Property p = new Property();         p.setValue(dateTime);         p.setProp(Constants.PARAMETER_SHECDULE_TIME);         paramsMap.put(Constants.PARAMETER_SHECDULE_TIME, p);       }       script = ParameterUtils.convertParameterPlaceholders2(script, ParamUtils.convert(paramsMap));     } ``` </body>
		<created>2020-03-21 05:06:38</created>
		<closed>2020-03-28 02:42:47</closed>
	</bug>
	<bug>
		<id>2235</id>
		<title>[BUG] A 400 error occurred while uploading a UDF resource in the create UDF function popup  </title>
		<body> ![image](https://user-images.githubusercontent.com/55787491/77044190-ef40dc80-69f9-11ea-8340-3a861d84e092.png)  **Which version of Dolphin Scheduler:**  -[dev-resource-tree] </body>
		<created>2020-03-19 07:54:57</created>
		<closed>2020-03-24 06:07:26</closed>
	</bug>
	<bug>
		<id>2234</id>
		<title>[BUG] The UDF resource directory is empty. An error occurred when renaming the UDF resource directory  </title>
		<body>![image](https://user-images.githubusercontent.com/55787491/77041502-fdd8c500-69f4-11ea-9ca7-46af522d8374.png)  ![image](https://user-images.githubusercontent.com/55787491/77041852-95d6ae80-69f5-11ea-8093-137a6877b57e.png)   **Which version of Dolphin Scheduler:**  -[dev-resource-tree]  </body>
		<created>2020-03-19 07:22:21</created>
		<closed>2020-03-20 03:12:12</closed>
	</bug>
	<bug>
		<id>2233</id>
		<title>[BUG] Edit the files in the secondary directory, the file details are not updated</title>
		<body>The contents of the file before editing in the secondary directory, as shown below：  ![image](https://user-images.githubusercontent.com/55787491/77039844-b997f580-69f1-11ea-886c-f75a6c32924e.png) The contents of the edited file in the secondary directory, as shown below： ![image](https://user-images.githubusercontent.com/55787491/77039924-e8ae6700-69f1-11ea-8012-fda5c64168b0.png) Check the content of the file in the secondary directory again, as shown below, the file content is the content before editing ![image](https://user-images.githubusercontent.com/55787491/77040031-1bf0f600-69f2-11ea-9d3d-afbb6e458559.png)   **Which version of Dolphin Scheduler:**  -[dev-resource-tree]  </body>
		<created>2020-03-19 07:00:36</created>
		<closed>2020-03-23 03:38:02</closed>
	</bug>
	<bug>
		<id>2228</id>
		<title>[BUG] delete resource error</title>
		<body> ![image](https://user-images.githubusercontent.com/55787491/77024958-d3721200-69ca-11ea-8530-92175a614977.png) ![image](https://user-images.githubusercontent.com/55787491/77025036-0d431880-69cb-11ea-97a6-dfd0b549107a.png)  **Which version of Dolphin Scheduler:**  -[dev-resource-tree]    </body>
		<created>2020-03-19 02:19:55</created>
		<closed>2020-03-20 03:14:36</closed>
	</bug>
	<bug>
		<id>2227</id>
		<title>[BUG] When the data in the multi-level directory is empty,  an error pops up</title>
		<body> ![image](https://user-images.githubusercontent.com/55787491/77024357-4c706a00-69c9-11ea-98be-d028f1734550.png)  **Which version of Dolphin Scheduler:** -[dev-resource-tree]</body>
		<created>2020-03-19 02:14:17</created>
		<closed>2020-03-23 03:41:09</closed>
	</bug>
	<bug>
		<id>2223</id>
		<title>[BUG] Throw exception when create file.</title>
		<body>When kerberos startup, create file fail, throw exception: ``` Caused by: org.apache.hadoop.security.AccessControlException: Client cannot authenticate via:[TOKEN, KERBEROS] ``` Of course, kerberos config is well.</body>
		<created>2020-03-18 08:54:33</created>
		<closed>2020-04-05 16:11:38</closed>
	</bug>
	<bug>
		<id>2197</id>
		<title>[BUG]  Api server startup fail</title>
		<body>**Describe the bug** When the Api server startup, Scan all packages under "org.apache.dolphinscheduler" by default. Will execute the master and worker run methods.  `@ComponentScan("org.apache.dolphinscheduler")`</body>
		<created>2020-03-17 02:51:39</created>
		<closed>2020-03-17 05:47:48</closed>
	</bug>
	<bug>
		<id>2178</id>
		<title>[BUG] SqlTask kerberos authentication process</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** When the keytab is expired or deactivated, other tasks that did not require authentication also failed. Obviously there is something wrong with the kerberos authentication process and it should only do it when it is needed.  **Which version of Dolphin Scheduler:**  -[1.2.1-release]  **Requirement or improvement - Change CommonUtils.loadKerberosConf() call scope; </body>
		<created>2020-03-14 11:25:36</created>
		<closed>2020-03-28 09:42:34</closed>
	</bug>
	<bug>
		<id>2174</id>
		<title>[BUG] MasterExecThread NullPointException</title>
		<body>**Describe the bug** When the number of parallel tasks exceeds the set number of threads, there are tasks waiting to be submitted to the database, These tasks have not been assigned a task ID. Failed task at this point, master server will kill running tasks, killTheOtherTasks method will get NullPointException.  ```             TaskInstance taskInstance = taskExecThread.getTaskInstance();             taskInstance = processService.findTaskInstanceById(taskInstance.getId());             if(taskInstance.getState().typeIsFinished()){                 continue;             } ```  ![image](https://user-images.githubusercontent.com/39549317/76677163-1e280e80-6606-11ea-9fd1-3787eacc5630.png) </body>
		<created>2020-03-14 07:08:36</created>
		<closed>2020-03-14 11:20:47</closed>
	</bug>
	<bug>
		<id>2163</id>
		<title>[BUG] The master and worker server exit exception</title>
		<body>**Describe the bug** The current service exit is implemented by adding a shutdown hook through the Runtime class. When service exit, send service stop notify, depend on Spring been. Spring's exit is also implemented through registration hooks. The hooks inside the Runtime class are maintained through HashMap. Hook is a thread. Hooks run out of order.  This will cause the Spring service to be destroyed when the master service exits. DataSource connection pool is closed. May cause exception.  ![image](https://user-images.githubusercontent.com/39549317/76586194-23f4f580-651b-11ea-9610-c3287fc1aa69.png)  Solution 1.Exit operation is implemented through Spring's @PreDestory. ```     @PreDestroy     public void destroy() { ``` --- 2.Avoid loading each other when the master and worker services start `@ComponentScan("org.apache.dolphinscheduler")`  change to ``` @ComponentScan(value = "org.apache.dolphinscheduler", excludeFilters = {         @ComponentScan.Filter(type = FilterType.ASSIGNABLE_TYPE, classes = {WorkerServer.class}) }) ``` --- 3.Worker server daemon Plan 1： ``` latch = new CountDownLatch(1); latch.await(); ```  change to ``` public class WorkerServer implements CommandLineRunner {     @Override     public void run(String... args) throws Exception {         Thread.currentThread().join();     } ``` CountDownLatch will block subsequent loading operations of Spring beans, such as @PreDestroy.  Plan 2： The thread heartbeatWorkerService set to non-daemon thread. Springboot will not quit after startup. I agree with this plan  **Which version of Dolphin Scheduler:**  -[1.2.0-preview]</body>
		<created>2020-03-13 10:14:24</created>
		<closed>2020-03-14 10:10:31</closed>
	</bug>
	<bug>
		<id>2160</id>
		<title>[BUG] Toolbar of the DAG has not prompt </title>
		<body>Toolbar of the DAG has not prompt for task type.  This mainly reason is as follows: ```javascript // dolphinscheduler-ui/src/js/conf/home/pages/dag/_source/config.js, line 242 let tasksType = {   'SHELL': {     desc: 'SHELL',     color: '#646464'   },   ... }  // dolphinscheduler-ui/src/js/conf/home/pages/dag/_source/dag.vue, line 28 // &lt;div data-toggle="tooltip" :title="item.description"&gt; &lt;div data-toggle="tooltip" :title="item.desc"&gt; ```  So, I will implete it. </body>
		<created>2020-03-13 06:40:12</created>
		<closed>2020-03-13 15:38:30</closed>
	</bug>
	<bug>
		<id>2129</id>
		<title>[BUG] Data truncation: Data too long for column 'app_link' at row 1</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** ``` [ERROR] 2020-03-09 22:29:33.824  - [taskAppId=TASK-10-1331-7022]:[189] -  ### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'app_link' at row 1 ### The error may exist in org/apache/dolphinscheduler/dao/mapper/TaskInstanceMapper.java (best guess) ### The error may involve org.apache.dolphinscheduler.dao.mapper.TaskInstanceMapper.updateById-Inline ### The error occurred while setting parameters ### SQL: UPDATE t_ds_task_instance  SET flag=?, task_json=?, pid=?, app_link=?, task_type=?, task_instance_priority=?, log_path=?, host=?, start_time=?, state=?, process_instance_id=?, process_definition_id=?, alert_flag=?, execute_path=?, worker_group_id=?, max_retry_times=?, retry_times=?, submit_time=?, name=?, retry_interval=?  WHERE id=? ### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'app_link' at row 1 ; Data truncation: Data too long for column 'app_link' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'app_link' at row 1 org.springframework.dao.DataIntegrityViolationException:  ### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'app_link' at row 1 ### The error may exist in org/apache/dolphinscheduler/dao/mapper/TaskInstanceMapper.java (best guess) ### The error may involve org.apache.dolphinscheduler.dao.mapper.TaskInstanceMapper.updateById-Inline ### The error occurred while setting parameters ### SQL: UPDATE t_ds_task_instance  SET flag=?, task_json=?, pid=?, app_link=?, task_type=?, task_instance_priority=?, log_path=?, host=?, start_time=?, state=?, process_instance_id=?, process_definition_id=?, alert_flag=?, execute_path=?, worker_group_id=?, max_retry_times=?, retry_times=?, submit_time=?, name=?, retry_interval=?  WHERE id=? ### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'app_link' at row 1 ; Data truncation: Data too long for column 'app_link' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'app_link' at row 1 at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81) at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:74) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:440) at com.sun.proxy.$Proxy86.update(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.update(SqlSessionTemplate.java:287) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.execute(MybatisMapperMethod.java:63) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy.invoke(MybatisMapperProxy.java:61) at com.sun.proxy.$Proxy93.updateById(Unknown Source) at org.apache.dolphinscheduler.dao.ProcessDao.updateTaskInstance(ProcessDao.java:1190) at org.apache.dolphinscheduler.dao.ProcessDao.saveTaskInstance(ProcessDao.java:1168) at org.apache.dolphinscheduler.dao.ProcessDao.updatePidByTaskInstId(ProcessDao.java:1435) at org.apache.dolphinscheduler.dao.ProcessDao$$FastClassBySpringCGLIB$$ee5e71ba.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684) at org.apache.dolphinscheduler.dao.ProcessDao$$EnhancerBySpringCGLIB$$5b328c6c.updatePidByTaskInstId(&lt;generated&gt;) at org.apache.dolphinscheduler.server.worker.task.AbstractCommandExecutor.updateState(AbstractCommandExecutor.java:237) at org.apache.dolphinscheduler.server.worker.task.AbstractCommandExecutor.run(AbstractCommandExecutor.java:170) at org.apache.dolphinscheduler.server.worker.task.shell.ShellTask.handle(ShellTask.java:105) at org.apache.dolphinscheduler.server.worker.runner.TaskScheduleThread.run(TaskScheduleThread.java:142) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'app_link' at row 1 at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3931) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3869) at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2524) at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2675) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2465) at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1912) at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:1251) at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:497) at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:47) at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74) at sun.reflect.GeneratedMethodAccessor123.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63) at com.sun.proxy.$Proxy105.update(Unknown Source) at com.baomidou.mybatisplus.core.executor.MybatisSimpleExecutor.doUpdate(MybatisSimpleExecutor.java:54) at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117) at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76) at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:197) at sun.reflect.GeneratedMethodAccessor121.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:426) ... 21 common frames omitted [ERROR] 2020-03-09 22:29:33.824  - [taskAppId=TASK-10-1331-7022]:[107] - shell task failure java.lang.RuntimeException: process error . exitCode is :  -1 at org.apache.dolphinscheduler.server.worker.task.AbstractCommandExecutor.run(AbstractCommandExecutor.java:190) at org.apache.dolphinscheduler.server.worker.task.shell.ShellTask.handle(ShellTask.java:105) at org.apache.dolphinscheduler.server.worker.runner.TaskScheduleThread.run(TaskScheduleThread.java:142) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) ```</body>
		<created>2020-03-09 14:42:38</created>
		<closed>2020-03-12 13:52:49</closed>
	</bug>
	<bug>
		<id>2128</id>
		<title>[BUG] Upload the shell script with 3000 lines , only display 2000 lines, and has scheduled the script with 2000 lines.</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** Upload the shell script with 3000 lines . Issue1: only display 2000 lines Issue2: has scheduled the script with 2000 lines.  [issues-2117](https://github.com/apache/incubator-dolphinscheduler/issues/2117)</body>
		<created>2020-03-09 14:39:46</created>
		<closed>2020-03-12 10:16:57</closed>
	</bug>
	<bug>
		<id>2123</id>
		<title>[BUG] The toolbar buttons of Dag disable bug</title>
		<body>The toolbar buttons of Dag disable bug. ![image](https://user-images.githubusercontent.com/39549317/76190408-e12fd680-6217-11ea-8983-3bebbbcd1e16.png)  1.In the online state, full screen is disable. 2.Fix condition check of boolean (disable)  **Which version of Dolphin Scheduler:**  -[1.2.0-preview]</body>
		<created>2020-03-09 07:16:50</created>
		<closed>2020-03-12 10:00:34</closed>
	</bug>
	<bug>
		<id>2117</id>
		<title>[BUG] Upload the shell script with 3000 lines , only display 2000 lines</title>
		<body>**Describe the bug** Upload the shell script with 3000 lines , only display 2000 lines. Although the download is 3000 lines, but the user experience is not good.</body>
		<created>2020-03-08 10:29:39</created>
		<closed>2020-03-13 16:23:38</closed>
	</bug>
	<bug>
		<id>2111</id>
		<title>[BUG] sun.misc.JavaIOFileDescriptorAccess is not portable</title>
		<body>Current implementation relies on `sun.misc.JavaIOFileDescriptorAccess` which is only accessible on oraclejdk8.  Basically the demand is getting &amp; setting `field` field of `FileDescriptor`, so we can directly do that with reflection.  Though, I suspect the necessity we introduce `ProcessImplForWin32`. Maybe we could have a better way to support worker server to run bat script.</body>
		<created>2020-03-08 05:09:46</created>
		<closed>2020-03-09 11:06:42</closed>
	</bug>
	<bug>
		<id>2100</id>
		<title>[BUG] When the branch flow of the if / else task is empty, the prompt is ambiguous  </title>
		<body>当任务状态为成功或失败的分支流转都为空时，点击“确认提交”按钮，提示语改为“成功分支流转或失败分支流转不能为空” ![image](https://user-images.githubusercontent.com/55787491/76070260-2f9e6480-5fcf-11ea-8f7f-b60005b3e275.png)   **Which version of Dolphin Scheduler:**  -[1.2.0_release] </body>
		<created>2020-03-06 09:29:22</created>
		<closed>2020-04-07 06:10:07</closed>
	</bug>
	<bug>
		<id>2098</id>
		<title>[BUG] Click the if / else node and request the / process / get-task-list? Interface to report an error</title>
		<body>request  Interface:  http://192.168.xx.xx:12345/dolphinscheduler/projects/cxc_if/process/get-task-list?processDefinitionIdList=&amp;_t=0.8965307575465242 ![image](https://user-images.githubusercontent.com/55787491/76063756-4f2f9000-5fc3-11ea-9ffc-e94b454f1521.png)    **Which version of Dolphin Scheduler:**  -[1.2.0_release]  </body>
		<created>2020-03-06 08:00:16</created>
		<closed>2020-04-07 06:14:43</closed>
	</bug>
	<bug>
		<id>2089</id>
		<title>[BUG]View authorized file resources, only show directories, and the directory tree is incorrect  </title>
		<body>1.Authorize the user to the file /directory1/directory2.sh 【给用户授权文件/directory1/directory2.sh】 ![image](https://user-images.githubusercontent.com/55787491/75957931-1a093c00-5ef6-11ea-86b8-6d31a0ef70c9.png) 2.View the user authorization file, only the  /directory1 is displayed, and there is no file directory2.sh under / directory1 in the directory tree. The directory2.sh file is displayed in the first-level directory.【查看用户授权文件，只显示目录/directory1，且目录树中/directory1下没有文件directory2.sh，directory2.sh文件显示在一级目录中】 ![image](https://user-images.githubusercontent.com/55787491/75957950-255c6780-5ef6-11ea-8412-b21e82461326.png)  **Branch** -[dev-resource-tree]</body>
		<created>2020-03-05 07:30:34</created>
		<closed>2020-03-23 03:34:39</closed>
	</bug>
	<bug>
		<id>2088</id>
		<title>[BUG] After the resource is renamed, the parent directory of the subdirectory does not display the renamed name</title>
		<body> ![image](https://user-images.githubusercontent.com/55787491/75956332-a3b70a80-5ef2-11ea-9145-bf7bf823d031.png)  **Which version of Dolphin Scheduler:**  -[dev-resource-tree]   </body>
		<created>2020-03-05 07:05:01</created>
		<closed>2020-04-20 08:34:17</closed>
	</bug>
	<bug>
		<id>2087</id>
		<title>[BUG]Spark, Flink, MR main jar packages are not displayed,Python does not display resources  </title>
		<body>![image](https://user-images.githubusercontent.com/55787491/75955815-90f00600-5ef1-11ea-8c8f-0c3e46525277.png) ![image](https://user-images.githubusercontent.com/55787491/75955913-bda41d80-5ef1-11ea-9182-bbd9c2d3b19c.png)  **Branch** [dev-resource-tree]</body>
		<created>2020-03-05 06:59:03</created>
		<closed>2020-03-19 03:45:57</closed>
	</bug>
	<bug>
		<id>2086</id>
		<title>It has a bug on Binary Distribution of dolphinscheduler 1.2.1 </title>
		<body>1.2.1版本 Binary Distribution包中没有 install-dolphinscheduler-ui.install 没有这个怎么部署启动前端呢？在Source code包中 就有这个文件   ![无标题](https://user-images.githubusercontent.com/55619711/75950923-96dfea00-5ee5-11ea-9796-ba34ba1af9d1.png) </body>
		<created>2020-03-05 05:31:28</created>
		<closed>2020-03-05 16:02:07</closed>
	</bug>
	<bug>
		<id>2052</id>
		<title>[BUG] Github action checkout failed when rerun failed workflow</title>
		<body>Github action checkout failed when rerun failed workflow, logs as below ``` ##[error]fatal: reference is not a tree: a39f728609e40bc26fc317b7505c8e4a2e90ff52 Removed matchers: 'checkout-git' ##[error]Git checkout failed with exit code: 128 ##[error]Exit code 1 returned from process: file name '/home/runner/runners/2.165.2/bin/Runner.PluginHost', arguments 'action "GitHub.Runner.Plugins.Repository.v1_0.CheckoutTask, Runner.Plugins"'. ``` </body>
		<created>2020-03-02 06:57:43</created>
		<closed>2020-03-12 10:36:53</closed>
	</bug>
	<bug>
		<id>2038</id>
		<title>make the source code into RPM package</title>
		<body>### I want to make the source code into RPM package，but have a question。 ![微信截图_20200228091709](https://user-images.githubusercontent.com/54257101/75501489-1e6fb980-5a0b-11ea-977e-6dcb5b146e9b.png)  [INFO] ------------------------------------------------------------------------ [INFO] Reactor Summary for dolphinscheduler 1.2.1: [INFO]  [INFO] dolphinscheduler ................................... SUCCESS [  9.994 s] [INFO] dolphinscheduler-ui ................................ SUCCESS [  1.827 s] [INFO] dolphinscheduler-common ............................ SUCCESS [ 30.829 s] [INFO] dolphinscheduler-dao ............................... SUCCESS [01:47 min] [INFO] dolphinscheduler-rpc ............................... SUCCESS [09:46 min] [INFO] dolphinscheduler-alert ............................. SUCCESS [01:29 min] [INFO] dolphinscheduler-server ............................ SUCCESS [ 19.841 s] [INFO] dolphinscheduler-api ............................... SUCCESS [06:49 min] [INFO] dolphinscheduler-dist .............................. FAILURE [ 51.450 s] [INFO] ------------------------------------------------------------------------ [INFO] BUILD FAILURE [INFO] ------------------------------------------------------------------------ [INFO] Total time:  21:52 min [INFO] Finished at: 2020-02-27T11:43:35+08:00 [INFO] ------------------------------------------------------------------------ [ERROR] Failed to execute goal org.codehaus.mojo:rpm-maven-plugin:2.2.0:attached-rpm (default) on project dolphinscheduler-dist: Source location /opt/apache-dolphinscheduler-incubating-1.2.1-src-release/dolphinscheduler-dist/../dolphinscheduler-ui/dist does not exist -&gt; [Help 1] [ERROR]  [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch. [ERROR] Re-run Maven using the -X switch to enable full debug logging. [ERROR]  [ERROR] For more information about the errors and possible solutions, please read the following articles: [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException [ERROR]  [ERROR] After correcting the problems, you can resume the build with the command [ERROR]   mvn &lt;goals&gt; -rf :dolphinscheduler-dist</body>
		<created>2020-02-28 01:18:04</created>
		<closed>2020-03-19 01:26:48</closed>
	</bug>
	<bug>
		<id>2036</id>
		<title>[BUG] java.lang.NoSuchMethodError: com.google.protobuf.CodedInputStream.readStringRequireUtf8()Ljava/lang/String;</title>
		<body>logger-server启动后，一直报  Exception in thread "grpc-default-executor-0" java.lang.NoSuchMethodError: com.google.protobuf.CodedInputStream.readStringRequireUtf8()Ljava/lang/String; at cn.escheduler.rpc.LogParameter.&lt;init&gt;(LogParameter.java:61) at cn.escheduler.rpc.LogParameter.&lt;init&gt;(LogParameter.java:14) at cn.escheduler.rpc.LogParameter$1.parsePartialFrom(LogParameter.java:699) at cn.escheduler.rpc.LogParameter$1.parsePartialFrom(LogParameter.java:694) at com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:89) at com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:49) at io.grpc.protobuf.lite.ProtoLiteUtils$2.parseFrom(ProtoLiteUtils.java:173) at io.grpc.protobuf.lite.ProtoLiteUtils$2.parse(ProtoLiteUtils.java:165) at io.grpc.protobuf.lite.ProtoLiteUtils$2.parse(ProtoLiteUtils.java:82) at io.grpc.MethodDescriptor.parseRequest(MethodDescriptor.java:287) at io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:252) at io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:626) at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37) at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:748)</body>
		<created>2020-02-27 13:41:29</created>
		<closed>2020-03-19 12:29:33</closed>
	</bug>
	<bug>
		<id>1996</id>
		<title>[BUG] install.sh will happen "sh: bin/dolphinscheduler-daemon.sh: No such file or directory" when first deploy</title>
		<body>**Describe the bug** when I first deploy the DolphinScheduler, I find that ``` # 3,stop server echo "3,stop server" sh ${workDir}/script/stop-all.sh ... # 5,scp resources echo "5,scp resources" sh ${workDir}/script/scp-hosts.sh if [ $? -eq 0 ] then echo 'scp copy completed' else echo 'scp copy failed to exit' exit -1 fi ``` **Which version of Dolphin Scheduler:**  -[1.2.0]   **how to solve**  the 3 step should change position to the 5 step, becase on the 3 step, the shell scripts not exists in the install path</body>
		<created>2020-02-22 12:20:33</created>
		<closed>2020-02-24 01:05:26</closed>
	</bug>
	<bug>
		<id>1988</id>
		<title>[BUG] some errors in master log</title>
		<body>branch: dev  when start a process instance, some exceptions follow:  ![image](https://user-images.githubusercontent.com/29528966/75022076-643ef600-54d0-11ea-9086-e16d94bc1390.png) </body>
		<created>2020-02-21 09:35:45</created>
		<closed>2020-02-21 09:51:45</closed>
	</bug>
	<bug>
		<id>1986</id>
		<title>[BUG] The task details window should not be switch by the toolbar.</title>
		<body>**Describe the bug** When in the projects define page, click the toolbar's button(task type) will cause the task details window switch to new one.  **To Reproduce** Go to the projects define page. 1. Drag to create a new task node or edit an exist node, and the task details window will be open. 2. Click any toolbar's button on the left. 3. See error. The task details window will switch to new one.  **Which version of Dolphin Scheduler:**  -[dev]  **Requirement or improvement The task details window does't switch.</body>
		<created>2020-02-21 08:55:14</created>
		<closed>2020-02-25 07:14:25</closed>
	</bug>
	<bug>
		<id>1984</id>
		<title>[BUG] TaskInstance.isSubProcess Misjudgment</title>
		<body> **Describe the bug** TaskInstance.isSubProcess method misjudgment task type  **To Reproduce** 1 String taskType = sub process 2 TaskType.SUB_PROCESS.toString=SUB_PROCESS 3 TaskType.SUB_PROCESS.toString().equals(this.taskType.toUpperCase()) misjudgment  **Which version of Dolphin Scheduler:**  -[dev]  </body>
		<created>2020-02-21 06:50:34</created>
		<closed>2020-02-28 08:15:46</closed>
	</bug>
	<bug>
		<id>1968</id>
		<title>[BUG] The task details window did not close properly.</title>
		<body> **Describe the bug** The task details window did not close properly.  **To Reproduce** 1. Go to the page of the definition create or definition edit. 2. Drag to create a new task node or edit an exist  node. And the task details window will be open. 3. Delete the task node or click the DataSource menu. 4. See error. The task details window still open.  **Which version of Dolphin Scheduler:**  -[dev]  **Requirement or improvement The task details window should be close.</body>
		<created>2020-02-17 03:36:53</created>
		<closed>2020-02-17 13:07:05</closed>
	</bug>
	<bug>
		<id>1947</id>
		<title>[BUG] ProcessUtils.kill blocked</title>
		<body>ProcessUtils.kill method always invoke killYarnJob ,no matter what's the task type, why ? ``` public static void kill(TaskInstance taskInstance) {     try {       int processId = taskInstance.getPid();       if(processId == 0 ){           logger.error("process kill failed, process id :{}, task id:{}",                   processId, taskInstance.getId());           return ;       }        String cmd = String.format("kill -9 %s", getPidsStr(processId));        logger.info("process id:{}, cmd:{}", processId, cmd);        OSUtils.exeCmd(cmd);        // find log and kill yarn job       killYarnJob(taskInstance);      } catch (Exception e) {       logger.error("kill failed : " + e.getMessage(), e);     }   } ```  In our product environment，the killYarnJob blocked, so all the process instance cannot be killed.  The jstack log: "Worker-Kill-Thread-Executor" #43 daemon prio=5 os_prio=0 tid=0x00007f0ee5972800 nid=0x15084 waiting on condition [0x00007f0e2c6af000]    java.lang.Thread.State: WAITING (parking)  at sun.misc.Unsafe.park(Native Method)  - parking to wait for  &lt;0x00000004379b7a90&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)  at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)  at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)  at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)  at io.grpc.stub.ClientCalls$ThreadlessExecutor.waitAndDrain(ClientCalls.java:623)  at io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:122)  at cn.escheduler.rpc.LogViewServiceGrpc$LogViewServiceBlockingStub.viewLog(LogViewServiceGrpc.java:321)  at cn.escheduler.server.rpc.LogClient.viewLog(LogClient.java:97)  at cn.escheduler.server.utils.ProcessUtils.killYarnJob(ProcessUtils.java:303)  at cn.escheduler.server.utils.ProcessUtils.kill(ProcessUtils.java:270)  at cn.escheduler.server.worker.WorkerServer$3.run(WorkerServer.java:282)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)  at java.lang.Thread.run(Thread.java:748)     Locked ownable synchronizers:  - &lt;0x00000004379d9c70&gt; (a java.util.concurrent.ThreadPoolExecutor$Worker)</body>
		<created>2020-02-13 06:49:13</created>
		<closed>2020-02-23 11:54:49</closed>
	</bug>
	<bug>
		<id>1929</id>
		<title>[BUG] checkOtherParams unreasonable logic</title>
		<body>The ProcessDefinitionService.checkProcessNodeList method has below codes: ``` for (TaskNode taskNode : taskNodes) { if (!CheckUtils.checkTaskNodeParameters(taskNode.getParams(), taskNode.getType())) { logger.error("task node {} parameter invalid", taskNode.getName()); putMsg(result, Status.PROCESS_NODE_S_PARAMETER_INVALID, taskNode.getName()); return result; }          // check extra params CheckUtils.checkOtherParams(taskNode.getExtras()); } ``` What's the meaning of 'CheckUtils.checkOtherParams'?  Should ‘CheckUtils.checkOtherParams’ throw an exception？  ```   public static boolean checkTaskNodeParameters(String parameter, String taskType) {     AbstractParameters abstractParameters = TaskParametersUtils.getParameters(taskType, parameter);      if (abstractParameters != null) {       return abstractParameters.checkParameters();     }      return false;   }``` </body>
		<created>2020-02-11 02:33:09</created>
		<closed>2020-04-12 12:29:06</closed>
	</bug>
	<bug>
		<id>1893</id>
		<title>[BUG] Starting master didn't output full log to log file</title>
		<body>When start master use command below  `sh ./bin/dolphinscheduler-daemon.sh start master-serve` there is just some part of beginning output in log files, like this ![](https://user-images.githubusercontent.com/22913838/73748345-2fbf0080-4794-11ea-8923-895a5d53b2bb.png)  After modified start command in dolphinscheduler-daemon.sh , ``` #nohup $JAVA_HOME/bin/java $exec_command &gt; $log 2&gt;&amp;1 &lt; /dev/null &amp; $JAVA_HOME/bin/java $exec_command ``` And added STDOUT in conf/master_logback.xml file ``` &lt;root level="INFO"&gt;    &lt;appender-ref ref="STDOUT"/&gt;    ... &lt;/root&gt; ```  The same command output the full log  ![](https://user-images.githubusercontent.com/22913838/73748731-094d9500-4795-11ea-9a54-985525ff8623.png)  It seems like the log didn't output to the file correctly.</body>
		<created>2020-02-04 13:29:20</created>
		<closed>2020-03-28 03:13:56</closed>
	</bug>
	<bug>
		<id>1889</id>
		<title>[BUG] problem with zookeeper 3.5 version when deploying DS</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** When deploying DS with zookeeper3.5, the zookeeper monitoring status of the monitoring center will be invalid. ![图片](https://user-images.githubusercontent.com/39879133/73719385-3fb9ee80-475a-11ea-82f8-20646b376528.png)  If replace the zookeeper-3.4.14.jar package under lib / with version 3.5, the DS master cannot be started. Only the 3.4.14 version of zookeeper was installed successfully.  </body>
		<created>2020-02-04 06:27:56</created>
		<closed>2020-03-13 16:20:47</closed>
	</bug>
	<bug>
		<id>1885</id>
		<title>fix api server startup failure</title>
		<body>1. add jsp-2.1 dependency ``` &lt;dependency&gt;       &lt;groupId&gt;org.mortbay.jetty&lt;/groupId&gt;       &lt;artifactId&gt;jsp-2.1&lt;/artifactId&gt; &lt;/dependency&gt; ``` 2. remove jasper-runtime dependency </body>
		<created>2020-02-02 16:33:47</created>
		<closed>2020-02-03 05:36:02</closed>
	</bug>
	<bug>
		<id>1878</id>
		<title>some updates for pom</title>
		<body>1. remove tomcat dependency ```   &lt;dependency&gt;       &lt;groupId&gt;tomcat&lt;/groupId&gt;       &lt;artifactId&gt;jasper-runtime&lt;/artifactId&gt;     &lt;/dependency&gt; ``` 2. remove combined_logback.xml in api module 3. format pom.xml for not aligning</body>
		<created>2020-01-31 16:15:10</created>
		<closed>2020-02-01 10:22:40</closed>
	</bug>
	<bug>
		<id>1871</id>
		<title>[BUG] correct some spelling in MasterExecThread </title>
		<body>correct below spelling : ``` excpetion -&gt; exception instace -&gt; instance standy -&gt; standby ```  </body>
		<created>2020-01-26 03:08:36</created>
		<closed>2020-01-26 06:09:38</closed>
	</bug>
	<bug>
		<id>1864</id>
		<title>[BUG] fix dependency and createCommand date check</title>
		<body>**Describe the bug** A clear and concise description of what the bug is. 1. compile failed as: ![](https://user-images.githubusercontent.com/22913838/72798454-168b5f80-3c7e-11ea-8ca7-d3587c481c3a.png) 2. In ExecutorService, check whether start and end are null return wrong.  </body>
		<created>2020-01-21 10:46:41</created>
		<closed>2020-01-22 15:16:47</closed>
	</bug>
	<bug>
		<id>1851</id>
		<title>[dev_1.2.1]Optimize the width of the resource file popup  </title>
		<body>![image](https://user-images.githubusercontent.com/55787491/72601502-80d79380-3950-11ea-94fe-9dd84f840df4.png) ![image](https://user-images.githubusercontent.com/55787491/72601703-e461c100-3950-11ea-8aeb-81d99132dad3.png) </body>
		<created>2020-01-17 09:45:27</created>
		<closed>2020-02-04 01:28:22</closed>
	</bug>
	<bug>
		<id>1842</id>
		<title>The workflow caused by the upgrade does not trigger(升级造成的工作流不触发)</title>
		<body>After the system version upgrade (1.05-&gt; 1.20), the previously configured workflow cannot dispatch tasks automatically when it is time.  系统版本升级(１.０５－＞１.２０)后，原来已配置好的工作流到时间却无法自动派发任务． </body>
		<created>2020-01-17 03:46:59</created>
		<closed>2020-07-14 08:55:03</closed>
	</bug>
	<bug>
		<id>1828</id>
		<title>[dev_1.2.1] After executing the authorized UDF function, the path of the read resource file is incorrect</title>
		<body>![image](https://user-images.githubusercontent.com/55787491/72336392-addf3880-36fb-11ea-8a92-9360323a2d67.png)  1.Authorize the udf function of the tenant hdfs to user A.  2.User A creates a hive SQL and selects the authorized udf function.  3.After running the workflow, the path of the resource file read by the udf is incorrect, as shown in the figure above, but the udf resource of the tenant hdfs The path is shown below  1.将租户hdfs的udf函数授权给用户A 2.用户A创建hive类型的sql,并选择授权的udf函数， 3.运行工作流后，udf读取的资源文件路径不正确，如上图所示，但租户hdfs的udf资源路径如下图所示： ![image](https://user-images.githubusercontent.com/55787491/72336939-a8ceb900-36fc-11ea-8389-d001916a73e7.png)  </body>
		<created>2020-01-14 10:34:46</created>
		<closed>2020-02-05 06:23:26</closed>
	</bug>
	<bug>
		<id>1816</id>
		<title>[dev_1.2.1] Add multiple dependencies, the workflow definitions of the first few dependencies read the workflow definition of the last project</title>
		<body>![image](https://user-images.githubusercontent.com/55787491/72312120-fd087780-36c1-11ea-8969-6ad6fae3df23.png) ![image](https://user-images.githubusercontent.com/55787491/72312239-8029cd80-36c2-11ea-99ef-2b2eda128851.png) </body>
		<created>2020-01-14 03:37:39</created>
		<closed>2020-01-15 02:59:54</closed>
	</bug>
	<bug>
		<id>1810</id>
		<title>[dev_1.2.1]Workflow instance does not show dependencies</title>
		<body>![image](https://user-images.githubusercontent.com/55787491/72236150-9d9e5f00-3610-11ea-82e1-3c0b18a6a68e.png) </body>
		<created>2020-01-13 06:27:47</created>
		<closed>2020-01-15 02:59:33</closed>
	</bug>
	<bug>
		<id>1789</id>
		<title>[dev_1.2.1]  Click to view the history, enter the task instance page, the results of the query based on the search conditions are displayed incorrectly</title>
		<body>![image](https://user-images.githubusercontent.com/55787491/72060392-d5ef2600-330e-11ea-8fc1-df2cbc33b439.png)  1. As shown above, click the View History to enter the task instance page 2. As shown in the following figure, according to the status of the successful query, the request parameter processInstanceId = 92 should be passed empty  ![image](https://user-images.githubusercontent.com/55787491/72060613-4f871400-330f-11ea-8ff1-866f7d1e83d9.png)  </body>
		<created>2020-01-09 10:40:35</created>
		<closed>2020-01-10 09:47:41</closed>
	</bug>
	<bug>
		<id>1787</id>
		<title>[dev_1.2.1] The node runs backward. If the next node also depends on other nodes, the process instance status is always running and will not end</title>
		<body>![image](https://user-images.githubusercontent.com/55787491/72049500-04aed180-32fa-11ea-822a-d2ed3528c67b.png)  1.  As shown above, choose to run backward in the task shell_file_dev_1.2.1_2； 2. Task shell_file_dev_1.2.1_4 also depends on shell_file_dev_1.2.1_3； 3.  As shown in the figure below, the status of the process instance is always running, there is no final state  ![image](https://user-images.githubusercontent.com/55787491/72049509-0bd5df80-32fa-11ea-98e6-45fc4bc701c7.png) </body>
		<created>2020-01-09 08:10:07</created>
		<closed>2020-03-20 13:27:52</closed>
	</bug>
	<bug>
		<id>1780</id>
		<title>[BUG] Update from 1.1.0 to 1.2.0 then the web interface cannot show the process defenition's node</title>
		<body>I have finished upgraded dolphinscheduler from 1.1.0(not Apache) to 1.2.0(Apache). And run all kind of services. When I run it, everything is OK but the process defenition's node can not be shown.  Chrome tells me that api works well and gives a correct response. ![image](https://user-images.githubusercontent.com/6407672/72032913-bbe02400-32cb-11ea-8dce-b4720c5ddcb3.png) </body>
		<created>2020-01-09 02:35:30</created>
		<closed>2020-07-14 08:55:50</closed>
	</bug>
	<bug>
		<id>1779</id>
		<title>[dev_1.2.1]  The execution of the SUB_PROCESS task failed first, but eventually succeeded</title>
		<body> ![image](https://user-images.githubusercontent.com/55787491/72032071-51c67f80-32c9-11ea-889f-aeeb40320457.png)  </body>
		<created>2020-01-09 02:18:44</created>
		<closed>2020-01-10 10:03:54</closed>
	</bug>
	<bug>
		<id>1775</id>
		<title>[BUG] delete process definition when process instance is running</title>
		<body>  **Describe the bug** Delete process definition when process instance is running.  worker server execute task throw NullPointException when process definition is null , task blocked  **resolve method** FetchTaskThread thread throw exception，delete zk queue task and set task status failure</body>
		<created>2020-01-08 08:56:23</created>
		<closed>2020-01-09 08:58:05</closed>
	</bug>
	<bug>
		<id>1770</id>
		<title>[dev_1.2.1] After canceling the file authorization, the running workflow should not obtain resource files from the original tenant directory  </title>
		<body>**Describe the bug** 1. Authorize the resource files under the journey tenant to user A 2.A user creates a workflow to import the file 3. Cancel the resource file authorization of user A 4.A user can obtain resource files from the journey tenant when running the workflow, as shown in the figure below ![image](https://user-images.githubusercontent.com/55787491/71958139-7ddef380-322a-11ea-9fe0-36e0dcaee358.png)  **Expected behavior** After canceling the resource authorization, user A should not obtain the resource files under the journey tenant   **Which version of Dolphin Scheduler:**  -[dev_1.2.1] </body>
		<created>2020-01-08 07:21:29</created>
		<closed>2020-01-17 09:48:34</closed>
	</bug>
	<bug>
		<id>1768</id>
		<title>[dev_1.2.1] There are multiple pages of data. After deleting all the data on one page, the data is displayed as empty</title>
		<body>**Describe the bug** ![image](https://user-images.githubusercontent.com/55787491/71954811-6fd8a500-3221-11ea-8f35-0563fdc62f15.png) User management has 2 pages of data. As shown in the figure above, after deleting the second page of data, the page shows no data. As shown in the figure below, the remaining 10 pieces of data should be displayed.  ![image](https://user-images.githubusercontent.com/55787491/71954833-8252de80-3221-11ea-9830-ffe0d9640468.png)  All pages with pagination controls have this problem   **Which version of Dolphin Scheduler:**  -[[dev_1.2.1]]  </body>
		<created>2020-01-08 06:19:09</created>
		<closed>2020-01-14 02:16:39</closed>
	</bug>
	<bug>
		<id>1724</id>
		<title>[BUG] createProcessDefinition bug</title>
		<body>version: 1.2.1 If different users create the same project, there will be problems.  According to the code, only the first project name will be obtained without considering the different users.  ![image](https://user-images.githubusercontent.com/39816903/71797464-3a00b880-3089-11ea-9734-2c8e15b7130a.png)   ![image](https://user-images.githubusercontent.com/39816903/71797595-d9be4680-3089-11ea-8036-3159208acfa3.png)   ![image](https://user-images.githubusercontent.com/39816903/71797469-3f5e0300-3089-11ea-9747-d76a37955b54.png)          </body>
		<created>2020-01-06 05:37:48</created>
		<closed>2020-01-06 08:35:02</closed>
	</bug>
	<bug>
		<id>1723</id>
		<title>[BUG] createProcessDefinition BUG</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** A clear and concise description of what the bug is.  **To Reproduce** Steps to reproduce the behavior, for example: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error  **Expected behavior** A clear and concise description of what you expected to happen.  **Screenshots** If applicable, add screenshots to help explain your problem.   **Which version of Dolphin Scheduler:**  -[1.1.0-preview]  **Additional context** Add any other context about the problem here.  **Requirement or improvement - Please describe about your requirements or improvement suggestions. </body>
		<created>2020-01-06 05:30:59</created>
		<closed>2020-01-06 05:32:33</closed>
	</bug>
	<bug>
		<id>1720</id>
		<title>[BUG] Fix bug: NullPointerException etc.</title>
		<body>**Describe the bug** Not enough arguments. https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;issues=AW9Pvj4OYzPBRjkobYxH&amp;open=AW9Pvj4OYzPBRjkobYxH  Use try-with-resources or close this "Scanner" in a "finally" clause. https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;issues=AW9PvjupYzPBRjkobYuk&amp;open=AW9PvjupYzPBRjkobYuk  NullPointerException https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;issues=AW9r2-hNEWQS9hv4qe7s&amp;open=AW9r2-hNEWQS9hv4qe7s https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;issues=AW9PvjqrYzPBRjkobYr7&amp;open=AW9PvjqrYzPBRjkobYr7 https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;issues=AW9PvjduYzPBRjkobYmi&amp;open=AW9PvjduYzPBRjkobYmi https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;issues=AW9PvjduYzPBRjkobYmj&amp;open=AW9PvjduYzPBRjkobYmj https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;issues=AW9PvkAdYzPBRjkobY0x&amp;open=AW9PvkAdYzPBRjkobY0x  </body>
		<created>2020-01-05 13:54:03</created>
		<closed>2020-01-17 08:55:17</closed>
	</bug>
	<bug>
		<id>1714</id>
		<title>[BUG] Fix bug: Use try-with-resources or close this "Socket" in a "finally" clause.</title>
		<body>**Describe the bug** Connections, streams, files, and other classes that implement the Closeable interface or its super-interface, AutoCloseable, needs to be closed after use. Further, that close call must be made in a finally block otherwise an exception could keep the call from being made. Preferably, when class implements AutoCloseable, resource should be created using "try-with-resources" pattern and will be closed automatically.  Failure to properly close resources will result in a resource leak which could bring first the application and then perhaps the box it's on to their knees.  **File** dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/utils/FourLetterWordMain.java dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/task/sql/SqlTask.java  **Link** https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;issues=AW9Pvju3YzPBRjkobYuy&amp;open=AW9Pvju3YzPBRjkobYuy  https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;issues=AW9PvkJkYzPBRjkobY5H&amp;open=AW9PvkJkYzPBRjkobY5H https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;issues=AW9PvkJkYzPBRjkobY5F&amp;open=AW9PvkJkYzPBRjkobY5F https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;issues=AW9PvkJkYzPBRjkobY5G&amp;open=AW9PvkJkYzPBRjkobY5G</body>
		<created>2020-01-04 14:34:41</created>
		<closed>2020-01-17 11:22:31</closed>
	</bug>
	<bug>
		<id>1706</id>
		<title>[BUG] Sonarcloud analysis of dev branch not updated after merge pull request</title>
		<body>**Describe the bug** For now, Sonarcloud is triggered by pull request, and just update corresponding PR branch. After pull request is merged, analysis of dev branch is not updated. </body>
		<created>2020-01-04 02:20:54</created>
		<closed>2020-01-06 05:17:22</closed>
	</bug>
	<bug>
		<id>1704</id>
		<title>[BUG]delete processdefinition when a task aleady exec by worker lead to NPE</title>
		<body>**Describe the bug** delete processdefinition when a task aleady exec by worker lead to NPE  **To Reproduce** Steps to reproduce the behavior, for example: 1. a task aleady exec by worker 2. delete the task processdefinition  3. get tenant will lead java.lang.NullPointerException  **Expected behavior** deal with NPE  **Which version of Dolphin Scheduler:**  -[dev] </body>
		<created>2020-01-03 16:37:24</created>
		<closed>2020-01-17 11:23:06</closed>
	</bug>
	<bug>
		<id>1701</id>
		<title>[BUG] Fix bug: Use try-with-resources or close this "Statement" in a "finally" clause.</title>
		<body>**Describe the bug** Resources should be closed  Connections, streams, files, and other classes that implement the Closeable interface or its super-interface, AutoCloseable, needs to be closed after use. Further, that close call must be made in a finally block otherwise an exception could keep the call from being made. Preferably, when class implements AutoCloseable, resource should be created using "try-with-resources" pattern and will be closed automatically.  Failure to properly close resources will result in a resource leak which could bring first the application and then perhaps the box it's on to their knees.  **File** dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/ScriptRunner.java  **SonarCloud Link** https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;issues=AW9Pvj4rYzPBRjkobYxo&amp;open=AW9Pvj4rYzPBRjkobYxo https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;issues=AW9Pvj4rYzPBRjkobYxq&amp;open=AW9Pvj4rYzPBRjkobYxq https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;issues=AW9Pvj4rYzPBRjkobYxn&amp;open=AW9Pvj4rYzPBRjkobYxn https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;issues=AW9Pvj4rYzPBRjkobYxp&amp;open=AW9Pvj4rYzPBRjkobYxp</body>
		<created>2020-01-03 13:26:48</created>
		<closed>2020-02-28 08:52:08</closed>
	</bug>
	<bug>
		<id>1697</id>
		<title>[BUG] Missing connection line when downloading pictures</title>
		<body> ![image](https://user-images.githubusercontent.com/39816903/71715461-68de1b00-2e4c-11ea-9382-cfc6708c09fd.png)   ![image](https://user-images.githubusercontent.com/39816903/71715553-bbb7d280-2e4c-11ea-97dc-1af9353fdaea.png)       </body>
		<created>2020-01-03 09:16:13</created>
		<closed>2020-01-03 09:35:29</closed>
	</bug>
	<bug>
		<id>1696</id>
		<title>[BUG] ZK miss tasks_queue &amp; tasks_kill</title>
		<body>  Error is reported when starting the worker node, as shown in the following figure.  ![image](https://user-images.githubusercontent.com/39816903/71715310-f66d3b00-2e4b-11ea-8d60-df73160ff2ea.png) </body>
		<created>2020-01-03 09:12:34</created>
		<closed>2020-01-03 11:51:15</closed>
	</bug>
	<bug>
		<id>1688</id>
		<title>[BUG] Fix bug : Use try-with-resources or close this "ResultSet" in a "finally" clause</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** A clear and concise description of what the bug is. Connections, streams, files, and other classes that implement the Closeable interface or its super-interface, AutoCloseable, needs to be closed after use. Further, that close call must be made in a finally block otherwise an exception could keep the call from being made. Preferably, when class implements AutoCloseable, resource should be created using "try-with-resources" pattern and will be closed automatically.  Failure to properly close resources will result in a resource leak which could bring first the application and then perhaps the box it's on to their knees.  **Source FIle** dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/utils/PostgrePerformance.java dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/utils/MysqlPerformance.java  **SonarCloud Link** https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;issues=AW9PvjdUYzPBRjkobYmb&amp;open=AW9PvjdUYzPBRjkobYmb https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;issues=AW9PvjdUYzPBRjkobYma&amp;open=AW9PvjdUYzPBRjkobYma https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;issues=AW9PvjdUYzPBRjkobYmc&amp;open=AW9PvjdUYzPBRjkobYmc  https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;issues=AW9Pvjd_YzPBRjkobYmy&amp;open=AW9Pvjd_YzPBRjkobYmy https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;issues=AW9Pvjd_YzPBRjkobYmx&amp;open=AW9Pvjd_YzPBRjkobYmx </body>
		<created>2020-01-02 14:54:56</created>
		<closed>2020-01-06 05:16:16</closed>
	</bug>
	<bug>
		<id>1679</id>
		<title>Zoom in or out of the DAG , the arrow does not move after dragging the task</title>
		<body>![image](https://user-images.githubusercontent.com/55787491/71657749-2c42ee80-2d7c-11ea-94be-270c9c51991d.png) </body>
		<created>2020-01-02 08:23:21</created>
		<closed>2020-01-17 11:23:28</closed>
	</bug>
	<bug>
		<id>1671</id>
		<title>Incorrect URL for import workflow and view project list</title>
		<body>![image](https://user-images.githubusercontent.com/55787491/71649066-95a80a80-2d46-11ea-923e-045889c19852.png) ![image](https://user-images.githubusercontent.com/55787491/71649124-f0d9fd00-2d46-11ea-8872-ac87bccb9cd7.png) </body>
		<created>2020-01-02 02:02:20</created>
		<closed>2020-01-02 08:00:56</closed>
	</bug>
	<bug>
		<id>1666</id>
		<title>[BUG] Fix SonarCloud bug “Resources should be closed”</title>
		<body>Description Connections, streams, files, and other classes that implement the Closeable interface or its super-interface, AutoCloseable, needs to be closed after use. Further, that close call must be made in a finally block otherwise an exception could keep the call from being made. Preferably, when class implements AutoCloseable, resource should be created using "try-with-resources" pattern and will be closed automatically.  Failure to properly close resources will result in a resource leak which could bring first the application and then perhaps the box it's on to their knees.  Soucre file： dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/utils/ZooKeeperState.java  link： https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;issues=AW9PvjupYzPBRjkobYuj&amp;open=AW9PvjupYzPBRjkobYuj  https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;issues=AW9PvjupYzPBRjkobYuk&amp;open=AW9PvjupYzPBRjkobYuk</body>
		<created>2020-01-01 13:53:08</created>
		<closed>2020-01-07 13:53:22</closed>
	</bug>
	<bug>
		<id>1661</id>
		<title>[BUG] Fix wrong UT coverage by SonarCloud  with  PR</title>
		<body>When PR to main repo ,Sonarcloud analysis new code ,but get 0% new code UT coverage ,even if code is already 100% tested. </body>
		<created>2020-01-01 07:03:54</created>
		<closed>2020-01-01 09:46:40</closed>
	</bug>
	<bug>
		<id>1652</id>
		<title>[BUG] project dependency failed</title>
		<body>**Describe the bug** Add dependency front-end error in project dependency node interface.  **Screenshots** If applicable, add screenshots to help explain your problem. ![image](https://user-images.githubusercontent.com/5669148/71609922-3ff92400-2bc7-11ea-9129-d6c4856743db.png)  **Which version of Dolphin Scheduler:**  -[dev]</body>
		<created>2019-12-31 04:19:19</created>
		<closed>2020-02-12 11:22:21</closed>
	</bug>
	<bug>
		<id>1650</id>
		<title>定时任务时间开始小于当前编辑的时间时，定时任务将无法被执行</title>
		<body>当编辑定时任务的时间段时，QRTZ_TRIGGERS表中的NEXT_FIRE_TIME下一次执行时间等于编辑时的开始时间戳，所以当编辑完成上线时，如果编辑时的开始时间小于当前时间那么定时任务将无法被执行 </body>
		<created>2019-12-31 02:08:35</created>
		<closed>2020-02-28 08:53:09</closed>
	</bug>
	<bug>
		<id>1648</id>
		<title>[BUG] fix "wait(...)" should be used instead of "Thread.sleep(...)" when a lock is held</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** If Thread.sleep(...) is called when the current thread holds a lock, it could lead to performance and scalability issues, or even worse to deadlocks because the execution of the thread holding the lock is frozen. It's better to call wait(...) on the monitor object to temporarily release the lock and allow other threads to run.  see sonarcloud : https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;issues=AW9PvkGGYzPBRjkobY32&amp;open=AW9PvkGGYzPBRjkobY32 </body>
		<created>2019-12-30 13:53:01</created>
		<closed>2020-07-14 09:01:31</closed>
	</bug>
	<bug>
		<id>1640</id>
		<title>commit successfully and cannot continue</title>
		<body>**Describe the bug** Task remains submitted successfully and process instance cannot continue, and this problem only occasionally occurs  **To Reproduce** Unable to reproduce stably  **Screenshots**  ![运行情况](https://user-images.githubusercontent.com/11663381/71572420-f9012500-2b19-11ea-9ab7-2d9b43398fd7.png)  **Which version of Dolphin Scheduler:**  -[1.2.0]  **Requirement or improvement By tracking the code, the possible problems are as follows: ![代码问题](https://user-images.githubusercontent.com/11663381/71572447-251ca600-2b1a-11ea-8f80-7f164e921281.png)  Add DB and the zk queue in the same transaction，the FetchTaskThread may not be able to get the task instance by task id </body>
		<created>2019-12-30 07:41:36</created>
		<closed>2020-01-02 07:58:51</closed>
	</bug>
	<bug>
		<id>1632</id>
		<title>[BUG] sonarcloud bug  fix</title>
		<body>1. file:         dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/EnterpriseWeChatUtils.java     bug:       -  https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;issues=AW9PvkP_YzPBRjkobY7y&amp;open=AW9PvkP_YzPBRjkobY7y     -  https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;issues=AW9PvkP_YzPBRjkobY7z&amp;open=AW9PvkP_YzPBRjkobY7z  2. file:    dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/AlertServer.java     bug:      - https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&amp;issues=AW9PvkRwYzPBRjkobY87&amp;open=AW9PvkRwYzPBRjkobY87</body>
		<created>2019-12-30 01:57:33</created>
		<closed>2019-12-30 13:36:01</closed>
	</bug>
	<bug>
		<id>1613</id>
		<title>[BUG] In a cluster environment, verify that nodes have matching bug</title>
		<body>E.g: master node1 ip : 192.168.1.6 master node2 ip : 192.168.1.61, failed at startup.</body>
		<created>2019-12-27 09:11:16</created>
		<closed>2019-12-28 12:18:11</closed>
	</bug>
	<bug>
		<id>1601</id>
		<title>Scheduled tasks start two tasks at the same time（同一时间启动了两个任务实例）</title>
		<body>**Describe the bug**       Scheduled tasks start two tasks at the same time Instance definition：      ![image](https://user-images.githubusercontent.com/24928399/71505762-6b26ff00-28b9-11ea-8965-da6f550daaf9.png)  ![image](https://user-images.githubusercontent.com/24928399/71505784-7c700b80-28b9-11ea-9144-4bf2ab6492d1.png)   **Expected behavior**  ![image](https://user-images.githubusercontent.com/24928399/71505827-a6c1c900-28b9-11ea-9eb9-9af248f4320f.png)   **Which version of Dolphin Scheduler:**  -[1.1.0] </body>
		<created>2019-12-27 07:01:10</created>
		<closed>2020-01-08 01:32:08</closed>
	</bug>
	<bug>
		<id>1584</id>
		<title>[BUG] The method getserverlistfromzk of zookeepermonitor in monitorservice cannot be re instantiated, otherwise there is a problem in getting ZK connection</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** The method getserverlistfromzk of zookeepermonitor in monitorservice cannot be re instantiated, otherwise there is a problem in getting ZK connection  **Expected behavior**     **Which version of Dolphin Scheduler:**  -[1.2.1-SNAPSHOT-dev]  **Additional context** Server monitoring is not available  **Requirement or improvement public List&lt;Server&gt; getServerListFromZK(boolean isMaster){     List&lt;Server&gt; servers = new ArrayList&lt;&gt;();     try{       ZKNodeType zkNodeType = isMaster ? ZKNodeType.MASTER : ZKNodeType.WORKER;       servers = zookeeperMonitor.getServersList(zkNodeType);     }catch (Exception e){       throw e;     }     return servers;   } </body>
		<created>2019-12-26 01:40:43</created>
		<closed>2020-01-02 07:47:50</closed>
	</bug>
	<bug>
		<id>1580</id>
		<title>Problem creating session logic</title>
		<body>  **Describe the bug** Writing UT found that SessionService.createSession () creates a new session that will query all user sessions, but will keep the first one and delete others. If the first session ip and userId are exactly the same as the one created, the success will occur There will be two session data for the same ip and userId. The logout is queried by ip and userId. Session session = sessionMapper.queryByUserIdAndIp (loginUser.getId (), ip); The method just returns a piece of data, and the actual result database has two pieces of data, which will cause an error.  写UT发现，SessionService.createSession()新建session会查询用户所有session，但是会保留第一个，其他删除，假如刚好保留的第一个session ip,userId和创建session的一致，创建成功会就会出现相同的ip,userId会有两条session数据，注销是通过ip和userId去查询的， Session session = sessionMapper.queryByUserIdAndIp(loginUser.getId(),ip); 方法只是返回一条数据，实际结果数据库有两条数据,这样就会报错。  **Which version of Dolphin Scheduler:**  -[1.2.0-preview]  **Requirement or improvement**  When creating a session, first delete the session with the same userid and ip, and then create a new session. The purpose is that the userId and ip of the two session data cannot exist in the database. 在创建session时，先删除userid和ip相同的session，然后再新建session,目的是数据库中不能存在两条session数据的userId和ip相同。   If the suggestions are ok, I can modify  如果建议没问题，我可以修改 </body>
		<created>2019-12-26 00:03:56</created>
		<closed>2020-01-15 05:46:05</closed>
	</bug>
	<bug>
		<id>1544</id>
		<title>The workflow import user's other project or other user's project, the database table t_ds_process_definition stores data incorrectly</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug**  1. After the user successfully imported the workflow of user’s  project B  in project A, t_ds_process_definition.project_id is still project B, and project_id should be the project ID of project A 2. The workflow of importing other users prompts success, but the data is not stored in the database table t_ds_process_definition   1.用户在A项目导入该用户B项目的工作流成功后，t_ds_process_definition.project_id仍为B项目的id，project_id应该为A项目的id 2.导入其他用户的工作流提示成功，但是数据未存入数据库  **version** [1.2.0]    </body>
		<created>2019-12-24 02:10:40</created>
		<closed>2020-02-28 08:57:29</closed>
	</bug>
	<bug>
		<id>1526</id>
		<title>[BUG] version 1.2 "/tmp/dolphinscheduler/" 目录权限问题 directory permission</title>
		<body>从1.1版本升级到1.2版本之后，作业无法执行，从dolphinscheduler-worker.log日志中看到错误信息如下：”Unable to create directory /tmp/dolphinscheduler/exec/process/1/14/1875/7851“ After upgrading from version 1.1 to version 1.2, the job cannot be executed, the error message from the file 'dolphinscheduler-worker.log'  :”Unable to create directory /tmp/dolphinscheduler/exec/process/1/14/1875/7851“  修改目录权限为777之后作业能执行，但是产生的文件属主是dolphinscheduler，不是root The job can be executed when the directory permission is changed to 777, but the file owner is dolphinscheduler, not root  说明文件是由dolphinscheduler用户直接生成的，不是sudo生成 This indicates that the file was generated by the dolphinscheduler user, not by sudo  这与1.1版本不一致，请问这否是个bug？ This is not consistent with version 1.1. Is this a bug?  </body>
		<created>2019-12-19 10:21:04</created>
		<closed>2020-03-12 10:26:17</closed>
	</bug>
	<bug>
		<id>1522</id>
		<title>MasterSchedulerThread bug</title>
		<body>MasterSchedulerThread should not be sleep after handle command  ``` if(OSUtils.checkResource(masterConfig.getMasterMaxCpuloadAvg(), masterConfig.getMasterReservedMemory())){                     if (zkMasterClient.getZkClient().getState() == CuratorFrameworkState.STARTED) {                          // create distributed lock with the root node path of the lock space as /dolphinscheduler/lock/masters                         String znodeLock = zkMasterClient.getMasterLockPath();                          mutex = new InterProcessMutex(zkMasterClient.getZkClient(), znodeLock);                         mutex.acquire();                          ThreadPoolExecutor poolExecutor = (ThreadPoolExecutor) masterExecService;                         int activeCount = poolExecutor.getActiveCount();                         // make sure to scan and delete command  table in one transaction                         Command command = processDao.findOneCommand();                         if (command != null) {                             logger.info(String.format("find one command: id: %d, type: %s", command.getId(),command.getCommandType().toString()));                              try{                                 processInstance = processDao.handleCommand(logger, OSUtils.getHost(), this.masterExecThreadNum - activeCount, command);                                 if (processInstance != null) {                                     logger.info("start master exec thread , split DAG ...");                                     masterExecService.execute(new MasterExecThread(processInstance,processDao));                                 }                             }catch (Exception e){                                 logger.error("scan command error ", e);                                 processDao.moveToErrorCommand(command, e.toString());                             }                         }                     }                 }                  // should not sleep here                 Thread.sleep(Constants.SLEEP_TIME_MILLIS); ```</body>
		<created>2019-12-19 07:00:59</created>
		<closed>2019-12-19 07:05:54</closed>
	</bug>
	<bug>
		<id>1515</id>
		<title>FetchTaskThread minor bug</title>
		<body>should not sleep there. ``` boolean runCheckFlag = OSUtils.checkResource(workerConfig.getWorkerMaxCpuloadAvg(), workerConfig.getWorkerReservedMemory()) &amp;&amp; checkThreadCount(poolExecutor);     Thread.sleep(Constants.SLEEP_TIME_MILLIS);                  if(!runCheckFlag) {                     continue;                 } ``` i think the right way is :  ``` boolean runCheckFlag = OSUtils.checkResource(workerConfig.getWorkerMaxCpuloadAvg(), workerConfig.getWorkerReservedMemory()) &amp;&amp; checkThreadCount(poolExecutor);                  if(!runCheckFlag) {                     Thread.sleep(Constants.SLEEP_TIME_MILLIS);                     continue;                 } ``` </body>
		<created>2019-12-18 12:46:57</created>
		<closed>2019-12-18 13:03:59</closed>
	</bug>
	<bug>
		<id>1514</id>
		<title>the field queue in  table t_ds_user not change with tabke t_ds_queue modify queue_name field</title>
		<body>**Describe the bug** A user have add a queue like 'developQueue', when admin modify the  developQueue queue, the  field queue in  table t_ds_queue not change  **To Reproduce** 1. Add a user with a queue like  'developQueue' 2. admin modify the 'developQueue' queue 3. the field queue in  table t_ds_user not change  **Expected behavior**  the field queue in  table t_ds_user change with tabke t_ds_queue any modify  **Screenshots** If applicable, add screenshots to help explain your problem.  **Which version of Dolphin Scheduler:**  -[dev]  **Requirement or improvement - the field queue in  table t_ds_user change with table t_ds_queue modify the field queue_name  </body>
		<created>2019-12-18 10:44:08</created>
		<closed>2019-12-19 03:29:54</closed>
	</bug>
	<bug>
		<id>1480</id>
		<title>[BUG] The method checkEmail do not have null check</title>
		<body>**Describe the bug**  The method checkEmail do not have null check  When the email is empty , it wll be nullpointexception.  **To Reproduce**  goto org/apache/dolphinscheduler/api/utils/CheckUtils.java  The method checkEmail  **Expected behavior**  Include  null check  **Which version of Dolphin Scheduler:**  -[1.2.1] </body>
		<created>2019-12-15 11:53:33</created>
		<closed>2019-12-16 03:33:20</closed>
	</bug>
	<bug>
		<id>1477</id>
		<title>[BUG] some tasks would be running all the time when db delayed.</title>
		<body> Because of inserting MySQL and ZK data in a transaction, ZK data would be inserted first, when mysql data is delayed for some reason, worker cannot find the corresponding MySQL data when getting ZK data, which causes the problem that the worker deletes ZK data, and the task would be running all the time.  **Describe the bug** task state would not change when db delayed.  **Which version of Dolphin Scheduler:**  -[1.2.0]  </body>
		<created>2019-12-13 10:36:51</created>
		<closed>2019-12-19 03:37:44</closed>
	</bug>
	<bug>
		<id>1442</id>
		<title>[BUG] code comment error</title>
		<body> **Describe the bug** in this class: org.apache.dolphinscheduler.server.master.runner.MasterSchedulerThread. the line number 104, zkMasterClient.getMasterLockPath() The lock path obtained may should be /dolphinscheduler/lock/masters,  but in the comment, is's /dolphinscheduler/lock/failover/master, I think it's easy to mislead people who read the source code,  please check this,  if it does, I can open a pr to fix it  **To Reproduce** None  **Expected behavior** Node  **Screenshots** None  **Which version of Dolphin Scheduler:** latest version  **Additional context** None  **Requirement or improvement None </body>
		<created>2019-12-11 03:47:22</created>
		<closed>2019-12-12 08:42:51</closed>
	</bug>
	<bug>
		<id>1441</id>
		<title>[Feature] add user error when user name contains '.'</title>
		<body>**Is your feature request related to a problem? Please describe.** add a user when user name contains '.'  i think maybe the username  regex string is error. </body>
		<created>2019-12-11 03:07:47</created>
		<closed>2019-12-12 06:19:56</closed>
	</bug>
	<bug>
		<id>1431</id>
		<title>[BUG] high risk 0day vulnerability of fastjson</title>
		<body>**Describe the bug** The low version of fastjson have a high risk 0day vulnerability. Attackers can exploit scripts to attack. Please fix it in time.  **Which version of Dolphin Scheduler:**  -[1.1.0]  **Requirement or improvement 1. Please upgrade the version of fastjson to 1.2.62 or higher 2. It is recommended to use Jackson or Gson if possible. Note: if the webserver is online, please change the jar of fastjson in lib directory, and restart the server. </body>
		<created>2019-12-10 07:22:15</created>
		<closed>2020-03-19 01:08:18</closed>
	</bug>
	<bug>
		<id>1425</id>
		<title>[Enhancement] JDBC class driver are duplicate define in Constants, We can only use one of them.</title>
		<body>**Describe**  JDBC class driver are duplicate define in Constants.java ,such as:  ``` public static final String JDBC_POSTGRESQL_CLASS_NAME = "org.postgresql.Driver";  and  public static final String ORG_POSTGRESQL_DRIVER = "org.postgresql.Driver"; ``` There are same effect, We can only use one of them.</body>
		<created>2019-12-10 01:55:16</created>
		<closed>2019-12-10 10:58:15</closed>
	</bug>
	<bug>
		<id>1420</id>
		<title>[BUG] gitignore file imperfect</title>
		<body>I forked the project and checkout branch dev-db, Then i run 'mvn clean install -Prelease -Dmaven.test.skip=true' to build the project. I found  `dolphinscheduler-dist/dolphinscheduler-backend/target`  `dolphinscheduler-dist/dolphinscheduler-front/target/`  `dolphinscheduler-dist/dolphinscheduler-src/target/`  `dolphinscheduler-ui/dist`  `dolphinscheduler-ui/node`  was in the untracked files list.  I checked the .gitignore file and found it is imperfect. To solve it we can edit the .gitignore file and add this lines: `**/**/target/**` `dolphinscheduler-ui/dist` `dolphinscheduler-ui/dist`  @qiaozhanwei   Is it a bug? And can I update the .gitignore file?</body>
		<created>2019-12-09 09:23:19</created>
		<closed>2019-12-11 07:04:24</closed>
	</bug>
	<bug>
		<id>1417</id>
		<title>add user error</title>
		<body>*For better global communication, please give priority to using English description, thx! *  i cannot judge what's wrong when the website display this error.  ![image](https://user-images.githubusercontent.com/29528966/70419641-cc209b80-1aa0-11ea-87b6-0bea0797e037.png)  **Which version of Dolphin Scheduler:**  -[1.2.0] </body>
		<created>2019-12-09 08:29:31</created>
		<closed>2019-12-09 08:35:46</closed>
	</bug>
	<bug>
		<id>1414</id>
		<title>[BUG] cant start task when i upgrade to version 1.2.0 from 1.1.0</title>
		<body> **Describe the bug** Its really hard to upgrade to version 1.2.0,all the table names has been changed,and a lot shell script must to reconfig.just like reinstall another software ,and when i finish it all the feautrue is ok.but cant start Process when i click the start button .and the success tip is is show, i try to find the problem in the backend logs but cant find any exceptions,just a few info logs.       **To Reproduce** Steps to reproduce the behavior, for example: 1. Go to Process definition page 2. Click on start button and success tip is slid 3. Go to  process_instance page and no instance display     **Which version of Dolphin Scheduler:**  -[1.2.0-release]   </body>
		<created>2019-12-07 07:38:20</created>
		<closed>2020-07-14 09:04:06</closed>
	</bug>
	<bug>
		<id>1411</id>
		<title>[BUG] There are some word errors and inconsistencies in project website</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** Some words are wrong and inconsistent: 1. In http://dolphinscheduler.incubator.apache.org/en-us/, "Rich Scanerios" should be "Widely Scenarios" or "Rich Scenarios"  2. In http://dolphinscheduler.incubator.apache.org/en-us/docs/user_doc/subscribe.html, http://dolphinscheduler.incubator.apache.org/en-us/docs/development/developers.html,  The words in the list on the left should follow the hump nomenclature, For example, "Backend deployment" should be "Backend Deployment", etc.  **To Reproduce**  Open the website, and search the keywords mentioned above.  **Expected behavior** As described above </body>
		<created>2019-12-06 15:56:29</created>
		<closed>2020-03-31 01:51:20</closed>
	</bug>
	<bug>
		<id>1410</id>
		<title>[BUG] Dependent file does not add version information</title>
		<body>The `jcip-annotations` in `pom.xml` does not define version information, and `maven-assembly-plugin` is missing `groupId`  ```xml &lt;dependency&gt;  &lt;groupId&gt;net.jcip&lt;/groupId&gt;  &lt;artifactId&gt;jcip-annotations&lt;/artifactId&gt;  &lt;version&gt;${jcip.version}&lt;/version&gt;  &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; ```  and  ```xml &lt;plugin&gt;  &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;  &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;  &lt;version&gt;${maven-assembly-plugin.version}&lt;/version&gt; &lt;/plugin&gt; ``` </body>
		<created>2019-12-06 15:56:06</created>
		<closed>2020-02-28 09:02:49</closed>
	</bug>
	<bug>
		<id>1407</id>
		<title>DolphinScheduler1.2.0数据库初始化时抛出错误</title>
		<body>MySQL版本：5.6 Dolphinscheduler版本：1.2.0  执行完以下步骤后： CREATE DATABASE dolphinscheduler DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci; GRANT ALL PRIVILEGES ON dolphinscheduler.* TO '{user}'@'%' IDENTIFIED BY '{password}'; GRANT ALL PRIVILEGES ON dolphinscheduler.* TO '{user}'@'localhost' IDENTIFIED BY '{password}'; flush privileges;  运行： sh ./script/create-dolphinscheduler.sh  抛出： java.sql.SQLException: com.mysql.jdbc.Driver at com.alibaba.druid.util.JdbcUtils.createDriver(JdbcUtils.java:620) at com.alibaba.druid.pool.DruidDataSource.init(DruidDataSource.java:874) at com.alibaba.druid.pool.DruidDataSource.getConnection(DruidDataSource.java:1300) at com.alibaba.druid.pool.DruidDataSource.getConnection(DruidDataSource.java:1296) at org.apache.dolphinscheduler.dao.upgrade.UpgradeDao.getCurrentDbType(UpgradeDao.java:80) at org.apache.dolphinscheduler.dao.upgrade.UpgradeDao.&lt;clinit&gt;(UpgradeDao.java:45) at org.apache.dolphinscheduler.dao.upgrade.DolphinSchedulerManager.initUpgradeDao(DolphinSchedulerManager.java:37)</body>
		<created>2019-12-06 04:02:41</created>
		<closed>2019-12-06 04:12:58</closed>
	</bug>
	<bug>
		<id>1403</id>
		<title>Create user check</title>
		<body>**Describe the bug** 当我创建用户时，用户信息输入不合规范（邮箱为rd_ifactory@163.com 带有下划线），如下图 ： When I created a user, the user information entered was substandard (the mailbox is rd_ifactory@163.com with an underscore), as shown below:  ![image](https://user-images.githubusercontent.com/32353326/70221311-12b18580-1783-11ea-9a88-7928431ecc50.png)  系统给出提示，如下图： The system prompts as follows:  ![image](https://user-images.githubusercontent.com/32353326/70221362-2826af80-1783-11ea-8ddd-e0ad735b25f2.png)  相应的校验代码，如下图： The corresponding verification code is as follows:  ![image](https://user-images.githubusercontent.com/32353326/70221498-6e7c0e80-1783-11ea-9a41-ba5235411e09.png) ![image](https://user-images.githubusercontent.com/32353326/70221516-78057680-1783-11ea-8666-e44c76d7faad.png)  1、userName、email、password、phone四个参数同时校验，但是当其中一个参数不合规范时给出的提示并没有对应到某一个不和规范的参数，而是提示userName是无效的  The userName, email, password, and phone parameters are checked at the same time, but the prompt given when one of the parameters does not meet the specifications does not correspond to a parameter that does not meet the specifications  2、邮箱带有“_”下划线无法通过校验  Mailbox with "_" underscore cannot pass verification  **To Reproduce** Steps to reproduce the behavior, for example: 1、创建用户     create user  2、不填写手机号 Do not fill in the phone number  3、设置一个带有“_”下划线的邮箱 Set up a mailbox with "_" underline  **Expected behavior** 1、希望当用户信息填写不符合规范时，可以提示哪一个参数不符合规范，最好前端也加上校验与提示  I hope that when the user information is not in compliance with the specifications, it can be prompted which parameters do not meet the specifications. It is best to add a check and prompt in the front end.  2、允许邮箱带有"_"下划线 Allow mailboxes with "_" underline  **Screenshots** If applicable, add screenshots to help explain your problem.   **Which version of Dolphin Scheduler:**  -[1.2.0-preview]  **Additional context** Add any other context about the problem here.  **Requirement or improvement - Please describe about your requirements or improvement suggestions. </body>
		<created>2019-12-05 09:25:58</created>
		<closed>2019-12-11 06:52:13</closed>
	</bug>
	<bug>
		<id>1399</id>
		<title>[BUG] The wrong field order in logger.info</title>
		<body>**Describe the bug**  The method onlineCreateResource in class ResourcesController，The logger.info has wrong  field order with fileName and type.  **Screenshots**  &lt;img width="1021" alt="" src="https://user-images.githubusercontent.com/3699743/70215243-0f64cc80-1778-11ea-9ec5-f6a38559b051.png"&gt;   **Which version of Dolphin Scheduler:**  - [dev-db branch] </body>
		<created>2019-12-05 07:59:57</created>
		<closed>2019-12-09 08:56:12</closed>
	</bug>
	<bug>
		<id>1397</id>
		<title>[BUG] [Resource Management]  resources can not be previewed or updated</title>
		<body>**Describe the bug** if one resource file is renamed with no suffix or no supported suffix, it can not be previewed or updated.  **To Reproduce** STEP 1: Create a resource, whose name is test.sh. Under the circumstances,you can preview or update this resource's content.But if I take STEP 2, these actions can not be done. STEP2: Rename test.sh to test.  **Where to find relavant code** GOTO: ResouceService line:505 and 633 **Screenshots** ![image](https://user-images.githubusercontent.com/37128453/70209592-a414fd80-176b-11ea-9b27-3cdd771b149e.png)  **Which version of Dolphin Scheduler:** [all versions]  **Requirement or improvement Resources whose suffix is one of txt,log,sh,conf,cfg,py,java,sql,hql,xml,properties can be preview and updated whatever their names are.  change resource.getAlias() to resource.getFileName()  ![image](https://user-images.githubusercontent.com/37128453/70209795-1f76af00-176c-11ea-8e62-305b93bbede9.png)  </body>
		<created>2019-12-05 06:36:54</created>
		<closed>2020-03-31 02:11:29</closed>
	</bug>
	<bug>
		<id>1379</id>
		<title>[BUG] SQL task，date parameter need to add explicit type casts</title>
		<body>**Describe the bug** SQL task with where condition, i define a parameter named v_createdate,it is in type,and date data type with  $[yyyy-MM-dd]，SQL statement as follow： insert into t_wms_stock_2 select * from t_wms_stock where create_time=${v_createdate};  it failed with error: "ERROR: operator does not exist: date = character varying   Hint: No operator matches the given name and argument type(s). You might need to add explicit type casts."  **To Reproduce** Steps to reproduce the behavior, for example: 1. Go to 'Project-Process definition' and click ‘create process’ 2. Click on 'SQL'，drag it to the DAG panel,define as follow:   datasource:postgressql,select Greenplum datasource which i defnie   SQL type:non query   SQL Statement: insert into t_wms_stock_2 select * from t_wms_stock where create_time=${v_createdate};   Custom Parameters: v_createdate  int  date $[yyyy-MM-dd]   save it 3. online and start it 4. error message:    [INFO] 2019-12-03 11:02:59.919 cn.escheduler.server.worker.log.TaskLogger:[178] - [taskAppId=TASK_2_49_67] prepare statement replace sql:insert into t_wms_stock_2 select * from t_wms_stock where create_time='2019-12-03' [ERROR] 2019-12-03 11:03:00.007 cn.escheduler.server.worker.log.TaskLogger:[313] - [taskAppId=TASK_2_49_67] ERROR: operator does not exist: date = character varying   Hint: No operator matches the given name and argument type(s). You might need to add explicit type casts.  when SQL Statement defines as follow,it works fine： 1、insert into t_wms_stock_2 select * from t_wms_stock where create_time='2019-12-03'; 2、insert into t_wms_stock_2 select * from t_wms_stock where create_time=to_date(${v_createdate},'yyyy-mm-dd')  **Expected behavior** SQL Statement executes sucessfully  **Screenshots** If applicable, add screenshots to help explain your problem.   **Which version of Dolphin Scheduler:**  -[1.1.0-preview]  **Additional context** OS: CentOS 7.3 Greenplum: Greenplum-db-6.0.1-rhel7 escheduler: escheduler-1.1.0   **Requirement or improvement define parameter with date type, no need to explicit type casts like to_date </body>
		<created>2019-12-03 04:01:08</created>
		<closed>2020-03-31 02:33:23</closed>
	</bug>
	<bug>
		<id>1356</id>
		<title>[BUG] Hive-1.1.0-CDH not supported cause missing field 'client_protocol'</title>
		<body> **Describe the bug** I tried to connect my CDH hive-1.1.0 but failed with following logs: ``` [ERROR] 2019-11-29 17:01:38.579 org.apache.hive.jdbc.HiveConnection:[600] - Error opening session org.apache.thrift.TApplicationException: Required field 'client_protocol' is unset! Struct:TOpenSessionReq(client_protocol:null, configuration:{use:database=default}) ... ...         at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:683)         at java.lang.Thread.run(Thread.java:748) Caused by: org.apache.thrift.TApplicationException: Required field 'client_protocol' is unset! Struct:TOpenSessionReq(client_protocol:null, configuration:{use:database=default})         at org.apache.thrift.TApplicationException.read(TApplicationException.java:111)         at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:79) ... ... ```  **To Reproduce** data source management -&gt; create datasource -&gt; hive/impala -&gt; use my cdh-hive datasource -&gt; test connection  **Expected behavior** connection success  **Screenshots**  connection datasource failure   **Which version of Dolphin Scheduler:**  -[1.1.0]  </body>
		<created>2019-11-29 09:31:49</created>
		<closed>2019-12-09 09:04:27</closed>
	</bug>
	<bug>
		<id>1336</id>
		<title>[BUG] [api]Dependent execution fails after task performs serial complement</title>
		<body> **To Reproduce** 1.  A task depends on B task, the deviation range is the first 3 days 2. The serial complement of 3 days before the B task execution 3.  Run workflow, dependent execution fails   ![image](https://user-images.githubusercontent.com/55787491/69607569-74297400-1060-11ea-9d15-8175e79056ff.png)   **Which version of Dolphin Scheduler:**  -[1.2.0]   </body>
		<created>2019-11-26 07:23:55</created>
		<closed>2020-08-05 02:43:06</closed>
	</bug>
	<bug>
		<id>1324</id>
		<title>[BUG] 文件管理-上传的文件太大时线程不工作</title>
		<body>上传的资源文件太大的时候，校验不通过，无法继续执行 </body>
		<created>2019-11-25 06:55:02</created>
		<closed>2019-11-29 07:18:01</closed>
	</bug>
	<bug>
		<id>1316</id>
		<title>[BUG] rename FILE successfully (mysql), while hdfs is unavailable</title>
		<body>**Describe the [bug** rename FILE successfully (mysql), while hadoop is Unavailable  **To Reproduce** Steps to reproduce the behavior, for example: 1. rename **FILE** A to B , while hdfs server is Unavailable hdfs服务异常时，对文件A重命名，修改为B  **Expected behavior** the file's name should be maintained mysql存储的文件名不变  **Which version of Dolphin Scheduler:**  -[1.1.0-preview]  **Requirement or improvement throw runtimeException in catch block / rollback manually </body>
		<created>2019-11-22 12:01:34</created>
		<closed>2020-07-14 09:09:12</closed>
	</bug>
	<bug>
		<id>1315</id>
		<title>ERROR 1022 (23000): Can't write; duplicate key in table 't_escheduler_task_instance'[BUG] bug title </title>
		<body>mysql数据库版本：5.6.28 ERROR 1022 (23000): Can't write; duplicate key in table 't_escheduler_task_instance'</body>
		<created>2019-11-22 10:25:40</created>
		<closed>2019-11-28 09:10:11</closed>
	</bug>
	<bug>
		<id>1312</id>
		<title>create dolphinscheduler sql failed</title>
		<body>there is an error in the branch 1.2.0-release when i create sql.   ![image](https://user-images.githubusercontent.com/29528966/69396334-dd398080-0d1c-11ea-8d2b-75615222a948.png) </body>
		<created>2019-11-22 03:41:53</created>
		<closed>2019-11-22 08:55:13</closed>
	</bug>
	<bug>
		<id>1298</id>
		<title> Application id error in parsing log after Flink task starts</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** Flink流处理任务启动后 dolphinscheduler中的任务状态变为完成，但是Flink任务，还在运行并未执行完毕或关闭  After the Flink stream processing task is started, the task status in the dolphinscheduler becomes complete, but the Flink task is still running or not closed.      `private String findAppId(String line) {         Matcher matcher = APPLICATION_REGEX.matcher(line);        // 此处应去掉checkFindApp(line) 判断条件       // The checkFindApp(line) condition should be removed here.         if (matcher.find() &amp;&amp; checkFindApp(line)) {             return matcher.group();         }         return null;     }`  **To Reproduce** Steps to reproduce the behavior, for example: 1. 创建带有Flink任务的GAG，   Create a GAG with a Flink task 2. 手动执行运行 ，  Manual execution 3. 查看任务状态 ，   View task status  **Expected behavior** A clear and concise description of what you expected to happen.  **Screenshots** If applicable, add screenshots to help explain your problem.   **Which version of Dolphin Scheduler:**  -dev  **Additional context** Add any other context about the problem here.  **Requirement or improvement - Please describe about your requirements or improvement suggestions. </body>
		<created>2019-11-20 03:05:49</created>
		<closed>2019-11-27 02:34:34</closed>
	</bug>
	<bug>
		<id>1297</id>
		<title>[BUG] UdfFuncMapperProvider. queryAllUdfFuncPaging()中sql的where条件里的字段名与表中字段名不一致</title>
		<body>导致资源中心-&gt;函数管理模糊查询异常</body>
		<created>2019-11-20 02:12:04</created>
		<closed>2019-11-21 02:34:29</closed>
	</bug>
	<bug>
		<id>1281</id>
		<title>[BUG] 1.10 master  start error </title>
		<body>Non root user master startup error !!!!!!!! version 1.10   ![image](https://user-images.githubusercontent.com/39816903/69114591-d57da000-0ac0-11ea-84d0-c5502aa2b0c7.png)    </body>
		<created>2019-11-19 03:37:46</created>
		<closed>2020-03-31 12:42:43</closed>
	</bug>
	<bug>
		<id>1245</id>
		<title>[BUG] when Master Server scanCommand, in rare case, there maybe dirty data saved into ProcessInstance due to Transactional logic problem</title>
		<body>Currently, in scanCommand, the exception is swallowed inside try{} catch{}, so, the transational is not working as expected.   https://github.com/apache/incubator-dolphinscheduler/blob/dev-db/dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/ProcessDao.java#L146  ![图片](https://user-images.githubusercontent.com/4434603/68911560-60dcf580-0790-11ea-8167-ee9840adbd7e.png)  If the lines (marked in red rectangle) throws exception. The processinstance will still be saved. but no thread will be created to handle this one.    I will provide PR for this. </body>
		<created>2019-11-15 02:13:07</created>
		<closed>2019-12-05 12:15:05</closed>
	</bug>
	<bug>
		<id>1243</id>
		<title>taskInfo can be NULL-XX</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** A clear and concise description of what the bug is.  **To Reproduce** Steps to reproduce the behavior, for example: 1. 'run a process instance' 2. 'stop the process instance ' 3. some times, the console will print below log  ``` [INFO] 2019-11-14 23:59:43.874 org.apache.dolphinscheduler.server.worker.WorkerServer:[325] - get one kill command from tasks kill queue: NULL-41 [INFO] 2019-11-14 23:59:43.879 org.apache.dolphinscheduler.server.worker.WorkerServer:[365] - delete task from tasks queue: 41 [INFO] 2019-11-14 23:59:43.884 org.apache.dolphinscheduler.common.queue.TaskQueueZkImpl:[102] - check task 2_7_2_41_-1 exists in task queue  [INFO] 2019-11-14 23:59:43.887 org.apache.dolphinscheduler.common.queue.TaskQueueZkImpl:[278] - consume task /dolphinscheduler/tasks_queue/2_7_2_41_-1 [INFO] 2019-11-14 23:59:43.891 org.apache.dolphinscheduler.common.queue.TaskQueueZkImpl:[339] - delete task:NULL-41 from tasks set  ```   **Which version of Easy Scheduler:**  -[dev-db] </body>
		<created>2019-11-14 16:01:29</created>
		<closed>2019-11-23 02:53:32</closed>
	</bug>
	<bug>
		<id>1239</id>
		<title>[BUG] create user error by the missing field 'queue' in table 't_escheduler_user'</title>
		<body>when create a new user,  it occur exception "create user error".  the API Server exception info as follow: ``` org.springframework.jdbc.BadSqlGrammarException:  ### Error updating database.  Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown column 'queue' in 'field list' ### The error may exist in cn/escheduler/dao/mapper/UserMapper.java (best guess) ### The error may involve cn.escheduler.dao.mapper.UserMapper.insert-Inline ### The error occurred while setting parameters ### SQL: INSERT INTO t_escheduler_user  (`user_name`, `user_password`, `email`, `phone`, `user_type`, `tenant_id`, `queue`, `create_time`, `update_time`) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?) ### Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown column 'queue' in 'field list' ; bad SQL grammar []; nested exception is com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown column 'queue' in 'field list' at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.doTranslate(SQLErrorCodeSQLExceptionTranslator.java:234) ~[spring-jdbc-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72) ~[spring-jdbc-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:73) ~[mybatis-spring-2.0.1.jar:2.0.1] at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:446) ~[mybatis-spring-2.0.1.jar:2.0.1] at com.sun.proxy.$Proxy89.insert(Unknown Source) ~[na:na] at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:278) ~[mybatis-spring-2.0.1.jar:2.0.1] at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:62) ~[mybatis-3.5.1.jar:3.5.1] at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:58) ~[mybatis-3.5.1.jar:3.5.1] at com.sun.proxy.$Proxy103.insert(Unknown Source) ~[na:na] at cn.escheduler.api.service.UsersService.createUser(UsersService.java:124) ~[classes/:na] at cn.escheduler.api.service.UsersService$$FastClassBySpringCGLIB$$11005e8f.invoke(&lt;generated&gt;) ~[classes/:na] at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) ~[spring-core-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:749) ~[spring-aop-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) ~[spring-aop-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294) ~[spring-tx-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98) ~[spring-tx-5.1.5.RELEASE.jar:5.  ```  i found that , the table  t_escheduler_user dose't have the filed 'queue'.  my code is forkd from the master </body>
		<created>2019-11-14 09:01:55</created>
		<closed>2019-11-14 09:19:34</closed>
	</bug>
	<bug>
		<id>1238</id>
		<title>The first step of the official website login in with incorrect password(官网快速上手第一步登录给的密码不正确)</title>
		<body>https://dolphinscheduler.apache.org/zh-cn/docs/user_doc/quick-start.html 官网快速上手给的默认的用户名和密码登录不了</body>
		<created>2019-11-14 08:36:48</created>
		<closed>2019-12-09 10:52:18</closed>
	</bug>
	<bug>
		<id>1210</id>
		<title>[BUG] bug title sql组建插入语句换成一个变量就不能插入这个语句在sql客户端执行没问题</title>
		<body>[INFO] 2019-11-12 16:31:18.612 cn.escheduler.server.worker.log.TaskLogger:[173] - [taskAppId=TASK_2_16642_16642] SqlParameters{type='MYSQL', datasource=1, sql='  insert into t2(item) values("test"); insert into t2(item) values(${biz_time}); ', sqlType=1, udfs='', showType='', connParams='', title='', receivers='', receiversCc='', preStatements=[], postStatements=[]} [INFO] 2019-11-12 16:31:18.612 cn.escheduler.server.worker.log.TaskLogger:[188] - [taskAppId=TASK_2_16642_16642] sql type : MYSQL, datasource : 1, sql :   insert into t2(item) values("test"); insert into t2(item) values(${biz_time});  , localParams : [Property{prop='biz_time', direct=IN, type=INTEGER, value='${system.biz.date}'}],udfs : ,showType : ,connParams :  [INFO] 2019-11-12 16:31:18.615 cn.escheduler.server.worker.log.TaskLogger:[188] - [taskAppId=TASK_2_16642_16642] datasource name : 192.168.251.94 , type : MYSQL , desc : area  , user_id : 1 , parameter : {"address":"jdbc:mysql://192.168.251.94:3306","database":"mysql_ods","jdbcUrl":"jdbc:mysql://192.168.251.94:3306/mysql_ods","user":"root","password":"hl.Data2018","other":"characterEncoding=utf-8"} [INFO] 2019-11-12 16:31:18.619 cn.escheduler.server.worker.log.TaskLogger:[178] - [taskAppId=TASK_2_16642_16642] after replace sql , preparing :   insert into t2(item) values("test"); insert into t2(item) values(?);  [INFO] 2019-11-12 16:31:18.619 cn.escheduler.server.worker.log.TaskLogger:[173] - [taskAppId=TASK_2_16642_16642] replaced sql , parameters:20191111(INTEGER) [INFO] 2019-11-12 16:31:18.631 cn.escheduler.server.worker.log.TaskLogger:[178] - [taskAppId=TASK_2_16642_16642] prepare statement replace sql:  insert into t2(item) values("test"); insert into t2(item) values(20191111);  [ERROR] 2019-11-12 16:31:18.632 cn.escheduler.server.worker.log.TaskLogger:[313] - [taskAppId=TASK_2_16642_16642] You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'insert into t2(item) values(20191111)' at line 2 com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'insert into t2(item) values(20191111)' at line 2 at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:423) at com.mysql.jdbc.Util.handleNewInstance(Util.java:377) at com.mysql.jdbc.Util.getInstance(Util.java:360) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:978) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3887) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3823) at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2435) at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2582) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2530) at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1907) at com.mysql.jdbc.PreparedStatement.executeUpdate(PreparedStatement.java:2141) at com.mysql.jdbc.PreparedStatement.executeUpdate(PreparedStatement.java:2077) at com.mysql.jdbc.PreparedStatement.executeUpdate(PreparedStatement.java:2062) at cn.escheduler.common.task.sql.LoggableStatement.executeUpdate(LoggableStatement.java:118)   **Which version of Easy Scheduler:**  -[1.1.0-preview]  **Additional context** Add any other context about the problem here.  **Requirement or improvement - Please describe about your requirements or improvement suggestions.  还有像这样的复合语句执行也是报错的。 insert into t2(item) select   count(1) cnt  from t1; 这样是需要先执行一个查询sql把变量保存下来，然后再使用一个非查询sql来实现吗？ 如果是这个原因，那么针对复杂的处理实现就比较复杂了。希望给出解答。 </body>
		<created>2019-11-12 08:56:00</created>
		<closed>2019-11-13 09:23:55</closed>
	</bug>
	<bug>
		<id>1201</id>
		<title>[BUG] wrong network address when master-server has multiple network addresses</title>
		<body>**Describe the bug** when I run master-server(multiple network addresses), I got the network address of master-server not in the same network segment as worker-server.  **Expected behavior** Got the network address of master-server which  in the same segment as worker-server.  **Which version of Easy Scheduler:**  -[dev] </body>
		<created>2019-11-11 09:27:04</created>
		<closed>2019-12-09 09:26:45</closed>
	</bug>
	<bug>
		<id>1197</id>
		<title>[BUG] wrong spell in lock implementation flow chart</title>
		<body>**Describe the bug** 文档[配图](https://analysys.github.io/easyscheduler_docs_cn/images/distributed_lock_procss.png)中用词错误,如图标红部分,应该为 `取到`  **To Reproduce** ![image](https://user-images.githubusercontent.com/22912087/68565799-85cf2100-048f-11ea-878b-95a46abe120c.png)  </body>
		<created>2019-11-11 06:29:07</created>
		<closed>2019-12-05 14:22:31</closed>
	</bug>
	<bug>
		<id>1184</id>
		<title>[BUG]same user and ip has two sessions, user login failed</title>
		<body>Version(版本): 1.1.0  描述： 同一用户，同一IP有2个Session，导致登陆失败。 删掉一个Session后，登陆成功  现象： ![image](https://user-images.githubusercontent.com/24906133/68462629-dd7b4b80-0247-11ea-91d2-3eac39da2f2f.png) ![image](https://user-images.githubusercontent.com/24906133/68462651-e79d4a00-0247-11ea-9b50-1fdbe5d29146.png) ![image](https://user-images.githubusercontent.com/24906133/68462665-ed932b00-0247-11ea-9f36-6d88205b6280.png)   补充： 期间mysql存在连接不上的问题 com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure  The last packet successfully received from the server was 0 milliseconds ago.  The last packet sent successfully to the server was 601,132 milliseconds ago.</body>
		<created>2019-11-08 08:54:44</created>
		<closed>2019-12-09 08:36:45</closed>
	</bug>
	<bug>
		<id>1164</id>
		<title>[BUG] cn.escheduler.api.controller.ResourcesController:[313] - create resource file online error</title>
		<body>**Describe the bug** cn.escheduler.api.controller.ResourcesController:[313] - create resource file online error.  **To Reproduce** 1. 进入 资源中心-文件管理 2. 点击 创建文件 3. 输入完必填项后点击创建 4. See error  **Log** [ERROR] 2019-11-06 14:01:46.177 cn.escheduler.api.controller.ResourcesController:[313] - create resource file online error java.lang.NullPointerException: null         at cn.escheduler.api.service.ResourcesService.verifyResourceName(ResourcesService.java:445)         at cn.escheduler.api.service.ResourcesService.onlineCreateResource(ResourcesService.java:580)         at cn.escheduler.api.service.ResourcesService$$FastClassBySpringCGLIB$$ad56f2d2.invoke(&lt;generated&gt;)         at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)         at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:749)         at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)         at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)         at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)         at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)         at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688)         at cn.escheduler.api.service.ResourcesService$$EnhancerBySpringCGLIB$$a1f86aa3.onlineCreateResource(&lt;generated&gt;)         at cn.escheduler.api.controller.ResourcesController.onlineCreateResource(ResourcesController.java:311)         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)         at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)         at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)         at java.lang.reflect.Method.invoke(Method.java:498)         at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:189)         at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138)         at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102)         at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)         at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:800)         at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)         at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1038)         at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942)         at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1005)         at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:908)         at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)         at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:882)         at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)         at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:867)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1623)         at com.github.xiaoymin.swaggerbootstrapui.filter.SecurityBasicAuthFilter.doFilter(SecurityBasicAuthFilter.java:84) </body>
		<created>2019-11-06 06:06:51</created>
		<closed>2019-12-09 09:30:10</closed>
	</bug>
	<bug>
		<id>1135</id>
		<title>[BUG] the 'file' feild of appender 'TASKLOGFILE' in logs/worker_logback.xml maybe wrong!</title>
		<body>version: 1.1.0 ![image](https://user-images.githubusercontent.com/30412237/67930160-12f5b880-fbfa-11e9-8a55-4e50c2e41c69.png)  the file name maybe as following: ${log.base}/${processDefinitionId}/${processInstanceId}/${taskInstanceId}.log  it is lack of a '$' that may cause the local dir is  ![image](https://user-images.githubusercontent.com/30412237/67930279-5d773500-fbfa-11e9-9bf2-52a5e1017986.png) </body>
		<created>2019-10-31 08:20:44</created>
		<closed>2019-11-04 13:02:10</closed>
	</bug>
	<bug>
		<id>1075</id>
		<title>[BUG] prompt resource not exsit when administrative users delete data sources created by ordinary users in the data source center</title>
		<body> **First, I logged in to admin and deleted the normal user.** when the management user deletes the data source created by ordinary users in the data source center, it prompts resource not exsit, and the background query database finds that the corresponding data exists, and the back-end data displayed in the web interface is normal </body>
		<created>2019-10-23 03:57:47</created>
		<closed>2020-02-07 11:14:47</closed>
	</bug>
	<bug>
		<id>1036</id>
		<title>[BUG] cross-project dependency cascading exception(跨项目流依赖级联异常)</title>
		<body>Cross project flow depends on the data of cascading nodes, which is always the data of the first workflow. Changing the selection workflow is also invalid （跨项目流依赖级联节点的数据一直是第一个工作流的数据，改变选择工作流也无效）</body>
		<created>2019-10-17 01:53:12</created>
		<closed>2019-10-18 11:53:51</closed>
	</bug>
	<bug>
		<id>1012</id>
		<title>[BUG] 分布式任务时，任务被移除，任务卡在已提交状态</title>
		<body>2019-10-14 12:11:18.476  INFO 49523 --- [Thread-Executor] c.e.s.worker.runner.FetchTaskThread      : task : 6545 ready to submit to task scheduler thread 2019-10-14 12:11:18.476  INFO 49523 --- [Thread-Executor] c.e.common.queue.TaskQueueZkImpl         : consume task /escheduler/tasks_queue/2_3306_2_6545_174422043  debug：代码定位在 cn.escheduler.server.worker.runner.TaskScheduleThread 的 getTaskLogPath方法  ((TaskLogDiscriminator) ((SiftingAppender) ((LoggerContext) LoggerFactory.getILoggerFactory())                 .getLogger("ROOT")                 .getAppender("TASKLOGFILE")) 返回 null 导致 任务一直卡在已提交状态，无法执行，也无法重置状态</body>
		<created>2019-10-14 04:31:26</created>
		<closed>2020-07-14 09:18:49</closed>
	</bug>
	<bug>
		<id>1009</id>
		<title>[BUG] [Docker] io.js:681 GET http://localhost:8888/escheduler/users/get-user-info?_t=0.7582670985443458 404 (Not Found)</title>
		<body>``` docker pull ww1516123/incubator-dolphinscheduler docker run -d --name incubator-dolphinscheduler -p 8888:8888 ww1516123/incubator-dolphinscheduler ``` 浏览器打开页面 http://localhost:8888/#/ 始终在加载状态。 ![image](https://user-images.githubusercontent.com/377955/66710732-00cdea80-edb1-11e9-95ff-94d915613bcb.png) 报下面错误： ![image](https://user-images.githubusercontent.com/377955/66710757-3f63a500-edb1-11e9-8d0e-b44977db8f9b.png) </body>
		<created>2019-10-13 04:02:07</created>
		<closed>2019-12-09 09:41:27</closed>
	</bug>
	<bug>
		<id>1007</id>
		<title>[BUG] bug title </title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** A clear and concise description of what the bug is.  Does that project provide coordinated services for distributed tasks in the form of jar packages. Please give more details, thx  </body>
		<created>2019-10-12 13:52:17</created>
		<closed>2019-12-10 12:20:29</closed>
	</bug>
	<bug>
		<id>991</id>
		<title>[BUG] zookeeper dashboard error</title>
		<body>![深度截图_选择区域_20191011191100](https://user-images.githubusercontent.com/2173239/66652051-4383ab80-ec67-11e9-8cbd-083330c92434.png)  Everything is -1.  ``` root@34a2c3b68a9c:/opt/escheduler/logs# cat escheduler-api-server-34a2c3b68a9c.out       .   ____          _            __ _ _  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \ ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )   '  |____| .__|_| |_|_| |_\__, | / / / /  =========|_|==============|___/=/_/_/_/  :: Spring Boot ::        (v2.1.3.RELEASE)  Exception in thread "FourLetterCmd:ruok" java.lang.NoClassDefFoundError: org/apache/logging/log4j/message/Message     at org.apache.zookeeper.client.FourLetterWordMain.&lt;clinit&gt;(FourLetterWordMain.java:35)     at cn.escheduler.api.utils.ZooKeeperState$SendThread.run(ZooKeeperState.java:135) Caused by: java.lang.ClassNotFoundException: org.apache.logging.log4j.message.Message     at java.net.URLClassLoader.findClass(URLClassLoader.java:382)     at java.lang.ClassLoader.loadClass(ClassLoader.java:424)     at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)     at java.lang.ClassLoader.loadClass(ClassLoader.java:357)     ... 2 more Exception in thread "FourLetterCmd:ruok" java.lang.NoClassDefFoundError: Could not initialize class org.apache.zookeeper.client.FourLetterWordMain     at cn.escheduler.api.utils.ZooKeeperState$SendThread.run(ZooKeeperState.java:135) ```  **Which version of Easy Scheduler:** dev branch  log4j jar is missing. </body>
		<created>2019-10-11 12:40:25</created>
		<closed>2019-10-12 02:37:50</closed>
	</bug>
	<bug>
		<id>979</id>
		<title>[BUG] After the workflow fails to run multiple times, the number of failures of the home page and the project home page is incorrect</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** After the workflow run fails, the re-run 3 times fails,  the number of failures of the task status statistics on the home page and the project home page is incorrect 【工作流运行失败后，重跑3次均失败，首页和项目首页的任务状态统计的失败次数为1，应该为4】  **To Reproduce** 1.Workflow definition setting failed retries 3 times ![image](https://user-images.githubusercontent.com/55787491/66540755-80fd1180-eb5f-11e9-9987-1ce04f7e11af.png) 2.After running the workflow, there are 4 failure data for viewing the task instance, as shown below ![image](https://user-images.githubusercontent.com/55787491/66540897-f7017880-eb5f-11e9-93f1-2b3d9dd723cd.png) 3.The number of failures of task status statistics on the home page and project home page is 1. It should be 4 ![image](https://user-images.githubusercontent.com/55787491/66540971-392aba00-eb60-11e9-835e-d20d08686f09.png) ![image](https://user-images.githubusercontent.com/55787491/66540982-43e54f00-eb60-11e9-8e56-32d99df3c9db.png)   **Which version of Easy Scheduler:**  -[dev分支]  </body>
		<created>2019-10-10 05:17:26</created>
		<closed>2019-11-05 05:48:37</closed>
	</bug>
	<bug>
		<id>971</id>
		<title>[BUG] Files should not be deleted and renamed after they are associated with a workflow</title>
		<body>*For better global communication, please give priority to using English description, thx! * **To Reproduce** ![image](https://user-images.githubusercontent.com/55787491/66462865-877f8080-eaae-11e9-838d-cb9d734286cf.png)  **Which version of Easy Scheduler:**  -[dev分支]  </body>
		<created>2019-10-09 08:05:02</created>
		<closed>2019-11-05 05:47:38</closed>
	</bug>
	<bug>
		<id>967</id>
		<title>[dev]Zookeeper 管理 can't response right datas.</title>
		<body>We Compiled dev source code  and start service .We found that the interface  "escheduler/monitor/zookeeper/list" could not obtain zk right state ![image](https://user-images.githubusercontent.com/6259646/66449174-b1bd4800-ea86-11e9-9919-e3f48fac7846.png) but We started release 1.1.0 backend，response right  I also run  release 1.1.0 source  ![image](https://user-images.githubusercontent.com/6259646/66449253-006ae200-ea87-11e9-972f-f948314e35fc.png) but run dev echo this msg. ![image](https://user-images.githubusercontent.com/6259646/66449294-242e2800-ea87-11e9-9491-c520df07b4c3.png) --------------------------     我们通过dev 分支打包，启动服务后发现“escheduler/monitor/zookeeper/list”接口获取的数据不正确；但是我们启动 release 1.1.0 的backend 接口返回没问题。 我们本地运行release 1.1.0 分支代码也能够获取zk 状态信息；但是运行dev 分支就不行。。 **Which version of Easy Scheduler:**  -[dev] </body>
		<created>2019-10-09 03:34:51</created>
		<closed>2019-10-13 14:52:13</closed>
	</bug>
	<bug>
		<id>956</id>
		<title>[BUG] Login to different accounts in the same browser, the old account display is not changed to new account</title>
		<body>*For better global communication, please give priority to using English description, thx! * **To Reproduce** 1. Log in to the 'admin' account on the browser tab A. 2. Log in to the 'chenxingchun' account in tab B of the same browser. 3. On the tab page A switch page, check that the login account is still 'admin', it should be 'chengxingchun'  【1. 在浏览器标签页A登录admin账号     2. 在同一个浏览器的标签页B再登录chenxingchun账号     3. 进入标签页A切换页面，查看登录的账号仍为admin，应该为chengxingchun】   **Which version of Easy Scheduler:**  -[dev分支]  </body>
		<created>2019-10-08 03:36:43</created>
		<closed>2019-11-05 05:49:28</closed>
	</bug>
	<bug>
		<id>955</id>
		<title>/home/xx/escheduler/conf/env/.escheduler_env.sh: 权限不够</title>
		<body>部署了1.1.0的rel版本，执行任务时日志显示; /home/xx/escheduler/conf/env/.escheduler_env.sh: 权限不够  如何处理</body>
		<created>2019-10-03 13:39:47</created>
		<closed>2019-10-03 13:59:21</closed>
	</bug>
	<bug>
		<id>948</id>
		<title>[BUG] Alert Server startup faild</title>
		<body>/opt/escheduler/bin/escheduler-daemon.sh start alert-server  logs: ``` [INFO] 2019-09-30 16:10:46.589 org.apache.zookeeper.ZooKeeper:[100] - Client environment:java.io.tmpdir=/tmp [INFO] 2019-09-30 16:10:46.589 org.apache.zookeeper.ZooKeeper:[100] - Client environment:java.compiler=&lt;NA&gt; [INFO] 2019-09-30 16:10:46.590 org.apache.zookeeper.ZooKeeper:[100] - Client environment:os.name=Linux [INFO] 2019-09-30 16:10:46.590 org.apache.zookeeper.ZooKeeper:[100] - Client environment:os.arch=amd64 [INFO] 2019-09-30 16:10:46.590 org.apache.zookeeper.ZooKeeper:[100] - Client environment:os.version=3.19.0-59-generic [INFO] 2019-09-30 16:10:46.591 org.apache.zookeeper.ZooKeeper:[100] - Client environment:user.name=root [INFO] 2019-09-30 16:10:46.591 org.apache.zookeeper.ZooKeeper:[100] - Client environment:user.home=/root [INFO] 2019-09-30 16:10:46.591 org.apache.zookeeper.ZooKeeper:[100] - Client environment:user.dir=/opt/escheduler [INFO] 2019-09-30 16:10:46.593 org.apache.zookeeper.ZooKeeper:[438] - Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=300000 watcher=org.apache.curator.ConnectionState@571a663c [INFO] 2019-09-30 16:10:46.623 org.apache.zookeeper.ClientCnxn:[1032] - Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) [INFO] 2019-09-30 16:10:46.635 org.apache.zookeeper.ClientCnxn:[876] - Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session [INFO] 2019-09-30 16:10:46.644 org.apache.zookeeper.ClientCnxn:[1299] - Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x1078ae4e7e50009, negotiated timeout = 40000 [INFO] 2019-09-30 16:10:46.688 org.apache.curator.framework.state.ConnectionStateManager:[228] - State change: CONNECTED [INFO] 2019-09-30 16:10:46.691 cn.escheduler.common.zk.AbstractZKClient:[115] - state changed , current state : CONNECTED [INFO] 2019-09-30 16:10:47.708 springfox.documentation.spring.web.PropertySourcedRequestMappingHandlerMapping:[69] - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity&lt;springfox.documentation.spring.web.json.Json&gt; springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)] [INFO] 2019-09-30 16:10:48.138 org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor:[171] - Initializing ExecutorService 'applicationTaskExecutor' [INFO] 2019-09-30 16:10:48.635 springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper:[160] - Context refreshed [INFO] 2019-09-30 16:10:48.669 springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper:[163] - Found 1 custom documentation plugin(s) [INFO] 2019-09-30 16:10:48.770 springfox.documentation.spring.web.scanners.ApiListingReferenceScanner:[41] - Scanning for api listing references [INFO] 2019-09-30 16:10:49.363 springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator:[40] - Generating unique operation named: viewTreeUsingGET_1 [INFO] 2019-09-30 16:10:49.621 org.eclipse.jetty.server.handler.ContextHandler.application:[2345] - Initializing Spring DispatcherServlet 'dispatcherServlet' [INFO] 2019-09-30 16:10:49.622 org.springframework.web.servlet.DispatcherServlet:[524] - Initializing Servlet 'dispatcherServlet' [INFO] 2019-09-30 16:10:49.632 org.springframework.web.servlet.DispatcherServlet:[546] - Completed initialization in 10 ms [INFO] 2019-09-30 16:10:49.711 org.mortbay.log:[67] - Logging to Logger[org.mortbay.log] via org.mortbay.log.Slf4jLog [INFO] 2019-09-30 16:10:49.816 org.eclipse.jetty.server.AbstractConnector:[292] - Started ServerConnector@2c08c787{HTTP/1.1,[http/1.1]}{0.0.0.0:7789} [INFO] 2019-09-30 16:10:49.821 org.springframework.boot.web.embedded.jetty.JettyWebServer:[159] - Jetty started on port(s) 7789 (http/1.1) with context path '/' [INFO] 2019-09-30 16:10:49.825 cn.escheduler.alert.AlertServer:[59] - Started AlertServer in 8.784 seconds (JVM running for 9.342) [INFO] 2019-09-30 16:10:49.828 cn.escheduler.alert.AlertServer:[65] - Alert Server ready start! [INFO] 2019-09-30 16:10:54.834 org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener:[142] -   Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. [ERROR] 2019-09-30 16:10:54.842 org.springframework.boot.SpringApplication:[858] - Application run failed java.lang.IllegalStateException: Failed to execute CommandLineRunner at org.springframework.boot.SpringApplication.callRunner(SpringApplication.java:816) at org.springframework.boot.SpringApplication.callRunners(SpringApplication.java:797) at org.springframework.boot.SpringApplication.run(SpringApplication.java:324) at cn.escheduler.alert.AlertServer.main(AlertServer.java:81) Caused by: java.lang.NullPointerException: null at cn.escheduler.alert.AlertServer.start(AlertServer.java:72) at cn.escheduler.alert.AlertServer.run(AlertServer.java:87) at org.springframework.boot.SpringApplication.callRunner(SpringApplication.java:813) ... 3 common frames omitted [INFO] 2019-09-30 16:10:54.851 org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor:[208] - Shutting down ExecutorService 'applicationTaskExecutor' [INFO] 2019-09-30 16:10:54.868 com.alibaba.druid.pool.DruidDataSource:[1928] - {dataSource-1} closed [INFO] 2019-09-30 16:10:54.881 org.eclipse.jetty.server.AbstractConnector:[341] - Stopped ServerConnector@2c08c787{HTTP/1.1,[http/1.1]}{0.0.0.0:7789} [INFO] 2019-09-30 16:10:54.882 org.eclipse.jetty.server.session:[167] - node0 Stopped scavenging [INFO] 2019-09-30 16:10:54.884 org.eclipse.jetty.server.handler.ContextHandler.application:[2345] - Destroying Spring FrameworkServlet 'dispatcherServlet' [INFO] 2019-09-30 16:10:54.885 org.eclipse.jetty.server.handler.ContextHandler:[1045] - Stopped o.s.b.w.e.j.JettyEmbeddedWebAppContext@7b1e5e55{application,/,[file:///tmp/jetty-docbase.9040941700357288704.7789/, jar:file:/opt/escheduler/lib/swagger-bootstrap-ui-1.9.3.jar!/META-INF/resources, jar:file:/opt/escheduler/lib/springfox-swagger-ui-2.9.2.jar!/META-INF/resources],UNAVAILABLE} ```  https://github.com/apache/incubator-dolphinscheduler/blob/dev/escheduler-alert/src/main/java/cn/escheduler/alert/AlertServer.java#L72 ``` List&lt;Alert&gt; alerts = alertDao.listWaitExecutionAlert(); ``` **alertDao is null**  **Which version of Easy Scheduler:** dev branch  **Requirement or improvement code reviewed or tested?   https://github.com/apache/incubator-dolphinscheduler/pull/872/commits/eb7c1694a7088d5d3ef7de2941f8686f9a6cd03a </body>
		<created>2019-09-30 08:38:33</created>
		<closed>2019-11-16 14:25:37</closed>
	</bug>
	<bug>
		<id>937</id>
		<title>[BUG] docker build fail on centos7</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** The error message is as follows. ``` incubator-dolphinscheduler-1.1.0/sql/upgrade/1.1.0_schema/mysql/escheduler_dml.sql mv: cannot stat 'EasyScheduler-1.1.0': No such file or directory The command '/bin/sh -c cd /opt &amp;&amp;     wget https://github.com/analysys/EasyScheduler/archive/${version}.tar.gz &amp;&amp;     tar -zxvf ${version}.tar.gz &amp;&amp;     mv EasyScheduler-${version} easyscheduler_source &amp;&amp;     rm -rf ./${version}.tar.gz' returned a non-zero code: 1 ```  **To Reproduce** docker build command: docker build -t dolphinscheduler:1.1.0 --build-arg version=1.1.0 --build -arg tar_version=1.1.0 .   **Expected behavior**   **Screenshots**   **Which version of Easy Scheduler:**  -[1.1.0]  **Additional context** The changes I made in Dockerfile are as follows, ``` 68    #mv EasyScheduler-${version} easyscheduler_source &amp;&amp; \ 69    mv incubator-dolphinscheduler-${version} easyscheduler_source &amp;&amp; \ ```  **Requirement or improvement os: centos7 (vm) </body>
		<created>2019-09-30 03:12:39</created>
		<closed>2019-12-09 09:57:15</closed>
	</bug>
	<bug>
		<id>936</id>
		<title>[BUG] You can enter the wrong password infinitely when logging in. Should limit the number of times the wrong password is entered</title>
		<body>1.You can enter the wrong password infinitely when logging in,Should limit the number of times the wrong password is entered. 2.When adding a user, you can enter the weak passaword 123456, it is recommended to increase the password complexity. ![image](https://user-images.githubusercontent.com/55787491/65846221-a58f0780-e36f-11e9-893b-5af6369775ca.png) </body>
		<created>2019-09-30 02:40:08</created>
		<closed>2020-03-04 14:14:30</closed>
	</bug>
	<bug>
		<id>935</id>
		<title>[BUG] Mouse over the name, it is recommended to remove the gesture icon and underline</title>
		<body>![image](https://user-images.githubusercontent.com/55787491/65844708-d9672e80-e369-11e9-96e5-90145fb63d85.png) ![image](https://user-images.githubusercontent.com/55787491/65844729-f0a61c00-e369-11e9-84f0-903fe8cd016b.png) ![image](https://user-images.githubusercontent.com/55787491/65844751-01569200-e36a-11e9-87d3-42e75ad2c91a.png) ![image](https://user-images.githubusercontent.com/55787491/65844791-264b0500-e36a-11e9-9ec4-de0c4555dbcc.png) </body>
		<created>2019-09-30 02:09:30</created>
		<closed>2019-11-05 05:50:16</closed>
	</bug>
	<bug>
		<id>934</id>
		<title>[BUG] All crontab tasks doesnot execute after upgrading v1.1.0</title>
		<body>All crontab tasks doesnot execute after upgrading v1.1.0. Only created crontab task can be scheduled. Could you please help me quickly resolve this question?  升级v1.1.0版本后，所有的原先配置好的定时任务均不能被调度执行。只能执行新增的定时任务。</body>
		<created>2019-09-30 01:39:49</created>
		<closed>2019-12-09 10:04:23</closed>
	</bug>
	<bug>
		<id>933</id>
		<title>[BUG] English version of the home page and project home page data display is incomplete, style confusion</title>
		<body>![image](https://user-images.githubusercontent.com/55787491/65842913-53df8080-e361-11e9-96b5-475594f11bdb.png) ![image](https://user-images.githubusercontent.com/55787491/65843539-bede8680-e364-11e9-9ece-c8bb8922dd9e.png) ![image](https://user-images.githubusercontent.com/55787491/65843711-ac188180-e365-11e9-922d-f3206118233d.png) ![image](https://user-images.githubusercontent.com/55787491/65843727-c05c7e80-e365-11e9-99f1-3e45add151c0.png) ![image](https://user-images.githubusercontent.com/55787491/65843737-d66a3f00-e365-11e9-9c09-1a28af607e49.png) ![image](https://user-images.githubusercontent.com/55787491/65843743-e124d400-e365-11e9-9734-b6060f0166c8.png) ![image](https://user-images.githubusercontent.com/55787491/65843756-f00b8680-e365-11e9-9ccc-14e95480c99f.png) ![image](https://user-images.githubusercontent.com/55787491/65843784-19c4ad80-e366-11e9-817f-3778e790d18f.png) ![image](https://user-images.githubusercontent.com/55787491/65843800-2812c980-e366-11e9-90f0-1a79884878b8.png) ![image](https://user-images.githubusercontent.com/55787491/65843903-93f53200-e366-11e9-97f4-0e349c0e80b6.png) ![image](https://user-images.githubusercontent.com/55787491/65843908-9c4d6d00-e366-11e9-90c1-c0798fdb7f31.png) ![image](https://user-images.githubusercontent.com/55787491/65844359-8ccf2380-e368-11e9-8c81-5da4fc79cd34.png)  </body>
		<created>2019-09-30 01:08:26</created>
		<closed>2019-12-09 10:05:45</closed>
	</bug>
	<bug>
		<id>927</id>
		<title>[BUG] Timing setting selects item 4, but item 2 is selected </title>
		<body> ![image](https://user-images.githubusercontent.com/55787491/65830691-53ed6b00-e2e4-11e9-9da6-eb4baeaff5ec.png)    </body>
		<created>2019-09-29 10:10:00</created>
		<closed>2019-11-05 05:50:41</closed>
	</bug>
	<bug>
		<id>926</id>
		<title>[BUG] The number of processes to be executed for statistical management and the number of commands that failed to execute are incorrect.</title>
		<body>![image](https://user-images.githubusercontent.com/55787491/65830243-3fa76f00-e2e0-11e9-8014-d161a0c71a94.png) </body>
		<created>2019-09-29 09:43:13</created>
		<closed>2019-11-05 05:51:26</closed>
	</bug>
	<bug>
		<id>915</id>
		<title>[BUG] When the worker starts, it does not need to load and run the deleted task instance</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** Currently, when the Worker restarts, the deleted task instance is loaded and run. This is unreasonable. When failover occurs, it is better to judge whether the current task is deleted first, and then judge whether the corresponding task instance needs to be run.  **To Reproduce** Steps to reproduce the behavior, for example: 1.  Run a large number of task instances. 2.  Delete related tasks. 3. Check whether the worker restores the current task instance and runs  **Expected behavior** A large number of deleted task instances continue to run.  </body>
		<created>2019-09-27 11:50:44</created>
		<closed>2019-12-09 10:09:02</closed>
	</bug>
	<bug>
		<id>912</id>
		<title>[BUG] WORKER 在一次任务失败暂停后，无法再次 在该节点worker 上提交以前成功的任务(需要再次重新启动worker-server)</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** worker 在一次任务失败后无法再次执行任务，显示失败  **To Reproduce**  我在一个节点运行一个任务停止后，该节点无法运行以前成功运行的任务 显示为失败，日志中返回状态code 为 [log.txt](https://github.com/apache/incubator-dolphinscheduler/files/3662002/log.txt) 1 ，但是我手动执行日志中的脚本 没问题。目前还发现在新增worker 后 会导致某些正在运行worker 无法运行任务。 **Expected behavior**   **Screenshots**    **Which version of Easy Scheduler:**  -[1.1.0]   </body>
		<created>2019-09-27 09:27:31</created>
		<closed>2019-12-09 10:11:30</closed>
	</bug>
	<bug>
		<id>910</id>
		<title>[BUG] Flow chart issues</title>
		<body>     ![image](https://user-images.githubusercontent.com/39816903/65749273-64f97900-e138-11e9-948b-1881d24ad2f7.png)     ![image](https://user-images.githubusercontent.com/39816903/65749286-67f46980-e138-11e9-9cc3-9eb284b23ab8.png)  疑问:  如上图, 第一个为创建任务的流程图, 第二个为执行任务的 DAG 图.  task02,和 task03 在图二中, 是不是应该汇聚到 taks04 节点上 ????   ------------------------------------------------  As shown above, the first is the flow chart for creating tasks, and the second is the DAG diagram for executing tasks.    Should task02 and task03 converge on the taks04 node in Figure 2???             </body>
		<created>2019-09-27 07:08:39</created>
		<closed>2019-09-29 01:08:04</closed>
	</bug>
	<bug>
		<id>909</id>
		<title>[BUG] The postgresql data source of the SQL task, if it is connected to the public schema, does not need to write the database.</title>
		<body>The postgresql data source of the SQL task, if it is connected to the public schema, does not need to write the database. The front end needs to remove the validation of the database. The backend needs to be jdbc:postgresql://192.168.xx.xx:5432/ when jdbc is connected. The final backslash is required.   SQL任务的postgresql数据源，如果是连接public schema，是不需要写数据库的 前端需要去掉数据库的验证，后端需要在jdbc连接的时候jdbc:postgresql://192.168.xx.xx:5432/，需要有最后的反斜杠</body>
		<created>2019-09-27 06:19:49</created>
		<closed>2019-12-09 10:12:02</closed>
	</bug>
	<bug>
		<id>902</id>
		<title>[BUG] The node settings for the workflow definition are changed after modifying the node settings in the workflow instance</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **To Reproduce** 1. Enter the workflow definition and view the test_python_import node settings for test_001, as shown below: ![image](https://user-images.githubusercontent.com/55787491/65678401-c6144480-e085-11e9-804a-7cca8c225977.png)  2. Enter the workflow instance and modify the test_python_import node setting of test_001-0-1569489937960, as shown in Figure 2 below: ![image](https://user-images.githubusercontent.com/55787491/65678468-ed6b1180-e085-11e9-81de-5aa5d03ec6af.png) ![image](https://user-images.githubusercontent.com/55787491/65679676-21473680-e088-11e9-815f-03341208cb23.png)   3. Save the DAG diagram of test_001-0-1569489937960 ![image](https://user-images.githubusercontent.com/55787491/65678587-286d4500-e086-11e9-8e17-1141adcd4a86.png)  4. Enter the workflow definition, view the test_python_import node settings of test_001, as shown below, the node settings of test_python_import of test_001 are also modified. ![image](https://user-images.githubusercontent.com/55787491/65678687-581c4d00-e086-11e9-973b-d2e2c31a9d96.png)  **Expected behavior** After modifying the node settings for an instance in a workflow instance, it should not affect the node settings for the workflow definition.  **Which version of Easy Scheduler** -[dev分支]</body>
		<created>2019-09-26 09:59:42</created>
		<closed>2019-09-26 10:42:30</closed>
	</bug>
	<bug>
		<id>901</id>
		<title>[BUG] SQL task SQL type from query mode to non-query mode</title>
		<body>Switch from query mode to non-query mode 由查询模式切换到非查询模式 ![1](https://user-images.githubusercontent.com/23756105/65674295-e7bdfd80-e07e-11e9-9bc4-f7d7f6b42606.png)  After the operation is completed, the subject, the recipient and the CC are actually echoed. 运行完毕之后，主题，收件人和抄送人竟然回显了 ![2](https://user-images.githubusercontent.com/23756105/65674325-f4425600-e07e-11e9-9b4a-d4ebac6ac7aa.png) </body>
		<created>2019-09-26 09:02:19</created>
		<closed>2019-12-09 10:12:19</closed>
	</bug>
	<bug>
		<id>896</id>
		<title>[BUG] Can successfully import an existing workflow</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** Successfully import an existing workflow, importing an existing workflow should not succeed  **To Reproduce** 1. Enter the workflow definition page of project management, import an existing workflow, and import it successfully, as shown below: ![image](https://user-images.githubusercontent.com/55787491/65656129-4f5d5400-e051-11e9-8cbf-2e772c7d4c88.png)    **Expected behavior** Cannot import an existing workflow   **Which version of Easy Scheduler:**  -[dev分支]  </body>
		<created>2019-09-26 03:40:38</created>
		<closed>2019-11-05 05:51:45</closed>
	</bug>
	<bug>
		<id>888</id>
		<title>[BUG] The imported workflow timer is online and ineffective （导入工作流定时器状态为上线，不起效果）</title>
		<body>The imported workflow timer is online and ineffective  （导入工作流定时器状态为上线，不起效果）</body>
		<created>2019-09-25 12:37:57</created>
		<closed>2019-09-26 05:43:36</closed>
	</bug>
	<bug>
		<id>885</id>
		<title>[BUG] ProcessDao.taskZkInfo comment error</title>
		<body>in ProcessDao class , then function taskZkInfo  comment error   ${taskId}  should be   ${taskInstanceId} ? </body>
		<created>2019-09-25 10:17:39</created>
		<closed>2019-09-25 10:47:32</closed>
	</bug>
	<bug>
		<id>884</id>
		<title>[BUG] The number of processes defined under the single project home page counts the number of processes for all projects</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** The number of processes defined under the single project home page counts the number of processes for all projects   **To Reproduce** 1. View the number of process definitions for project management. As shown in the following figure, the number of process definitions for all projects is 6, and the number of test007 is 3. ![image](https://user-images.githubusercontent.com/55787491/65589820-48d0cd00-dfbc-11e9-8594-c868b4d141cc.png) 2. Click test007, enter the project home page of test007, view the process definition statistics, as shown below: ![image](https://user-images.githubusercontent.com/55787491/65589980-91888600-dfbc-11e9-934d-7368d36263cc.png)  **Expected behavior** For the project home page of a single project, the number of process definition statistics should be defined for the process of the project, and the number of processes for all projects should not be counted.  **Which version of Easy Scheduler:**  -[dev分支]</body>
		<created>2019-09-25 09:56:57</created>
		<closed>2019-09-26 08:40:12</closed>
	</bug>
	<bug>
		<id>883</id>
		<title>[IMPROVE]  Tenant selection experience</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** Tenants with the same name are not easy to distinguish when choosing  **To Reproduce** Steps to reproduce the behavior, for example: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error  **Expected behavior** A clear and concise description of what you expected to happen.  **Screenshots** If applicable, add screenshots to help explain your problem. ![image](https://user-images.githubusercontent.com/16920347/65589856-5a19d980-dfbc-11e9-8a7d-d89d6a626b69.png)   **Which version of Easy Scheduler:**  -[1.1.0-preview]  **Additional context** Add any other context about the problem here.  **Requirement or improvement - Please describe about your requirements or improvement suggestions. </body>
		<created>2019-09-25 09:47:12</created>
		<closed>2019-09-25 09:49:15</closed>
	</bug>
	<bug>
		<id>882</id>
		<title>[BUG] The tenant problems</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** The shell script executes with the tenant code, causing the task to fail  **To Reproduce** Steps to reproduce the behavior, for example: 1. Define a workflow in which the shell task performs datax data synchronization 2. Look at the instance log and find failure error messages，"python: can't open file '/data/datax/bin/datax.py': [Errno 13] Permission denied" 3. The analysis found that tenants created on the operating system use the tenant code, not the tenant name 4. Analysis of the source code reveals that the system users are indeed created using the tenant code, and the commands executed using the tenant code，It's not unreasonable.   private void buildProcess(String commandFile) throws IOException {         //init process builder         ProcessBuilder processBuilder = new ProcessBuilder();         // setting up a working directory         processBuilder.directory(new File(taskDir));         // merge error information to standard output stream         processBuilder.redirectErrorStream(true);         // setting up user to run commands         processBuilder.command("sudo", "-u", tenantCode, commandType(), commandFile);          process = processBuilder.start();          // print command         printCommand(processBuilder);     }  **Expected behavior** A clear and concise description of what you expected to happen.  **Screenshots** If applicable, add screenshots to help explain your problem.   **Which version of Easy Scheduler:**  -[1.0.5]  **Additional context** Add any other context about the problem here.  **Requirement or improvement - Please describe about your requirements or improvement suggestions. </body>
		<created>2019-09-25 09:20:24</created>
		<closed>2019-09-25 09:36:36</closed>
	</bug>
	<bug>
		<id>877</id>
		<title>[BUG] zh_CN.js Content repetition</title>
		<body>path escheduler-ui/src/js/module/i18n/locale/zh_CN.js   ![image](https://user-images.githubusercontent.com/19225068/65576158-faafcf80-dfa3-11e9-9ba8-e947be645d6c.png) </body>
		<created>2019-09-25 06:52:10</created>
		<closed>2019-09-25 13:24:26</closed>
	</bug>
	<bug>
		<id>865</id>
		<title>[BUG] flink stream job  yarn status is Wrong</title>
		<body>when i submit a flink-stream job , then kill zhe yarn job  the job  yarn status is killed  ,but scheduler is success    ![image](https://user-images.githubusercontent.com/19225068/65415846-28bcd480-de29-11e9-9215-e0e1e4d04cdd.png)   ![image](https://user-images.githubusercontent.com/19225068/65415775-fc08bd00-de28-11e9-8f71-882752b96d2d.png) ![image](https://user-images.githubusercontent.com/19225068/65415819-180c5e80-de29-11e9-854e-079f535ad27a.png)</body>
		<created>2019-09-23 09:32:30</created>
		<closed>2019-09-23 10:12:23</closed>
	</bug>
	<bug>
		<id>860</id>
		<title>[BUG] jar包冲突Correct the classpath of your application so that it contains a single, compatible version of javax.servlet.ServletContext</title>
		<body>![image](https://user-images.githubusercontent.com/19225068/65402961-69eebd80-de04-11e9-97a9-51b9f9ec844b.png)    解决： pom排除依赖或者移除lib目录下的 lib/servlet-api-2.5-6.1.14.jar</body>
		<created>2019-09-23 05:18:14</created>
		<closed>2019-09-25 07:22:13</closed>
	</bug>
	<bug>
		<id>857</id>
		<title>[BUG] Cross-project dependency delete bug(跨项目流依赖删除有异常)</title>
		<body>Cross-project dependency delete bug (跨项目流依赖删除有异常)</body>
		<created>2019-09-23 01:46:35</created>
		<closed>2019-09-24 11:02:41</closed>
	</bug>
	<bug>
		<id>847</id>
		<title>[BUG] fastjson版本过低，存在安全漏洞</title>
		<body>ds目前使用较低版本fastjson 1.2.29。fastjson历史上多次暴露了安全问题，存在远程代码执行漏洞，建议替换为gson或者升级到最新版本。</body>
		<created>2019-09-21 09:58:25</created>
		<closed>2019-09-23 02:40:44</closed>
	</bug>
	<bug>
		<id>832</id>
		<title>[BUG] 开发模式下shell任务bug: sudo: sh: command not found</title>
		<body>**描述错误** Mac本地IDEA开发模式，执行shell任务第一个节点时，总是会报错：[INFO] server.worker.log.TaskLogger:[163] - [taskAppId=TASK_4_47_93]  -&gt; sudo: sh: command not found 但是相同的代码，打包启动后，同一个shell任务，执行一切正常。。。  **哪个版本的容易调度程序:** ——(1.1.0-preview)  * *我的解决方法*** 修改代码: ShellCommandExecutor.java //      public static final String SH = "sh";         public static final String SH = "/bin/sh";</body>
		<created>2019-09-19 13:00:07</created>
		<closed>2019-09-19 13:00:14</closed>
	</bug>
	<bug>
		<id>827</id>
		<title>[question] ./script/create_escheduler.sh: line 21: /bin/java: No such file or directory</title>
		<body>./script/create_escheduler.sh: line 21: /bin/java: No such file or directory  是需要配置环境变量  配置 classpath吗</body>
		<created>2019-09-19 06:57:42</created>
		<closed>2019-09-19 11:42:33</closed>
	</bug>
	<bug>
		<id>822</id>
		<title>[BUG]   Database initialization error</title>
		<body>  run  CreateDolphinScheduler error    Reason:  /sql/create/release-1.0.0_schema/mysql/dolphinscheduler_ddl.sql  miss  table `t_escheduler_version`   ![image](https://user-images.githubusercontent.com/39816903/65212670-b28d3a80-dad5-11e9-8135-baa19cfc8c53.png)          </body>
		<created>2019-09-19 04:05:29</created>
		<closed>2019-09-20 00:14:13</closed>
	</bug>
	<bug>
		<id>820</id>
		<title>[BUG] ./escheduler-server/src/main/resources/application_worker.properties  bug</title>
		<body>**Describe the bug**    the content of application_worker.properties  is " logging.config=classpath:master_logback.xml"    the right content should  "logging.config=classpath:worker_logback.xml" </body>
		<created>2019-09-19 01:19:57</created>
		<closed>2019-09-26 10:35:48</closed>
	</bug>
	<bug>
		<id>807</id>
		<title>[BUG] dev 1.1.0 数据库脚本不同步.</title>
		<body>  执行初始化脚本:  sh ./script/create_escheduler.sh  报错:   t_escheduler_version 表找不到.  手动创建一个t_escheduler_version表之后,  里面版本设置为 1.1.0   创建用户界面报错:   ![image](https://user-images.githubusercontent.com/39816903/65123140-363b1e80-da25-11e9-886e-96c3cb97d4d4.png)   添加任务时报错   ![image](https://user-images.githubusercontent.com/39816903/65123159-405d1d00-da25-11e9-9f47-7dd4bd98e8dd.png)       需要一份完整可用的数据库初始化脚本.         </body>
		<created>2019-09-18 07:02:25</created>
		<closed>2019-09-20 00:14:50</closed>
	</bug>
	<bug>
		<id>792</id>
		<title>无法保存 工作流定义</title>
		<body>![图片](https://user-images.githubusercontent.com/26478730/64919997-cdfdfa00-d7e4-11e9-919c-e3e022151398.png)  无法 添加 DAG图</body>
		<created>2019-09-15 10:17:27</created>
		<closed>2019-09-16 01:45:21</closed>
	</bug>
	<bug>
		<id>791</id>
		<title>EasyScheduler 后端部署完成后,缺失API-server和Master-Server服务</title>
		<body>问题: 没有 MasterServer  服务 和 ApiApplicationServer 服务; Mvn手动部署  [root@Master logs]# jps |grep Server 15988 AlertServer 15897 WorkerServer 15935 LoggerServer   *************** API-Server 失败日志 *************************  [INFO] 2019-09-15 14:01:30.807 cn.escheduler.api.ApiApplicationServer:[50] - Starting ApiApplicationServer on Master.Hadoop with PID 14321 (/opt/escheduler/lib/eschedu ler-api-1.1.0-SNAPSHOT.jar started by root in /opt/escheduler) [INFO] 2019-09-15 14:01:30.814 cn.escheduler.api.ApiApplicationServer:[675] - No active profile set, falling back to default profiles: default [INFO] 2019-09-15 14:01:36.369 org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[330] - Bean 'org.springframework.transac tion.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringC GLIB$$dd4d17c9] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) [INFO] 2019-09-15 14:01:36.964 org.eclipse.jetty.util.log:[193] - Logging initialized @9077ms to org.eclipse.jetty.util.log.Slf4jLog [INFO] 2019-09-15 14:01:37.105 org.springframework.boot.web.embedded.jetty.JettyServletWebServerFactory:[143] - Server initialized with port: 12345 [INFO] 2019-09-15 14:01:37.108 org.eclipse.jetty.server.Server:[370] - jetty-9.4.14.v20181114; built: 2018-11-14T21:20:31.478Z; git: c4550056e785fb5665914545889f21dc13 6ad9e6; jvm 1.8.0_121-b13 [WARN] 2019-09-15 14:01:37.155 org.eclipse.jetty.webapp.WebAppContext:[554] - Failed startup of context o.s.b.w.e.j.JettyEmbeddedWebAppContext@6963b88c{application,/es cheduler,[file:///tmp/jetty-docbase.2126115480907704550.12345/, jar:file:/opt/escheduler/lib/springfox-swagger-ui-2.9.2.jar!/META-INF/resources, jar:file:/opt/eschedul er/lib/swagger-bootstrap-ui-1.9.3.jar!/META-INF/resources],UNAVAILABLE} java.lang.BootstrapMethodError: java.lang.NoSuchMethodError: javax.servlet.ServletContext.setInitParameter(Ljava/lang/String;Ljava/lang/String;)Z         at org.springframework.boot.web.servlet.server.AbstractServletWebServerFactory.lambda$mergeInitializers$0(AbstractServletWebServerFactory.java:253)         at org.springframework.boot.web.embedded.jetty.ServletContextInitializerConfiguration.callInitializers(ServletContextInitializerConfiguration.java:66)         at org.springframework.boot.web.embedded.jetty.ServletContextInitializerConfiguration.configure(ServletContextInitializerConfiguration.java:55)         at org.eclipse.jetty.webapp.WebAppContext.configure(WebAppContext.java:517)         at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1454)         at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:852)         at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:278)         at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)         at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)         at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)         at org.eclipse.jetty.server.Server.start(Server.java:415)         at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:108)         at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)         at org.eclipse.jetty.server.Server.doStart(Server.java:382)         at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)         at org.springframework.boot.web.embedded.jetty.JettyWebServer.initialize(JettyWebServer.java:108)         at org.springframework.boot.web.embedded.jetty.JettyWebServer.&lt;init&gt;(JettyWebServer.java:86)         at org.springframework.boot.web.embedded.jetty.JettyServletWebServerFactory.getJettyWebServer(JettyServletWebServerFactory.java:410)         at org.springframework.boot.web.embedded.jetty.JettyServletWebServerFactory.getWebServer(JettyServletWebServerFactory.java:153)         at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.createWebServer(ServletWebServerApplicationContext.java:181)         at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:154)         at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:543)         at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142)         at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775)         at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397)         at org.springframework.boot.SpringApplication.run(SpringApplication.java:316)         at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260)         at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248)         at cn.escheduler.api.ApiApplicationServer.main(ApiApplicationServer.java:33) Caused by: java.lang.NoSuchMethodError: javax.servlet.ServletContext.setInitParameter(Ljava/lang/String;Ljava/lang/String;)Z         at java.lang.invoke.MethodHandleNatives.resolve(Native Method)         at java.lang.invoke.MemberName$Factory.resolve(MemberName.java:975)         at java.lang.invoke.MemberName$Factory.resolveOrFail(MemberName.java:1000)         at java.lang.invoke.MethodHandles$Lookup.resolveOrFail(MethodHandles.java:1394)         at java.lang.invoke.MethodHandles$Lookup.linkMethodHandleConstant(MethodHandles.java:1750)         at java.lang.invoke.MethodHandleNatives.linkMethodHandleConstant(MethodHandleNatives.java:477)         ... 29 common frames omitted                   ********************************* master-server ,没有log文件,.out信息:******************************         more escheduler-master-server-Master.Hadoop.out 14:08:31.792 [main] DEBUG org.apache.commons.configuration.PropertiesConfiguration - FileName set to master.properties 14:08:31.796 [main] DEBUG org.apache.commons.configuration.ConfigurationUtils - ConfigurationUtils.locate(): base is null, name is master.properties 14:08:31.796 [main] DEBUG org.apache.commons.configuration.DefaultFileSystem - Could not locate file master.properties at null: no protocol: master.properties 14:08:31.799 [main] DEBUG org.apache.commons.configuration.ConfigurationUtils - Loading configuration from the context classpath (master.properties) 14:08:31.799 [main] DEBUG org.apache.commons.configuration.PropertiesConfiguration - Base path set to file:///opt/escheduler/conf/master.properties  </body>
		<created>2019-09-15 06:34:54</created>
		<closed>2019-09-15 07:33:17</closed>
	</bug>
	<bug>
		<id>788</id>
		<title>[BUG] many System.exit(1) in code, use exception instead or any other friendly actions? </title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** A clear and concise description of what the bug is.  **To Reproduce**   many System.exit(1) in code, use exception instead or other any other friendly actions?  **Expected behavior**  **Screenshots** ![image](https://user-images.githubusercontent.com/26567069/64750760-8cebb880-d54c-11e9-9e7e-6fdbb7b6c2d1.png) **Which version of Easy Scheduler:**  -[1.0.4]  **Additional context**  **Requirement or improvement many System.exit(1) in code, use **exception** instead or any other friendly actions to proceed?   项目代码中，多处使用System.exit(1），能不能用异常替代或者其他更好的处理方式， 进程默默的退出了，日志中发现不了异常日志，可用性不友好。</body>
		<created>2019-09-12 03:07:18</created>
		<closed>2019-12-09 10:13:03</closed>
	</bug>
	<bug>
		<id>783</id>
		<title>[BUG] bug title test</title>
		<body>just test bug title!</body>
		<created>2019-09-10 06:53:09</created>
		<closed>2019-09-10 06:53:20</closed>
	</bug>
	<bug>
		<id>771</id>
		<title>[BUG] The edit timer did not assign the original data</title>
		<body>The edit timer did not assign the original data （编辑定时器没有把原数据赋值）</body>
		<created>2019-09-06 03:47:17</created>
		<closed>2019-09-26 10:36:42</closed>
	</bug>
	<bug>
		<id>754</id>
		<title>[BUG] The process instance is deleted, the task corresponding to the zk queue still exists, and the task is squeezed.</title>
		<body>  &lt;img width="941" alt="微信图片_20190902162004" src="https://user-images.githubusercontent.com/23756105/64100140-90897d80-cd9d-11e9-9843-1c4f7531cca3.png"&gt; </body>
		<created>2019-09-02 08:20:33</created>
		<closed>2019-09-24 11:11:09</closed>
	</bug>
	<bug>
		<id>742</id>
		<title>[BUG]开启kerberos认证之后，隔一天之后tgt失效</title>
		<body>在开启了kerberos之后，上传文件到hdfs正常。  但是过了一天之后，tgt失效了，再次上传文件，后端api-server的日志中报kerberos认证失败。无效的tgt。   </body>
		<created>2019-08-27 08:16:34</created>
		<closed>2019-09-02 06:58:01</closed>
	</bug>
	<bug>
		<id>738</id>
		<title>[BUG] sql节点中正则表达式中的问号影响变量替换，导致查询出错</title>
		<body>版本：1.1.0 在sql节点中正则表达式有问号，有两个局部变量，在执行时出错 ![image](https://user-images.githubusercontent.com/30412237/63745340-8dd9e480-c8d4-11e9-97a1-07f9920c248a.png) 错误日志如下： [ERROR] 2019-08-27 14:05:02.225 cn.escheduler.server.worker.log.TaskLogger:[313] - [taskAppId=TASK_93_13101_29425] Index: 3, Size: 3 java.lang.IndexOutOfBoundsException: Index: 3, Size: 3 at java.util.ArrayList.rangeCheck(ArrayList.java:653) at java.util.ArrayList.get(ArrayList.java:429) at cn.escheduler.common.task.sql.LoggableStatement.getQueryString(LoggableStatement.java:89) at cn.escheduler.server.worker.task.sql.SqlTask.prepareStatementAndBind(SqlTask.java:344) at cn.escheduler.server.worker.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:278) at cn.escheduler.server.worker.task.sql.SqlTask.handle(SqlTask.java:160) at cn.escheduler.server.worker.runner.TaskScheduleThread.call(TaskScheduleThread.java:212) at cn.escheduler.server.worker.runner.TaskScheduleThread.call(TaskScheduleThread.java:62) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) [ERROR] 2019-08-27 14:05:02.225 cn.escheduler.server.worker.runner.TaskScheduleThread:[249] - task escheduler failure : Index: 3, Size: 3 java.lang.RuntimeException: Index: 3, Size: 3 at cn.escheduler.server.worker.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:327) at cn.escheduler.server.worker.task.sql.SqlTask.handle(SqlTask.java:160) at cn.escheduler.server.worker.runner.TaskScheduleThread.call(TaskScheduleThread.java:212) at cn.escheduler.server.worker.runner.TaskScheduleThread.call(TaskScheduleThread.java:62) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) [ERROR] 2019-08-27 14:05:02.225 cn.escheduler.server.worker.runner.TaskScheduleThread:[251] - task process exception, process id : 13101 , task : push_status java.lang.RuntimeException: Index: 3, Size: 3 at cn.escheduler.server.worker.task.sql.SqlTask.executeFuncAndSql(SqlTask.java:327) at cn.escheduler.server.worker.task.sql.SqlTask.handle(SqlTask.java:160) at cn.escheduler.server.worker.runner.TaskScheduleThread.call(TaskScheduleThread.java:212) at cn.escheduler.server.worker.runner.TaskScheduleThread.call(TaskScheduleThread.java:62) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) </body>
		<created>2019-08-27 06:13:16</created>
		<closed>2019-09-26 10:09:04</closed>
	</bug>
	<bug>
		<id>735</id>
		<title>[BUG]Errors in submitting requests through API to perform a task under a workflow( 通过API提交请求执行某个工作流下的某个任务出错)</title>
		<body>版本：dev-1.1.0 工作流如下图： ![image](https://user-images.githubusercontent.com/30412237/63663642-cd7dcf00-c7f5-11e9-80ee-9157893ebbd2.png)  通过postman提交的请求结果如下图： ![image](https://user-images.githubusercontent.com/30412237/63663676-f1411500-c7f5-11e9-9e02-cea033de6e59.png) 上面请求结果显示“success”，我进到escheduler界面看的时候，工作流实例里确实有刚才请求运行的工作流，但是失败了，如下图： ![image](https://user-images.githubusercontent.com/30412237/63663716-159cf180-c7f6-11e9-8cb1-c0bc96183c81.png) 然后进到任务实例里发现没有我要运行的任务实例 ![image](https://user-images.githubusercontent.com/30412237/63663738-29e0ee80-c7f6-11e9-8daf-6bb62d612422.png) 又查看了一下master日志发现如下错误： ![image](https://user-images.githubusercontent.com/30412237/63663752-3ebd8200-c7f6-11e9-9aa6-0365ea122c03.png) 对照源码也看了，还没找到哪块造成的原因，还请大佬帮忙看看哈</body>
		<created>2019-08-26 03:41:12</created>
		<closed>2019-09-02 08:03:21</closed>
	</bug>
	<bug>
		<id>734</id>
		<title>[BUG] ExecutorController.java 92行logger.info日志输出缺少参数</title>
		<body>版本dev-1.1.0 ExecutorController.java类中，startProcessInstance这个方法里的logger.info输出，里面有15个参数位置，但实际传的时候只传了14个，有个startNodeList值缺失，导致日志输出时参数位置错乱。 `logger.info("login user {}, start process instance, project name: {}, process definition id: {}, schedule time: {}, "                             + "failure policy: {}, node name: {}, node dep: {}, notify type: {}, "                             + "notify group id: {},receivers:{},receiversCc:{}, run mode: {},process instance priority:{}, workerGroupId: {}, timeout: {}",                     loginUser.getUserName(), projectName, processDefinitionId, scheduleTime, failureStrategy,                     taskDependType, warningType, warningGroupId,receivers,receiversCc,runMode,processInstancePriority,                     workerGroupId, timeout);` </body>
		<created>2019-08-25 08:00:13</created>
		<closed>2019-09-01 10:49:34</closed>
	</bug>
	<bug>
		<id>731</id>
		<title>[BUG] API Document error(swagger html)[swagger文档错误]</title>
		<body>An error was found. Interface path:/escheduler/projects/{projectName}/process/batch-delete Problem Description: there is no  swagger annotation at the corresponding code  --- 发现了1个错误 接口路径:/escheduler/projects/{projectName}/process/batch-delete 问题描述：我查看了对应代码并没有swagger 注解</body>
		<created>2019-08-23 03:18:46</created>
		<closed>2019-09-26 08:00:46</closed>
	</bug>
	<bug>
		<id>730</id>
		<title>Concurrent task log bug</title>
		<body>Describe the bug： When the concurrent task runs, the log interleaving error occurs and the log is written.  Case： ![image](https://user-images.githubusercontent.com/24928399/63561368-4bd73880-c58c-11e9-81ec-b83bba13a60b.png) ![image](https://user-images.githubusercontent.com/24928399/63561413-69a49d80-c58c-11e9-8d10-23797953e070.png) ![image](https://user-images.githubusercontent.com/24928399/63561420-6f01e800-c58c-11e9-8f13-da82a1638c16.png)  Which version of Easy Scheduler: -[1.1.0]  </body>
		<created>2019-08-23 01:59:08</created>
		<closed>2019-09-26 10:01:17</closed>
	</bug>
	<bug>
		<id>728</id>
		<title>mail issue</title>
		<body>There are three questions： 1. The parameter mail.smtp.ssl.trust is not supported 2. The mailSender in PasswordAuthentication() and setFrom() may not be the same in actual use, and it's best to set it up separately 3. Cannot have "-" in email account name</body>
		<created>2019-08-22 08:06:09</created>
		<closed>2019-09-18 09:00:11</closed>
	</bug>
	<bug>
		<id>723</id>
		<title>[BUG] 任务实际日志路径和任务实例的日志路径不相同，导致无法查看日志</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** the task instance log is System.getProperty("user.dir") + "/logs/" *  but I can change the path with the log xml   **To Reproduce** Steps to reproduce the behavior, for example: 1. I config the log Path to other dir for worker_log.xml 2. run the task ,then get the rollView log 3. the log path of task instance in database is still the user work dir + "/logs" 4. the path not exist  **Expected behavior** the task instance log path should be same with the log xml properties  **Screenshots** If applicable, add screenshots to help explain your problem.   **Which version of Easy Scheduler:**  -[1.1.0]  **Additional context** Add any other context about the problem here.  **Requirement or improvement  </body>
		<created>2019-08-22 01:47:11</created>
		<closed>2019-09-26 10:01:46</closed>
	</bug>
	<bug>
		<id>719</id>
		<title>[BUG] the first task checkWorkerGroup error then others task cant execute in task queen</title>
		<body>[BUG] the first task checkWorkerGroup error then others task cant execute in task queen,and then cycle execute first task then and then</body>
		<created>2019-08-21 08:53:10</created>
		<closed>2019-09-26 08:10:30</closed>
	</bug>
	<bug>
		<id>717</id>
		<title>[BUG]DEPENDENT task problem(DEPENDENT任务依赖问题)</title>
		<body>Under a workflow, I configured the DEPENDENT task to rely on other workflow tasks under the same project, setting the number of failed retries, but it did not take effect. Phenomenon: Once the upstream workflow is not completed, the test is completed once, and the failed task ends. Expectations: The number of failed retries function works  --- 一个工作流下我配置了DEPENDENT组件，用来依赖同一个项目下其他工作流的任务，设置了失败重试次数，但是并没有生效 现象： 一旦上游工作流未完成，检测一次，失败了任务就结束了 期望：失败重试次数功能起作用   **Which version of Easy Scheduler:**  1.1.0 </body>
		<created>2019-08-21 06:03:38</created>
		<closed>2019-12-04 03:44:54</closed>
	</bug>
	<bug>
		<id>716</id>
		<title>Zookeeper Connection Number Not Released(Zookeeper 连接数未释放)</title>
		<body>I found a problem. When I clicked on `Master` or `Worker` on the left side of `Monitoring Center` , and then clicked on `Zookeeper` to see `Connection Number` , I found that the number of `Master` or `Worker` would increase by one for every click and then look at `Zookeeper` , because `Zookeepr` has default `Connection Number` When the number of connections exceeds `Zookeeper` , the `Master` and `Worker` service values cannot be registered properly to `Zookeeper` , which results in the operation being unable to execute normally.  **Current version in use:**  `1.1.0-release`  **Expected results:**  Hope to fix this problem, and then click on `Master'or `Worker` , the `Zookeeper` `connection number` will not increase, and the service can be registered normally.  ---  我发现一个问题, 当我在 `监控中心` 点击一次左侧的 `Master` 或 `Worker` 然后再点击 `Zookeeper` 查看 `连接数` 的时候, 发现每点击一次 `Master` 或 `Worker` 然后查看 `Zookeeper` 的 `连接数` 都会增加一, 由于 `Zookeeper` 是有默认的 `连接数` 的, 当超过 `Zookeeper` 的 `连接数` 的时候, `Master` 和 `Worker` 服务值无法正常注册到 `Zookeeper` 然后导致作业无法正常执行.  **当前使用版本:**  `1.1.0-release`  **期望结果:**  希望能修复这个问题，然后再点击 `Master` 或 `Worker` 的时候 `Zookeeper` 的 `连接数` 不会递增, 服务能够正常注册 </body>
		<created>2019-08-20 06:35:26</created>
		<closed>2019-09-02 06:57:37</closed>
	</bug>
	<bug>
		<id>700</id>
		<title>[BUG] TaskQueueZkImpl.poll() throw NullPointerException</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** TaskQueueZkImpl.poll() task queue poll error, task detail :2_1_2_1_-1 , please check! add task to tasks queue exception java.lang.NullPointerException: null.  **To Reproduce** Steps to reproduce the behavior, for example: 1. 部署易调度1.0.5版本 2. 创建任务 3. 查看worker日志 4. TaskQueueZkImpl的poll方法报空指针异常  **Expected behavior** A clear and concise description of what you expected to happen.  **Screenshots**  - 日志  ![image](https://user-images.githubusercontent.com/30776503/62940554-6da32380-be06-11e9-9345-89ae414c879d.png)  - 代码  ![image](https://user-images.githubusercontent.com/30776503/62940608-87446b00-be06-11e9-8891-11311cf7e9e4.png)   **Which version of Easy Scheduler:**  -[1.0.5]  **Additional context** Add any other context about the problem here.  **Requirement or improvement - Please describe about your requirements or improvement suggestions. </body>
		<created>2019-08-13 12:12:19</created>
		<closed>2019-08-15 03:06:19</closed>
	</bug>
	<bug>
		<id>688</id>
		<title>[BUG] a user generated multiple ip session, the query error</title>
		<body>SessionMapper :    /**      * query by user id and ip      * @param userId      * @return      */     @Results(value = {             @Result(property = "id", column = "id", id = true, javaType = String.class, jdbcType = JdbcType.VARCHAR),             @Result(property = "userId", column = "user_id", javaType = int.class, jdbcType = JdbcType.INTEGER),             @Result(property = "ip", column = "ip", javaType = String.class, jdbcType = JdbcType.VARCHAR),             @Result(property = "lastLoginTime", column = "last_login_time", javaType = Timestamp.class, jdbcType = JdbcType.DATE)     })     @SelectProvider(type = SessionMapperProvider.class, method = "queryByUserId")     Session queryByUserId(@Param("userId") int userId);   Update:  /**      * query by user id and ip      * @param userId      * @return      */     @Results(value = {             @Result(property = "id", column = "id", id = true, javaType = String.class, jdbcType = JdbcType.VARCHAR),             @Result(property = "userId", column = "user_id", javaType = int.class, jdbcType = JdbcType.INTEGER),             @Result(property = "ip", column = "ip", javaType = String.class, jdbcType = JdbcType.VARCHAR),             @Result(property = "lastLoginTime", column = "last_login_time", javaType = Timestamp.class, jdbcType = JdbcType.DATE)     })     @SelectProvider(type = SessionMapperProvider.class, method = "queryByUserId")     List&lt;Session&gt; queryByUserId(@Param("userId") int userId); </body>
		<created>2019-08-09 09:13:08</created>
		<closed>2019-08-12 03:03:49</closed>
	</bug>
	<bug>
		<id>686</id>
		<title>[BUG] 1.1.0release sql not update</title>
		<body></body>
		<created>2019-08-09 03:25:01</created>
		<closed>2019-08-12 03:01:52</closed>
	</bug>
	<bug>
		<id>685</id>
		<title>[BUG] there is no error log, and the result is also generated normally, but the display status is failure, sometimes it will be displayed after retrying.（任务日志无报错，结果也正常生成，但显示状态为失败，有时重试后会显示成功）</title>
		<body>*For better global communication, please give priority to using English description, thx! *  **Describe the bug** A clear and concise description of what the bug is. 任务日志无报错，结果也正常生成，但显示状态为失败，有时重试后会显示成功  ![image](https://user-images.githubusercontent.com/30412237/62749571-81a9f680-ba8f-11e9-90af-c9dabf9a2064.png)  version：1.0.3</body>
		<created>2019-08-09 02:22:21</created>
		<closed>2019-09-01 12:34:01</closed>
	</bug>
	<bug>
		<id>667</id>
		<title>[BUG] HivePreparedStatement can't print the actual SQL executed</title>
		<body> </body>
		<created>2019-08-02 08:05:45</created>
		<closed>2019-08-05 02:21:55</closed>
	</bug>
	<bug>
		<id>655</id>
		<title>[BUG] when deploy a spark task,the tentant queue not empty,set with a empty queu name</title>
		<body> debug code like that. ![image](https://user-images.githubusercontent.com/3957251/62126646-c81a8b00-b302-11e9-9c27-d1fd148f8205.png) </body>
		<created>2019-07-30 11:47:51</created>
		<closed>2019-08-06 03:32:18</closed>
	</bug>
	<bug>
		<id>650</id>
		<title>[BUG] Creating a hive data source without a principal will cause the connection to fail.（建立hive数据源principal未开启的时候会导致连接失败）</title>
		<body>In version 1.1.0, when the hive data source is created, the principal is not enabled, the principal field returns null, and is spliced into the string of jdbcUrl with principal=null, which will eventually cause the connection to fail. If this sentence is removed, it will be OK.  Modify the HiveDataSource rewrite method getJdbcUrl field to judge.  --- 1.1.0版本中 ，建立hive数据源的时候principal未开启，principal字段返回的null，并被拼接到jdbcUrl的字符串当中principal=null，最终会导致连接失败，如果把这句去掉就OK了。  修改方式HiveDataSource的重写方法getJdbcUrl字段进行判断即可。</body>
		<created>2019-07-30 03:01:14</created>
		<closed>2019-08-06 03:32:17</closed>
	</bug>
	<bug>
		<id>646</id>
		<title>[Discussion] Why doesn't ProcessScheduleJob add @DisallowConcurrentExecution（[Discussion] ProcessScheduleJob为什么不加上@DisallowConcurrentExecution）</title>
		<body>Excuse me, why does ProcessScheduleJob not add the @DisallowConcurrentExecution annotation? The current scheduled execution should be executed concurrently. Is it more reasonable to wait until the last execution? There are still other reasons to implement better, and ask you  --- 请问下ProcessScheduleJob为什么不加上@DisallowConcurrentExecution注解，现在的定时执行应该都是并发执行吧，等到上个执行完再执行不是更合理？还是有其他的理由并发执行更好，，，请教一下各位</body>
		<created>2019-07-29 10:57:44</created>
		<closed>2019-07-30 06:31:11</closed>
	</bug>
	<bug>
		<id>645</id>
		<title>[BUG]Monitoring Center - Service Management only shows one device status（[BUG]监控中心-服务管理只显示一台设备状态）</title>
		<body>![image](https://user-images.githubusercontent.com/28653771/62039540-7d2d4480-b22a-11e9-9f50-7bb2bcc2bbbb.png)  As shown in the figure above, after clustering, only the status of one device is displayed. The master and worker pages have this problem.  --- ![image](https://user-images.githubusercontent.com/28653771/62039540-7d2d4480-b22a-11e9-9f50-7bb2bcc2bbbb.png)  如上图 , 集群起来后 , 只显示一台设备的状态 , master , worker页面有有这个问题 ; </body>
		<created>2019-07-29 09:59:40</created>
		<closed>2019-09-02 07:05:10</closed>
	</bug>
	<bug>
		<id>644</id>
		<title>The interface link in the official documentation is wrong（官方说明文档中的接口链接是错误的）</title>
		<body>The interface link in the official documentation is wrong. Clicking is an error page for nginx http://52.82.13.76:8888/easyscheduler/doc.html?language=zh_CN&amp;lang=cn  --- 官方说明文档中的接口链接是错误的.点开是个nginx的错误页面 http://52.82.13.76:8888/easyscheduler/doc.html?language=zh_CN&amp;lang=cn</body>
		<created>2019-07-29 07:00:38</created>
		<closed>2019-07-29 11:15:55</closed>
	</bug>
	<bug>
		<id>641</id>
		<title>[BUG] The cellphone is not supported for 199 telecom segment when create a user</title>
		<body>**Describe the bug** when i create a user, the cellphone is not supported for 199 telecom segment  ![image](https://user-images.githubusercontent.com/14704224/62017409-1cc9e300-b1e9-11e9-877d-810054b9c551.png)  **Which version of Easy Scheduler:**  -[1.1.0-preview] </body>
		<created>2019-07-29 02:12:38</created>
		<closed>2019-08-05 02:23:00</closed>
	</bug>
	<bug>
		<id>637</id>
		<title>CONTRIBUTING.md need set to EN</title>
		<body>The link at here, https://github.com/analysys/EasyScheduler#how-to-contribute-code, is pointing to Chinese document. Need to fix.</body>
		<created>2019-07-29 01:50:18</created>
		<closed>2019-07-29 10:10:52</closed>
	</bug>
	<bug>
		<id>636</id>
		<title>[BUG] "Statistics" menu, there are not datas display on the page</title>
		<body>**Describe the bug** when i click the "Statistics" menu, there are not datas display on the page, the blackgroud of escheduler-api-server.log Exception is:   ![image](https://user-images.githubusercontent.com/14704224/62016383-6401a500-b1e4-11e9-8cb8-270e122547c9.png)  **Which version of Easy Scheduler:**  -[1.1.0-preview] </body>
		<created>2019-07-29 01:39:00</created>
		<closed>2019-09-26 10:08:02</closed>
	</bug>
	<bug>
		<id>628</id>
		<title>links number of zookeeper would increase when refresh monitor site</title>
		<body>When the monitoring center is refreshed, it will increase the number of zk connections.  --- 监控中心刷新的时候，会增加zk连接数</body>
		<created>2019-07-25 03:46:10</created>
		<closed>2019-07-29 11:16:34</closed>
	</bug>
	<bug>
		<id>627</id>
		<title>Different sql node task logs in parallel in the same workflow will be mixed（同一工作流中并行的不同sql节点任务日志会混合）</title>
		<body>In the same workflow, the sql node task executed in parallel, the execution log of task B will appear in the log of task A, which may eventually cause the variable replacement of a task to fail. ![image](https://user-images.githubusercontent.com/30412237/61792807-2a314700-ae50-11e9-995a-9b31cb3ffd2c.png) ![image](https://user-images.githubusercontent.com/30412237/61792837-387f6300-ae50-11e9-9b41-ea4cc5a8d46e.png) As shown above, status_fav_num and status_retweet_num are two separate tasks, but the execution log of the status_retweet_num task appears in the status_fav_num task log. For detailed log of the above 4 tasks, you can contact me (WeChat group: EasyScheduler China User Group 1 Chen Yuan)  --- 在同一工作流中，并行执行的sql节点任务，任务A的日志里会出现任务B的执行日志，最终可能导致某个任务的变量替换失败。 ![image](https://user-images.githubusercontent.com/30412237/61792807-2a314700-ae50-11e9-995a-9b31cb3ffd2c.png) ![image](https://user-images.githubusercontent.com/30412237/61792837-387f6300-ae50-11e9-9b41-ea4cc5a8d46e.png) 如上图，status_fav_num和status_retweet_num是两个独立的任务，但是在status_fav_num任务日志中出现了status_retweet_num任务的执行日志。 如需要以上4个任务的详细日志，可以联系我（微信群：EasyScheduler China User Group 1 陈源)</body>
		<created>2019-07-24 12:23:37</created>
		<closed>2019-08-06 03:32:50</closed>
	</bug>
	<bug>
		<id>621</id>
		<title>Enterprise WeChat message failed to push（企业微信消息推送失败）</title>
		<body>We are now experiencing a problem. When we configure dozens of jobs in a workflow, if these dozens of jobs fail, I find that `mail` can receive the message push normally, but  I found that `Enterprise WeChat` did not receive the message push normally. When I checked the log, I found an error message. The following is the error message:  ``` Resp:{"errcode":45002,"errmsg":"content size out of limit, hint: [1563869667_1_f6b18ca536f2925269b2b36e95aa4dd1], from ip: 111.202.110.196, more info at https://open.work.weixin.qq.com/ Devtool/query?e=45002"} ```  It is possible that there are too many jobs in a single workflow. If all the jobs fail, because the WeChat has a limit on the length of a single piece of content, too much content of a single message causes the WeChat to fail to be sent.  If you adjust the sending policy of the message content, it may be better. The current sending strategy is to send all the failed jobs in a workflow to a message.  **current version:**  `1.1.0-preview`  ** Expected results: **  Enterprise WeChat can receive all message pushes normally  --- 我们现在遇到一个问题，当我们在一个工作流里面配置几十个作业时，如果这几十个作业都失败了，我发现 `邮件` 是可以正常接收到消息推送的，但是  我发现 `企业微信` 没有正常接收到消息推送，当我查看日志的时候发现有报错信息，以下是报错信息：  ``` resp:{"errcode":45002,"errmsg":"content size out of limit, hint: [1563869667_1_f6b18ca536f2925269b2b36e95aa4dd1], from ip: 111.202.110.196, more info at https://open.work.weixin.qq.com/devtool/query?e=45002"} ```  有可能是单个工作流里面的作业太多，如果所有作业都失败了，由于企业微信对单条内容长度有限制，单条消息的内容太多导致企业微信发送失败。  如果调整一下消息内容的发送策略可能会好些，现在的发送策略是把一个工作流里面所有失败的作业都集中都一条消息里面发送了。  **当前版本：**  `1.1.0-preview`  **期望达到的效果：**  企业微信可以正常接收到所有消息推送</body>
		<created>2019-07-24 04:27:22</created>
		<closed>2019-09-26 10:02:17</closed>
	</bug>
	<bug>
		<id>594</id>
		<title>After the soft kill task, the process still exists (parent process child process)(soft kill task 后 进程依旧存在(父进程 子进程))</title>
		<body> In the shell script, the task is executed in a multi-threaded manner. The timeout of the task is set to fail. After the timeout, the process of starting the task is executed, but the parent process is not yet killed.  Worker LOG: [INFO] 2019-07-18 02:03:01.513 cn.escheduler.server.worker.log.TaskLogger:[178] - [taskAppId=TASK_33_552_739] task run command: Sudo sudo -u rundeck sh /tmp/escheduler/exec/process/5/33/552/739/33_552_739.command [INFO] 2019-07-18 02:03:01.516 cn.escheduler.server.worker.log.TaskLogger:[178] - [taskAppId=TASK_33_552_739] process start, process id is: 185464 [INFO] 2019-07-18 02:04:18.082 cn.escheduler.server.worker.log.TaskLogger:[188] - [taskAppId=TASK_33_552_739] process has exited, work dir:/tmp/escheduler/exec/process/ 5/33/552/739, pid:185464, exitStatusCode: 0 [INFO] 2019-07-18 02:04:18.083 cn.escheduler.server.worker.runner.TaskScheduleThread:[198] - task : 33_552_739 exit status code : 0 [INFO] 2019-07-18 02:17:15.531 cn.escheduler.server.worker.log.TaskLogger:[178] - [taskAppId=TASK_24_548_737] -&gt; ============== ========== [INFO] 2019-07-18 02:17:15.531 cn.escheduler.server.worker.log.TaskLogger:[178] - [taskAppId=TASK_24_548_737] cancel process: 170216 [INFO] 2019-07-18 02:17:15.531 cn.escheduler.server.worker.log.TaskLogger:[188] - [taskAppId=TASK_24_548_737] soft kill task:24_548_737, process id:170216, cmd:sudo kill 170216 [WARN] 2019-07-18 02:17:15.533 cn.escheduler.server.worker.log.TaskLogger:[243] - [taskAppId=TASK_24_548_737] process timeout, work dir:/tmp/escheduler/exec/process/3 /24/548/737, pid:170216 [INFO] 2019-07-18 02:17:15.533 cn.escheduler.server.worker.runner.TaskScheduleThread:[198] - task : 24_548_737 exit status code : -1 [INFO] 2019-07-18 02:18:18.758 cn.escheduler.common.queue.TaskQueueZkImpl:[181] - consume task /escheduler/tasks_queue/0_548_2_740 [INFO] 2019-07-18 02:18:18.758 cn.escheduler.common.queue.TaskQueueZkImpl:[188] - consume task: 740,there still have 0 tasks need to be executed  --- shell脚本中使用多线程的方式执行任务, 对任务设定超时失败, 超时后启动任务的进程被执行 kill, 但父进程 并没有被killed 子进程也依旧存在.  Worker LOG: [INFO] 2019-07-18 02:03:01.513 cn.escheduler.server.worker.log.TaskLogger:[178] - [taskAppId=TASK_33_552_739] task run command: sudo sudo -u rundeck sh /tmp/escheduler/exec/process/5/33/552/739/33_552_739.command [INFO] 2019-07-18 02:03:01.516 cn.escheduler.server.worker.log.TaskLogger:[178] - [taskAppId=TASK_33_552_739] process start, process id is: 185464 [INFO] 2019-07-18 02:04:18.082 cn.escheduler.server.worker.log.TaskLogger:[188] - [taskAppId=TASK_33_552_739] process has exited, work dir:/tmp/escheduler/exec/process/5/33/552/739, pid:185464 ,exitStatusCode:0 [INFO] 2019-07-18 02:04:18.083 cn.escheduler.server.worker.runner.TaskScheduleThread:[198] - task : 33_552_739 exit status code : 0 [INFO] 2019-07-18 02:17:15.531 cn.escheduler.server.worker.log.TaskLogger:[178] - [taskAppId=TASK_24_548_737]  -&gt; ======================== [INFO] 2019-07-18 02:17:15.531 cn.escheduler.server.worker.log.TaskLogger:[178] - [taskAppId=TASK_24_548_737] cancel process: 170216 [INFO] 2019-07-18 02:17:15.531 cn.escheduler.server.worker.log.TaskLogger:[188] - [taskAppId=TASK_24_548_737] soft kill task:24_548_737, process id:170216, cmd:sudo kill 170216 [WARN] 2019-07-18 02:17:15.533 cn.escheduler.server.worker.log.TaskLogger:[243] - [taskAppId=TASK_24_548_737] process timeout, work dir:/tmp/escheduler/exec/process/3/24/548/737, pid:170216 [INFO] 2019-07-18 02:17:15.533 cn.escheduler.server.worker.runner.TaskScheduleThread:[198] - task : 24_548_737 exit status code : -1 [INFO] 2019-07-18 02:18:18.758 cn.escheduler.common.queue.TaskQueueZkImpl:[181] - consume task /escheduler/tasks_queue/0_548_2_740 [INFO] 2019-07-18 02:18:18.758 cn.escheduler.common.queue.TaskQueueZkImpl:[188] - consume task: 740,there still have 0 tasks need to be executed</body>
		<created>2019-07-18 03:19:00</created>
		<closed>2019-07-18 08:04:01</closed>
	</bug>
	<bug>
		<id>569</id>
		<title>Timed tasks can't really stop(定时任务无法真正停止)</title>
		<body>I encountered a rather strange problem today. When I put the timed task off the assembly line, it seems that the timed task did not really stop. After a while, I will run a batch of tasks myself. After I delete the timed task, it will not work. After a while, I still have myself. Run a batch of tasks.  --- 我今天遇到一个比较奇怪的问题，当我把定时任务下线后好像定时任务没有真正停止，过一会儿就会自己运行一批任务，我把定时任务删除后也不起作用，过一会儿还是自己运行一批任务。</body>
		<created>2019-07-13 12:43:39</created>
		<closed>2019-07-15 09:06:56</closed>
	</bug>
	<bug>
		<id>567</id>
		<title>When offline process, offline timing is error.</title>
		<body>When offline process, it should first offline process according to process ID, and then according to the corresponding timing ID offline timing.  In fact, the offline timing is based on the process ID, as follows: **ProcessDefinitionService: delete Schedule (project. getId (), id);**  It should be amended to read: **ProcessDefinitionService: delete Schedule (project. getId (), schedule. getId ());**</body>
		<created>2019-07-13 05:06:59</created>
		<closed>2019-07-15 09:12:30</closed>
	</bug>
	<bug>
		<id>562</id>
		<title>ApiApplicationServer service does not start properly（ApiApplicationServer 服务无法正常启动）</title>
		<body>I encountered a problem when deploying `Easy Scheduler`. I followed the official documentation step by step. After the installation is complete, when I use the normal user to execute the `sh bin/start_all.sh` command, `ApiApplicationServer` starts. No, sometimes other processes can't start, such as `MasterServer, WorkerServer` process, the following is the error log of `ApiApplicationServer` service `escheduler-api-server.log` file  ``` [INFO] 2019-07-11 09:30:37.810 cn.escheduler.api.ApiApplicationServer:[50] - Starting ApiApplicationServer on slave1 with PID 75717 (/opt/escheduler/escheduler-backend/lib/escheduler-api-1.0.4-SNAPSHOT.jar started by escheduler in /opt/escheduler/escheduler-backend) [INFO] 2019-07-11 09:30:37.832 cn.escheduler.api.ApiApplicationServer:[675] - No active profile set, falling back to default profiles: default [INFO] 2019-07-11 09:30:43.467 org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[330] - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$bf967649] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) [INFO] 2019-07-11 09:30:44.245 org.eclipse.jetty.util.log:[193] - Logging initialized @9231ms to org.eclipse.jetty.util.log.Slf4jLog [INFO] 2019-07-11 09:30:44.637 org.springframework.boot.web.embedded.jetty.JettyServletWebServerFactory:[143] - Server initialized with port: 12345 [INFO] 2019-07-11 09:30:44.642 org.eclipse.jetty.server.Server:[370] - jetty-9.4.14.v20181114; built: 2018-11-14T21:20:31.478Z; git: c4550056e785fb5665914545889f21dc136ad9e6; jvm 1.8.0_151-b12 [INFO] 2019-07-11 09:30:44.813 org.eclipse.jetty.server.handler.ContextHandler.application:[2345] - Initializing Spring embedded WebApplicationContext [INFO] 2019-07-11 09:30:44.816 org.springframework.web.context.ContextLoader:[296] - Root WebApplicationContext: initialization completed in 6774 ms [INFO] 2019-07-11 09:30:45.061 org.eclipse.jetty.server.session:[365] - DefaultSessionIdManager workerName=node0 [INFO] 2019-07-11 09:30:45.072 org.eclipse.jetty.server.session:[370] - No SessionScavenger set, using defaults [INFO] 2019-07-11 09:30:45.074 org.eclipse.jetty.server.session:[149] - node0 Scavenging every 600000ms [INFO] 2019-07-11 09:30:45.099 org.eclipse.jetty.server.handler.ContextHandler:[855] - Started o.s.b.w.e.j.JettyEmbeddedWebAppContext@164642a4{application,/escheduler,[file:///tmp/jetty-docbase.5198879188764957027.12345/, jar:file:/opt/escheduler/escheduler-backend/lib/springfox-swagger-ui-2.9.2.jar!/META-INF/resources, jar:file:/opt/escheduler/escheduler-backend/lib/swagger-bootstrap-ui-1.9.3.jar!/META-INF/resources],AVAILABLE} [INFO] 2019-07-11 09:30:45.101 org.eclipse.jetty.server.Server:[407] - Started @10091ms [INFO] 2019-07-11 09:30:45.476 ru.yandex.clickhouse.ClickHouseDriver:[42] - Driver registered [INFO] 2019-07-11 09:30:46.046 com.alibaba.druid.pool.DruidDataSource:[991] - {dataSource-1} inited [INFO] 2019-07-11 09:30:47.009 cn.escheduler.common.queue.TaskQueueFactory:[51] - task queue impl use zookeeper  [INFO] 2019-07-11 09:30:47.355 org.apache.curator.framework.imps.CuratorFrameworkImpl:[235] - Starting [INFO] 2019-07-11 09:30:47.589 org.apache.curator.framework.state.ConnectionStateManager:[228] - State change: CONNECTED [INFO] 2019-07-11 09:30:47.592 cn.escheduler.common.zk.AbstractZKClient:[127] - state changed , current state : CONNECTED [INFO] 2019-07-11 09:30:49.531 springfox.documentation.spring.web.PropertySourcedRequestMappingHandlerMapping:[69] - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity&lt;springfox.documentation.spring.web.json.Json&gt; springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)] [INFO] 2019-07-11 09:30:50.096 org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor:[171] - Initializing ExecutorService 'applicationTaskExecutor' [INFO] 2019-07-11 09:30:51.172 springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper:[160] - Context refreshed [INFO] 2019-07-11 09:30:51.221 springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper:[163] - Found 1 custom documentation plugin(s) [INFO] 2019-07-11 09:30:51.402 springfox.documentation.spring.web.scanners.ApiListingReferenceScanner:[41] - Scanning for api listing references [INFO] 2019-07-11 09:30:52.514 springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator:[40] - Generating unique operation named: viewTreeUsingGET_1 [INFO] 2019-07-11 09:30:52.829 org.eclipse.jetty.server.handler.ContextHandler.application:[2345] - Initializing Spring DispatcherServlet 'dispatcherServlet' [INFO] 2019-07-11 09:30:52.830 org.springframework.web.servlet.DispatcherServlet:[524] - Initializing Servlet 'dispatcherServlet' [INFO] 2019-07-11 09:30:52.870 org.springframework.web.servlet.DispatcherServlet:[546] - Completed initialization in 38 ms [WARN] 2019-07-11 09:30:53.064 org.eclipse.jetty.server.handler.ContextHandler.application:[2355] - unavailable java.lang.NullPointerException: null at org.apache.jasper.compiler.Localizer.getMessage(Localizer.java:150) at org.apache.jasper.compiler.Localizer.getMessage(Localizer.java:76) at org.apache.jasper.EmbeddedServletOptions.&lt;init&gt;(EmbeddedServletOptions.java:588) at org.apache.jasper.servlet.JspServlet.init(JspServlet.java:98) at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:672) at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:429) at org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:750) at java.util.stream.SortedOps$SizedRefSortingSink.end(SortedOps.java:352) at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) at java.util.stream.StreamSpliterators$WrappingSpliterator.forEachRemaining(StreamSpliterators.java:312) at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:743) at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:744) at org.springframework.boot.web.embedded.jetty.JettyEmbeddedWebAppContext$JettyEmbeddedServletHandler.deferredInitialize(JettyEmbeddedWebAppContext.java:46) at org.springframework.boot.web.embedded.jetty.JettyEmbeddedWebAppContext.deferredInitialize(JettyEmbeddedWebAppContext.java:36) at org.springframework.boot.web.embedded.jetty.JettyWebServer.handleDeferredInitialize(JettyWebServer.java:221) at org.springframework.boot.web.embedded.jetty.JettyWebServer.start(JettyWebServer.java:142) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.startWebServer(ServletWebServerApplicationContext.java:311) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.finishRefresh(ServletWebServerApplicationContext.java:164) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:552) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) at cn.escheduler.api.ApiApplicationServer.main(ApiApplicationServer.java:33) [INFO] 2019-07-11 09:30:53.068 org.eclipse.jetty.server.session:[167] - node0 Stopped scavenging [INFO] 2019-07-11 09:30:53.075 org.eclipse.jetty.server.handler.ContextHandler.application:[2345] - Destroying Spring FrameworkServlet 'dispatcherServlet' [INFO] 2019-07-11 09:30:53.076 org.eclipse.jetty.server.handler.ContextHandler:[1045] - Stopped o.s.b.w.e.j.JettyEmbeddedWebAppContext@164642a4{application,/escheduler,[file:///tmp/jetty-docbase.5198879188764957027.12345/, jar:file:/opt/escheduler/escheduler-backend/lib/springfox-swagger-ui-2.9.2.jar!/META-INF/resources, jar:file:/opt/escheduler/escheduler-backend/lib/swagger-bootstrap-ui-1.9.3.jar!/META-INF/resources],UNAVAILABLE} [INFO] 2019-07-11 09:30:53.091 org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener:[142] -   Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. [ERROR] 2019-07-11 09:30:53.100 org.springframework.boot.SpringApplication:[858] - Application run failed org.springframework.boot.web.server.WebServerException: Unable to start embedded Jetty server at org.springframework.boot.web.embedded.jetty.JettyWebServer.start(JettyWebServer.java:168) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.startWebServer(ServletWebServerApplicationContext.java:311) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.finishRefresh(ServletWebServerApplicationContext.java:164) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:552) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) at cn.escheduler.api.ApiApplicationServer.main(ApiApplicationServer.java:33) Caused by: javax.servlet.ServletException: jsp@19c47==org.apache.jasper.servlet.JspServlet,jsp=null,order=3,inst=false,async=true at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:693) at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:429) at org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:750) at java.util.stream.SortedOps$SizedRefSortingSink.end(SortedOps.java:352) at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) at java.util.stream.StreamSpliterators$WrappingSpliterator.forEachRemaining(StreamSpliterators.java:312) at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:743) at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:744) at org.springframework.boot.web.embedded.jetty.JettyEmbeddedWebAppContext$JettyEmbeddedServletHandler.deferredInitialize(JettyEmbeddedWebAppContext.java:46) at org.springframework.boot.web.embedded.jetty.JettyEmbeddedWebAppContext.deferredInitialize(JettyEmbeddedWebAppContext.java:36) at org.springframework.boot.web.embedded.jetty.JettyWebServer.handleDeferredInitialize(JettyWebServer.java:221) at org.springframework.boot.web.embedded.jetty.JettyWebServer.start(JettyWebServer.java:142) ... 10 common frames omitted Caused by: java.lang.NullPointerException: null at org.apache.jasper.compiler.Localizer.getMessage(Localizer.java:150) at org.apache.jasper.compiler.Localizer.getMessage(Localizer.java:76) at org.apache.jasper.EmbeddedServletOptions.&lt;init&gt;(EmbeddedServletOptions.java:588) at org.apache.jasper.servlet.JspServlet.init(JspServlet.java:98) at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:672) ... 24 common frames omitted [INFO] 2019-07-11 09:30:53.106 org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor:[208] - Shutting down ExecutorService 'applicationTaskExecutor' [INFO] 2019-07-11 09:30:53.133 com.alibaba.druid.pool.DruidDataSource:[1928] - {dataSource-1} closed ```  and  `escheduler-api-server-slave1.out` file error log  ``` 09:30:35,688 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml] 09:30:35,689 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.groovy] 09:30:35,689 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Found resource [logback.xml] at [file:/opt/escheduler/escheduler-backend/conf/logback.xml] 09:30:35,691 |-WARN in ch.qos.logback.classic.LoggerContext[default] - Resource [logback.xml] occurs multiple times on the classpath. 09:30:35,691 |-WARN in ch.qos.logback.classic.LoggerContext[default] - Resource [logback.xml] occurs at [jar:file:/opt/escheduler/escheduler-backend/lib/escheduler-api-1.0.4-SNAPSHOT.jar!/logback.xml] 09:30:35,691 |-WARN in ch.qos.logback.classic.LoggerContext[default] - Resource [logback.xml] occurs at [file:/opt/escheduler/escheduler-backend/conf/logback.xml] 09:30:36,046 |-INFO in ch.qos.logback.classic.joran.action.ConfigurationAction - debug attribute not set 09:30:36,067 |-INFO in ch.qos.logback.classic.joran.action.ConfigurationAction - Will scan for changes in [file:/opt/escheduler/escheduler-backend/conf/logback.xml]  09:30:36,067 |-INFO in ch.qos.logback.classic.joran.action.ConfigurationAction - Setting ReconfigureOnChangeTask scanning period to 2 minutes 09:30:36,071 |-INFO in ch.qos.logback.classic.joran.action.LoggerAction - Setting level of logger [org.apache.zookeeper] to WARN 09:30:36,071 |-INFO in ch.qos.logback.classic.joran.action.LoggerAction - Setting level of logger [org.apache.hbase] to WARN 09:30:36,071 |-INFO in ch.qos.logback.classic.joran.action.LoggerAction - Setting level of logger [org.apache.hadoop] to WARN 09:30:36,082 |-INFO in ch.qos.logback.core.joran.action.AppenderAction - About to instantiate appender of type [ch.qos.logback.core.ConsoleAppender] 09:30:36,086 |-INFO in ch.qos.logback.core.joran.action.AppenderAction - Naming appender as [STDOUT] 09:30:36,115 |-INFO in ch.qos.logback.core.joran.action.NestedComplexPropertyIA - Assuming default type [ch.qos.logback.classic.encoder.PatternLayoutEncoder] for [encoder] property 09:30:36,280 |-INFO in ch.qos.logback.core.joran.action.AppenderAction - About to instantiate appender of type [ch.qos.logback.core.rolling.RollingFileAppender] 09:30:36,292 |-INFO in ch.qos.logback.core.joran.action.AppenderAction - Naming appender as [APISERVERLOGFILE] 09:30:36,315 |-INFO in c.q.l.core.rolling.SizeAndTimeBasedRollingPolicy@1906808037 - Archive files will be limited to [64 MB] each. 09:30:36,319 |-INFO in c.q.l.core.rolling.SizeAndTimeBasedRollingPolicy@1906808037 - No compression will be used 09:30:36,321 |-INFO in c.q.l.core.rolling.SizeAndTimeBasedRollingPolicy@1906808037 - Will use the pattern logs/escheduler-api-server.%d{yyyy-MM-dd_HH}.%i.log for the active file 09:30:36,326 |-INFO in ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP@76329302 - The date pattern is 'yyyy-MM-dd_HH' from file name pattern 'logs/escheduler-api-server.%d{yyyy-MM-dd_HH}.%i.log'. 09:30:36,326 |-INFO in ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP@76329302 - Roll-over at the top of every hour. 09:30:36,331 |-INFO in ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP@76329302 - Setting initial period to Thu Jul 11 09:30:34 CST 2019 09:30:36,336 |-INFO in ch.qos.logback.core.joran.action.NestedComplexPropertyIA - Assuming default type [ch.qos.logback.classic.encoder.PatternLayoutEncoder] for [encoder] property 09:30:36,340 |-INFO in ch.qos.logback.core.rolling.RollingFileAppender[APISERVERLOGFILE] - Active log file name: logs/escheduler-api-server.log 09:30:36,340 |-INFO in ch.qos.logback.core.rolling.RollingFileAppender[APISERVERLOGFILE] - File property is set to [logs/escheduler-api-server.log] 09:30:36,341 |-INFO in ch.qos.logback.classic.joran.action.RootLoggerAction - Setting level of ROOT logger to INFO 09:30:36,341 |-INFO in ch.qos.logback.core.joran.action.AppenderRefAction - Attaching appender named [STDOUT] to Logger[ROOT] 09:30:36,342 |-INFO in ch.qos.logback.classic.joran.action.ConfigurationAction - End of configuration. 09:30:36,343 |-INFO in ch.qos.logback.classic.joran.JoranConfigurator@5e25a92e - Registering current configuration as safe fallback point     .   ____          _            __ _ _  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \ ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )   '  |____| .__|_| |_|_| |_\__, | / / / /  =========|_|==============|___/=/_/_/_/  :: Spring Boot ::        (v2.1.3.RELEASE)  java.util.MissingResourceException: Can't find bundle for base name org.apache.jasper.resources.LocalStrings, locale en_US at java.util.ResourceBundle.throwMissingResourceException(ResourceBundle.java:1564) at java.util.ResourceBundle.getBundleImpl(ResourceBundle.java:1387) at java.util.ResourceBundle.getBundle(ResourceBundle.java:773) at org.apache.jasper.compiler.Localizer.&lt;clinit&gt;(Localizer.java:36) at org.apache.jasper.EmbeddedServletOptions.&lt;init&gt;(EmbeddedServletOptions.java:588) at org.apache.jasper.servlet.JspServlet.init(JspServlet.java:98) at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:672) at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:429) at org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:750) at java.util.stream.SortedOps$SizedRefSortingSink.end(SortedOps.java:352) at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) at java.util.stream.StreamSpliterators$WrappingSpliterator.forEachRemaining(StreamSpliterators.java:312) at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:743) at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:744) at org.springframework.boot.web.embedded.jetty.JettyEmbeddedWebAppContext$JettyEmbeddedServletHandler.deferredInitialize(JettyEmbeddedWebAppContext.java:46) at org.springframework.boot.web.embedded.jetty.JettyEmbeddedWebAppContext.deferredInitialize(JettyEmbeddedWebAppContext.java:36) at org.springframework.boot.web.embedded.jetty.JettyWebServer.handleDeferredInitialize(JettyWebServer.java:221) at org.springframework.boot.web.embedded.jetty.JettyWebServer.start(JettyWebServer.java:142) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.startWebServer(ServletWebServerApplicationContext.java:311) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.finishRefresh(ServletWebServerApplicationContext.java:164) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:552) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) at cn.escheduler.api.ApiApplicationServer.main(ApiApplicationServer.java:33) ```   How can I solve this problem?    The current version is:  `dev` latest version    The results I expect to be are:  I can start the service normally and use this software normally.  --- 我在部署 `Easy Scheduler` 的时候遇到一个问题，我按照官方文档来一步一步的操作安装完成后，当我使用普通用户执行 `sh bin/start_all.sh` 这个命令的时候， `ApiApplicationServer` 启动不起来，有些时候其他进程也启动不了，比如 `MasterServer、WorkerServer` 进程，以下是 `ApiApplicationServer` 服务 `escheduler-api-server.log`  文件的错误日志  ``` [INFO] 2019-07-11 09:30:37.810 cn.escheduler.api.ApiApplicationServer:[50] - Starting ApiApplicationServer on slave1 with PID 75717 (/opt/escheduler/escheduler-backend/lib/escheduler-api-1.0.4-SNAPSHOT.jar started by escheduler in /opt/escheduler/escheduler-backend) [INFO] 2019-07-11 09:30:37.832 cn.escheduler.api.ApiApplicationServer:[675] - No active profile set, falling back to default profiles: default [INFO] 2019-07-11 09:30:43.467 org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:[330] - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$bf967649] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) [INFO] 2019-07-11 09:30:44.245 org.eclipse.jetty.util.log:[193] - Logging initialized @9231ms to org.eclipse.jetty.util.log.Slf4jLog [INFO] 2019-07-11 09:30:44.637 org.springframework.boot.web.embedded.jetty.JettyServletWebServerFactory:[143] - Server initialized with port: 12345 [INFO] 2019-07-11 09:30:44.642 org.eclipse.jetty.server.Server:[370] - jetty-9.4.14.v20181114; built: 2018-11-14T21:20:31.478Z; git: c4550056e785fb5665914545889f21dc136ad9e6; jvm 1.8.0_151-b12 [INFO] 2019-07-11 09:30:44.813 org.eclipse.jetty.server.handler.ContextHandler.application:[2345] - Initializing Spring embedded WebApplicationContext [INFO] 2019-07-11 09:30:44.816 org.springframework.web.context.ContextLoader:[296] - Root WebApplicationContext: initialization completed in 6774 ms [INFO] 2019-07-11 09:30:45.061 org.eclipse.jetty.server.session:[365] - DefaultSessionIdManager workerName=node0 [INFO] 2019-07-11 09:30:45.072 org.eclipse.jetty.server.session:[370] - No SessionScavenger set, using defaults [INFO] 2019-07-11 09:30:45.074 org.eclipse.jetty.server.session:[149] - node0 Scavenging every 600000ms [INFO] 2019-07-11 09:30:45.099 org.eclipse.jetty.server.handler.ContextHandler:[855] - Started o.s.b.w.e.j.JettyEmbeddedWebAppContext@164642a4{application,/escheduler,[file:///tmp/jetty-docbase.5198879188764957027.12345/, jar:file:/opt/escheduler/escheduler-backend/lib/springfox-swagger-ui-2.9.2.jar!/META-INF/resources, jar:file:/opt/escheduler/escheduler-backend/lib/swagger-bootstrap-ui-1.9.3.jar!/META-INF/resources],AVAILABLE} [INFO] 2019-07-11 09:30:45.101 org.eclipse.jetty.server.Server:[407] - Started @10091ms [INFO] 2019-07-11 09:30:45.476 ru.yandex.clickhouse.ClickHouseDriver:[42] - Driver registered [INFO] 2019-07-11 09:30:46.046 com.alibaba.druid.pool.DruidDataSource:[991] - {dataSource-1} inited [INFO] 2019-07-11 09:30:47.009 cn.escheduler.common.queue.TaskQueueFactory:[51] - task queue impl use zookeeper  [INFO] 2019-07-11 09:30:47.355 org.apache.curator.framework.imps.CuratorFrameworkImpl:[235] - Starting [INFO] 2019-07-11 09:30:47.589 org.apache.curator.framework.state.ConnectionStateManager:[228] - State change: CONNECTED [INFO] 2019-07-11 09:30:47.592 cn.escheduler.common.zk.AbstractZKClient:[127] - state changed , current state : CONNECTED [INFO] 2019-07-11 09:30:49.531 springfox.documentation.spring.web.PropertySourcedRequestMappingHandlerMapping:[69] - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity&lt;springfox.documentation.spring.web.json.Json&gt; springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)] [INFO] 2019-07-11 09:30:50.096 org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor:[171] - Initializing ExecutorService 'applicationTaskExecutor' [INFO] 2019-07-11 09:30:51.172 springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper:[160] - Context refreshed [INFO] 2019-07-11 09:30:51.221 springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper:[163] - Found 1 custom documentation plugin(s) [INFO] 2019-07-11 09:30:51.402 springfox.documentation.spring.web.scanners.ApiListingReferenceScanner:[41] - Scanning for api listing references [INFO] 2019-07-11 09:30:52.514 springfox.documentation.spring.web.readers.operation.CachingOperationNameGenerator:[40] - Generating unique operation named: viewTreeUsingGET_1 [INFO] 2019-07-11 09:30:52.829 org.eclipse.jetty.server.handler.ContextHandler.application:[2345] - Initializing Spring DispatcherServlet 'dispatcherServlet' [INFO] 2019-07-11 09:30:52.830 org.springframework.web.servlet.DispatcherServlet:[524] - Initializing Servlet 'dispatcherServlet' [INFO] 2019-07-11 09:30:52.870 org.springframework.web.servlet.DispatcherServlet:[546] - Completed initialization in 38 ms [WARN] 2019-07-11 09:30:53.064 org.eclipse.jetty.server.handler.ContextHandler.application:[2355] - unavailable java.lang.NullPointerException: null at org.apache.jasper.compiler.Localizer.getMessage(Localizer.java:150) at org.apache.jasper.compiler.Localizer.getMessage(Localizer.java:76) at org.apache.jasper.EmbeddedServletOptions.&lt;init&gt;(EmbeddedServletOptions.java:588) at org.apache.jasper.servlet.JspServlet.init(JspServlet.java:98) at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:672) at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:429) at org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:750) at java.util.stream.SortedOps$SizedRefSortingSink.end(SortedOps.java:352) at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) at java.util.stream.StreamSpliterators$WrappingSpliterator.forEachRemaining(StreamSpliterators.java:312) at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:743) at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:744) at org.springframework.boot.web.embedded.jetty.JettyEmbeddedWebAppContext$JettyEmbeddedServletHandler.deferredInitialize(JettyEmbeddedWebAppContext.java:46) at org.springframework.boot.web.embedded.jetty.JettyEmbeddedWebAppContext.deferredInitialize(JettyEmbeddedWebAppContext.java:36) at org.springframework.boot.web.embedded.jetty.JettyWebServer.handleDeferredInitialize(JettyWebServer.java:221) at org.springframework.boot.web.embedded.jetty.JettyWebServer.start(JettyWebServer.java:142) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.startWebServer(ServletWebServerApplicationContext.java:311) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.finishRefresh(ServletWebServerApplicationContext.java:164) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:552) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) at cn.escheduler.api.ApiApplicationServer.main(ApiApplicationServer.java:33) [INFO] 2019-07-11 09:30:53.068 org.eclipse.jetty.server.session:[167] - node0 Stopped scavenging [INFO] 2019-07-11 09:30:53.075 org.eclipse.jetty.server.handler.ContextHandler.application:[2345] - Destroying Spring FrameworkServlet 'dispatcherServlet' [INFO] 2019-07-11 09:30:53.076 org.eclipse.jetty.server.handler.ContextHandler:[1045] - Stopped o.s.b.w.e.j.JettyEmbeddedWebAppContext@164642a4{application,/escheduler,[file:///tmp/jetty-docbase.5198879188764957027.12345/, jar:file:/opt/escheduler/escheduler-backend/lib/springfox-swagger-ui-2.9.2.jar!/META-INF/resources, jar:file:/opt/escheduler/escheduler-backend/lib/swagger-bootstrap-ui-1.9.3.jar!/META-INF/resources],UNAVAILABLE} [INFO] 2019-07-11 09:30:53.091 org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener:[142] -   Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. [ERROR] 2019-07-11 09:30:53.100 org.springframework.boot.SpringApplication:[858] - Application run failed org.springframework.boot.web.server.WebServerException: Unable to start embedded Jetty server at org.springframework.boot.web.embedded.jetty.JettyWebServer.start(JettyWebServer.java:168) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.startWebServer(ServletWebServerApplicationContext.java:311) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.finishRefresh(ServletWebServerApplicationContext.java:164) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:552) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) at cn.escheduler.api.ApiApplicationServer.main(ApiApplicationServer.java:33) Caused by: javax.servlet.ServletException: jsp@19c47==org.apache.jasper.servlet.JspServlet,jsp=null,order=3,inst=false,async=true at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:693) at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:429) at org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:750) at java.util.stream.SortedOps$SizedRefSortingSink.end(SortedOps.java:352) at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) at java.util.stream.StreamSpliterators$WrappingSpliterator.forEachRemaining(StreamSpliterators.java:312) at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:743) at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:744) at org.springframework.boot.web.embedded.jetty.JettyEmbeddedWebAppContext$JettyEmbeddedServletHandler.deferredInitialize(JettyEmbeddedWebAppContext.java:46) at org.springframework.boot.web.embedded.jetty.JettyEmbeddedWebAppContext.deferredInitialize(JettyEmbeddedWebAppContext.java:36) at org.springframework.boot.web.embedded.jetty.JettyWebServer.handleDeferredInitialize(JettyWebServer.java:221) at org.springframework.boot.web.embedded.jetty.JettyWebServer.start(JettyWebServer.java:142) ... 10 common frames omitted Caused by: java.lang.NullPointerException: null at org.apache.jasper.compiler.Localizer.getMessage(Localizer.java:150) at org.apache.jasper.compiler.Localizer.getMessage(Localizer.java:76) at org.apache.jasper.EmbeddedServletOptions.&lt;init&gt;(EmbeddedServletOptions.java:588) at org.apache.jasper.servlet.JspServlet.init(JspServlet.java:98) at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:672) ... 24 common frames omitted [INFO] 2019-07-11 09:30:53.106 org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor:[208] - Shutting down ExecutorService 'applicationTaskExecutor' [INFO] 2019-07-11 09:30:53.133 com.alibaba.druid.pool.DruidDataSource:[1928] - {dataSource-1} closed ```  以及 `escheduler-api-server-slave1.out` 文件的错误日志  ``` 09:30:35,688 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml] 09:30:35,689 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.groovy] 09:30:35,689 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Found resource [logback.xml] at [file:/opt/escheduler/escheduler-backend/conf/logback.xml] 09:30:35,691 |-WARN in ch.qos.logback.classic.LoggerContext[default] - Resource [logback.xml] occurs multiple times on the classpath. 09:30:35,691 |-WARN in ch.qos.logback.classic.LoggerContext[default] - Resource [logback.xml] occurs at [jar:file:/opt/escheduler/escheduler-backend/lib/escheduler-api-1.0.4-SNAPSHOT.jar!/logback.xml] 09:30:35,691 |-WARN in ch.qos.logback.classic.LoggerContext[default] - Resource [logback.xml] occurs at [file:/opt/escheduler/escheduler-backend/conf/logback.xml] 09:30:36,046 |-INFO in ch.qos.logback.classic.joran.action.ConfigurationAction - debug attribute not set 09:30:36,067 |-INFO in ch.qos.logback.classic.joran.action.ConfigurationAction - Will scan for changes in [file:/opt/escheduler/escheduler-backend/conf/logback.xml]  09:30:36,067 |-INFO in ch.qos.logback.classic.joran.action.ConfigurationAction - Setting ReconfigureOnChangeTask scanning period to 2 minutes 09:30:36,071 |-INFO in ch.qos.logback.classic.joran.action.LoggerAction - Setting level of logger [org.apache.zookeeper] to WARN 09:30:36,071 |-INFO in ch.qos.logback.classic.joran.action.LoggerAction - Setting level of logger [org.apache.hbase] to WARN 09:30:36,071 |-INFO in ch.qos.logback.classic.joran.action.LoggerAction - Setting level of logger [org.apache.hadoop] to WARN 09:30:36,082 |-INFO in ch.qos.logback.core.joran.action.AppenderAction - About to instantiate appender of type [ch.qos.logback.core.ConsoleAppender] 09:30:36,086 |-INFO in ch.qos.logback.core.joran.action.AppenderAction - Naming appender as [STDOUT] 09:30:36,115 |-INFO in ch.qos.logback.core.joran.action.NestedComplexPropertyIA - Assuming default type [ch.qos.logback.classic.encoder.PatternLayoutEncoder] for [encoder] property 09:30:36,280 |-INFO in ch.qos.logback.core.joran.action.AppenderAction - About to instantiate appender of type [ch.qos.logback.core.rolling.RollingFileAppender] 09:30:36,292 |-INFO in ch.qos.logback.core.joran.action.AppenderAction - Naming appender as [APISERVERLOGFILE] 09:30:36,315 |-INFO in c.q.l.core.rolling.SizeAndTimeBasedRollingPolicy@1906808037 - Archive files will be limited to [64 MB] each. 09:30:36,319 |-INFO in c.q.l.core.rolling.SizeAndTimeBasedRollingPolicy@1906808037 - No compression will be used 09:30:36,321 |-INFO in c.q.l.core.rolling.SizeAndTimeBasedRollingPolicy@1906808037 - Will use the pattern logs/escheduler-api-server.%d{yyyy-MM-dd_HH}.%i.log for the active file 09:30:36,326 |-INFO in ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP@76329302 - The date pattern is 'yyyy-MM-dd_HH' from file name pattern 'logs/escheduler-api-server.%d{yyyy-MM-dd_HH}.%i.log'. 09:30:36,326 |-INFO in ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP@76329302 - Roll-over at the top of every hour. 09:30:36,331 |-INFO in ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP@76329302 - Setting initial period to Thu Jul 11 09:30:34 CST 2019 09:30:36,336 |-INFO in ch.qos.logback.core.joran.action.NestedComplexPropertyIA - Assuming default type [ch.qos.logback.classic.encoder.PatternLayoutEncoder] for [encoder] property 09:30:36,340 |-INFO in ch.qos.logback.core.rolling.RollingFileAppender[APISERVERLOGFILE] - Active log file name: logs/escheduler-api-server.log 09:30:36,340 |-INFO in ch.qos.logback.core.rolling.RollingFileAppender[APISERVERLOGFILE] - File property is set to [logs/escheduler-api-server.log] 09:30:36,341 |-INFO in ch.qos.logback.classic.joran.action.RootLoggerAction - Setting level of ROOT logger to INFO 09:30:36,341 |-INFO in ch.qos.logback.core.joran.action.AppenderRefAction - Attaching appender named [STDOUT] to Logger[ROOT] 09:30:36,342 |-INFO in ch.qos.logback.classic.joran.action.ConfigurationAction - End of configuration. 09:30:36,343 |-INFO in ch.qos.logback.classic.joran.JoranConfigurator@5e25a92e - Registering current configuration as safe fallback point     .   ____          _            __ _ _  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \ ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )   '  |____| .__|_| |_|_| |_\__, | / / / /  =========|_|==============|___/=/_/_/_/  :: Spring Boot ::        (v2.1.3.RELEASE)  java.util.MissingResourceException: Can't find bundle for base name org.apache.jasper.resources.LocalStrings, locale en_US at java.util.ResourceBundle.throwMissingResourceException(ResourceBundle.java:1564) at java.util.ResourceBundle.getBundleImpl(ResourceBundle.java:1387) at java.util.ResourceBundle.getBundle(ResourceBundle.java:773) at org.apache.jasper.compiler.Localizer.&lt;clinit&gt;(Localizer.java:36) at org.apache.jasper.EmbeddedServletOptions.&lt;init&gt;(EmbeddedServletOptions.java:588) at org.apache.jasper.servlet.JspServlet.init(JspServlet.java:98) at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:672) at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:429) at org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:750) at java.util.stream.SortedOps$SizedRefSortingSink.end(SortedOps.java:352) at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) at java.util.stream.StreamSpliterators$WrappingSpliterator.forEachRemaining(StreamSpliterators.java:312) at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:743) at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:744) at org.springframework.boot.web.embedded.jetty.JettyEmbeddedWebAppContext$JettyEmbeddedServletHandler.deferredInitialize(JettyEmbeddedWebAppContext.java:46) at org.springframework.boot.web.embedded.jetty.JettyEmbeddedWebAppContext.deferredInitialize(JettyEmbeddedWebAppContext.java:36) at org.springframework.boot.web.embedded.jetty.JettyWebServer.handleDeferredInitialize(JettyWebServer.java:221) at org.springframework.boot.web.embedded.jetty.JettyWebServer.start(JettyWebServer.java:142) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.startWebServer(ServletWebServerApplicationContext.java:311) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.finishRefresh(ServletWebServerApplicationContext.java:164) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:552) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) at cn.escheduler.api.ApiApplicationServer.main(ApiApplicationServer.java:33) ```   ，我如何才能解决这个问题呢？    当前版本是：  `dev` 最新版    我期望得到的结果是：  我能正常启动服务以及正常使用这个软件  </body>
		<created>2019-07-11 01:51:12</created>
		<closed>2019-08-12 03:02:09</closed>
	</bug>
	<bug>
		<id>532</id>
		<title>python node does not execute the problem(python节点不执行的问题)</title>
		<body>When creating a python node on escheduler, it was found that the execution did not report an error but the python task did not start.  --- 在escheduler上面创建python节点时发现执行不报错但是python任务并没有启动。</body>
		<created>2019-07-08 11:18:11</created>
		<closed>2019-07-09 03:42:42</closed>
	</bug>
	<bug>
		<id>525</id>
		<title>A worker exits, zk listens for an error(一个worker退出,zk监听报错)</title>
		<body>Environment: 1 worker, 1 api, 1 master are all on the same machine. Problem: Every time the worker is shut down, an error is reported in the master's zk listener: org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /escheduler/dead-servers/worker_xxxxxxxx See picture for details  ![企业微信截图_6f841e0b-6f1c-446e-aa6b-e8b5bf954dbd](https://user-images.githubusercontent.com/8623830/60695014-ca134900-9f12-11e9-89fd-3bf820d1f637.png)  --- 环境:1个worker、1个api、1个master都在同一台机器上。 问题:每次关闭worker,在master的zk监听中都会报错：org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /escheduler/dead-servers/worker_xxxxxxxx 详情请见图片  ![企业微信截图_6f841e0b-6f1c-446e-aa6b-e8b5bf954dbd](https://user-images.githubusercontent.com/8623830/60695014-ca134900-9f12-11e9-89fd-3bf820d1f637.png) </body>
		<created>2019-07-05 02:51:18</created>
		<closed>2019-09-02 07:12:40</closed>
	</bug>
	<bug>
		<id>517</id>
		<title>Complement - subworkflow - time parameter(补数 - 子工作流 - 时间参数)</title>
		<body>Scenario: Rerun a main workflow (including child workflows). The child workflow calls the global variables of the main workflow.  Problem: The global variable value of the child workflow does not change. It is always the first time value of the complement.  --- 场景:  重跑一个主工作流（包含子工作流）.  子工作流会调用主工作流的全局变量.  问题:  子工作流的全局变量值不会变. 始终是补数的第一时间值.</body>
		<created>2019-07-04 07:46:36</created>
		<closed>2019-07-08 12:30:53</closed>
	</bug>
	<bug>
		<id>516</id>
		<title>The task instance of MR cannot stop in some cases</title>
		<body>The task instance of MR cannot stop in some cases</body>
		<created>2019-07-04 04:51:57</created>
		<closed>2019-09-02 07:13:27</closed>
	</bug>
	<bug>
		<id>486</id>
		<title>The shell process exits, and the yarn state is not final.（shell进程退出，yarn状态非终态等待判断）</title>
		<body>When the shell task exits, the yarn task has not been completed, and the task will be determined to fail.  --- shell任务退出的时候，yarn任务还未完成，这时候会判定该任务失败。</body>
		<created>2019-06-25 10:00:58</created>
		<closed>2019-06-26 11:25:43</closed>
	</bug>
	<bug>
		<id>481</id>
		<title>offline schedule error</title>
		<body>![image](https://user-images.githubusercontent.com/15651066/60081029-9b071580-9763-11e9-8c26-1ee4ca961cb1.png) </body>
		<created>2019-06-25 08:10:03</created>
		<closed>2019-06-25 08:36:07</closed>
	</bug>
	<bug>
		<id>463</id>
		<title>Email verification does not support very rare suffix mailboxes（邮箱验证不支持非常见后缀邮箱）</title>
		<body>![555555555](https://user-images.githubusercontent.com/23161557/59562090-ebdb8780-905a-11e9-806c-0d3e6de91a76.png)  Email verification does not support very rare suffix mailboxes  --- ![555555555](https://user-images.githubusercontent.com/23161557/59562090-ebdb8780-905a-11e9-806c-0d3e6de91a76.png)  邮箱验证不支持非常见后缀邮箱</body>
		<created>2019-06-16 09:20:32</created>
		<closed>2019-07-15 09:08:44</closed>
	</bug>
	<bug>
		<id>431</id>
		<title>Version 1.0.3 cannot delete tenants（1.0.3版本无法删除租户）</title>
		<body>![image](https://user-images.githubusercontent.com/12029814/58945340-413fab00-87b6-11e9-95e1-e7f3994b8677.png) </body>
		<created>2019-06-05 09:20:56</created>
		<closed>2019-06-26 11:25:42</closed>
	</bug>
	<bug>
		<id>425</id>
		<title>停止工作流，并不能停止任务进程 (任务进程是常驻类型)</title>
		<body>启动es 进程：  这个进程会启动一个work 进程， work进程执行shell 任务，shell任务是一个常驻进程，它会创建自己的子进程。  停止es的进程，会kill掉worker进程，但是不会kill  shell 任务创建的子进程</body>
		<created>2019-06-04 04:00:08</created>
		<closed>2019-06-26 11:25:41</closed>
	</bug>
	<bug>
		<id>422</id>
		<title>After the resource file is edited, the update time has not changed!（资源文件被编辑后，更新时间没有变！）</title>
		<body></body>
		<created>2019-06-03 07:36:36</created>
		<closed>2019-06-26 11:25:41</closed>
	</bug>
	<bug>
		<id>419</id>
		<title>Create a file online, the hdfs file is not created, but it returns success（在线创建文件，hdfs文件未创建，却返回成功）</title>
		<body>Create a file online. If the hdfs path does not exist, the page returns successfully, and the database inserts data. Api module ResourcesService#uploadContentToHdfs()  --- 在线创建文件，如果hdfs路径不存在，页面返回成功，数据库插入数据 api模块 ResourcesService#uploadContentToHdfs()</body>
		<created>2019-05-31 10:47:41</created>
		<closed>2019-06-26 11:25:41</closed>
	</bug>
	<bug>
		<id>405</id>
		<title>Timely modify/add pages, start time and end time cannot be the same(定时修改/添加页面，开始时间和结束时间不能相同)</title>
		<body>Timely modify/add pages, start time and end time cannot be the same The same time will report an exception error.  --- 定时修改/添加页面，开始时间和结束时间不能相同 时间相同会报异常错误。</body>
		<created>2019-05-29 10:09:18</created>
		<closed>2019-07-08 12:31:16</closed>
	</bug>
	<bug>
		<id>394</id>
		<title>When the master&amp;worker is deployed on the same machine, if the master&amp;worker service is restarted, the previously scheduled tasks cannot be scheduled.（master&amp;worker部署在同一台机器上时，如果重启master&amp;worker服务，会导致之前调度的任务无法继续调度）</title>
		<body>Problem recurrence: When the master&amp;worker is deployed on the same machine, if the master&amp;worker service is restarted, the tasks in the previously run workflow instance will not be rescheduled and the task status cannot be changed.  From the UI, although the task is still running, the task process has actually been hung, because the task state cannot be modified, so it is always in the state before the restart (running). This is very confusing.  Recommendation: Capture the kill signal before stopping the master&amp;worker service. Make a snapshot of the current running state before stopping the service (probably related to the status of the task database and zk)  Then when the service is restarted, the snapshot is first checked, and if so, the tasks in the snapshot are restored.  --- 问题重现： master&amp;worker部署在同一台机器上时，如果重启master&amp;worker服务，之前运行的工作流实例中的任务都不会被重新调度，且任务状态无法改变。  从UI上看，虽然任务还是处于运行状态，但实际上任务进程已经挂了，因为任务状态无法修改，所以一直处于重启之前的状态(运行中)。这点很有迷惑性。  建议：在停止master&amp;worker服务前，捕获kill信号，在停止服务之前，给当前的运行状态做一个快照(可能是涉及到任务数据库和zk之类的状态保持)  然后在重启服务时，首先检查快照，如果有则恢复快照中的任务。  </body>
		<created>2019-05-29 03:30:23</created>
		<closed>2019-07-01 07:42:00</closed>
	</bug>
	<bug>
		<id>383</id>
		<title>sql mail does not display the blank line in front（ sql邮件不显示前面的空行）</title>
		<body>sql mail does not display the blank line in front  ---  sql邮件不显示前面的空行</body>
		<created>2019-05-27 12:19:45</created>
		<closed>2019-05-28 02:59:12</closed>
	</bug>
	<bug>
		<id>379</id>
		<title>When the scheduled task is resumed across days, the time parameter is incorrect.（跨天恢复执行定时任务时，时间参数不对）</title>
		<body>When the scheduled task fails, the time parameter is incorrect when the next day is restored.  --- 定时任务失败时，第二天恢复的时候，时间参数不对。 </body>
		<created>2019-05-27 10:24:59</created>
		<closed>2019-05-27 10:25:10</closed>
	</bug>
	<bug>
		<id>377</id>
		<title>Resource file renaming only when the description is modified will report the name already exists error（资源文件重命名只修改描述时会报名称已存在错误）</title>
		<body>Resource file renaming only when the description is modified will report the name already exists error  --- 资源文件重命名只修改描述时会报名称已存在错误</body>
		<created>2019-05-27 09:54:18</created>
		<closed>2019-05-27 09:54:39</closed>
	</bug>
	<bug>
		<id>324</id>
		<title>tasks state error when complementing data </title>
		<body>the task's state display error when the process run second day in complementing data mode.  ![image](https://user-images.githubusercontent.com/29528966/58096455-af596f00-7c07-11e9-899f-99c3c4dc77d1.png)</body>
		<created>2019-05-21 12:35:09</created>
		<closed>2019-05-27 07:54:43</closed>
	</bug>
	<bug>
		<id>305</id>
		<title>In the case of multiple network cards, the front-end installation script install-escheduler-ui.sh prompts the information incorrectly.（多块网卡的情况下前端安装脚本install-escheduler-ui.sh提示信息有误）</title>
		<body>Configure the install-escheduler-ui.sh script as follows: `# Configuring front-end access ports Esc_proxy="8888"  #Configuring the agent backend interface Esc_proxy_port="http://192.168.1.115:12345"  #本ip ip Esc_ipaddr='127.0.0.1'`  Then execute install-escheduler-ui.sh. On the device of the multi-NIC, the prompt information is incorrect: `Please visit the browser: http://192.168.1.115 172.17.0.1:8888`  The error indicates another network card 172.17.0.1.  My machine's network card information `[root@rbtnode1 esui]# ifconfig Docker0: flags=4099&lt;UP,BROADCAST,MULTICAST&gt; mtu 1500         Inet 172.17.0.1 netmask 255.255.0.0 broadcast 172.17.255.255         Ether 02:42:6a:f3:34:84 txqueuelen 0 (Ethernet)         RX packets 0 bytes 0 (0.0 B)         RX errors 0 dropped 0 overruns 0 frame 0         TX packets 0 bytes 0 (0.0 B)         TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0  Eno16780032: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500         Inet 192.168.1.115 netmask 255.255.255.0 broadcast 192.168.1.255         Inet6 fe80::20c:29ff:feaa:663 prefixlen 64 scopeid 0x20&lt;link&gt;         Ether 00:0c:29:aa:06:63 txqueuelen 1000 (Ethernet)         RX packets 646196 bytes 467950746 (446.2 MiB)         RX errors 0 dropped 211 overruns 0 frame 0         TX packets 341590 bytes 792160531 (755.4 MiB)         TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0  Lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536         Inet 127.0.0.1 netmask 255.0.0.0         Inet6 ::1 prefixlen 128 scopeid 0x10&lt;host&gt;         Loop txqueuelen 1000 (Local Loopback)         RX packets 990746 bytes 1294705355 (1.2 GiB)         RX errors 0 dropped 0 overruns 0 frame 0         TX packets 990746 bytes 1294705355 (1.2 GiB)         TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0`  --- 配置install-escheduler-ui.sh脚本如下： `# 配置前端访问端口 esc_proxy="8888"  # 配置代理后端接口 esc_proxy_port="http://192.168.1.115:12345"  # 本机ip esc_ipaddr='127.0.0.1'`  然后执行install-escheduler-ui.sh，在多网卡的设备上，提示信息有误： `请浏览器访问：http://192.168.1.115 172.17.0.1:8888`  错误提示出另外一个网卡172.17.0.1。  我机器的网卡信息 `[root@rbtnode1 esui]# ifconfig docker0: flags=4099&lt;UP,BROADCAST,MULTICAST&gt;  mtu 1500         inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255         ether 02:42:6a:f3:34:84  txqueuelen 0  (Ethernet)         RX packets 0  bytes 0 (0.0 B)         RX errors 0  dropped 0  overruns 0  frame 0         TX packets 0  bytes 0 (0.0 B)         TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0  eno16780032: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500         inet 192.168.1.115  netmask 255.255.255.0  broadcast 192.168.1.255         inet6 fe80::20c:29ff:feaa:663  prefixlen 64  scopeid 0x20&lt;link&gt;         ether 00:0c:29:aa:06:63  txqueuelen 1000  (Ethernet)         RX packets 646196  bytes 467950746 (446.2 MiB)         RX errors 0  dropped 211  overruns 0  frame 0         TX packets 341590  bytes 792160531 (755.4 MiB)         TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0  lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536         inet 127.0.0.1  netmask 255.0.0.0         inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;         loop  txqueuelen 1000  (Local Loopback)         RX packets 990746  bytes 1294705355 (1.2 GiB)         RX errors 0  dropped 0  overruns 0  frame 0         TX packets 990746  bytes 1294705355 (1.2 GiB)         TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0`</body>
		<created>2019-05-17 10:01:21</created>
		<closed>2019-05-27 07:55:09</closed>
	</bug>
	<bug>
		<id>300</id>
		<title>超时告警时间单位</title>
		<body>**Describe the bug** 创建流程的时候填写的超时时间单位是分，数据库存储的时间也是分，没有转化成毫秒，在代码中，运行时间的计算结果单位却是毫秒，所以每个流程运行都是会报超时错误  **To Reproduce** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error  **Expected behavior** A clear and concise description of what you expected to happen.  **Screenshots** ![image](https://user-images.githubusercontent.com/21357069/57829051-4ecdca80-77e0-11e9-98b7-944bb4fe5d4a.png)   **Additional context** Add any other context about the problem here. </body>
		<created>2019-05-16 05:41:54</created>
		<closed>2019-05-21 05:42:23</closed>
	</bug>
	<bug>
		<id>286</id>
		<title>worker register 127.0.0.1 problem</title>
		<body>**Describe the bug** worker register 127.0.0.1 IP cannot be recognized by the task, the program cannot be executed  **To Reproduce** Steps to reproduce the behavior:  1. environment: Linux 10-10-56-138 2.6.32-642.3.1.el6.centos.plus.x86_64; CentOS release 6.6; Front-end backend on the same device; Use Local storage;  2. start: sh ./bin/start_all.sh   3. worker grouping Create a new work group, ip is 192.168.10.101  4. Task uses this grouping Running error: task instance does not set host  5. Found worker and tasker configuration All registered as 127.0.0.1, but my installation configuration is 192.168.10.101   **Expected behavior** The program cannot be executed  **Screenshots**  ![2444](https://user-images.githubusercontent.com/8359848/57668267-661e8380-7639-11e9-810f-d46259099aa8.jpeg) ![2312](https://user-images.githubusercontent.com/8359848/57668268-661e8380-7639-11e9-838e-9182a40f979e.jpeg)         </body>
		<created>2019-05-14 03:11:24</created>
		<closed>2019-05-21 03:35:08</closed>
	</bug>
	<bug>
		<id>277</id>
		<title>save global parameters error</title>
		<body>edit the definition, click "save" button.   ![image](https://user-images.githubusercontent.com/29528966/57519301-81de0d00-734d-11e9-9c6d-3462a3a8cf1e.png)     delete the two parameters, then click "cancel". and save again.  ![image](https://user-images.githubusercontent.com/29528966/57519331-91f5ec80-734d-11e9-83d4-c4cd105093b8.png) </body>
		<created>2019-05-10 10:00:41</created>
		<closed>2019-05-27 05:49:47</closed>
	</bug>
	<bug>
		<id>272</id>
		<title>Administrator cannot generate token（管理员不能生成token）</title>
		<body></body>
		<created>2019-05-10 03:45:40</created>
		<closed>2019-05-27 07:55:23</closed>
	</bug>
	<bug>
		<id>266</id>
		<title>Stop process return: process definition 1 not on line</title>
		<body>![image](https://user-images.githubusercontent.com/6831829/57428946-16b50d80-725d-11e9-8463-2b51e8bb3214.png) </body>
		<created>2019-05-09 05:19:40</created>
		<closed>2019-05-21 05:51:12</closed>
	</bug>
	<bug>
		<id>256</id>
		<title>Child process parameter display exception（子父流程参数显示异常）</title>
		<body></body>
		<created>2019-05-07 06:29:20</created>
		<closed>2019-05-27 05:51:49</closed>
	</bug>
	<bug>
		<id>248</id>
		<title>MysqlUtil.java method realeaseResource spelling mistakes.（MysqlUtil.java 方法realeaseResource拼写失误）</title>
		<body>MysqlUtil.java method spelling error：realease--&gt;release。 public static void realeaseResource(ResultSet rs, PreparedStatement ps, Connection conn)  realeaseResource--&gt;releaseResource</body>
		<created>2019-05-06 00:54:49</created>
		<closed>2019-05-07 07:40:30</closed>
	</bug>
	<bug>
		<id>211</id>
		<title>Error executing script/del_zk_node.py, tab and space mixed（执行script/del_zk_node.py出错，tab和空格混用）</title>
		<body>Code 11 lines, tab and space mixed  --- 代码11行，tab和空格混用</body>
		<created>2019-04-28 03:54:05</created>
		<closed>2019-05-27 08:13:16</closed>
	</bug>
	<bug>
		<id>185</id>
		<title>Project deletion workflow definition still exists（项目删除工作流定义还存在）</title>
		<body>Delete the project and the workflow data still exists. Is there any need to add delete verification here? If there is a workflow under the project, can't I delete it?  --- 删除项目，工作流数据还存在。 这里是否需要增加删除验证，如果项目下有工作流，就不能删除呢？</body>
		<created>2019-04-27 04:33:06</created>
		<closed>2019-05-21 03:36:40</closed>
	</bug>
	<bug>
		<id>183</id>
		<title>Create a Chinese name for the Worker packet error（创建中文名称的Worker分组报错）</title>
		<body>The group name is Chinese name and the save will fail. ```   SQL: SELECT * FROM t_escheduler_worker_group WHERE (name = ?) ### Cause: java.sql.SQLException: Illegal mix of collations (latin1_swedish_ci, IMPLICIT) and (utf8_general_ci,COERCIBLE) for operation '=' ```  After analysis, it is judged whether the name has an error. ` at cn.escheduler.api.service.WorkerGroupService.checkWorkerGroupNameExists(WorkerGroupService.java:91) ~[classes/:na]`  View the table structure. ``` `name` varchar(256) CHARACTER SET latin1 DEFAULT NULL COMMENT 'group name',    `ip_list` varchar(256) CHARACTER SET latin1 DEFAULT NULL COMMENT 'worker address list',  ```  The reason is that the characters do not match, change the structure below to ok  --- 组名称为中文名称，保存会失败 ```  SQL: SELECT * FROM t_escheduler_worker_group WHERE (name = ?) ### Cause: java.sql.SQLException: Illegal mix of collations (latin1_swedish_ci,IMPLICIT) and (utf8_general_ci,COERCIBLE) for operation '=' ```  经过分析是在判断名称是否存在报错 `at cn.escheduler.api.service.WorkerGroupService.checkWorkerGroupNameExists(WorkerGroupService.java:91) ~[classes/:na]`  查看了表结构。 ``` `name` varchar(256) CHARACTER SET latin1 DEFAULT NULL COMMENT '组名称',   `ip_list` varchar(256) CHARACTER SET latin1 DEFAULT NULL COMMENT 'worker地址列表',  ```  原因就是字符不匹配，改下表结构就ok </body>
		<created>2019-04-27 03:55:46</created>
		<closed>2019-05-27 08:14:32</closed>
	</bug>
	<bug>
		<id>129</id>
		<title>In tenant management, special characters such as underscores in the tenant code cannot pass the check.（租户管理中，租户编码带下划线等特殊字符无法通过校验）</title>
		<body>According to the setting, the tenant code = linux user name. When the linux user name is underlined and other special characters, the tenant will be prompted [Please enter the English tenant code].  Temporary solution: directly modify the contents of the corresponding database table t_escheduler_tenant.  Expectations: Front-end validation logic can be optimized to allow for special characters.  --- 按照设定，租户编码=linux用户名，当linux用户名带下划线等特殊字符时，创建租户会提示【请输入英文租户编码】。  临时解决方案：直接修改对应数据库表t_escheduler_tenant的内容。  期望：前端校验逻辑可以优化下，允许特殊字符的情况。</body>
		<created>2019-04-24 09:10:55</created>
		<closed>2019-04-24 11:44:18</closed>
	</bug>
	<bug>
		<id>125</id>
		<title>The mobile phone number in the user account cannot be recognized. The latest number of Unicom number 166 begins.（用户账号中手机号无法识别联通最新号码166开头）</title>
		<body>As the title, the format will be incorrect.  --- 如题，会提示格式不对。</body>
		<created>2019-04-24 06:32:35</created>
		<closed>2019-04-24 11:45:45</closed>
	</bug>
	<bug>
		<id>100</id>
		<title>Schedule the who am i command, the log does not display（调度who am i命令，日志不显示）</title>
		<body>Create a simple shell task in ui and put it in the dag, the content is who am i, can be executed successfully, but the log of the task instance is not printed. No logs are displayed. At the same time, the log of escheduler's log server will print the following error: 16:14:04.366 [grpc-default-executor-8] INFO cn.escheduler.server.rpc.LoggerServer - log parameter path : /app/escheduler-bin/logs/3/9/22.log ,skipLine : 0, Limit : 10000 16:14:04.366 [grpc-default-executor-8] ERROR cn.escheduler.server.rpc.LoggerServer - read file failed : /app/escheduler-bin/logs/3/9/22.log java.nio.file.NoSuchFileException: /app/escheduler-bin/logs/3/9/22.log At sun.nio.fs.UnixException.translateToIOException(UnixException.java:86) At sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) At sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) At sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) At java.nio.file.Files.newByteChannel(Files.java:361) At java.nio.file.Files.newByteChannel(Files.java:407) At java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384) At java.nio.file.Files.newInputStream(Files.java:152) At java.nio.file.Files.newBufferedReader(Files.java:2784) At java.nio.file.Files.lines(Files.java:3744) At java.nio.file.Files.lines(Files.java:3785) At cn.escheduler.server.rpc.LoggerServer.readFile(LoggerServer.java:166) At cn.escheduler.server.rpc.LoggerServer.access$200(LoggerServer.java:38) At cn.escheduler.server.rpc.LoggerServer$LogViewServiceGrpcImpl.rollViewLog(LoggerServer.java:99) At cn.escheduler.rpc.LogViewServiceGrpc$MethodHandlers.invoke(LogViewServiceGrpc.java:418) At io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:171) At io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:272) At io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:650) At io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37) At io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123) At java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) At java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) At java.lang.Thread.run(Thread.java:748) 16:14:04.366 [grpc-default-worker-ELG-3-1] DEBUG io.grpc.netty.NettyServerHandler - [id: 0xaa5e2e06, L:/192.168.135.183:50051 - R:/192.168.135.183:52064] OUTBOUND HEADERS: streamId=3 headers=GrpcHttp2OutboundHeaders[:status: 200, content-type: application/grpc, grpc-status: 2] streamDependency=0 weight=16 exclusive=false padding=0 endStream=true Apr 22, 2019 4:14:04 PM io.grpc.internal.SerializingExecutor run SEVERE: Exception while executing runnable io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed@2a04a176 java.lang.NullPointerException At cn.escheduler.server.rpc.LoggerServer$LogViewServiceGrpcImpl.rollViewLog(LoggerServer.java:101) At cn.escheduler.rpc.LogViewServiceGrpc$MethodHandlers.invoke(LogViewServiceGrpc.java:418) At io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:171) At io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:272) At io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:650) At io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37) At io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123) At java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) At java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) At java.lang.Thread.run(Thread.java:748)   At present, only the am am i is detected, and other commands such as ls and pwd have no problem.  --- 在ui里创建一个最简单的shell 任务并放到dag中，内容为who am i，可以执行成功，但是查看任务实例的日志，并没有打印。显示没有日志。与此同时，escheduler的log server的日志会打印如下错误： 16:14:04.366 [grpc-default-executor-8] INFO cn.escheduler.server.rpc.LoggerServer - log parameter path : /app/escheduler-bin/logs/3/9/22.log ,skipLine : 0, limit : 10000 16:14:04.366 [grpc-default-executor-8] ERROR cn.escheduler.server.rpc.LoggerServer - read file failed : /app/escheduler-bin/logs/3/9/22.log java.nio.file.NoSuchFileException: /app/escheduler-bin/logs/3/9/22.log at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86) at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) at java.nio.file.Files.newByteChannel(Files.java:361) at java.nio.file.Files.newByteChannel(Files.java:407) at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384) at java.nio.file.Files.newInputStream(Files.java:152) at java.nio.file.Files.newBufferedReader(Files.java:2784) at java.nio.file.Files.lines(Files.java:3744) at java.nio.file.Files.lines(Files.java:3785) at cn.escheduler.server.rpc.LoggerServer.readFile(LoggerServer.java:166) at cn.escheduler.server.rpc.LoggerServer.access$200(LoggerServer.java:38) at cn.escheduler.server.rpc.LoggerServer$LogViewServiceGrpcImpl.rollViewLog(LoggerServer.java:99) at cn.escheduler.rpc.LogViewServiceGrpc$MethodHandlers.invoke(LogViewServiceGrpc.java:418) at io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:171) at io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:272) at io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:650) at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37) at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) 16:14:04.366 [grpc-default-worker-ELG-3-1] DEBUG io.grpc.netty.NettyServerHandler - [id: 0xaa5e2e06, L:/192.168.135.183:50051 - R:/192.168.135.183:52064] OUTBOUND HEADERS: streamId=3 headers=GrpcHttp2OutboundHeaders[:status: 200, content-type: application/grpc, grpc-status: 2] streamDependency=0 weight=16 exclusive=false padding=0 endStream=true Apr 22, 2019 4:14:04 PM io.grpc.internal.SerializingExecutor run SEVERE: Exception while executing runnable io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed@2a04a176 java.lang.NullPointerException at cn.escheduler.server.rpc.LoggerServer$LogViewServiceGrpcImpl.rollViewLog(LoggerServer.java:101) at cn.escheduler.rpc.LogViewServiceGrpc$MethodHandlers.invoke(LogViewServiceGrpc.java:418) at io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:171) at io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:272) at io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:650) at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37) at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)   目前测出只有who am i为如此，其他命令如ls和pwd之类的都没有问题</body>
		<created>2019-04-22 08:24:04</created>
		<closed>2019-04-24 02:11:44</closed>
	</bug>
	<bug>
		<id>84</id>
		<title>The DAG graph can draw a ring diagram in some cases.（DAG图某些情况下可以画出环状图）</title>
		<body>The method of recurring, taking the SHELL node as an example: 1. Drag 4 shell nodes, the names are s1, s2, s3, s4 2. Connection method: s1-&gt;s3; s2-&gt;s3; s3-&gt;s4; s4-&gt;s2; s4-&gt;s1  --- 复现方法，以SHELL节点为例： 1.拖4个shell节点，名称分别为s1,s2,s3,s4 2.连接方法：s1-&gt;s3 ; s2-&gt;s3; s3-&gt;s4 ;s4-&gt;s2 ; s4-&gt;s1</body>
		<created>2019-04-19 03:47:46</created>
		<closed>2019-04-26 08:41:17</closed>
	</bug>
	<bug>
		<id>83</id>
		<title>1.0.1 version starts api server error java.lang.NoSuchFieldError: IS_SECURITY_ENABLED（1.0.1版本启动api server报错java.lang.NoSuchFieldError: IS_SECURITY_ENABLED）</title>
		<body>As shown below, api-log prints as follows: Error starting ApplicationContext. To display the auto-configuration report re-run your application with 'debug' enabled. [ERROR] 2019-04-19 00:07:28.550 org.springframework.boot.SpringApplication:[839] - Application startup failed java.lang.NoSuchFieldError: IS_SECURITY_ENABLED          At org.apache.jasper.compiler.JspRuntimeContext.&lt;init&gt;(JspRuntimeContext.java:197)          At org.apache.jasper.servlet.JspServlet.init(JspServlet.java:150)          At org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:643)          At org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:422)          At org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:892)   After analysis, remove jasper-runtime-5.5.23.jar from lib, api server can be started, it should be a jar problem, I do not know what is dependent on this jar  --- 如下所示，api-log打印如下： Error starting ApplicationContext. To display the auto-configuration report re-run your application with 'debug' enabled. [ERROR] 2019-04-19 00:07:28.550 org.springframework.boot.SpringApplication:[839] - Application startup failed java.lang.NoSuchFieldError: IS_SECURITY_ENABLED         at org.apache.jasper.compiler.JspRuntimeContext.&lt;init&gt;(JspRuntimeContext.java:197)         at org.apache.jasper.servlet.JspServlet.init(JspServlet.java:150)         at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:643)         at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:422)         at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:892)   经过分析，把jasper-runtime-5.5.23.jar从lib中移除，api server则可以启动，应该是jar的问题，不知是什么依赖引用了此jar</body>
		<created>2019-04-19 02:23:58</created>
		<closed>2019-05-27 08:16:22</closed>
	</bug>
</bugs>
