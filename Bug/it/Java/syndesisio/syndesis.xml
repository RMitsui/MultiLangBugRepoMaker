<?xml version="1.0" encoding="ISO-8859-1"?>

<bugs>
	<bug>
		<id>8888</id>
		<title>Import extensions is no longer working</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When I try to import any extension, the server log the following error trace: ``` 2020-08-04 10:33:25.490 ERROR 1 --- [  XNIO-1 task-3] .s.s.e.v.h.e.SyndesisRestExceptionMapper : An error has occurred while trying to process the technical extension. Please, check the input file. An error has occurred.  io.syndesis.server.endpoint.v1.SyndesisRestException: An error has occurred while trying to process the technical extension. Please, check the input file. An error has occurred. at io.syndesis.server.endpoint.v1.handler.extension.ExtensionHandler.upload(ExtensionHandler.java:187) ~[server-endpoint-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_181] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_181] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_181] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_181] at org.jboss.resteasy.core.MethodInjectorImpl.invoke(MethodInjectorImpl.java:151) ~[resteasy-core-4.4.2.Final.jar!/:4.4.2.Final] at org.jboss.resteasy.core.MethodInjectorImpl.lambda$invoke$3(MethodInjectorImpl.java:122) ~[resteasy-core-4.4.2.Final.jar!/:4.4.2.Final] at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:602) ~[na:1.8.0_181] at java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:614) ~[na:1.8.0_181] at java.util.concurrent.CompletableFuture.thenApply(CompletableFuture.java:1983) ~[na:1.8.0_181] at java.util.concurrent.CompletableFuture.thenApply(CompletableFuture.java:110) ~[na:1.8.0_181] at org.jboss.resteasy.core.MethodInjectorImpl.invoke(MethodInjectorImpl.java:122) ~[resteasy-core-4.4.2.Final.jar!/:4.4.2.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.internalInvokeOnTarget(ResourceMethodInvoker.java:594) ~[resteasy-core-4.4.2.Final.jar!/:4.4.2.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTargetAfterFilter(ResourceMethodInvoker.java:468) ~[resteasy-core-4.4.2.Final.jar!/:4.4.2.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.lambda$invokeOnTarget$2(ResourceMethodInvoker.java:421) ~[resteasy-core-4.4.2.Final.jar!/:4.4.2.Final] at org.jboss.resteasy.core.interception.jaxrs.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:363) ~[resteasy-core-4.4.2.Final.jar!/:4.4.2.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTarget(ResourceMethodInvoker.java:423) ~[resteasy-core-4.4.2.Final.jar!/:4.4.2.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:391) ~[resteasy-core-4.4.2.Final.jar!/:4.4.2.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.lambda$invoke$1(ResourceMethodInvoker.java:365) ~[resteasy-core-4.4.2.Final.jar!/:4.4.2.Final] at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:981) ~[na:1.8.0_181] at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2124) ~[na:1.8.0_181] at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:110) ~[na:1.8.0_181] at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:365) ~[resteasy-core-4.4.2.Final.jar!/:4.4.2.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:477) [resteasy-core-4.4.2.Final.jar!/:4.4.2.Final] at org.jboss.resteasy.core.SynchronousDispatcher.lambda$invoke$4(SynchronousDispatcher.java:252) [resteasy-core-4.4.2.Final.jar!/:4.4.2.Final] at org.jboss.resteasy.core.SynchronousDispatcher.lambda$preprocess$0(SynchronousDispatcher.java:153) [resteasy-core-4.4.2.Final.jar!/:4.4.2.Final] at org.jboss.resteasy.core.interception.jaxrs.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:363) ~[resteasy-core-4.4.2.Final.jar!/:4.4.2.Final] at org.jboss.resteasy.core.SynchronousDispatcher.preprocess(SynchronousDispatcher.java:156) [resteasy-core-4.4.2.Final.jar!/:4.4.2.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:238) [resteasy-core-4.4.2.Final.jar!/:4.4.2.Final] at org.jboss.resteasy.plugins.server.servlet.ServletContainerDispatcher.service(ServletContainerDispatcher.java:249) ~[resteasy-core-4.4.2.Final.jar!/:4.4.2.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:60) ~[resteasy-core-4.4.2.Final.jar!/:4.4.2.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:55) ~[resteasy-core-4.4.2.Final.jar!/:4.4.2.Final] at javax.servlet.http.HttpServlet.service(HttpServlet.java:590) ~[jakarta.servlet-api-4.0.3.jar!/:4.0.3] at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:92) ~[spring-web-5.2.5.RELEASE.jar!/:5.2.5.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.5.RELEASE.jar!/:5.2.5.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:320) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:126) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:90) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:118) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:158) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.authentication.preauth.AbstractPreAuthenticatedProcessingFilter.doFilter(AbstractPreAuthenticatedProcessingFilter.java:124) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.csrf.CsrfFilter.doFilterInternal(CsrfFilter.java:141) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.5.RELEASE.jar!/:5.2.5.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:92) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:77) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.5.RELEASE.jar!/:5.2.5.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.5.RELEASE.jar!/:5.2.5.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178) ~[spring-security-web-5.3.3.RELEASE.jar!/:5.3.3.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:358) ~[spring-web-5.2.5.RELEASE.jar!/:5.2.5.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:271) ~[spring-web-5.2.5.RELEASE.jar!/:5.2.5.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) ~[spring-web-5.2.5.RELEASE.jar!/:5.2.5.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.5.RELEASE.jar!/:5.2.5.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) ~[spring-web-5.2.5.RELEASE.jar!/:5.2.5.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.5.RELEASE.jar!/:5.2.5.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:109) ~[spring-boot-actuator-2.2.6.RELEASE.jar!/:2.2.6.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.5.RELEASE.jar!/:5.2.5.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) ~[spring-web-5.2.5.RELEASE.jar!/:5.2.5.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.5.RELEASE.jar!/:5.2.5.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.opentracing.contrib.web.servlet.filter.TracingFilter.doFilter(TracingFilter.java:189) ~[opentracing-web-servlet-filter-0.4.0.jar!/:na] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:68) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.servlet.handlers.RedirectDirHandler.handleRequest(RedirectDirHandler.java:68) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:132) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) ~[undertow-core-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) ~[undertow-core-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) ~[undertow-core-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:269) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:78) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:133) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:130) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:249) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:78) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:99) ~[undertow-servlet-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.server.Connectors.executeRootHandler(Connectors.java:376) ~[undertow-core-2.0.30.Final.jar!/:2.0.30.Final] at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) ~[undertow-core-2.0.30.Final.jar!/:2.0.30.Final] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_181] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_181] at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_181] Caused by: io.syndesis.common.util.SyndesisServerException: An error has occurred. at io.syndesis.common.util.SyndesisServerException.launderThrowable(SyndesisServerException.java:60) ~[common-util-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] at io.syndesis.common.util.SyndesisServerException.launderThrowable(SyndesisServerException.java:46) ~[common-util-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] at io.syndesis.extension.converter.DefaultBinaryExtensionAnalyzer.readPath(DefaultBinaryExtensionAnalyzer.java:103) ~[extension-converter-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] at io.syndesis.extension.converter.DefaultBinaryExtensionAnalyzer.doGetExtension(DefaultBinaryExtensionAnalyzer.java:85) ~[extension-converter-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] at io.syndesis.extension.converter.DefaultBinaryExtensionAnalyzer.getExtension(DefaultBinaryExtensionAnalyzer.java:52) ~[extension-converter-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] at io.syndesis.server.endpoint.v1.handler.extension.ExtensionHandler.extractExtension(ExtensionHandler.java:283) ~[server-endpoint-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] at io.syndesis.server.endpoint.v1.handler.extension.ExtensionHandler.upload(ExtensionHandler.java:133) ~[server-endpoint-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] ... 124 common frames omitted Suppressed: org.skife.jdbi.v2.exceptions.TransactionException: Failed to commit transaction at org.skife.jdbi.v2.tweak.transactions.LocalTransactionHandler.commit(LocalTransactionHandler.java:71) ~[jdbi-2.78.jar!/:2.78] at org.skife.jdbi.v2.BasicHandle.commit(BasicHandle.java:171) ~[jdbi-2.78.jar!/:2.78] at io.syndesis.server.filestore.impl.SqlFileStore$HandleCloserInputStream.close(SqlFileStore.java:353) ~[server-filestore-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] at io.syndesis.server.endpoint.v1.handler.extension.ExtensionHandler.extractExtension(ExtensionHandler.java:282) ~[server-endpoint-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] ... 125 common frames omitted Caused by: java.sql.SQLException: Connection is closed at com.zaxxer.hikari.pool.ProxyConnection$ClosedConnection.lambda$getClosedConnection$0(ProxyConnection.java:494) at com.sun.proxy.$Proxy119.commit(Unknown Source) at com.zaxxer.hikari.pool.ProxyConnection.commit(ProxyConnection.java:366) at com.zaxxer.hikari.pool.HikariProxyConnection.commit(HikariProxyConnection.java) at org.skife.jdbi.v2.tweak.transactions.LocalTransactionHandler.commit(LocalTransactionHandler.java:68) ... 128 common frames omitted Caused by: java.io.IOException: org.postgresql.util.PSQLException: ERROR: invalid large-object descriptor: 0 at org.postgresql.largeobject.BlobInputStream.read(BlobInputStream.java:110) ~[postgresql-42.2.11.jar!/:42.2.11] at java.io.InputStream.read(InputStream.java:170) ~[na:1.8.0_181] at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[na:1.8.0_181] at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[na:1.8.0_181] at java.io.PushbackInputStream.read(PushbackInputStream.java:186) ~[na:1.8.0_181] at java.util.zip.ZipInputStream.readFully(ZipInputStream.java:403) ~[na:1.8.0_181] at java.util.zip.ZipInputStream.readLOC(ZipInputStream.java:278) ~[na:1.8.0_181] at java.util.zip.ZipInputStream.getNextEntry(ZipInputStream.java:122) ~[na:1.8.0_181] at java.util.jar.JarInputStream.&lt;init&gt;(JarInputStream.java:83) ~[na:1.8.0_181] at java.util.jar.JarInputStream.&lt;init&gt;(JarInputStream.java:62) ~[na:1.8.0_181] at io.syndesis.extension.converter.DefaultBinaryExtensionAnalyzer.readPath(DefaultBinaryExtensionAnalyzer.java:101) ~[extension-converter-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] ... 128 common frames omitted ``` </body>
		<created>2020-08-04 10:41:10</created>
		<closed>2020-08-07 07:01:50</closed>
	</bug>
	<bug>
		<id>8811</id>
		<title>Errors in mail connector are not propagated anymore</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  This can be seen as part of #8776 for fixing the `SendMail_IT` integration test in particular.  The integration test is failing because the simulated error on the mail server is not propagated anymore. The Syndesis integration is triggered with a Webhook request and sends a mail message as part of the integration logic. The mail server simulates an error and this should be reflected in a Http 500 in the Webhook response to the calling client.  At the moment the mail server error is ignored and the Webhoook returns a 200 OK status code. This is why the test fails.</body>
		<created>2020-07-14 08:33:05</created>
		<closed>2020-07-29 14:01:51</closed>
	</bug>
	<bug>
		<id>8637</id>
		<title>DefaultValue is not set for the boolean returnBody in the api-provider</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [*] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Both the webhook and the api-connector are setting the defaultValue for 'returnBody' to *true*.   ``` "returnBody": { "order": 3, "componentProperty": false, "defaultValue": true, "deprecated": false, "displayName": "Include error message in the return body", "javaType": "Boolean", "kind": "parameter", "required": false, "secret": false, "type": "boolean" }, ```  When create a new integration with a webhook the check is indeed checked ![unnamed](https://user-images.githubusercontent.com/35576/83754484-53278880-a66c-11ea-8d2f-b7ba776e610d.png)  However it is *not* set when using the api-provider  ![unnamed-1](https://user-images.githubusercontent.com/35576/83754570-72261a80-a66c-11ea-905b-dbb3848630d4.png)  To reproduce 1. Create a new integration using the api-provider and configure the final step of any of the flows. See that the returnBody check is not set.</body>
		<created>2020-06-04 12:06:00</created>
		<closed>2020-07-30 10:32:23</closed>
	</bug>
	<bug>
		<id>8608</id>
		<title>[Verification] Unsupported/missing verification</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description While working on #7466 I noticed that the `UI` is not treating a verification `unsupported` status properly, showing any unsupported verification as `validated` instead:  ![unsupported_verification](https://user-images.githubusercontent.com/23169723/83391532-e5712780-a3f3-11ea-8d30-fbd302c37ef0.png)  The verification endpoint returns: ``` [{"status":"UNSUPPORTED","scope":"PARAMETERS","errors":[{"code":"unknown-connector","description":"No connector for ID i-M8PdK9xYED-7ijVaUwYz registered"}]}] ``` But the `UI` is showing as verified correctly. I suggest to either show an error or a warning mentioning the verification is not supported for that connector. </body>
		<created>2020-06-01 08:39:48</created>
		<closed>2020-06-10 18:01:24</closed>
	</bug>
	<bug>
		<id>8584</id>
		<title>[Camel 3.x] MongoDB integration cannot start</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Failure due to some missing runtime class: ``` *************************** APPLICATION FAILED TO START *************************** Description: An attempt was made to call a method that does not exist. The attempt was made from the following location:     org.apache.camel.component.mongodb.MongoDbEndpoint.initializeConnection(MongoDbEndpoint.java:245) The following method did not exist:     com.mongodb.client.MongoClient.getClusterDescription()Lcom/mongodb/connection/ClusterDescription; The method's class, com.mongodb.client.MongoClient, is available from the following locations:     jar:file:/deployments/project-0.1-SNAPSHOT.jar!/BOOT-INF/lib/mongo-java-driver-3.9.0.jar!/com/mongodb/client/MongoClient.class It was loaded from the following location:     jar:file:/deployments/project-0.1-SNAPSHOT.jar!/BOOT-INF/lib/mongo-java-driver-3.9.0.jar!/ ``` </body>
		<created>2020-05-28 07:24:22</created>
		<closed>2020-05-28 16:36:28</closed>
	</bug>
	<bug>
		<id>8519</id>
		<title>[Connection autodiscovery] Always showing a "connection modified" warning</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When we use the connection autodiscovery feature (available only for Kafka connector at the moment), we always have a warning notifying the user that the connection changed:  ![image](https://user-images.githubusercontent.com/23169723/82542501-5e4dc500-9b52-11ea-91e6-5526ba91e5ce.png)  I guess that the warning simply matches the `connection` json configuration stored in the database against the `integration` json configuration enriched with dynamic properties. This is a bit misleading as the connection did not really change.</body>
		<created>2020-05-21 09:05:49</created>
		<closed>2020-06-15 13:31:45</closed>
	</bug>
	<bug>
		<id>8501</id>
		<title>OpenAPI and absolute references</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ X ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Some openapi doesn't seem to be compatible with our connector and/or apicurio.  If I try for example https://services.interactive-instruments.de/t15/daraa/api?f=json I can, according to the UI, successfully create the connection (with warnings that don't prevent me to move on), but the server throws an error on the log and no connection is created.  If I try for example https://demo.pygeoapi.io/cite/openapi?f=json it throws an error, the UI tells me to contact the administrator but no clue what was wrong (except when taking a look at the log).  Exploring this issue on Gitter, @zregvart mentions absolute references may not be supported.  Looking either to show some indication on the UI on how to manually fix/why it doesn't work and/or make it work.</body>
		<created>2020-05-19 08:18:11</created>
		<closed>2020-08-29 08:41:08</closed>
	</bug>
	<bug>
		<id>8466</id>
		<title>Connection verifier is not using configuredProperties parameters</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  I am trying to add a `configuredProperties` into my connector, something like the following:  ```   "componentScheme": "kafka",   "configuredProperties": {     "transportProtocol": "PLAINTEXT" ...   "name": "Debezium CDC over Kafka",   "properties": {     "brokers": {       "componentProperty": true, ....     }   }, ``` I need to use the `transportProtocol` constant value both in `Verifier` and `Connection`. It seems that the verification POST is not adding those values in their body when called for a verification:  ![verifier_properties](https://user-images.githubusercontent.com/23169723/81922666-bb8ac900-95dc-11ea-85c1-de4b8c6552c0.png)  It results in a verification failure when it should not be.</body>
		<created>2020-05-14 10:19:06</created>
		<closed>2020-05-21 13:21:57</closed>
	</bug>
	<bug>
		<id>8317</id>
		<title>Cannot create a Connection from Extesions Connectors</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  I am trying to create a new connection from an imported extensions connector. As soon as I do that, the UI hang with an infinite loop of request to the json descriptor as shown in the snapshot:  ![extension-connector](https://user-images.githubusercontent.com/23169723/80106687-7a257180-857a-11ea-9860-1539c229d8f2.png)  Apparently the json descriptor is correct, neither I can see any error in server log.</body>
		<created>2020-04-23 13:54:27</created>
		<closed>2020-04-24 07:01:12</closed>
	</bug>
	<bug>
		<id>8296</id>
		<title>`syndesis-operator grant --cluster` error</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  If I run `syndesis-operator grant --cluster` I get:  ``` error: Object:   apiVersion: rbac.authorization.k8s.io/v1   kind: ClusterRoleBinding   metadata:     name: syndesis-installer-syndesis/syndesis-operator     namespace: default   roleRef:     apiGroup: rbac.authorization.k8s.io     kind: ClusterRole     name: syndesis-installer   subjects:   - apiGroup: rbac.authorization.k8s.io     kind: User     name: syndesis/syndesis-operator : ClusterRoleBinding.rbac.authorization.k8s.io "syndesis-installer-syndesis/syndesis-operator" is invalid: metadata.name: Invalid value: "syndesis-installer-syndesis/syndesis-operator": may not contain '/' ```  This is with [1.9.0](https://github.com/syndesisio/syndesis/releases/tag/1.9.0)</body>
		<created>2020-04-22 07:48:31</created>
		<closed>2020-04-23 09:56:11</closed>
	</bug>
	<bug>
		<id>8226</id>
		<title>Connections Screen Paging/Limit</title>
		<body>## This is a... [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  [ ] Documentation issue or request  ## The problem If more than 50 connections are created you lose access to some of them. This is because the XHR call to list connections uses a value of 50, (e.g `https://syndesis.apps.openshift.acme.com/api/v1/connections?per_page=50`) and the UI doesn't seem to support paging. The search box also operates on the 50 items stored in memory AFAICT so searching doesn't provide a workaround.  ## Expected behavior Users should be able to access all of their Connections.  ## Screenshot ![Screenshot 2020-04-08 at 10 45 01 AM](https://user-images.githubusercontent.com/1303687/78816550-bd7ebe00-7986-11ea-843b-b0b39ef222ac.png) ![Screenshot 2020-04-08 at 10 45 10 AM](https://user-images.githubusercontent.com/1303687/78816562-c1124500-7986-11ea-9641-bea8f81fb31a.png)   ## Request and Response Data N/A  ## API Endpoints and Schemas N/A  ## Tasks involved / Steps to Reproduce  1. Create more than 50 connections of any type. 2. Try to access them all. You will find some are not listed. </body>
		<created>2020-04-08 17:51:39</created>
		<closed>2020-07-18 06:10:16</closed>
	</bug>
	<bug>
		<id>8177</id>
		<title>Server query filter: object fallback not working</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  It seems there is an issue when trying to use the fallback method to filter base on a query parameter: https://github.com/syndesisio/syndesis/blob/master/app/server/endpoint/src/main/java/io/syndesis/server/endpoint/util/ReflectiveFilterer.java#L85   That method returns always null because there is a wrong check on the supertype: https://github.com/syndesisio/syndesis/blob/master/app/server/endpoint/src/main/java/io/syndesis/server/endpoint/util/ReflectionUtils.java#L51  Everything should be always fallback to `Object::toString`. Swapping the condition check in `ReflectionUtils` should solve the error.  </body>
		<created>2020-04-02 11:01:42</created>
		<closed>2020-04-02 13:37:01</closed>
	</bug>
	<bug>
		<id>8166</id>
		<title>No (pre-)releases on GitHub</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Seems the latest changes to the `release` command broke GitHub (pre-)releases. From 1.9.x daily release:  ``` Everything up-to-date ERROR: Cannot create release on remote github repository. Check if a release with the same tag already exists. ==== Pushing to GitHub * Pushing 1.9.0-20200401 ```</body>
		<created>2020-04-01 07:24:01</created>
		<closed>2020-04-01 15:43:33</closed>
	</bug>
	<bug>
		<id>8125</id>
		<title>Google Sheet skips empty values</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Hey,   I'm not 100% sure if it's a bug or a documentation issue. I'm exporting a table from Oracle (JDBC) to Google Sheets. The base table has some `null` values which get skipped by Google Sheets if I run the integration. Hence the next value gets inserted in this slot instead of it's original position. In between I run a Data Mapping step to connect the db columns with the spreadsheet ones. Because of this the data is not usefull for analysis anymore.  Is there any additional step to be done or is this a bug? </body>
		<created>2020-03-25 09:43:51</created>
		<closed>2020-04-03 08:10:30</closed>
	</bug>
	<bug>
		<id>8089</id>
		<title>[Camel 3.x] Prometheus failure when calling meta REST API</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Probably introduced by the new `camel` 3.x libraries upgrade. When calling a rest API it returns: ``` 2020-03-16 10:39:46.657 ERROR 1 --- [  XNIO-1 task-5] io.undertow.request: UT005023: Exception handling request to /api/v1/verifier/kafka ... 2020-03-16 10:33:23.560 ERROR 1 --- [  XNIO-1 task-4] io.undertow.request: UT005023: Exception handling request to /api/v1/connectors/kafka/properties/meta java.lang.IllegalArgumentException: Prometheus requires that all meters with the same name have the same set of tag keys. There is already an existing meter named 'http_server_requests_seconds' containing tag keys [method, status, uri]. The meter you are attempting to register has keys [exception, method, outcome, status, uri]. -- ``` See full [trace.log](https://github.com/syndesisio/syndesis/files/4337599/trace.log)  </body>
		<created>2020-03-16 10:40:48</created>
		<closed>2020-03-17 10:48:28</closed>
	</bug>
	<bug>
		<id>8088</id>
		<title>[Camel 3.x] Meta pod failure</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Meta pod is not able to start reporting: ``` Field camelContext in io.syndesis.connector.meta.v1.VerifierEndpoint required a bean of type 'org.apache.camel.ExtendedCamelContext' that could not be found. ```  [trace.log](https://github.com/syndesisio/syndesis/files/4337451/trace.log) </body>
		<created>2020-03-16 09:58:52</created>
		<closed>2020-03-17 09:07:11</closed>
	</bug>
	<bug>
		<id>8075</id>
		<title>Integration tests failing after Camel 3 upgrade</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Nightly integration tests are failing after the update to Camel 3.1. The integrations are not able to start. Integration container logs:  ``` *************************** APPLICATION FAILED TO START ***************************  Description:  An attempt was made to call a method that does not exist. The attempt was made from the following location:      org.apache.camel.spring.boot.CamelSpringBootBeanPostProcessor.&lt;init&gt;(CamelSpringBootBeanPostProcessor.java:27)  The following method did not exist:      org.apache.camel.spring.boot.CamelSpringBootBeanPostProcessor.setBindToRegistrySupported(Z)V  The method's class, org.apache.camel.spring.boot.CamelSpringBootBeanPostProcessor, is available from the following locations:      jar:file:/tmp/artifacts/m2/org/apache/camel/springboot/camel-spring-boot/3.1.0/camel-spring-boot-3.1.0.jar!/org/apache/camel/spring/boot/CamelSpringBootBeanPostProcessor.class  It was loaded from the following location:      file:/tmp/artifacts/m2/org/apache/camel/springboot/camel-spring-boot/3.1.0/camel-spring-boot-3.1.0.jar   Action:  Correct the classpath of your application so that it contains a single, compatible version of org.apache.camel.spring.boot.CamelSpringBootBeanPostProcessor ```  You can run the integration tests locally with:  ```bash $ syndesis -m s2i -i -f --docker $ syndesis integration-test ```  The error affects all integration tests so it may be good to analyze this with running the most simple integration test that we have:  ```bash $ syndesis integration-test -t io.syndesis.test.itest.timer.TimerToLog_IT#timeToLogExportTest ```  You can review the container logs at `syndesis/app/test/integration-test/target/integration-runtime.log`</body>
		<created>2020-03-12 10:08:07</created>
		<closed>2020-04-02 10:04:12</closed>
	</bug>
	<bug>
		<id>8056</id>
		<title>Micrometer filter breaking requests</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  I'm seeing this on the Camel-3.0.x branch.  ``` 15:59:24.814 [XNIO-1 task-2  ] ERROR io.undertow.request            - UT005023: Exception handling request to /api/v1/test-support/reset-db java.lang.IllegalArgumentException: Prometheus requires that all meters with the same name have the same set of tag keys. There is already an existing meter named 'http_server_requests_seconds' containing tag keys [method, status, uri]. The meter you are attempting to register has keys [exception, method, outcome, status, uri]. at io.micrometer.prometheus.PrometheusMeterRegistry.lambda$collectorByName$9(PrometheusMeterRegistry.java:382) at java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1877) at io.micrometer.prometheus.PrometheusMeterRegistry.collectorByName(PrometheusMeterRegistry.java:369) at io.micrometer.prometheus.PrometheusMeterRegistry.newTimer(PrometheusMeterRegistry.java:175) at io.micrometer.core.instrument.MeterRegistry.lambda$timer$2(MeterRegistry.java:271) at io.micrometer.core.instrument.MeterRegistry.getOrCreateMeter(MeterRegistry.java:576) at io.micrometer.core.instrument.MeterRegistry.registerMeterIfNecessary(MeterRegistry.java:529) at io.micrometer.core.instrument.MeterRegistry.timer(MeterRegistry.java:269) at io.micrometer.core.instrument.Timer$Builder.register(Timer.java:473) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.getTimer(WebMvcMetricsFilter.java:181) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.record(WebMvcMetricsFilter.java:143) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:124) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ```</body>
		<created>2020-03-09 16:35:20</created>
		<closed>2020-03-09 17:47:07</closed>
	</bug>
	<bug>
		<id>8052</id>
		<title>Unable to create Integration if Kafka is not currently running/active</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report   [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## The problem Unable to create an integration with Kafka if the broker/cluster is not currently active/running. To produce this issue try the following:  1. Create a connection of any type (this will be the start connection in the in integration) 2. Create a Kafka connection to a broker URL that doesn't exist/is not running 3. Create an Integration from the connection in step 1 to Kafka. When you select "Publish" messages to the topic "Something wrong" is shown (see attachment)  ## Expected behavior Should be able to create the Integration even if the Kafka broker/cluster is down.  ## Screenshot &lt;img width="1433" alt="Screenshot 2020-03-06 at 1 07 01 PM" src="https://user-images.githubusercontent.com/1303687/76122995-54cdab80-5fac-11ea-8c7b-c724f6680f1c.png"&gt;   ## Request and Response Data 400 response from https://HOSTNAME/api/v1/connections/i-M1le7YOaH8qq746bswFz/actions/io.syndesis:kafka-publish-action  ```json {     "inputDataShape": {         "kind": "any"     },     "outputDataShape": {         "kind": "none"     },     "propertyDefinitionSteps": [         {             "name": "Select the Kafka topic",             "properties": {                 "topic": {                     "order": 1,                     "componentProperty": false,                     "deprecated": false,                     "displayName": "Topic Name",                     "group": "common",                     "javaType": "java.lang.String",                     "kind": "path",                     "labelHint": "Select the Kafka topic to send data to.",                     "required": true,                     "secret": false,                     "type": "string"                 }             },             "description": "Specify Kafka topic name"         }     ],     "_meta": {         "message": "Connection to broker transactions-cluster-kafka-brokers.my-cluster.svc.cluster.local:9092 has failed.. Unable to fetch and process metadata",         "type": "DANGER"     } } ```  ## Tasks involved / Steps to Reproduce See above</body>
		<created>2020-03-06 21:17:17</created>
		<closed>2020-03-24 17:25:24</closed>
	</bug>
	<bug>
		<id>8038</id>
		<title>NPE at save of new API Client Connector</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Using this OpenAPI specification:  https://api.apis.guru/v2/specs/googleapis.com/dfareporting/v3.3/openapi.json  to create an API Client Connector and clicking Save leads to a NullPointerException in the syndesis-server:  ``` java.lang.NullPointerException: null at io.syndesis.server.api.generator.openapi.OpenApiParameterGenerator.createPropertyFromParameter(OpenApiParameterGenerator.java:86) ~[server-api-generator-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] at io.syndesis.server.api.generator.openapi.v3.Oas30ParameterGenerator.lambda$createConfigurationProperties$1(Oas30ParameterGenerator.java:49) ~[server-api-generator-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] at java.util.Optional.ifPresent(Optional.java:159) ~[na:1.8.0_181] at io.syndesis.server.api.generator.openapi.v3.Oas30ParameterGenerator.lambda$createConfigurationProperties$2(Oas30ParameterGenerator.java:49) ~[server-api-generator-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184) ~[na:1.8.0_181] at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ~[na:1.8.0_181] at java.util.Iterator.forEachRemaining(Iterator.java:116) ~[na:1.8.0_181] at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ~[na:1.8.0_181] at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ~[na:1.8.0_181] at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ~[na:1.8.0_181] at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151) ~[na:1.8.0_181] at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174) ~[na:1.8.0_181] at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[na:1.8.0_181] at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418) ~[na:1.8.0_181] at io.syndesis.server.api.generator.openapi.v3.Oas30ParameterGenerator.createConfigurationProperties(Oas30ParameterGenerator.java:47) ~[server-api-generator-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] at io.syndesis.server.api.generator.openapi.v3.Oas30ParameterGenerator.createConfigurationProperties(Oas30ParameterGenerator.java:33) ~[server-api-generator-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] at io.syndesis.server.api.generator.openapi.OpenApiParameterGenerator.addGlobalParameters(OpenApiParameterGenerator.java:45) ~[server-api-generator-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] at io.syndesis.server.api.generator.openapi.OpenApiConnectorGenerator.addGlobalParameters(OpenApiConnectorGenerator.java:318) ~[server-api-generator-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] at io.syndesis.server.api.generator.openapi.OpenApiConnectorGenerator.configureConnector(OpenApiConnectorGenerator.java:217) ~[server-api-generator-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] at io.syndesis.server.api.generator.openapi.OpenApiConnectorGenerator.generate(OpenApiConnectorGenerator.java:92) ~[server-api-generator-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] at io.syndesis.server.endpoint.v1.handler.connection.CustomConnectorHandler.lambda$create$1(CustomConnectorHandler.java:94) ~[server-endpoint-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] at io.syndesis.server.endpoint.v1.handler.connection.BaseConnectorGeneratorHandler.withGeneratorAndTemplate(BaseConnectorGeneratorHandler.java:49) ~[server-endpoint-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] at io.syndesis.server.endpoint.v1.handler.connection.CustomConnectorHandler.create(CustomConnectorHandler.java:93) ~[server-endpoint-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] ```  This is the request:  ```http POST /api/v1/connectors/custom HTTP/1.1 Accept: application/json,text/plain,*/* Content-Type: multipart/form-data; boundary=---------------------------9473194471271227221609302841 ```  And the response: ```http HTTP/1.1 500 Internal Server Error Cache-Control: no-cache, no-store, max-age=0, must-revalidate, proxy-revalidate, s-maxage=0 Content-Length: 133 Content-Type: application/json Date: Thu, 05 Mar 2020 09:45:41 GMT Gap-Auth: zregvart@cluster.local Gap-Upstream-Address: syndesis-server Strict-Transport-Security: max-age=31536000 ; includeSubDomains Syndesis-Xsrf-Token: awesome X-Content-Type-Options: nosniff X-Frame-Options: DENY X-Xss-Protection: 1; mode=block  {"errorCode":500,"userMsg":"Please contact the administrator and file a bug report","developerMsg":"Internal Server Exception. null"} ```</body>
		<created>2020-03-05 09:52:03</created>
		<closed>2020-03-05 13:34:03</closed>
	</bug>
	<bug>
		<id>8037</id>
		<title>Need to make an edit to have the Next button enabled</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; I'm creating an API client connector with OpenAPI specification from:  https://api.apis.guru/v2/specs/googleapis.com/dfareporting/v3.3/openapi.json  Which has values for Authorization URL and Access Token URL.  When I arrive at the step 3 Specify Security, I need to make an edit to either Authorization URL or Access Token URL to have the Next button enabled.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlisting the acceptance criteria. --&gt; Have the Next button enabled since the values are present.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![Screenshot_2020-03-05 Specify Security - Syndesis](https://user-images.githubusercontent.com/1306050/75968776-38f3d800-5ece-11ea-98f2-c470a7b2f4dc.png)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Click through the API Client Connectors workflow with the specification from above 2. Notice that on page 3, the Next is disabled even though the values are filled in </body>
		<created>2020-03-05 09:45:15</created>
		<closed>2020-03-05 13:18:50</closed>
	</bug>
	<bug>
		<id>8024</id>
		<title>Release tagging tags from `master` not from a release branch</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  When we perform `syndesis release` on the [daily CI releases](https://ci.fabric8.io/view/syndesis/job/syndesis-release-1.9.x-daily/) we seem to be creating a tag based on the `master` branch not on the `1.9.x` branch.  Having the tag based on the wrong branch makes me think that the tag for the release of 1.9.0 will not be pointing to the correct branch/change.  For example, this change: 5680129fc314f577a90acbf0fb37074896986ef6 was made on `master` but it's included in `1.9.1-20200229` tag.  When we fix this it would also make sense to remove the wrong daily tags, perhaps we can bulk remove all of the daily tags for all the releases other than `2.0.x`.  Thanks to @claudio4j for pointing this out.</body>
		<created>2020-03-04 10:10:29</created>
		<closed>2020-04-03 21:25:47</closed>
	</bug>
	<bug>
		<id>7504</id>
		<title>Issue with Strimzi discovery when no Strimzi is installed</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  I saw this on the staging cluster, I think the root cause might be that the Strimzi is not installed there. The call in the `meta` pod fails with:  ``` 2020-01-08 10:26:22.931 ERROR 1 --- [  XNIO-1 task-1] i.s.c.meta.VerifierExceptionMapper       : Exception while handling request: POST /api/v1/connectors/kafka/properties/meta  io.syndesis.common.util.SyndesisServerException: Error while performing the call to https://172.30.0.1:443/apis/kafka.strimzi.io/v1beta1/kafkas/ . Response code: 403. Unable to fetch and process metadata at io.syndesis.connector.support.verifier.api.MetadataRetrieval.handle(MetadataRetrieval.java:51) ~[connector-support-verifier-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] at io.syndesis.connector.meta.v1.ConnectorEndpoint.properties(ConnectorEndpoint.java:79) ~[classes!/:2.0-SNAPSHOT] ... Caused by: io.fabric8.kubernetes.client.KubernetesClientException: Error while performing the call to https://172.30.0.1:443/apis/kafka.strimzi.io/v1beta1/kafkas/ . Response code: 403 at io.fabric8.kubernetes.client.dsl.internal.RawCustomResourceOperationsImpl.makeCall(RawCustomResourceOperationsImpl.java:582) ~[kubernetes-client-4.6.1.jar!/:na] at io.fabric8.kubernetes.client.dsl.internal.RawCustomResourceOperationsImpl.list(RawCustomResourceOperationsImpl.java:338) ~[kubernetes-client-4.6.1.jar!/:na] at io.syndesis.connector.kafka.KafkaMetaDataRetrieval.fetchProperties(KafkaMetaDataRetrieval.java:92) ~[connector-kafka-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] at io.syndesis.connector.meta.v1.ConnectorEndpoint.properties(ConnectorEndpoint.java:74) ~[classes!/:2.0-SNAPSHOT] ```  That cascaded to the `server` pod as:  ``` 2020-01-08 15:08:00.608 ERROR 1 --- [  XNIO-1 task-6] .s.e.v.h.e.SyndesisServerExceptionMapper : Internal Server Exception. null  java.lang.NullPointerException: null at io.syndesis.server.endpoint.v1.handler.connection.ConnectorHandler.enrichWithDynamicProperties(ConnectorHandler.java:166) ~[server-endpoint-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] at io.syndesis.server.endpoint.v1.handler.connection.ConnectorHandler.get(ConnectorHandler.java:137) ~[server-endpoint-2.0-SNAPSHOT.jar!/:2.0-SNAPSHOT] ```</body>
		<created>2020-01-08 15:21:42</created>
		<closed>2020-01-10 10:50:53</closed>
	</bug>
	<bug>
		<id>7471</id>
		<title>[Usage Problem]The integration api with sort params</title>
		<body>Hello guys, I try to use the integration API to fetch list of Integrations which the URL path is `/api/v1/integrations`, But I got a problem  When I use this api with `sort` params like `/api/v1/integrations?sort=version`, then the response is  **Cannot find field %s in %s as int or String field**   I have already checked the IntegrationHandler, from L185-L194, here's the code  ```java      @Override     public ListResult&lt;IntegrationOverview&gt; list(final UriInfo uriInfo) {         final DataManager dataManager = getDataManager();         final ListResult&lt;Integration&gt; integrations = dataManager.fetchAll(Integration.class,             new ReflectiveSorter&lt;&gt;(Integration.class, new SortOptionsFromQueryParams(uriInfo)),             new PaginationFilter&lt;&gt;(new PaginationOptionsFromQueryParams(uriInfo)));          return ListResult.of(integrations.getItems().stream().map(i -&gt; integrationOverviewHelper.toCurrentIntegrationOverview(i))             .collect(Collectors.toList()));     } ```  And I have noticed that the error is relational with `ReflectiveSorter`, and the main code is   ```java      private Comparator&lt;T&gt; createDelegateComparator(Class&lt;T&gt; modelClass, String fieldName) {         Comparator&lt;T&gt; delegate = getIntComparator(modelClass, fieldName);         if (delegate != null) {             return delegate;         }          delegate = getStringComparator(modelClass, fieldName);         if (delegate != null) {             return delegate;         }          throw new IllegalArgumentException(String.format("Cannot find field %s in %s as int or String field",fieldName, modelClass.getName()));     } ```  That means the `ReflectiveSorter` will find the field with `get` method to get the value from the `Class&lt;T&gt; ` (aka `Integration.class` here), But the `Integration.class` doesn't have the file with `get` method in the type String or Int.  So, how to use the sort param in integrations fetch api ? feel free to tell me if I have missed some detail in docs or code </body>
		<created>2019-12-21 07:41:15</created>
		<closed>2019-12-23 11:32:43</closed>
	</bug>
	<bug>
		<id>7466</id>
		<title>[REST Swagger] Verification host with no scheme</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Validation should fail when creating a new API and the host is provided with no scheme: ![image](https://user-images.githubusercontent.com/23169723/71265136-e29ee080-2345-11ea-9b8a-0bb31b8cb869.png) If you go ahead with no scheme, then the issue will be thrown at runtime, as seen in #7460. </body>
		<created>2019-12-20 15:30:50</created>
		<closed>2020-06-01 08:57:46</closed>
	</bug>
	<bug>
		<id>7461</id>
		<title>Unable to clone syndesis git repo due to colon marks in file names ( Invalid argument )</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Could you please rename all files and directories with question marks (":") to simplify syndesis development/contribution on Windows OS. By default you can't use ":" in file names or directory names ( also the following reserved chars: &lt;&gt;:"/|?* https://docs.microsoft.com/ru-ru/windows/win32/fileio/naming-a-file?redirectedfrom=MSDN ). Similar issue with question marks: https://github.com/syndesisio/syndesis/issues/7241 Git clone error: &lt;pre&gt;&lt;code&gt; `fatal: cannot create directory at 'app/ui-react/syndesis/tapes/create-integration.spec.js/api/v1/connections/i-LkiT24SvERwF0KppRNIz/actions/i-LkAI0ut-OrgXelAq8JAz:4babf99c-6287-47bb-862c-da7d053338af': Invalid argument` &lt;/code&gt;&lt;/pre&gt;  </body>
		<created>2019-12-20 11:12:36</created>
		<closed>2020-04-02 08:17:30</closed>
	</bug>
	<bug>
		<id>7419</id>
		<title>Syndesis step extension fails when included in an integration with an API endpoint</title>
		<body>I am able to successfully import a custom step extensions and use it in an integration that does not include an API endpoint e.g.  Timer -&gt; custom step -&gt; log  If I import a Swagger doc and setup and API-based integration then try to include the custom step, the UI hangs and I see the following stacktrace in syndesis-server.log:  ``` 2019-12-16 16:36:10.422 ERROR [-,9c5044b9210ee566,9c5044b9210ee566,false] 1 --- [  XNIO-3 task-6] .s.e.v.h.e.EntityNotFoundExceptionMapper : Entity Not Found Exception null  javax.persistence.EntityNotFoundException: null at io.syndesis.server.endpoint.v1.operations.Getter.get(Getter.java:39) ~[server-endpoint-1.7.1-20190617.jar!/:1.7.1-20190617] at io.syndesis.server.endpoint.v1.handler.connection.ConnectorHandler.get(ConnectorHandler.java:117) ~[server-endpoint-1.7.1-20190617.jar!/:1.7.1-20190617] at io.syndesis.server.endpoint.v1.handler.connection.ConnectorHandler.getConnectorIcon(ConnectorHandler.java:136) ~[server-endpoint-1.7.1-20190617.jar!/:1.7.1-20190617] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_151] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_151] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151] at org.jboss.resteasy.core.ResourceLocatorInvoker.createResource(ResourceLocatorInvoker.java:69) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceLocatorInvoker.createResource(ResourceLocatorInvoker.java:48) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceLocatorInvoker.invoke(ResourceLocatorInvoker.java:99) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:443) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.lambda$invoke$4(SynchronousDispatcher.java:233) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.lambda$preprocess$0(SynchronousDispatcher.java:139) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:358) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.preprocess(SynchronousDispatcher.java:142) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:219) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.ServletContainerDispatcher.service(ServletContainerDispatcher.java:227) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:56) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:51) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) ~[javax.servlet-api-3.1.0.jar!/:3.1.0] at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:111) ~[spring-boot-actuator-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.security.web.authentication.preauth.AbstractPreAuthenticatedProcessingFilter.doFilter(AbstractPreAuthenticatedProcessingFilter.java:121) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.security.web.csrf.CsrfFilter.doFilterInternal(CsrfFilter.java:100) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:66) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) ~[spring-security-web-4.2.12.RELEASE.jar!/:4.2.12.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.cloud.sleuth.instrument.web.TraceFilter.doFilter(TraceFilter.java:186) ~[spring-cloud-sleuth-core-1.2.6.RELEASE.jar!/:1.2.6.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.micrometer.spring.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:106) ~[micrometer-spring-legacy-1.1.2.jar!/:1.1.2] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:103) ~[spring-boot-actuator-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.opentracing.contrib.web.servlet.filter.TracingFilter.doFilter(TracingFilter.java:165) ~[opentracing-web-servlet-filter-0.1.0.jar!/:na] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:65) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:132) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.server.Connectors.executeRootHandler(Connectors.java:336) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_151] at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_151] ```</body>
		<created>2019-12-16 17:44:13</created>
		<closed>2020-01-28 15:39:51</closed>
	</bug>
	<bug>
		<id>7253</id>
		<title>Unable to install via `syndesis minishift --install`</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  If I run `syndesis minishift --install` the script will be stuck in:  ``` Waiting for syndesis-operator to be scaled to 1 Sleeping 10s ... Sleeping 10s ... ```  This is because the DeploymentConfig for syndesis-operator is pointing to the internal OpenShift image registry which at that point cannot have the tag set in the `syndesis-operator` binary.  As a workaround one can build the operator using `./build.sh --image-build s2i`. And that will create the `latest` tag in the internal OpenShift image registry. So patching the syndesis-operator DeploymentConfig is also needed:  ``` $ oc patch dc syndesis-operator --type json -p '[{"op": "replace", "path": "/spec/triggers/0/imageChangeParams/from/name", "value": "syndesis-operator:latest"}]' # replace the tag 1.9.100-2019... with latest  ```</body>
		<created>2019-11-27 15:42:29</created>
		<closed>2019-12-09 12:43:39</closed>
	</bug>
	<bug>
		<id>7206</id>
		<title>syndesis bash completion seems to be broken</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Trying to enable bash completion for the syndesis script and got this error:  ``` $ source &lt;(tools/bin/syndesis completion bash) /home/lburgazz/work/redhat/dev/syndesis-go/src/github.com/syndesisio/syndesis/tools/bin/commands/release.bats: line 2: ./release: No such file or directory bash: /dev/fd/63: line 483: syntax error: unexpected end of file ```  </body>
		<created>2019-11-22 11:47:08</created>
		<closed>2019-12-04 08:33:27</closed>
	</bug>
	<bug>
		<id>7162</id>
		<title>Dynamic "any" datashape does not trigger "specify data type" step</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When creating an integration and using a connector whose dynamic datashape has kind `any` we don't trigger the "Specify Data Type" step to allow the user to specify a custom data type. The behavior is correct when the datashape `any` is static, as, for example webhook connector.  It applies to both input and output datashapes ![image](https://user-images.githubusercontent.com/23169723/69144768-6312bd00-0acc-11ea-8269-a3581c3b957e.png) You can see that it reports `json-schema` data type but the connector has `any` for both actions datashapes.  ## Steps to reproduce You can log to staging environment and create a source connection using the "mongodb" one actually present. Just use `test` as collection and the output datashape will be provided dynamically with `any`, but no step to specify is provided. </body>
		<created>2019-11-19 11:57:09</created>
		<closed>2019-11-19 23:14:10</closed>
	</bug>
	<bug>
		<id>7156</id>
		<title>Timer unexpectedly fires multiple times during startup</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I've built a simple integration triggered by a timer. The timer is set to fire every 1 hour and send a message to a slack channel. However, upon integration start I get unexpected multiple firings of the job. After startup is complete, the timer behaves as expected.   See the screenshot below.  Was using Fuse Online (as part of Integreatly 1.5.1 which I think means Syndesis 1.7.25).  ![cron-msgto-slack](https://user-images.githubusercontent.com/116840/69092559-a7458500-0a1a-11ea-87e9-5528e21cabb0.png)  </body>
		<created>2019-11-18 20:51:07</created>
		<closed>2019-12-03 07:54:18</closed>
	</bug>
	<bug>
		<id>7143</id>
		<title>System start time looks wrong</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description On staging, the duration seems right, but the start time doesn't look right:  ![image](https://user-images.githubusercontent.com/351660/68896723-1741cb80-06fa-11ea-8037-49554465457a.png)  The number that drives this (the `start` field) looks truncated to me in the data coming back:  ![image](https://user-images.githubusercontent.com/351660/68896817-49ebc400-06fa-11ea-8c06-2f31747c89e2.png)  Maybe this is a red herring 'cause it's staging, it'd be cool if someone could confirm this on another environment. </body>
		<created>2019-11-14 21:18:27</created>
		<closed>2019-11-27 20:17:46</closed>
	</bug>
	<bug>
		<id>7121</id>
		<title>Custom HTTP headers not set in custom API clients</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Seems that the whitelist of HTTP headers that are set on the HTTP request doesn't include the HTTP headers that are defined on the operation as header parameters.  Try creating a custom API client with a OpenAPI document with operation that contains a HTTP header parameter, that HTTP header parameter will not be passed to the service as it's not whitelisted.</body>
		<created>2019-11-12 11:32:46</created>
		<closed>2020-02-17 14:01:33</closed>
	</bug>
	<bug>
		<id>7120</id>
		<title>[Integration] Align spring boot dependency versio</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  At the moment we're compiling against Spring boot dependency version [1.5.16.RELEASE](https://github.com/syndesisio/syndesis/blob/master/app/pom.xml#L63) and we're using a runtime with [1.5.13.RELEASE](https://github.com/syndesisio/syndesis/blob/master/app/integration/bom/pom.xml#L30). </body>
		<created>2019-11-12 10:46:49</created>
		<closed>2020-02-17 14:01:32</closed>
	</bug>
	<bug>
		<id>6978</id>
		<title>Connector "pipe" actions</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description While working on documentation tasks I noticed that UI is not handling any connector action marked with the `pipe` pattern ([this is the only example found in our code base](https://github.com/syndesisio/syndesis/blob/master/app/connector/activemq/src/main/resources/META-INF/syndesis/connector/activemq.json#L293)).  ## How to reproduce Create a timer to log integration and then try to add a `pipe` action between them, at the moment the only one available is the activemq `io.syndesis.connector:connector-activemq-request`. This is not shown in the list of actions.</body>
		<created>2019-10-22 07:16:49</created>
		<closed>2019-10-25 13:04:31</closed>
	</bug>
	<bug>
		<id>6948</id>
		<title>Jackson version incompatibility</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Seems that the change in #6914 triggered a [nightly build failure](https://circleci.com/gh/syndesisio/syndesis/157090). We most likely are using two different versions of Jackson between Syndesis and integrations.  Perhaps it would be a good idea to remove dependency on syndesis/common-util from the integration runtime/connectors.  ``` 01:16:58.649 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT: Caused by: java.lang.NoSuchMethodError: com.fasterxml.jackson.databind.ObjectMapper.setDefaultPropertyInclusion(Lcom/fasterxml/jackson/annotation/JsonInclude$Value;)Lcom/fasterxml/jackson/databind/ObjectMapper; 01:16:58.649 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at io.syndesis.common.util.Json.&lt;clinit&gt; (Json.java:45) 01:16:58.650 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at io.syndesis.integration.runtime.IntegrationRouteBuilder.loadIntegration (IntegrationRouteBuilder.java:115) 01:16:58.650 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at io.syndesis.integration.runtime.IntegrationRouteBuilder.configure (IntegrationRouteBuilder.java:140) 01:16:58.651 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.apache.camel.builder.RouteBuilder.checkInitialized (RouteBuilder.java:462) 01:16:58.651 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.apache.camel.builder.RouteBuilder.configureRoutes (RouteBuilder.java:402) 01:16:58.651 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.apache.camel.builder.RouteBuilder.addRoutesToCamelContext (RouteBuilder.java:383) 01:16:58.654 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.apache.camel.impl.DefaultCamelContext$1.call (DefaultCamelContext.java:1027) 01:16:58.655 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.apache.camel.impl.DefaultCamelContext$1.call (DefaultCamelContext.java:1024) 01:16:58.655 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.apache.camel.impl.DefaultCamelContext.doWithDefinedClassLoader (DefaultCamelContext.java:3270) 01:16:58.656 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.apache.camel.impl.DefaultCamelContext.addRoutes (DefaultCamelContext.java:1024) 01:16:58.656 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at io.syndesis.integration.runtime.sb.IntegrationRuntimeAutoConfiguration$1.beforeApplicationStart (IntegrationRuntimeAutoConfiguration.java:93) 01:16:58.657 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.apache.camel.spring.boot.RoutesCollector.onApplicationEvent (RoutesCollector.java:152) 01:16:58.657 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.apache.camel.spring.boot.RoutesCollector.onApplicationEvent (RoutesCollector.java:57) 01:16:58.657 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener (SimpleApplicationEventMulticaster.java:172) 01:16:58.660 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener (SimpleApplicationEventMulticaster.java:165) 01:16:58.660 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent (SimpleApplicationEventMulticaster.java:139) 01:16:58.661 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.springframework.context.support.AbstractApplicationContext.publishEvent (AbstractApplicationContext.java:393) 01:16:58.661 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.springframework.context.support.AbstractApplicationContext.publishEvent (AbstractApplicationContext.java:399) 01:16:58.661 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.springframework.context.support.AbstractApplicationContext.publishEvent (AbstractApplicationContext.java:347) 01:16:58.663 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.springframework.context.support.AbstractApplicationContext.finishRefresh (AbstractApplicationContext.java:883) 01:16:58.663 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.finishRefresh (EmbeddedWebApplicationContext.java:144) 01:16:58.664 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.springframework.context.support.AbstractApplicationContext.refresh (AbstractApplicationContext.java:546) 01:16:58.664 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh (EmbeddedWebApplicationContext.java:122) 01:16:58.665 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration.createChildManagementContext (EndpointWebMvcAutoConfiguration.java:193) 01:16:58.667 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration.afterSingletonsInstantiated (EndpointWebMvcAutoConfiguration.java:156) 01:16:58.668 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons (DefaultListableBeanFactory.java:781) 01:16:58.668 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization (AbstractApplicationContext.java:867) 01:16:58.669 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.springframework.context.support.AbstractApplicationContext.refresh (AbstractApplicationContext.java:543) 01:16:58.676 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh (EmbeddedWebApplicationContext.java:122) 01:16:58.677 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.springframework.boot.SpringApplication.refresh (SpringApplication.java:693) 01:16:58.677 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.springframework.boot.SpringApplication.refreshContext (SpringApplication.java:360) 01:16:58.678 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.springframework.boot.SpringApplication.run (SpringApplication.java:303) 01:16:58.678 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.springframework.boot.SpringApplication.run (SpringApplication.java:1118) 01:16:58.680 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.springframework.boot.SpringApplication.run (SpringApplication.java:1107) 01:16:58.680 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at io.syndesis.example.Application.main (Application.java:13) 01:16:58.680 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method) 01:16:58.680 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62) 01:16:58.683 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43) 01:16:58.684 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at java.lang.reflect.Method.invoke (Method.java:498) 01:16:58.684 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at org.springframework.boot.maven.AbstractRunMojo$LaunchRunner.run (AbstractRunMojo.java:528) 01:16:58.684 [tc-okhttp-stream-788540094] INFO  INTEGRATION_RUNTIME_CONTAINER - STDOUT:     at java.lang.Thread.run (Thread.java:748) ```</body>
		<created>2019-10-18 07:35:33</created>
		<closed>2019-10-18 14:54:17</closed>
	</bug>
	<bug>
		<id>6880</id>
		<title>Duplicate connection message missing</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Creating a new connection using an existing name shows a generic `bad request` notification.  ![image](https://user-images.githubusercontent.com/23169723/66469792-d1557000-ea88-11e9-9df5-3c3d2b4ef6ca.png)  I suggest to use a specific message error as we got the value in the POST /connection/ response: ``` [{"error":"UniqueProperty","message":"Value 'MongoDB' is not unique","property":"create.obj.name"}] ```</body>
		<created>2019-10-09 09:36:42</created>
		<closed>2019-10-15 07:45:22</closed>
	</bug>
	<bug>
		<id>6872</id>
		<title>MongoDB intermittent junit test failure</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description There are intermittent failures in the `mongodb` connector junit test that cause builds to fail. I am noticing that with more frequency in the last weeks (ie, https://circleci.com/gh/syndesisio/syndesis/147220?utm_campaign=vcs-integration-link&amp;utm_medium=referral&amp;utm_source=github-checks-link). The embedded server provided is not able to properly stop in certain circumstances on CircleCI containers. Need some investigation to stabilize the unit test execution. </body>
		<created>2019-10-08 15:14:44</created>
		<closed>2019-10-10 09:19:41</closed>
	</bug>
	<bug>
		<id>6808</id>
		<title>AWSDDBMetadataAdapterTest::adaptTest is failing</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Fails intermittently with:  ``` [ERROR] Tests run: 2, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 2.236 s &lt;&lt;&lt; FAILURE! - in io.syndesis.connector.aws.ddb.metadata.AWSDDBMetadataAdapterTest [ERROR] adaptTest(io.syndesis.connector.aws.ddb.metadata.AWSDDBMetadataAdapterTest)  Time elapsed: 2.053 s  &lt;&lt;&lt; FAILURE! java.lang.AssertionError:   Expected: properties      but none found  at io.syndesis.connector.aws.ddb.metadata.AWSDDBMetadataAdapterTest.adaptTest(AWSDDBMetadataAdapterTest.java:97) ``` </body>
		<created>2019-09-30 22:30:40</created>
		<closed>2019-10-01 11:05:40</closed>
	</bug>
	<bug>
		<id>6527</id>
		<title>Error report </title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11572**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Using version 1.17.fuse-740001-redhat-00002, when publishing an integration there is a "View Logs" link next to the progress bar. Clicking on it, opens a new browser tab that says:  ![Screenshot 2019-09-05 at 14 08 21](https://user-images.githubusercontent.com/1889892/64340676-02a0d300-cfe7-11e9-8435-bcaf07469d91.png)  </body>
		<created>2019-09-05 12:11:48</created>
		<closed>2019-09-07 14:18:33</closed>
	</bug>
	<bug>
		<id>6501</id>
		<title>Migration Test, please ignore</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11347**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  </body>
		<created>2019-09-04 11:16:23</created>
		<closed>2019-09-04 11:27:49</closed>
	</bug>
	<bug>
		<id>6490</id>
		<title>Simple Syndesis build wipeout everything on minishift</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When I do a normal build of Syndesis e.g. using `syndesis build -f --clean` and when I am connected to a local minishift project at that time (`oc login -u developer`) the build wipeout everything I have on that minishift project.  You end up having just the operator deployment and nothing else in that project. Before that I had a full Syndesis installation with server, meta, db, ui, ... running on that minishift. </body>
		<created>2019-09-03 13:49:04</created>
		<closed>2019-12-11 12:27:34</closed>
	</bug>
	<bug>
		<id>6393</id>
		<title>Can't select Log step during create integration</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  In running some first-trial [E2E tests](https://github.com/syndesisio/syndesis/pull/6275) I noticed I can no longer use the Log step when creating an Integration. Confirmed on staging, using Chrome.  The page goes blank when selecting "Log" and in the browser console I get the following error: ``` auto-form.js:22 Uncaught TypeError: Cannot read property 'contextLoggingEnabled' of undefined     at auto-form.js:22     at Array.reduce (&lt;anonymous&gt;)     at sanitizeValues (auto-form.js:14)     at getInitialValues (auto-form.js:210)     at AutoForm (auto-form.js:823) [..] ```  and  ``` index.js:1437 The above error occurred in the &lt;AutoForm&gt; component:     in AutoForm (at WithConfigurationForm.tsx:127)     in WithConfigurationForm (at ConfigureStepPage.tsx:80)     in Route (created by WithRouteData)     in WithRouteData (at ConfigureStepPage.tsx:55)     in WithIntegrationHelpers (at ConfigureStepPage.tsx:53)     in ConfigureStepPage (at EditorApp.tsx:214) [..] ```  ## Screenshot/GIF  ![Kapture 2019-08-16 at 11 46 03](https://user-images.githubusercontent.com/3844502/63163017-1b3b5000-c01c-11e9-97e1-cdd3dd0bda5a.gif)  Eventually the blank page seems to display the error as well:  &lt;img width="1122" alt="Screenshot 2019-08-16 11 53 10" src="https://user-images.githubusercontent.com/3844502/63163196-a4528700-c01c-11e9-83a4-81041379d82d.png"&gt;  ## Steps to Reproduce 1. Go to Create Integration. 2. Select SQL or AMQ as start connection. Configure. 3. Select Log as end step.</body>
		<created>2019-08-16 10:57:50</created>
		<closed>2019-08-16 19:00:51</closed>
	</bug>
	<bug>
		<id>6384</id>
		<title>Local build failure</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Trying to build latest master branch with `syndesis build --clean --flash` brings me to the following error;  &lt;img width="1514" alt="Screen Shot 2019-08-15 at 8 43 35 AM" src="https://user-images.githubusercontent.com/5942899/63096909-1b185300-bf3d-11e9-85f0-bd0829b20353.png"&gt;  Is there a better command to use when building? If there's anything else I can provide to help diagnose please let me know!  Running macOS: 10.14.6 </body>
		<created>2019-08-15 13:16:30</created>
		<closed>2019-08-22 09:38:47</closed>
	</bug>
	<bug>
		<id>6382</id>
		<title>[camel-k] Namespace parameter required when trying to publish integration</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11383**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When I try to publish an integration in syndesis which is using camel-k, I get this error message right after publishing:  ``` 2019-08-15 10:51:46.854 ERROR [-,,,] 1 --- [tion Controller] i.s.s.c.i.BaseIntegrationController      : Error while processing integration status for integration i-LmJtuXIjG_aC1KZv6gsz:1 io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: GET at: https://kubernetes.default.svc/apis/camel.apache.org/v1alpha1/integrations/i-asdfsdaf . Message: Namespace parameter required.. Received status: Status(apiVersion=v1, code=400, details=null, kind=Status, message=Namespace parameter required., metadata=ListMeta(resourceVersion=null, selfLink=null, additionalProperties={}), reason=BadRequest, status=Failure, additionalProperties={}). at io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:472) ~[kubernetes-client-3.1.12.fuse-730022.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:411) ~[kubernetes-client-3.1.12.fuse-730022.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:381) ~[kubernetes-client-3.1.12.fuse-730022.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:344) ~[kubernetes-client-3.1.12.fuse-730022.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleGet(OperationSupport.java:313) ~[kubernetes-client-3.1.12.fuse-730022.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleGet(OperationSupport.java:296) ~[kubernetes-client-3.1.12.fuse-730022.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleGet(BaseOperation.java:780) ~[kubernetes-client-3.1.12.fuse-730022.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.BaseOperation.getMandatory(BaseOperation.java:196) ~[kubernetes-client-3.1.12.fuse-730022.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.BaseOperation.get(BaseOperation.java:163) ~[kubernetes-client-3.1.12.fuse-730022.jar!/:na] at io.syndesis.server.openshift.OpenShiftServiceImpl.getCR(OpenShiftServiceImpl.java:583) ~[server-openshift-1.8-SNAPSHOT.jar!/:1.8-SNAPSHOT] at io.syndesis.server.controller.integration.camelk.BaseCamelKHandler.getCamelkIntegration(BaseCamelKHandler.java:40) ~[server-controller-1.8-SNAPSHOT.jar!/:1.8-SNAPSHOT] at io.syndesis.server.controller.integration.camelk.CamelKPublishHandler.execute(CamelKPublishHandler.java:120) ~[server-controller-1.8-SNAPSHOT.jar!/:1.8-SNAPSHOT] at io.syndesis.server.controller.StateChangeHandler.execute(StateChangeHandler.java:33) ~[server-controller-1.8-SNAPSHOT.jar!/:1.8-SNAPSHOT] at io.syndesis.server.controller.integration.BaseIntegrationController.lambda$callStateChangeHandler$10(BaseIntegrationController.java:220) ~[server-controller-1.8-SNAPSHOT.jar!/:1.8-SNAPSHOT] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_151] at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_151] ``` I install syndesis with these commands: ``` syndesis install --setup --camel-k syndesis install --camel-k  syndesis kamel --activate syndesis kamel --configure syndesis kamel --sync-runtime syndesis kamel --sync-lib ``` if that's of any help while solving this issue, also I have to manually scale down the operator and sometimes add the integration: camel-k into the syndesis-server config, but I think that's implied in the commands before and i just always forget to scale the operator down :D </body>
		<created>2019-08-15 10:57:53</created>
		<closed>2019-09-07 10:19:13</closed>
	</bug>
	<bug>
		<id>6379</id>
		<title>Blank screen after select a Log step</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When selecting the Log step, an only blank screen is shown. In the Browser Log is error. ``` TypeError: "t is undefined"     s https://syndesis.192.168.42.85.nip.io/static/js/main.f85b70a4.chunk.js:1     s https://syndesis.192.168.42.85.nip.io/static/js/main.f85b70a4.chunk.js:1     getInitialValues https://syndesis.192.168.42.85.nip.io/static/js/main.f85b70a4.chunk.js:1     AutoForm https://syndesis.192.168.42.85.nip.io/static/js/main.f85b70a4.chunk.js:1     Zo https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     Ta https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     qc https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     Yc https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     ki https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     Si https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     xi https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     Qc https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     enqueueSetState https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     setState https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     e https://syndesis.192.168.42.85.nip.io/static/js/main.f85b70a4.chunk.js:1     s https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     _invoke https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     t https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     r https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     i https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1 2.8fe38986.chunk.js:1:3715997     dc https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     callback https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     oc https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     rc https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     Dc https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     Gc https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     ji https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     unstable_runWithPriority https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     ji https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     ki https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     Si https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     xi https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     Qc https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     enqueueSetState https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     setState https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     e https://syndesis.192.168.42.85.nip.io/static/js/main.f85b70a4.chunk.js:1     s https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     _invoke https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     t https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     r https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1     i https://syndesis.192.168.42.85.nip.io/static/js/2.8fe38986.chunk.js:1 ``` </body>
		<created>2019-08-15 10:48:55</created>
		<closed>2019-08-16 07:45:52</closed>
	</bug>
	<bug>
		<id>6375</id>
		<title>GUI hang up on json failure</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description While testing another fix, I stumbled upon the following. When the integration creation rest call is returning error messages (tested with 400 and 50x), the GUI hang on infinitely without providing any error message output.  ![image](https://user-images.githubusercontent.com/23169723/63014720-74c24400-be8f-11e9-9e6a-61fdb4d7ff7b.png)  _Originally posted by @squakez in https://github.com/syndesisio/syndesis/issues/6227#issuecomment-521192726_  ## Acceptance Criteria * should be able to display any error instead of hanging up.</body>
		<created>2019-08-14 15:31:52</created>
		<closed>2019-09-13 10:22:57</closed>
	</bug>
	<bug>
		<id>6372</id>
		<title>FHIR action page stuck loading</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11384**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;    ## Description 1. add FHIR connection when creating an integration 2. select a FHIR action - loading the action page stucks  ![FHIR_stuck](https://user-images.githubusercontent.com/8707251/63017969-f1f1b700-be97-11e9-91da-076d26049240.png)  </body>
		<created>2019-08-14 11:38:20</created>
		<closed>2019-09-07 10:21:59</closed>
	</bug>
	<bug>
		<id>6362</id>
		<title>Manage CI/CD UI doesn't check duplicates</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11386**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When I want to create a new tag with the same name as has the existed tag, I am able to click on Save button (however the tag is not created because the backend returns `400 "developerMsg":"Duplicate environment tag1"`).  When I want to rename a tag to the same name as has another tag, I am able to click on Save button and in the UI I see two duplicated tags. ![image](https://user-images.githubusercontent.com/16251792/62937432-e5545c80-bdcc-11e9-8bdd-d0b3e1ee8acd.png)  In the 1.7.x, the dialog for creating/updating the tag was checking whether the name is already used.  In the left side of the images is master, in the right side is 1.7.13 (CR3) Creating the tag with the same name: ![image](https://user-images.githubusercontent.com/16251792/62937209-3a43a300-bdcc-11e9-9de8-27f7446cf927.png) Updating to the same name: ![image](https://user-images.githubusercontent.com/16251792/62937332-96a6c280-bdcc-11e9-95d7-b087874222da.png)  The UI should check the duplicities as before. The endpoint `PUT .../api/v1/public/environments/&lt;tag&gt;` should check whether the name in params is not already used by another tag.  Step to reproduce: - Go to Manage CI/CD page - Create tag with name _tag1_ - Try to create _tag1_ again - Create tag with name _tag2_ - Try to rename _tag2_ to _tag1_</body>
		<created>2019-08-13 11:23:30</created>
		<closed>2019-09-07 10:23:18</closed>
	</bug>
	<bug>
		<id>6361</id>
		<title>Display Issue data mapper in Safari</title>
		<body>Looks like this - always..  &lt;img width="1354" alt="Screen Shot 2019-08-13 at 9 55 32 AM" src="https://user-images.githubusercontent.com/35576/62924528-95679c80-bdb0-11e9-8057-e324424ddf44.png"&gt; </body>
		<created>2019-08-13 07:56:27</created>
		<closed>2019-11-20 16:54:51</closed>
	</bug>
	<bug>
		<id>6360</id>
		<title>PublicAPI: Duplicate tag after import when tag already exists but integration not</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11387**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When I import exported integration with a tag which already exists in the Syndesis, the tag is duplicated. This happens only when the integration which will be imported is not in the Syndesis. E.g. I create Integration1 and tag1. I add tag1 to the Integration1 and export zip file according to that tag. `curl .../integrations/tag1/export.zip -O` After that, I delete Integration1. The tag1 still persist in the Syndesis ( fix for https://github.com/syndesisio/syndesis/issues/5917). I import back the exported zip file `curl .../integrations -F data=@export.zip -F environment=second` After that, the tag1 is duplicated. ![image](https://user-images.githubusercontent.com/16251792/62922759-77983880-bdac-11e9-89f0-54e79c51c022.png)  However, when I do the same steps but I don't delete the integration, the tag1 is not duplicated after importing. So it looks that this issue is caused by https://github.com/syndesisio/syndesis/issues/5917 fix.</body>
		<created>2019-08-13 07:32:46</created>
		<closed>2019-09-07 10:31:55</closed>
	</bug>
	<bug>
		<id>6357</id>
		<title>"No Data Available" as uptime when the published integration has not been triggered yet</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11388**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When no message comes to the integration, upltime is still set to "No Data Available". For example, when I have a integration Webhook to Log and I don't call webhook (e.g. for hour), the Uptime is still "No Data Available". When I call webhook, the Uptime is alredy shown.  Step to reproduce:  - Create and publish integration Webhook-to-log - Wait e.g. 5 minutes - Go to the Metrics tab in that integration. (Uptime is set to "No Data Available") - Trigger Webhook - Go to the Metrics tab in that integration. Uptime shows correct value.</body>
		<created>2019-08-12 14:14:11</created>
		<closed>2019-09-07 10:32:00</closed>
	</bug>
	<bug>
		<id>6329</id>
		<title>Cannot open Syndesis Web UI</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description After clicking on the route to the Syndesis Web UI and logging in, I see the following error page:  ![syndesis 192 168 42 132 nip io_](https://user-images.githubusercontent.com/1910095/62625944-a28e1280-b8fc-11e9-8e96-5a7502bae50a.png)  Using latest code from master.</body>
		<created>2019-08-07 13:20:06</created>
		<closed>2019-08-09 11:45:34</closed>
	</bug>
	<bug>
		<id>6328</id>
		<title>User is able to select any step when replacing the finish step</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11389**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When I delete the Finish step, I can choose any step I'd like. This is what I have by default: ![image](https://user-images.githubusercontent.com/46345469/62621104-5e5e3a80-b91b-11e9-866f-232d5c9cc6fd.png) After adding log and deleting it: ![image](https://user-images.githubusercontent.com/46345469/62621128-703fdd80-b91b-11e9-8e15-593e66124a83.png) After adding DB invoke procedure and deleting it: ![image](https://user-images.githubusercontent.com/46345469/62621163-864d9e00-b91b-11e9-854f-ed883aeee108.png) After adding split after the starting DB step: ![image](https://user-images.githubusercontent.com/46345469/62621200-9ebdb880-b91b-11e9-84b3-263b1fd559af.png)  </body>
		<created>2019-08-07 12:00:01</created>
		<closed>2019-09-07 10:32:05</closed>
	</bug>
	<bug>
		<id>6327</id>
		<title>"Top 5 by messages errors" panel in the Integration-home grafana dashboard doesn't show data</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Grafana integrations home dashboard doesn't show any data in the `Top 5 by messages errors` panel even though one integration is still failing. ![image](https://user-images.githubusercontent.com/16251792/62619990-64065100-b918-11e9-8946-91d2a09212b3.png) ![image](https://user-images.githubusercontent.com/16251792/62620014-72546d00-b918-11e9-8dfb-8549ccd23ecf.png) Integration for debugging (every 30 seconds the integration wants to create an invalid item in DB which causes an error): [integrationWithError-export.zip](https://github.com/syndesisio/syndesis/files/3476765/integrationWithError-export.zip)   </body>
		<created>2019-08-07 11:41:29</created>
		<closed>2019-08-13 19:56:25</closed>
	</bug>
	<bug>
		<id>6326</id>
		<title>"Something is wrong" with Basic filter (while using OData)</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  When I tried to use the `Basic filter` step, I got ![image](https://user-images.githubusercontent.com/46523434/62602260-a4070d00-b8f3-11e9-8d3d-d03b70bd8f9b.png)  That happened while playing with OData connector, trying to create integration consisting of: OData (Read) -&gt; Basic filter -&gt; Data Mapper -&gt; OData (Update)  the server pod log is throwing exception: ```  2019-08-07 07:37:43.694 ERROR [-,67c241d1125633d7,67c241d1125633d7,false] 1 --- [  XNIO-3 task-3] .s.e.v.h.e.SyndesisServerExceptionMapper : Internal Server Exception. null --  | java.lang.NullPointerException: null  | at io.syndesis.server.inspector.JsonSchemaInspector.fetchPaths(JsonSchemaInspector.java:105) ~[server-inspector-1.7.13.jar!/:1.7.13]  | at io.syndesis.server.inspector.JsonSchemaInspector.getPaths(JsonSchemaInspector.java:75) ~[server-inspector-1.7.13.jar!/:1.7.13]  | at io.syndesis.server.inspector.DefaultInspectors.getPaths(DefaultInspectors.java:40) ~[server-inspector-1.7.13.jar!/:1.7.13]  | at io.syndesis.server.endpoint.v1.handler.integration.IntegrationHandler.getFilterOptions(IntegrationHandler.java:154) ~[server-endpoint-1.7.13.jar!/:1.7.13]  | at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_151]  | at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_151]  | at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151]  | at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151]  | at org.jboss.resteasy.core.MethodInjectorImpl.invoke(MethodInjectorImpl.java:140) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]  | at org.jboss.resteasy.core.ResourceMethodInvoker.internalInvokeOnTarget(ResourceMethodInvoker.java:509) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]  | at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTargetAfterFilter(ResourceMethodInvoker.java:399) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]  | at org.jboss.resteasy.core.ResourceMethodInvoker.lambda$invokeOnTarget$0(ResourceMethodInvoker.java:363) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]  | at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:358) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]  | at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTarget(ResourceMethodInvoker.java:365) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]  | at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:337) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]  | at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:310) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]  | at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:443) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]  | at org.jboss.resteasy.core.SynchronousDispatcher.lambda$invoke$4(SynchronousDispatcher.java:233) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]  | at org.jboss.resteasy.core.SynchronousDispatcher.lambda$preprocess$0(SynchronousDispatcher.java:139) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]  | at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:358) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]  | at org.jboss.resteasy.core.SynchronousDispatcher.preprocess(SynchronousDispatcher.java:142) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]  | at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:219) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]  | at org.jboss.resteasy.plugins.server.servlet.ServletContainerDispatcher.service(ServletContainerDispatcher.java:227) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]  | at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:56) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]  | at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:51) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]  | at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) ~[javax.servlet-api-3.1.0.jar!/:3.1.0]  | at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:111) ~[spring-boot-actuator-1.5.16.RELEASE.jar!/:1.5.16.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.security.web.authentication.preauth.AbstractPreAuthenticatedProcessingFilter.doFilter(AbstractPreAuthenticatedProcessingFilter.java:121) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.security.web.csrf.CsrfFilter.doFilterInternal(CsrfFilter.java:124) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:66) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE]  | at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE]  | at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at org.springframework.cloud.sleuth.instrument.web.TraceFilter.doFilter(TraceFilter.java:186) ~[spring-cloud-sleuth-core-1.2.6.RELEASE.jar!/:1.2.6.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.micrometer.spring.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:106) ~[micrometer-spring-legacy-1.1.2.jar!/:1.1.2]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:103) ~[spring-boot-actuator-1.5.16.RELEASE.jar!/:1.5.16.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.opentracing.contrib.web.servlet.filter.TracingFilter.doFilter(TracingFilter.java:165) ~[opentracing-web-servlet-filter-0.1.0.jar!/:na]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:65) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:132) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]  | at io.undertow.server.Connectors.executeRootHandler(Connectors.java:336) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final]  | at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_151]  | at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_151]  | at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_151]   ```  This is not happening while doing integration for example: SQL (SELECT * FROM todo) -&gt; split -&gt; basic filter-&gt; log  I've tried to use the split results option in OData read step as well as split step, but neither of them would enable the functionality of `Basic filter` and every time it throws `Something is wrong`.  This seems to be a problem at OData connector side.</body>
		<created>2019-08-07 07:45:51</created>
		<closed>2019-08-13 12:27:51</closed>
	</bug>
	<bug>
		<id>6323</id>
		<title>[MongoDB Connector] Meta exception thrown</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  ``` 2019-08-06 13:54:21.056  INFO 1 --- [localhost:27017] org.mongodb.driver.cluster               : Exception in monitor thread while connecting to server localhost:27017 com.mongodb.MongoSocketOpenException: Exception opening socket at com.mongodb.connection.SocketStream.open(SocketStream.java:63) ~[mongo-java-driver-3.4.3.jar!/:na] at com.mongodb.connection.InternalStreamConnection.open(InternalStreamConnection.java:115) ~[mongo-java-driver-3.4.3.jar!/:na] at com.mongodb.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:113) ~[mongo-java-driver-3.4.3.jar!/:na] ```  Likely due to missing autoconfiguration spring boot loader.  AC: exception is no longer shown in meta startup load.</body>
		<created>2019-08-06 15:38:30</created>
		<closed>2019-09-12 12:43:03</closed>
	</bug>
	<bug>
		<id>6319</id>
		<title>Create new connection - connection list items are way too large</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11390**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description You can probably see what's wrong in the GIF: ![Peek 2019-08-06 15-10](https://user-images.githubusercontent.com/46345469/62542606-64d9ad00-b85c-11e9-93e4-fa8ae9c857d9.gif) Something made the connector cards way too wide and the loading icon looked also somewhat enlarged? (I am almost sure I remember it being a spinning circle, not a huge grey circle :smiley: ) </body>
		<created>2019-08-06 13:14:59</created>
		<closed>2019-09-07 10:32:14</closed>
	</bug>
	<bug>
		<id>6318</id>
		<title>Database Invoke stored procedure action dropdown is empty in configuration</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11392**  See also **https://issues.jboss.org/browse/ENTESB-11391**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The invoke stored procedure action configuration form dropdown is empty when I click on the configure button of once added step. ## Steps to reproduce Create DB stored procedure action:  ![image](https://user-images.githubusercontent.com/46345469/62540465-f98ddc00-b857-11e9-9d94-a51c972707e9.png) And then click on the configure button of the step you created in previous step: ![image](https://user-images.githubusercontent.com/46345469/62540439-ebd85680-b857-11e9-874b-2de42a6a44f8.png) The dropdown is now empty.  </body>
		<created>2019-08-06 12:41:00</created>
		<closed>2019-09-07 10:34:29</closed>
	</bug>
	<bug>
		<id>6317</id>
		<title>Template editor doesn't report errors correctly</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11393**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description ![image](https://user-images.githubusercontent.com/46345469/62539253-14128600-b855-11e9-8801-e067d542bad0.png) Earlier the message was `{{wrongid1}}' does not conform to the format {{xyz}} at line: 3, column: 12`, now the message `'' does not conform to the format   at line...` doesn't report much to the user. (But the line numbers are now correct :tada: #5273 ) </body>
		<created>2019-08-06 12:22:55</created>
		<closed>2019-09-07 10:35:25</closed>
	</bug>
	<bug>
		<id>6316</id>
		<title>Templates don't accept other file types than txt</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11394**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description AFAIK there is no known description of file extensions that the template steps allow to be uploaded. The only mention of uploading files is "Click browse to upload, navigate to a file, and upload it. ". To me this means whatever the extension is, it should be allowed to be uploaded. Restricting users to only uploading certain types of files doesn't make sense to me in this use case since most users are going to write those files themselves, so if there is any restriction regarding this. It should be mentioned somewhere in the UI &amp; there could also be a filter in the file upload dialog.  ![image](https://user-images.githubusercontent.com/46345469/62616635-55b43700-b910-11e9-91cc-9c7a7f57412a.png) (the file input button is there as a workaround for automated tests, don't worry it's not visible :D)  Testing files: [template1.txt](https://github.com/syndesisio/syndesis/files/3471943/template1.txt) [template.txt](https://github.com/syndesisio/syndesis/files/3471944/template.txt) SIDE NOTE: Github does the same thing of restricting only certain types of files, but informs the user in various ways that the file is not supported ![image](https://user-images.githubusercontent.com/46345469/62536924-83857700-b84f-11e9-8266-c9ff66e48bba.png) If I still upload wrong file type:  ![image](https://user-images.githubusercontent.com/46345469/62536959-9a2bce00-b84f-11e9-94de-535405c96c02.png) ping: @phantomjinx     </body>
		<created>2019-08-06 11:39:54</created>
		<closed>2019-09-07 10:39:57</closed>
	</bug>
	<bug>
		<id>6314</id>
		<title>Unable to deploy from master due to malformed config.json</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Deploying syndesis from master results in a non-functional UI, only shows the `Something is wrong` page.  As a workaround, one can edit the `syndesis-ui-config` map and editing the `config.json` key there to have `"enabled": 0` instead of just `"enabled:"`  Furthermore, any change to the `syndesis-ui-config` is reverted by the operator, so for the above workaround to actually help, one needs to scale down the operator to 0 first. </body>
		<created>2019-08-06 07:41:05</created>
		<closed>2019-08-09 13:46:44</closed>
	</bug>
	<bug>
		<id>6310</id>
		<title>UI dev server - live reloading broken</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  The dev server for the UI has stopped functioning properly. The live reloading feature no longer works and in addition, I'm seeing the following error which I believe may be related  `WebSocket connection to 'ws://localhost:3000/sockjs-node/912/0q05jnss/websocket' failed: Invalid frame header`  This increases the time it takes to develop and test features for anyone contributing to the UI. </body>
		<created>2019-08-05 13:59:19</created>
		<closed>2019-08-06 14:09:31</closed>
	</bug>
	<bug>
		<id>6309</id>
		<title>Issue when processing data from S3 to ELK using custom step</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11554**  ## This is an issue raised via eval email list  Background: Weve built the extension jar file as instructed. We are able to import it as an extension in Fuse Online and are able to use it to as a step:  Integration: Get obj on S3 Convert body with custom step Invoke URL ELK  But the job still fails. Can you help check why?  </body>
		<created>2019-08-05 13:26:04</created>
		<closed>2019-09-07 12:44:54</closed>
	</bug>
	<bug>
		<id>6294</id>
		<title>OData connector updates null values with Filter old results turned on</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11395**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  When doing simple integration OData (Read) -&gt; Data Mapper -&gt; OData (Update)  ![image](https://user-images.githubusercontent.com/46523434/62276567-a0334080-b444-11e9-9383-f914a214b283.png) with this configuration: ![image](https://user-images.githubusercontent.com/46523434/62276606-b5a86a80-b444-11e9-8110-727a812d7531.png) and updating other entity then the one specified in OData read configuration, the first run of integration run as supposed. BUT the second run updates with null values. See below: ![image](https://user-images.githubusercontent.com/46523434/62276459-62361c80-b444-11e9-831d-7c18f57a6df3.png)</body>
		<created>2019-08-01 08:15:39</created>
		<closed>2019-09-07 10:40:12</closed>
	</bug>
	<bug>
		<id>6292</id>
		<title>server/endpoint/pom.xml issue with org.json:json dependency</title>
		<body>## This is a...  Trying to build syndesis:master and getting the following in server/endpoint.  ``` [INFO] --- maven-dependency-plugin:3.1.1:analyze-only (basepom.default) @ server-endpoint --- [WARNING] Used undeclared dependencies found: [WARNING]    org.json:json:jar:20140107:compile [INFO] ------------------------------------------------------------------------ ``` ``` [INFO] Server :: Inspector ................................ SUCCESS [ 13.996 s] [INFO] Server :: Credential ............................... SUCCESS [ 24.949 s] [INFO] Server :: Endpoint ................................. FAILURE [ 16.563 s] ```  I'm not sure how to respond to this - if I exclude org.json:json from openshift-client (which is bringing it in), then I get an error   ``` [INFO] --- dependency-management-maven-plugin:0.11:analyze (basepom.default) @ server-endpoint --- [ERROR] Exclusions must be removed for managed dependency io.fabric8:openshift-client:jar ```  If I add a dependency to server/endpoint for org.json:json, I get a complaint that android-json has classes that are duplicated from org.json:json.     ## Description  </body>
		<created>2019-07-31 22:07:45</created>
		<closed>2019-08-09 08:17:52</closed>
	</bug>
	<bug>
		<id>6291</id>
		<title>[Upgrade] Rebuilding integration after upgrade results in Failure executing: PATCH</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11396**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I've created an integration `SQL (select * from contact) -&gt; log` on 7.3.1 version and then upgraded the infra to 7.4 CR3. When I rebuild the integration, I get this log in the server log every time:  ``` 2019-07-31 12:42:31.059  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.i.online.PublishHandler          : Integration [db-log]: Starting deployment 2019-07-31 12:42:35.570 ERROR [-,,,] 1 --- [tion Controller] i.s.s.c.i.online.PublishHandler          : Integration [db-log]: [ERROR] Activation failure io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: PATCH at: https://kubernetes.default.svc/apis/apps.openshift.io/v1/namespaces/syndesis/deploymentconfigs/i-db-log. Message: This request caused apiserver to panic. Look in the logs for details. . at io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:472) ~[kubernetes-client-3.1.12.fuse-740022-redhat-00001.jar!/:3.1.12.fuse-740022-redhat-00001] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:411) ~[kubernetes-client-3.1.12.fuse-740022-redhat-00001.jar!/:3.1.12.fuse-740022-redhat-00001] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:381) ~[kubernetes-client-3.1.12.fuse-740022-redhat-00001.jar!/:3.1.12.fuse-740022-redhat-00001] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:344) ~[kubernetes-client-3.1.12.fuse-740022-redhat-00001.jar!/:3.1.12.fuse-740022-redhat-00001] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handlePatch(OperationSupport.java:280) ~[kubernetes-client-3.1.12.fuse-740022-redhat-00001.jar!/:3.1.12.fuse-740022-redhat-00001] at io.fabric8.kubernetes.client.dsl.base.BaseOperation.handlePatch(BaseOperation.java:776) ~[kubernetes-client-3.1.12.fuse-740022-redhat-00001.jar!/:3.1.12.fuse-740022-redhat-00001] at io.fabric8.kubernetes.client.dsl.base.HasMetadataOperation$3.apply(HasMetadataOperation.java:156) ~[kubernetes-client-3.1.12.fuse-740022-redhat-00001.jar!/:3.1.12.fuse-740022-redhat-00001] at io.fabric8.kubernetes.client.dsl.base.HasMetadataOperation$3.apply(HasMetadataOperation.java:152) ~[kubernetes-client-3.1.12.fuse-740022-redhat-00001.jar!/:3.1.12.fuse-740022-redhat-00001] at io.fabric8.openshift.api.model.DoneableDeploymentConfig.done(DoneableDeploymentConfig.java:27) ~[kubernetes-model-2.0.10.jar!/:2.0.10] at io.fabric8.openshift.api.model.DoneableDeploymentConfig.done(DoneableDeploymentConfig.java:6) ~[kubernetes-model-2.0.10.jar!/:2.0.10] at io.fabric8.kubernetes.client.dsl.base.HasMetadataOperation.patch(HasMetadataOperation.java:163) ~[kubernetes-client-3.1.12.fuse-740022-redhat-00001.jar!/:3.1.12.fuse-740022-redhat-00001] at io.fabric8.openshift.client.dsl.internal.DeploymentConfigOperationsImpl.patch(DeploymentConfigOperationsImpl.java:84) ~[openshift-client-3.1.12.fuse-740022-redhat-00001.jar!/:3.1.12.fuse-740022-redhat-00001] at io.fabric8.openshift.client.dsl.internal.DeploymentConfigOperationsImpl.patch(DeploymentConfigOperationsImpl.java:47) ~[openshift-client-3.1.12.fuse-740022-redhat-00001.jar!/:3.1.12.fuse-740022-redhat-00001] at io.fabric8.kubernetes.client.dsl.base.HasMetadataOperation$1.apply(HasMetadataOperation.java:60) ~[kubernetes-client-3.1.12.fuse-740022-redhat-00001.jar!/:3.1.12.fuse-740022-redhat-00001] at io.fabric8.kubernetes.client.dsl.base.HasMetadataOperation$1.apply(HasMetadataOperation.java:50) ~[kubernetes-client-3.1.12.fuse-740022-redhat-00001.jar!/:3.1.12.fuse-740022-redhat-00001] at io.fabric8.openshift.api.model.DoneableDeploymentConfig.done(DoneableDeploymentConfig.java:27) ~[kubernetes-model-2.0.10.jar!/:2.0.10] at io.fabric8.openshift.client.dsl.internal.DeploymentConfigOperationsImpl.deployLatest(DeploymentConfigOperationsImpl.java:98) ~[openshift-client-3.1.12.fuse-740022-redhat-00001.jar!/:3.1.12.fuse-740022-redhat-00001] at io.fabric8.openshift.client.dsl.internal.DeploymentConfigOperationsImpl.deployLatest(DeploymentConfigOperationsImpl.java:89) ~[openshift-client-3.1.12.fuse-740022-redhat-00001.jar!/:3.1.12.fuse-740022-redhat-00001] at io.fabric8.openshift.client.dsl.internal.DeploymentConfigOperationsImpl.deployLatest(DeploymentConfigOperationsImpl.java:47) ~[openshift-client-3.1.12.fuse-740022-redhat-00001.jar!/:3.1.12.fuse-740022-redhat-00001] at io.syndesis.server.openshift.OpenShiftServiceImpl.deploy(OpenShiftServiceImpl.java:102) ~[server-openshift-1.7.13.fuse-740001-redhat-00002.jar!/:1.7.13.fuse-740001-redhat-00002] at io.syndesis.server.controller.integration.online.PublishHandler.deploy(PublishHandler.java:181) ~[server-controller-1.7.13.fuse-740001-redhat-00002.jar!/:1.7.13.fuse-740001-redhat-00002] at io.syndesis.server.controller.integration.online.PublishHandler$BuildStepOncePerformer.perform(PublishHandler.java:276) ~[server-controller-1.7.13.fuse-740001-redhat-00002.jar!/:1.7.13.fuse-740001-redhat-00002] at io.syndesis.server.controller.integration.online.PublishHandler.execute(PublishHandler.java:114) ~[server-controller-1.7.13.fuse-740001-redhat-00002.jar!/:1.7.13.fuse-740001-redhat-00002] at io.syndesis.server.controller.StateChangeHandler.execute(StateChangeHandler.java:33) [server-controller-1.7.13.fuse-740001-redhat-00002.jar!/:1.7.13.fuse-740001-redhat-00002] at io.syndesis.server.controller.integration.BaseIntegrationController.lambda$callStateChangeHandler$10(BaseIntegrationController.java:220) [server-controller-1.7.13.fuse-740001-redhat-00002.jar!/:1.7.13.fuse-740001-redhat-00002] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_212] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_212] at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_212] 2019-07-31 12:42:35.571  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.i.BaseIntegrationController      : Integration i-Ll6Qo0le2jlAxwAme4-z : Setting status to Pending (Failure executing: PATCH at: https://kubernetes.default.svc/apis/apps.openshift.io/v1/namespaces/syndesis/deploymentconfigs/i-db-log. Message: This request caused apiserver to panic. Look in the logs for details. .)  ```  But the changes I did (I added a new string in the log step) were present - So I added both p1 and p2 because I don't know what it is trying to change</body>
		<created>2019-07-31 12:45:29</created>
		<closed>2019-09-07 10:40:20</closed>
	</bug>
	<bug>
		<id>6282</id>
		<title>Can't login with Firefox &lt; 61.0b13</title>
		<body># This is a Bug report/probable regression  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ X ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  I'm trying to login to Syndesis using the default OAuth in **Firefox 60.8.0esr** (64-bit) (default version on Debian stable/buster). But a CORS error makes the config.json request to fail:  ![imagen](https://user-images.githubusercontent.com/726590/62134045-22eebb00-b2e0-11e9-81b8-65d051773885.png)  This is not reproducible since Firefox v61.0.b13 due to [implementation of the updated spec](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API/Using_Fetch):  &gt; By default, fetch won't send or receive any cookies from the server, resulting in unauthenticated requests if the site relies on maintaining a user session (to send cookies, the credentials init option must be set). &gt; Since Aug 25, 2017. The spec changed the default credentials policy to same-origin. Firefox changed since 61.0b13.  I suggest modifying the fetch call to explicitly add the cookies:  ![imagen](https://user-images.githubusercontent.com/726590/62134345-998bb880-b2e0-11e9-89d5-07967ebaafc6.png)  ![imagen](https://user-images.githubusercontent.com/726590/62134396-ae684c00-b2e0-11e9-9a9b-be84ea9890b7.png)  </body>
		<created>2019-07-30 13:42:54</created>
		<closed>2019-09-07 14:21:55</closed>
	</bug>
	<bug>
		<id>6281</id>
		<title>Integration grafana dashboard doesn't show integration name and some metrics</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I see running integrations in the Graph for Integration dashboard in the Grafana, however, I don't see any identification which curve is for which integration.  In the Integration dropdown menu, I have only None. Also, the first row of the metrics doesn't see any data.  ![image](https://user-images.githubusercontent.com/16251792/62127843-57a84580-b2d3-11e9-93aa-7f6febec8fc1.png)  Prometheus contains metrics for all integrations (I have three simple timer-to-log integrations): ![image](https://user-images.githubusercontent.com/16251792/62128015-c5ed0800-b2d3-11e9-9b18-8e4c329559d8.png)   **Step to reproduce** - Install syndesis `syndesis minishift --install --tag 1.7.13` - Install application-monitoring-operator (clone this [repo](https://github.com/integr8ly/application-monitoring-operator/) (tag 0.0.20) and run `make cluster/install`) -- When the operator is stuck in the first time. Delete project `application-monitoring` and run the command again. - Label syndesis project `oc label namespace syndesis monitoring-key=middleware` - Install Syndesis integrations monitoring configuration: ``` oc project syndesis BASEURL=https://raw.githubusercontent.com/syndesisio/syndesis/1.7.x/install/addons  for ADDON in syndesis-integration-dashboard.yml \   syndesis-integrations-service.yml \   syndesis-integrations-servicemonitor.yml do   oc create -f ${BASEURL}/${ADDON} done ``` - Create three simple integration (timer-to-log with 1-second timer) - Go to the Grafana and look at Fuse Online - Integration - Camel dashboard. </body>
		<created>2019-07-30 12:11:27</created>
		<closed>2019-08-06 08:32:47</closed>
	</bug>
	<bug>
		<id>6278</id>
		<title>Http connector configuration wizard having ghost step</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When using a Http connection in an integration the configuration wizard has a ghost step so user needs to click twice the `Next` button to finish the wizard.   So after choosing and configuring the type `Json Instance` and clicking on `Next` button nothing happens. User has to click once again to close the wizard.  ![Issue](https://user-images.githubusercontent.com/195264/62107690-71806300-b2a8-11e9-8c51-19a4d3133d92.gif)  </body>
		<created>2019-07-30 07:01:23</created>
		<closed>2019-11-06 16:50:56</closed>
	</bug>
	<bug>
		<id>6267</id>
		<title>Build - Fails at camel-k (no --camel-k flag included, $GOPATH is set)</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Technically not sure whether or not it's a bug, but after a while of not running Minishift I'm trying to set things up again. I start up minishift and then run the `syndesis ui` script, which is pretty [straightforward](https://github.com/syndesisio/syndesis/blob/master/tools/bin/commands/ui) and mostly the same things I'd run manually.  The build fails during the `Building camel-k` step.  ``` build.build.openshift.io/syndesis-operator-4 started ============================================================================== Building camel-k ============================================================================== ERROR: Can't find /Users/ryordan/.go/src/github.com/apache/camel-k. camel-k image can be build only locally (--local is implied) for camel-k builds). ERROR: Last command exited with 1 ```  The `syndesis ui` script, whether or not I run with `--nuke-everything` flag, seems to still to try to build camel-k despite there is no `--camel-k` flag. See gist here: https://gist.github.com/kahboom/13ca3256f3f0f1f33f3972a0ac9653c6  I'm on Mojave (don't judge me) and `minishift v1.33.0+ba29431`. I have also go `v.1.12.7` installed (I guess the camel-k part should work anyway, separately), this is the relative part of my `.bashrc`:  ``` # GO #export PATH=$PATH:/usr/local/opt/go/libexec/bin export GOPATH=$HOME/.go export PATH=$PATH:$GOPATH/bin ```  ``` $ echo $GOPATH /Users/ryordan/.go ```  Trying to delete my minishift instance now and start from scratch to see if it helps..  potentially related? https://github.com/syndesisio/syndesis/issues/4751</body>
		<created>2019-07-29 12:52:42</created>
		<closed>2019-07-30 12:50:18</closed>
	</bug>
	<bug>
		<id>6260</id>
		<title>Browser tab title shows Syndesis even with prod build</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description ![title](https://user-images.githubusercontent.com/265462/61960928-8309f800-af94-11e9-9c3e-e61b0708f3fd.png)  Zoran found it's hardcoded, needs to be replaced with `Fuse Online` at build time https://github.com/syndesisio/syndesis/blob/510c3ef961b2cbf137cd69c5a090c3b623d00ec5/app/ui-react/syndesis/public/index.html#L11</body>
		<created>2019-07-26 15:01:45</created>
		<closed>2020-02-05 23:33:57</closed>
	</bug>
	<bug>
		<id>6257</id>
		<title>Split step always adapts 1st output data shape</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Split step should adapt the output data shape of the previous step relative to its location in a flow. At the moment split always adapts the output data shape of the 1st step in the flow regardless of its position in the flow.  With this in place you can not use split on steps other than the 1st step in a flow. </body>
		<created>2019-07-26 07:38:18</created>
		<closed>2019-08-08 06:23:36</closed>
	</bug>
	<bug>
		<id>6252</id>
		<title>Cannot see datamapper in CR2</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Data mapper height is wrong.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlisting the acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![Screenshot from 2019-07-25 16-47-42](https://user-images.githubusercontent.com/4151857/61888203-6a053680-af03-11e9-99cb-ed1487906819.png)    ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Go to an instance with 7.4.0 CR2 installed, e.g. : https://fuse-online-74cr2.b6ff.rh-idev.openshiftapps.com/ 2. Create an integration from webhook (specify a datashape with a json instance) to database (add_lead) 3. Add a datamapper step 4. You get the screenshot (I've used chrome) </body>
		<created>2019-07-25 15:44:53</created>
		<closed>2019-07-25 19:43:05</closed>
	</bug>
	<bug>
		<id>6230</id>
		<title>API Provider shows icons from the flow on the top</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Before the API Provider showed the number of flows/operations tied to that integration (in the screenshots it says flows, conditional flows also have flows and those shouldn't be counted there) ![image](https://user-images.githubusercontent.com/46345469/61715810-2cb37400-ad5e-11e9-895c-9080bc370958.png) Now it just displays steps of the operation at the top (which is picked semi-randomly, by probably the last edit timestamp). ![image](https://user-images.githubusercontent.com/46345469/61715870-49e84280-ad5e-11e9-8a75-41e2d58b9802.png) Making this p1 for this release but we should focus on fixing this in the next release.  </body>
		<created>2019-07-23 13:27:20</created>
		<closed>2019-08-22 08:16:39</closed>
	</bug>
	<bug>
		<id>6229</id>
		<title>Invalid API specification form URL in API Provider doesn't show errors</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11397**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description If an invalid data is supplied to the API Provider definition via URL, no error is shown to the user in the UI. And there is only the loading animation, which is weirdly glitching out. ![Peek 2019-07-23 14-09](https://user-images.githubusercontent.com/46345469/61711094-8c585200-ad53-11e9-9e8a-0252fdc422e5.gif) (sometimes it does an entire spin :sunglasses:) Here's stacktrace from syndesis-server:  ``` h.e.SyndesisServerExceptionMapper : Internal Server Exception. RESTEASY004655: Unable to invoke request javax.ws.rs.ProcessingException: RESTEASY004655: Unable to invoke request at org.jboss.resteasy.client.jaxrs.engines.ApacheHttpClient4Engine.invoke(ApacheHttpClient4Engine.java:321) ~[resteasy-client-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.client.jaxrs.internal.ClientInvocation.invoke(ClientInvocation.java:439) ~[resteasy-client-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.client.jaxrs.internal.ClientInvocation.invoke(ClientInvocation.java:460) ~[resteasy-client-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.client.jaxrs.internal.ClientInvocationBuilder.get(ClientInvocationBuilder.java:189) ~[resteasy-client-3.6.1.Final.jar!/:3.6.1.Final] at io.syndesis.server.metrics.prometheus.HttpClient.queryPrometheus(HttpClient.java:46) ~[server-metrics-prometheus-1.7.10.jar!/:1.7.10] at io.syndesis.server.metrics.prometheus.PrometheusMetricsProviderImpl.getSummaryMetricValue(PrometheusMetricsProviderImpl.java:228) ~[server-metrics-prometheus-1.7.10.jar!/:1.7.10] at io.syndesis.server.metrics.prometheus.PrometheusMetricsProviderImpl.getTotalIntegrationMetricsSummary(PrometheusMetricsProviderImpl.java:183) ~[server-metrics-prometheus-1.7.10.jar!/:1.7.10] at io.syndesis.server.endpoint.v1.handler.metrics.IntegrationMetricsHandler.get(IntegrationMetricsHandler.java:65) ~[server-endpoint-1.7.10.jar!/:1.7.10] at sun.reflect.GeneratedMethodAccessor594.invoke(Unknown Source) ~[na:na] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151] at org.jboss.resteasy.core.MethodInjectorImpl.invoke(MethodInjectorImpl.java:140) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.internalInvokeOnTarget(ResourceMethodInvoker.java:509) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTargetAfterFilter(ResourceMethodInvoker.java:399) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.lambda$invokeOnTarget$0(ResourceMethodInvoker.java:363) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:358) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTarget(ResourceMethodInvoker.java:365) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:337) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:310) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:443) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.lambda$invoke$4(SynchronousDispatcher.java:233) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.lambda$preprocess$0(SynchronousDispatcher.java:139) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:358) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.preprocess(SynchronousDispatcher.java:142) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:219) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.ServletContainerDispatcher.service(ServletContainerDispatcher.java:227) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:56) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:51) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) ~[javax.servlet-api-3.1.0.jar!/:3.1.0] at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:111) ~[spring-boot-actuator-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.security.web.authentication.preauth.AbstractPreAuthenticatedProcessingFilter.doFilter(AbstractPreAuthenticatedProcessingFilter.java:121) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.security.web.csrf.CsrfFilter.doFilterInternal(CsrfFilter.java:100) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:66) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) ~[spring-security-web-4.2.13.RELEASE.jar!/:4.2.13.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.cloud.sleuth.instrument.web.TraceFilter.doFilter(TraceFilter.java:186) ~[spring-cloud-sleuth-core-1.2.6.RELEASE.jar!/:1.2.6.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.micrometer.spring.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:106) ~[micrometer-spring-legacy-1.1.2.jar!/:1.1.2] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:103) ~[spring-boot-actuator-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.opentracing.contrib.web.servlet.filter.TracingFilter.doFilter(TracingFilter.java:165) ~[opentracing-web-servlet-filter-0.1.0.jar!/:na] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:65) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:132) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.server.Connectors.executeRootHandler(Connectors.java:336) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_151] at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_151] Caused by: org.apache.http.conn.ConnectTimeoutException: Connect to syndesis-prometheus:80 [syndesis-prometheus/172.30.143.3] failed: connect timed out at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:151) ~[httpclient-4.5.6.jar!/:4.5.6] at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:373) ~[httpclient-4.5.6.jar!/:4.5.6] at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:394) ~[httpclient-4.5.6.jar!/:4.5.6] at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237) ~[httpclient-4.5.6.jar!/:4.5.6] at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185) ~[httpclient-4.5.6.jar!/:4.5.6] at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89) ~[httpclient-4.5.6.jar!/:4.5.6] at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110) ~[httpclient-4.5.6.jar!/:4.5.6] at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185) ~[httpclient-4.5.6.jar!/:4.5.6] at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83) ~[httpclient-4.5.6.jar!/:4.5.6] at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56) ~[httpclient-4.5.6.jar!/:4.5.6] at org.jboss.resteasy.client.jaxrs.engines.ApacheHttpClient4Engine.invoke(ApacheHttpClient4Engine.java:317) ~[resteasy-client-3.6.1.Final.jar!/:3.6.1.Final] ... 136 common frames omitted Caused by: java.net.SocketTimeoutException: connect timed out at java.net.PlainSocketImpl.socketConnect(Native Method) ~[na:1.8.0_151] at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[na:1.8.0_151] at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[na:1.8.0_151] at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[na:1.8.0_151] at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[na:1.8.0_151] at java.net.Socket.connect(Socket.java:589) ~[na:1.8.0_151] at org.apache.http.conn.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:75) ~[httpclient-4.5.6.jar!/:4.5.6] at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142) ~[httpclient-4.5.6.jar!/:4.5.6] ... 146 common frames omitted ``` And there's this error in the developer console in the browser: ``` TypeError: "w.actionsSummary is undefined"     content ReviewActionsPage.tsx:125     render utils.js:697     React 10     useApiProviderSummary api.js:2485 react-dom.production.min.js:4408 ``` ## Steps to reproduce 1. Start creating API Provider integration 2. Pick Use a URL 3. Input http://google.com for example or https://randomuser.me/api/ (if you want to test it on an actual JSON)</body>
		<created>2019-07-23 12:14:18</created>
		<closed>2019-09-07 10:41:21</closed>
	</bug>
	<bug>
		<id>6228</id>
		<title>Hanging daily release</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Example in build [#527](https://ci.fabric8.io/job/syndesis-release-daily/527/), looks very similar to the memory problem we had previously with #5468.</body>
		<created>2019-07-23 12:01:25</created>
		<closed>2019-08-17 05:41:41</closed>
	</bug>
	<bug>
		<id>6227</id>
		<title>Comma in the integration title crashes the integration</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I created an integration which had a comma in the name, it caused the integration to crash. Without any feedback why it happened or what did I do wrong. Since there's a possibility the user couldn't have access to Openshift and the logs, they wouldn't know what's wrong and most likely wouldn't suspect the integration name to be cause of their troubles. This is the stacktrace produced: ``` Caused by: javax.management.MalformedObjectNameException: Could not create ObjectName from: org.apache.camel:context=test,,type=context,name="test,". Reason: javax.management.MalformedObjectNameException: Invalid character ',' in key part of property at org.apache.camel.management.DefaultManagementNamingStrategy.createObjectName(DefaultManagementNamingStrategy.java:418) ~[camel-core-2.21.0.fuse-740038.jar!/:2.21.0.fuse-740038] at org.apache.camel.management.DefaultManagementNamingStrategy.getObjectNameForCamelContext(DefaultManagementNamingStrategy.java:106) ~[camel-core-2.21.0.fuse-740038.jar!/:2.21.0.fuse-740038] at org.apache.camel.management.DefaultManagementLifecycleStrategy.onContextStart(DefaultManagementLifecycleStrategy.java:167) ~[camel-core-2.21.0.fuse-740038.jar!/:2.21.0.fuse-740038] ... 40 common frames omitted ``` I believe there are many other characters that cause this behavior... I've found ':' to be problematic as well with quick search on the interwebz.  ## What I'd expect to happen Either we shouldn't allow these "problematic" characters in the integration name ![image](https://user-images.githubusercontent.com/46345469/61691164-3e2f5880-ad2b-11e9-9693-507e2f76bb25.png) Here the Name input should shine red, tell the user what's wrong, disable the save and publish buttons. OR  Use commas and other characters just for display, I can imagine someone using : or , in the title.</body>
		<created>2019-07-23 07:23:10</created>
		<closed>2019-08-22 15:56:53</closed>
	</bug>
	<bug>
		<id>6226</id>
		<title>Conditional flow fails with collections in API Provider</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Conditional flows cannot be used with collections in Syndesis, but API Provider makes a collection around its request body, even when it is specified in the API specification to contain only one object of specified type. Example: [conditional-provider.zip](https://github.com/syndesisio/syndesis/files/3420607/conditional-provider.zip) In this integration you can see that in the specification in the POST method it expects request body of Task. I'd expect that to be one Task. So if I create a condition `${body.completed}` it should work, or at least `${body["completed"]}`. I tried also splitting it, but split doesn't work well on these types of collections (see #4862). Also I tried `${body[0]["completed"]}` but that also didn't work for some reason. The log reported something along the lines of `cannot call method [0]["completed"] on ArrayList`.</body>
		<created>2019-07-23 07:00:31</created>
		<closed>2019-08-06 15:02:03</closed>
	</bug>
	<bug>
		<id>6225</id>
		<title>[Upgrade] Upgrade clears the syndesis-pull-secret link from service accounts</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I created the `syndesis-pull-secret` secret with my authentication details and deploy 7.3.1. Now when I do the upgrade, what the upgrade pod does is:  ``` ... === * Update resources (upgrade_40_update_resources)       - ServiceAccount: force update (delete/create)         * syndesis-default         * syndesis-integration         * syndesis-prometheus         * syndesis-server ... ``` so it deletes the old SAs with linked secret and replaces them with the ones from the template and those do not have the pull secret linked.  We will need to have this script https://github.com/syndesisio/syndesis/blob/1.6.x/tools/upgrade/migration/resource/any/03_ensure_service_account_setup.sh but not as a migration script (those are called before the SAs are re-created) but as part of the `upgrade_40_update_resources` script, after `apply_resources` call: https://github.com/syndesisio/syndesis/blob/d0c9225266b7dda3f4c1df326ed0583f39618f5a/tools/upgrade/steps/upgrade_40_update_resources#L48-L56  </body>
		<created>2019-07-23 06:36:52</created>
		<closed>2019-07-26 10:16:59</closed>
	</bug>
	<bug>
		<id>6224</id>
		<title>Conditional flow duplicate flow ids when used in API Provider</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description If I try to create an API Provider integration using Conditional flow, I have to get the condition right on the first try. When I try to edit the Conditional flow again, the integration crashes with this stacktrace: ``` org.apache.camel.RuntimeCamelException: org.apache.camel.FailedToStartRouteException: Failed to start route -LkSSIqHna4CNPrkrGeP because of duplicate id detected: -LkSSIqHna4CNPrkrGeP. Please correct ids to be unique among all your routes. at org.apache.camel.util.ObjectHelper.wrapRuntimeCamelException(ObjectHelper.java:1830) ~[camel-core-2.21.0.fuse-740038.jar!/:2.21.0.fuse-740038] at org.apache.camel.spring.SpringCamelContext.start(SpringCamelContext.java:136) ~[camel-spring-2.21.0.fuse-740038.jar!/:2.21.0.fuse-740038] at org.apache.camel.spring.SpringCamelContext.onApplicationEvent(SpringCamelContext.java:174) ~[camel-spring-2.21.0.fuse-740038.jar!/:2.21.0.fuse-740038] at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:393) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:399) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:347) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:883) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.finishRefresh(EmbeddedWebApplicationContext.java:144) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration.createChildManagementContext(EndpointWebMvcAutoConfiguration.java:193) ~[spring-boot-actuator-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration.afterSingletonsInstantiated(EndpointWebMvcAutoConfiguration.java:156) ~[spring-boot-actuator-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:781) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:543) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at io.syndesis.example.Application.main(Application.java:13) [classes!/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_191] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_191] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_191] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_191] at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.Launcher.launch(Launcher.java:87) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.Launcher.launch(Launcher.java:50) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.PropertiesLauncher.main(PropertiesLauncher.java:595) [project-0.1-SNAPSHOT.jar:na] Caused by: org.apache.camel.FailedToStartRouteException: Failed to start route -LkSSIqHna4CNPrkrGeP because of duplicate id detected: -LkSSIqHna4CNPrkrGeP. Please correct ids to be unique among all your routes. at org.apache.camel.impl.DefaultCamelContext.startRoute(DefaultCamelContext.java:1132) ~[camel-core-2.21.0.fuse-740038.jar!/:2.21.0.fuse-740038] at org.apache.camel.impl.DefaultCamelContext.startRouteDefinitions(DefaultCamelContext.java:3729) ~[camel-core-2.21.0.fuse-740038.jar!/:2.21.0.fuse-740038] at org.apache.camel.impl.DefaultCamelContext.doStartCamel(DefaultCamelContext.java:3443) ~[camel-core-2.21.0.fuse-740038.jar!/:2.21.0.fuse-740038] at org.apache.camel.impl.DefaultCamelContext.access$000(DefaultCamelContext.java:209) ~[camel-core-2.21.0.fuse-740038.jar!/:2.21.0.fuse-740038] at org.apache.camel.impl.DefaultCamelContext$2.call(DefaultCamelContext.java:3251) ~[camel-core-2.21.0.fuse-740038.jar!/:2.21.0.fuse-740038] at org.apache.camel.impl.DefaultCamelContext$2.call(DefaultCamelContext.java:3247) ~[camel-core-2.21.0.fuse-740038.jar!/:2.21.0.fuse-740038] at org.apache.camel.impl.DefaultCamelContext.doWithDefinedClassLoader(DefaultCamelContext.java:3270) ~[camel-core-2.21.0.fuse-740038.jar!/:2.21.0.fuse-740038] at org.apache.camel.impl.DefaultCamelContext.doStart(DefaultCamelContext.java:3247) ~[camel-core-2.21.0.fuse-740038.jar!/:2.21.0.fuse-740038] at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.21.0.fuse-740038.jar!/:2.21.0.fuse-740038] at org.apache.camel.impl.DefaultCamelContext.start(DefaultCamelContext.java:3163) ~[camel-core-2.21.0.fuse-740038.jar!/:2.21.0.fuse-740038] at org.apache.camel.spring.SpringCamelContext.start(SpringCamelContext.java:133) ~[camel-spring-2.21.0.fuse-740038.jar!/:2.21.0.fuse-740038] ... 31 common frames omitted ``` Exported integration:  [conditional-provider.zip](https://github.com/syndesisio/syndesis/files/3420514/conditional-provider.zip) ## Steps to reproduce 1. Create an API Provider integration 2. Add Conditional flow 3. Publish the integration 4. Edit the integration and change some condition 5. Publish again  </body>
		<created>2019-07-23 06:32:23</created>
		<closed>2019-08-07 12:15:45</closed>
	</bug>
	<bug>
		<id>6209</id>
		<title>Syndesis S2i build failing</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  The syndesis-s2i build is failing for me on master.   I have executed ``` syndesis build -m s2i -i -f ```  This is the error message: ``` [INFO] F8: Step 9/14 : RUN cd /tmp/artifacts/m2/project  &amp;&amp; mvn --batch-mode -s /tmp/settings.xml -Dmaven.repo.local=/tmp/artifacts/m2 package -DskipTests -Dmdep.skip=true -e -Dfabric8.skip=true  &amp;&amp; rm -rf /tmp/artifacts/m2/project  &amp;&amp; chgrp -R 0 /tmp/artifacts/m2  &amp;&amp; chmod -R g=u /tmp/artifacts/m2 [INFO] F8:  ---&gt; Running in 3e4409035f51 [INFO] F8: [INFO] Error stacktraces are turned on. [INFO] F8: [INFO] Scanning for projects... [INFO] F8: [ERROR] [ERROR] Some problems were encountered while processing the POMs: [INFO] F8: [ERROR] Non-resolvable import POM: Could not find artifact io.syndesis.integration:integration-bom:pom:1.8-SNAPSHOT @ line 45, column 19 [INFO] F8: [ERROR] 'dependencies.dependency.version' for io.atlasmap:camel-atlasmap:jar is missing. @ line 57, column 17 [INFO] F8: [ERROR] 'dependencies.dependency.version' for io.syndesis.connector:connector-activemq:jar is missing. @ line 63, column 17 [INFO] F8: [ERROR] 'dependencies.dependency.version' for io.syndesis.connector:connector-amqp:jar is missing. @ line 67, column 17 [INFO] F8: [ERROR] 'dependencies.dependency.version' for io.syndesis.connector:connector-api-provider:jar is missing. @ line 71, column 17  ...  [INFO] F8: [ERROR] The build could not read 1 project -&gt; [Help 1] [INFO] F8: org.apache.maven.project.ProjectBuildingException: Some problems were encountered while processing the POMs: [INFO] F8: [ERROR] Non-resolvable import POM: Could not find artifact io.syndesis.integration:integration-bom:pom:1.8-SNAPSHOT @ line 45, column 19  ...  [INFO] F8: [ERROR] 'dependencies.dependency.version' for io.syndesis.integration:integration-runtime-springboot:jar is missing. @ line 242, column 17 [INFO] F8:     at org.apache.maven.project.DefaultProjectBuilder.build (DefaultProjectBuilder.java:383) [INFO] F8:     at org.apache.maven.graph.DefaultGraphBuilder.collectProjects (DefaultGraphBuilder.java:414) [INFO] F8:     at org.apache.maven.graph.DefaultGraphBuilder.getProjectsForMavenReactor (DefaultGraphBuilder.java:405) [INFO] F8:     at org.apache.maven.graph.DefaultGraphBuilder.build (DefaultGraphBuilder.java:82) [INFO] F8:     at org.apache.maven.DefaultMaven.buildGraph (DefaultMaven.java:507) [INFO] F8:     at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:219) [INFO] F8:     at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192) [INFO] F8:     at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105) [INFO] F8:     at org.apache.maven.cli.MavenCli.execute (MavenCli.java:954) [INFO] F8:     at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:288) [INFO] F8:     at org.apache.maven.cli.MavenCli.main (MavenCli.java:192) [INFO] F8:     at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method) [INFO] F8:     at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62) [INFO] F8:     at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43) [INFO] F8:     at java.lang.reflect.Method.invoke (Method.java:498) [INFO] F8:     at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289) [INFO] F8:     at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229) [INFO] F8:     at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:415) [INFO] F8:     at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:356) [INFO] F8: [ERROR]    [INFO] F8: [ERROR]   The project io.syndesis.integrations:project:0.1-SNAPSHOT (/tmp/artifacts/m2/project/pom.xml) has 38 errors [INFO] F8: [ERROR]     Non-resolvable import POM: Could not find artifact io.syndesis.integration:integration-bom:pom:1.8-SNAPSHOT @ line 45, column 19 -&gt; [Help 2] [INFO] F8: org.apache.maven.model.resolution.UnresolvableModelException: Could not find artifact io.syndesis.integration:integration-bom:pom:1.8-SNAPSHOT ```</body>
		<created>2019-07-19 16:49:52</created>
		<closed>2019-07-23 07:04:35</closed>
	</bug>
	<bug>
		<id>6188</id>
		<title>[Connections] Invalid credentials lead to Something is wrong page</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11444**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Using connection with invalid credentials in integration ends up with `Something is wrong` page  1. Create a connection with incorrect credentials (kafka or slack are easy for reproducing this issue)  2. Use created connection in an integration  ![screenshot_20190717_153940](https://user-images.githubusercontent.com/14313995/61380629-05662e00-a8aa-11e9-935e-049b9d81f8ab.png)  ![screenshot_20190717_154411](https://user-images.githubusercontent.com/14313995/61380634-08f9b500-a8aa-11e9-8f55-194d73198884.png)  </body>
		<created>2019-07-17 13:54:13</created>
		<closed>2019-09-07 11:39:28</closed>
	</bug>
	<bug>
		<id>6186</id>
		<title>[Conditional Flow] datashape change is not propagated into condition</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description On following gif I have an integration with SQL -&gt; split -&gt; conditional flow -&gt; log. When I change SQL to different operation, the change is not propagated into the datamapper in one condition flow. I tried similar scenario without split step and the issue was still present. Not even an error is shown in data mapper.  Workaround is to configure main conditional flow, change nothing and click done. Then datamapper shows correct input.   ![out](https://user-images.githubusercontent.com/14313995/61360683-367d3900-a87f-11e9-9228-b618ec34aed4.gif)  </body>
		<created>2019-07-17 08:45:10</created>
		<closed>2019-09-07 10:43:17</closed>
	</bug>
	<bug>
		<id>6177</id>
		<title>Missing empty states views in the lists</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Since staging is kinda hosed I finally gave up on it and got minishift running.  And found that we're missing empty states for the integration list on the dashboard: ![image](https://user-images.githubusercontent.com/351660/61314075-c3fe5180-a7c9-11e9-96a8-a025cae3087e.png)  And the integration list page: ![image](https://user-images.githubusercontent.com/351660/61314131-e7c19780-a7c9-11e9-81ba-75e9a0a1da9a.png)  And API client connectors: ![image](https://user-images.githubusercontent.com/351660/61314282-57378700-a7ca-11e9-971a-3663ded81bc0.png)  And extensions too: ![image](https://user-images.githubusercontent.com/351660/61314241-396a2200-a7ca-11e9-8a36-64ca0a60b05a.png)  Note, this is on master.  I feel like we had these in place already.  Unless I'm just losing my mind, that's a definite possibility.  This is on a fresh clone, with a fresh install and fresh build. </body>
		<created>2019-07-16 17:06:32</created>
		<closed>2019-07-17 13:03:16</closed>
	</bug>
	<bug>
		<id>6176</id>
		<title>Datamapper - I must delete mapping twice to make it disappear</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11399**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  **Steps to reproduce:** 1. create a datamapper mapping 2. show mapping table in datamapper 3. select the mapping and click trash bin icon 4 click **Remove** button on **Remove Mapping?** dialog nothing happens with the mapping 5. repeat 3 and 4 mapping deleted  ![datamapper_delete](https://user-images.githubusercontent.com/8707251/61305076-78a86b00-a7ea-11e9-8dd5-47b83e4a869d.png)</body>
		<created>2019-07-16 14:57:12</created>
		<closed>2019-09-07 10:43:46</closed>
	</bug>
	<bug>
		<id>6173</id>
		<title>master doesn't build with a fresh clone and an empty repo</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Using `syndesis build -f -c` results in:  ![image](https://user-images.githubusercontent.com/351660/61298464-41b36480-a7ac-11e9-8dec-2acc65a0cc00.png)  well, eventually, a fair bit of stuff builds before this. </body>
		<created>2019-07-16 13:30:07</created>
		<closed>2019-08-09 13:04:39</closed>
	</bug>
	<bug>
		<id>6168</id>
		<title>Cannot login to syndesis</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [*] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description After logging in I get the following screen  &lt;img width="573" alt="Screen Shot 2019-07-15 at 4 06 43 PM" src="https://user-images.githubusercontent.com/35576/61245550-c35ab200-a71a-11e9-9130-7e79ae032781.png"&gt;  Logging in the auth pod:  ``` 2019/07/15 20:03:03 provider.go:593: 200 GET https://172.30.0.1/apis/user.openshift.io/v1/users/~ {"kind":"User","apiVersion":"user.openshift.io/v1","metadata":{"name":"developer","selfLink":"/apis/user.openshift.io/v1/users/developer","uid":"d1a4b0d7-a73a-11e9-a4f7-2a297d346f44","resourceVersion":"2230","creationTimestamp":"2019-07-15T19:57:47Z"},"identities":["anypassword:developer"],"groups":["system:authenticated","system:authenticated:oauth"]} 2019/07/15 20:03:03 provider.go:593: 201 POST https://172.30.0.1/apis/authorization.openshift.io/v1/subjectaccessreviews {"kind":"SubjectAccessReviewResponse","apiVersion":"authorization.openshift.io/v1","namespace":"myproject","allowed":true,"reason":"RBAC: allowed by ClusterRoleBinding \"syndesis-extra-permissions\" of ClusterRole \"syndesis-extra-permissions\" to User \"developer\""} 2019/07/15 20:03:03 oauthproxy.go:676: 172.17.0.1:42398 authentication complete Session{developer@cluster.local token:true} ```  fails on both Safari and Chrome. This is on a fresh install using  bash &lt;(curl -sL https://syndes.is/start)  Also fails in incognito mode. All pods seem happy:  ``` NAME                          READY     STATUS      RESTARTS   AGE syndesis-db-1-qwhqj           2/2       Running     0          22m syndesis-meta-1-f9nq4         1/1       Running     0          22m syndesis-oauthproxy-1-bxgvn   1/1       Running     0          22m syndesis-operator-1-w64jn     1/1       Running     0          23m syndesis-prometheus-1-fxknp   1/1       Running     0          22m syndesis-server-1-2mthp       1/1       Running     1          22m syndesis-ui-1-b9frv           1/1       Running     0          22m todo-1-4rrkm                  1/1       Running     0          20m todo-1-build                  0/1       Completed   0          22m ```</body>
		<created>2019-07-15 20:08:22</created>
		<closed>2019-09-18 11:47:00</closed>
	</bug>
	<bug>
		<id>6162</id>
		<title>Flow title is missing in API provider</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11400**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description There used to be the operation title displayed when editing the operation flow.  ![image](https://user-images.githubusercontent.com/46345469/61218394-34e23280-a712-11e9-853f-6ed785eaa64f.png) ![image](https://user-images.githubusercontent.com/46345469/61218354-26941680-a712-11e9-998e-28429f44d8e2.png) How can I know from these two screenshots which operation I am editing? </body>
		<created>2019-07-15 13:08:03</created>
		<closed>2019-09-07 10:45:15</closed>
	</bug>
	<bug>
		<id>6160</id>
		<title>can't create a new entry in todo app in latest syndesis</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11401**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  When using latest syndesis (1.8-SNAPSHOT) and try to create a new entry in todo app in its interface ![image](https://user-images.githubusercontent.com/46523434/61213168-8a174780-a704-11e9-83cf-6ccc38ae2597.png) and hit `add` button, I get message `Warning: pg_insert(): Table 'todo' doesn't exists in /opt/app-root/src/index.php on line 61 Insert failed:`  The same goes for deleting: `Warning: pg_delete(): Table 'todo' doesn't exists in /opt/app-root/src/index.php on line 82 Insert failed:`   and updating `Warning: pg_update(): Table 'todo' doesn't exists in /opt/app-root/src/index.php on line 65 Insert failed:`  This seems to be just a frontend problem as working with the table in DB works just fine.</body>
		<created>2019-07-15 11:32:42</created>
		<closed>2019-09-07 10:49:10</closed>
	</bug>
	<bug>
		<id>6135</id>
		<title>Not serving the newest activities</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  We noticed when working on #6052 that the most recent activities are not served. Upon investigating this further it seems that when we expunge activity data from the database wrong range of activities are retained.  On first look it seems like the property that the key generator should uphold, that the keys are both chronologically and alphabetically sorted at the same time, is broken.</body>
		<created>2019-07-11 13:09:51</created>
		<closed>2019-10-16 16:23:00</closed>
	</bug>
	<bug>
		<id>6127</id>
		<title>Links to user doc go to 7.3 doc when they should target 7.4 URLs</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  I noticed this behavior in the staging site, and Christoph just confirmed that this is the situation in the latest 1.7.x.    When I click the ? (Help) icon and then click User Guide, I get the 7.3 user guide at this link:   https://access.redhat.com/documentation/en-us/red_hat_fuse/7.3/html-single/integrating_applications_with_fuse_online/index  I expected the help icon links would now point to 7.4 titles, with links like this:   https://access.redhat.com/documentation/en-us/red_hat_fuse/7.4/html-single/integrating_applications_with_fuse_online/index  which would display "404 Not Found" until we publish the 7.4 doc.   I updated the release number in app/ui-react/syndesis/src/i18n/locales/shared-translations.en.json to 7.4:    "project": {         "name": "Syndesis",         "version": "7.4"  Also in that file, there are user doc links that contain references to $t(project.version)  My update to the shared-translations.en.json file is in this commit: https://github.com/syndesisio/syndesis/commit/214b64925d99a20c8b26426f784c0f843eded256  So it looks like I did not update the right file.  What file are the help links coming from? And just to be clear, there are three links to user doc and they all have the same problem.    </body>
		<created>2019-07-10 19:08:35</created>
		<closed>2019-07-15 10:47:29</closed>
	</bug>
	<bug>
		<id>6122</id>
		<title>API provider returns data even if data type is not defined</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11402**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description If I create this API provider definition:  ``` delete:     tags:         - tasks         - destruction     summary: Delete task     description: Deletes task by given identifier     operationId: 314844b1-3dad-4005-b3b2-d1c9d9463612     parameters:         -             name: id             in: path             description: Task identifier to delete             required: true             type: integer             format: int64     responses:         '204':             description: Task deleted ``` I expect to get **NO** response, since it's not defined. But I get the result of SQL invocation which is last step that returns some data in the flow. Which is quite unpleasant and unpredictable. It would be better to return either nothing or have an explicit option of returning None in the definition, which would then cause the API provider finishing step not to return anything. </body>
		<created>2019-07-10 14:06:08</created>
		<closed>2019-09-07 10:49:18</closed>
	</bug>
	<bug>
		<id>6119</id>
		<title>Box connector is still based on spring-boot</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Box connector is still based on spring-boot and should be migrate to pure camel implementation as the other connectors   /cc @tadayosi  </body>
		<created>2019-07-10 13:39:09</created>
		<closed>2019-12-02 22:41:46</closed>
	</bug>
	<bug>
		<id>6118</id>
		<title>Datamapper fails with split in some cases</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description We have had problems with datamapper causing errors when using split and aggregate steps. You can import this integration to see the error: https://drive.google.com/open?id=1aNSEt21U-NW8tyUrGo5JbL23V_tkNMQc Since it's an API provider, you need to invoke the flow with: ``` curl -X POST &lt;url&gt; -d '[{"id":2,"completed":1,"task":"task2"},{"id":3,"completed":1,"task":"task3"}]' ``` This is the resulting stacktrace (there are multiple errors so choose one you find most useful :D): [i-todo-integration-post-collection-2-6qkd4.log](https://github.com/syndesisio/syndesis/files/3377466/i-todo-integration-post-collection-2-6qkd4.log) </body>
		<created>2019-07-10 12:39:30</created>
		<closed>2019-07-22 07:33:52</closed>
	</bug>
	<bug>
		<id>6117</id>
		<title>Last Processed shows the actual date when no messages were processed yet.</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description On the metrics tab when the integration was not processed, the Last Processed section shows the actual date. The date is being changed after refreshing the page.  In my POV, the users can be confused that they see some date in the Last processed value however they don't see any activity in the activity log. They can assume that the integration was already triggered which is not true. Maybe when the no values available for Last processed, it should show something like "No processed yet" or so one. ![image](https://user-images.githubusercontent.com/16251792/60967123-311d6d00-a31a-11e9-95e2-357af5d02363.png)  Step to reproduce: 1. Create and publish simple integration Webhook-to-log 2. Don't trigger the webhook 3. Go to the Metrics tab</body>
		<created>2019-07-10 11:59:01</created>
		<closed>2019-08-12 14:34:16</closed>
	</bug>
	<bug>
		<id>6111</id>
		<title>[1.7.9] Komodo server doesn't start</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Because this property should be true/false, but it is not set during the template generation:  https://github.com/syndesisio/syndesis/blob/308b4cffd29cf85cb3276bec39f8ed775bce1efb/install/syndesis.yml#L2105-L2106  that results in this error in komodo-server:  ``` *************************** APPLICATION FAILED TO START *************************** Description: Binding to target org.komodo.rest.KomodoConfigurationProperties@4466af20 failed:     Property: controllers.exposeVia3scale     Value:      Reason: Failed to convert property value of type 'java.lang.String' to required type 'boolean' for property 'exposeVia3scale'; nested exception is org.springframework.core.convert.ConverterNotFoundException: No converter found capable of converting from type [java.lang.String] to type [boolean]  ```   </body>
		<created>2019-07-10 08:07:09</created>
		<closed>2019-07-15 07:30:44</closed>
	</bug>
	<bug>
		<id>6109</id>
		<title>Empty flow in API Provider doesn't save</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description It is possible to create an empty flow in API Provider, but without any modification of the default provided start and end steps, after saving it, it seems like no flow was created. So either it shouldn't be possible to create such flow, or it should be saved.  Also if the operation has response type set, the finish step doesn't report that there is no data supplied. ![image](https://user-images.githubusercontent.com/46345469/60949503-a0cd3100-a2f5-11e9-8281-9d6eb55f7a76.png)  ![Peek 2019-07-10 09-33](https://user-images.githubusercontent.com/46345469/60949650-eb4ead80-a2f5-11e9-891b-c0be0ebbcaf4.gif)  </body>
		<created>2019-07-10 07:34:39</created>
		<closed>2019-07-10 09:15:36</closed>
	</bug>
	<bug>
		<id>6102</id>
		<title>API Provider definition without any paths or operations leads to blank screen</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When creating an API provider from scratch, it is possible to click on Save without adding any paths or operations. Which leads to an error in the dev console and a blank screen, where the user has to modify the URL to get back to Syndesis.  ![Peek 2019-07-09 13-56](https://user-images.githubusercontent.com/46345469/60886235-bc7efb80-a251-11e9-9bfd-15af486e97c9.gif)  Console stacktrace:  TypeError: "c.integration.flows is undefined"     oo OperationsPage.tsx:121     React 11     r history.js:153     notifyListeners history.js:171     notifyListeners history.js:170     f history.js:291     push history.js:379     confirmTransitionTo history.js:140     push history.js:353     e ReviewActionsPage.tsx:68     s runtime.js:45     _invoke runtime.js:264     t runtime.js:98     r asyncToGenerator.js:3     c asyncToGenerator.js:25 react-dom.production.min.js:4408   </body>
		<created>2019-07-09 11:59:37</created>
		<closed>2019-07-17 07:11:14</closed>
	</bug>
	<bug>
		<id>6101</id>
		<title>Errors in API provider definition don't disable Next button</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The Next button is not disabled but clicking on it doesn't perform any action (as it should). If the button is not clickable or doesn't perform any action, it would be expected to be disabled. This can be replicated by creating an API Provider without any operation defined. (You still need to create a path and a operation, otherwise that leads to white screen (which is reported in #6102)  ![image](https://user-images.githubusercontent.com/46345469/60886323-f18b4e00-a251-11e9-820b-6cb98d55a4de.png) </body>
		<created>2019-07-09 11:58:24</created>
		<closed>2019-07-17 07:12:02</closed>
	</bug>
	<bug>
		<id>6099</id>
		<title>Implemented operations cannot be edited after changing API definition</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description If I implement an operation and "edit" the definition, all implemented operations appear as if they were not implemented. **Only way to edit those operations is by canceling the operation edit process and edit it again.**   ![Peek 2019-07-09 12-20](https://user-images.githubusercontent.com/46345469/60880820-af0f4480-a244-11e9-8cf2-e88200a17065.gif)  </body>
		<created>2019-07-09 10:26:13</created>
		<closed>2019-07-15 06:51:43</closed>
	</bug>
	<bug>
		<id>6085</id>
		<title>Stuck validation with Receive Email and Send Email</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  While validating https://github.com/syndesisio/syndesis/issues/5560, when everything is filled correctly, the validation goes as supposed. But when I try to set `Security Method` to something that's not correct (for example leaving it on `None` when the server and port uses `SSL/TLS`) and click on Validate, the validation just keeps going and never ends (there's no error message or anything).   While the validation is stuck, a change in the fields is useless since when I try to change the `Security Method` to the right one, the validation is still stuck, leaving me with no other option then to cancel the creation of a connector and start it all over again.  In the meta pod log, there is ``` 2019-07-08 07:56:31.266  INFO 1 --- [  XNIO-3 task-6] i.s.c.s.verifier.api.ComponentVerifier   : Verify (PARAMETERS): email === OK --  | 2019-07-08 07:57:01.370  INFO 1 --- [  XNIO-3 task-6] i.s.c.s.verifier.api.ComponentVerifier   : Verify (CONNECTIVITY): email === ERROR  | 2019-07-08 07:57:01.375 ERROR 1 --- [  XNIO-3 task-6] i.s.c.s.verifier.api.ComponentVerifier   : email --&gt;  | 2019-07-08 07:57:01.375 ERROR 1 --- [  XNIO-3 task-6] i.s.c.s.verifier.api.ComponentVerifier   :    AUTHENTICATION : Exception reading response ```  so this issue seems to be related only to the UI since the meta pod is aware of the error.</body>
		<created>2019-07-08 08:00:55</created>
		<closed>2019-08-08 10:51:10</closed>
	</bug>
	<bug>
		<id>6078</id>
		<title>Branch 1.7.x build failed due to missing camel-bom transient dependency</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Branch 1.7.x build is failing due to the following error:  ``` [INFO] ------------------------------------------------------------------------ [INFO] Reactor Summary: [INFO]  [INFO] Integration 1.7-SNAPSHOT ........................... SUCCESS [  6.101 s] [INFO] Integration :: Support :: Camel Acme ............... SUCCESS [ 15.613 s] [INFO] Integration :: API ................................. SUCCESS [ 11.791 s] [INFO] Integration :: Component Proxy ..................... SUCCESS [ 16.599 s] [INFO] Integration :: Runtime ............................. SUCCESS [ 23.971 s] [INFO] Integration :: Bill of Materials (BOM) ............. SUCCESS [  0.149 s] [INFO] Integration :: Project Generator ................... SUCCESS [ 16.465 s] [INFO] Integration :: Runtime :: Camel-k .................. FAILURE [ 11.290 s] [INFO] Integration :: Camel K :: Bill of Materials (BOM) .. SKIPPED [INFO] Integration :: Runtime :: SpringBoot 1.7-SNAPSHOT .. SKIPPED [INFO] ------------------------------------------------------------------------ [INFO] BUILD FAILURE [INFO] ------------------------------------------------------------------------ [INFO] Total time: 01:43 min [INFO] Finished at: 2019-07-05T15:56:10-03:00 [INFO] ------------------------------------------------------------------------ [ERROR] Plugin org.apache.camel.k:camel-k-maven-plugin:0.3.4.fuse-740007 or one of its dependencies could not be resolved: Failed to read artifact descriptor for org.apache.camel.k:camel-k-maven-plugin:jar:0.3.4.fuse-740007: Could not find artifact org.apache.camel:camel-bom:pom:2.21.0.fuse-740037 in redhat-ga-repository (https://maven.repository.redhat.com/ga) -&gt; [Help 1] ```  In the app/pom.xml, `camel-k-runtime.version` property is set to `0.3.4.fuse-740007`: https://github.com/syndesisio/syndesis/blob/2a5af41ba0cd6639e6456f8c5cdd71e6f2d260c8/app/pom.xml#L81  `camel-k-runtime-parent` version `0.3.4.fuse-740007` depends on Camel version `2.21.0.fuse-740037`: https://repository.jboss.org/nexus/content/groups/ea/org/apache/camel/k/camel-k-runtime-parent/0.3.4.fuse-740007/camel-k-runtime-parent-0.3.4.fuse-740007.pom  Camel version `2.21.0.fuse-740037` has been purged in the Maven repository: https://repository.jboss.org/nexus/content/groups/ea/org/apache/camel/camel-bom/2.21.0.fuse-740037/  The only valid version of `camel-k-runtime-parent` seems to be `0.3.4.fuse-740001`, which references Camel version `2.21.0.fuse-740028`. </body>
		<created>2019-07-05 19:13:11</created>
		<closed>2019-07-09 09:27:28</closed>
	</bug>
	<bug>
		<id>6077</id>
		<title>Add support for any data source with valid JDBC Driver</title>
		<body>## This is a feature request.  &lt;pre&gt;&lt;code&gt; [X ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description If a user needs to use any other database other than Derby, Postgresql, Oracle, MySQL, the recommendation is to add an "import extension" of the JDBC driver, then use that driver in creating the connection to the source. However, only above-mentioned drivers will work, any others will simply fail. For example, see #5978 Looks like this is similar to #1291 but the issue still exists.  There should be a mechanism to allow any JDBC driver and use its connection based on it in an Integration or Data Virtualization. It would be even helpful if there is a "generic" way the 'import extension mechanism" be extended to allow the JDBC drivers directly instead of forcing the user to build a uber import extension jar, even better to allow a maven repo co-ordinates directly rather than user supplying a physical jar. </body>
		<created>2019-07-05 17:52:12</created>
		<closed>2019-09-13 12:49:40</closed>
	</bug>
	<bug>
		<id>6069</id>
		<title>[Upgrade] Missing migration scripts for UI and Server CM (DV / knative / probes)</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description After upgrading from 1.6.13 to 1.7.8, the UI doesn't load because of:  ``` TypeError: Cannot read property 'dvUrl' of undefined     at Object.children (index.tsx:60)     at t.render (utils.js:697)     at Ma (react-dom.production.min.js:3785)     at Ea (react-dom.production.min.js:3776)     at La (react-dom.production.min.js:3960)     at qi (react-dom.production.min.js:5514)     at Yi (react-dom.production.min.js:5536)     at Mc (react-dom.production.min.js:5958)     at zc (react-dom.production.min.js:5925)     at xc (react-dom.production.min.js:5860) ```  this part needs to be added via the migration script into the syndesis-ui-config configmap:  ```         "datavirt": {           "dvUrl": "/vdb-builder/v1/",           "enabled": 0         },  ```  Also see the next comment for the bits missing in syndesis-server-config CM after the upgrade</body>
		<created>2019-07-04 17:28:55</created>
		<closed>2019-07-16 07:46:50</closed>
	</bug>
	<bug>
		<id>6068</id>
		<title>[Conditional Flow] Configuration required warning in working integration</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11403**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Fresh integration with conditional flow has `Configuration required` warning even though the integration works:  Picture 1: Integrations list ![screenshot_20190704_133751](https://user-images.githubusercontent.com/14313995/60664018-21f17780-9e61-11e9-8da3-a30b72fe0927.png)  Picture 2: Integration detail ![screenshot_20190704_133737](https://user-images.githubusercontent.com/14313995/60664028-29188580-9e61-11e9-83d9-797753753f8f.png)  Picture 3: Warning ![screenshot_20190704_133745](https://user-images.githubusercontent.com/14313995/60664036-2c137600-9e61-11e9-917f-8d779efeb0d5.png)  Picture 4: Edit integration ![screenshot_20190704_134029](https://user-images.githubusercontent.com/14313995/60664096-4e0cf880-9e61-11e9-9f91-f43fa0ae4b36.png)  Picture 5: One conditional flow of the integration ![screenshot_20190704_134051](https://user-images.githubusercontent.com/14313995/60664121-5c5b1480-9e61-11e9-9654-3fc3f1137884.png)   </body>
		<created>2019-07-04 11:43:57</created>
		<closed>2019-09-07 10:49:32</closed>
	</bug>
	<bug>
		<id>6067</id>
		<title>Add go to operation list to API provider</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11404**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Probably during the port to react-ui the "Go to operation list" button got forgotten. This was probably not intended, in our testsuite it was used to test the autosaving feature (that I can say works), but now the only way to access the operation list is by clicking the integration name in breadcrumbs or saving the integration (which means 2 button clicks each time I want go to another operation). </body>
		<created>2019-07-04 10:33:04</created>
		<closed>2019-09-07 10:49:38</closed>
	</bug>
	<bug>
		<id>6057</id>
		<title>Validate reconnecting Twitter OAuth connection shows "Could not authenticate you."</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11405**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Validation Twitter connection shows "Could not authenticate you." after reconnecting (due to new Consumer API keys.). When I refresh the page, the validation is successful.   ![output](https://user-images.githubusercontent.com/16251792/60598589-40963680-9dad-11e9-97db-eb5de732ddfe.gif)  **Step to reproduce:** - Go to the Settings -&gt; Twitter and fill in Consumer API Key and Consumer API Secret Key. - Go to the Connections -&gt; Create Connection -&gt; Twitter -&gt; Click on Connect Twitter and fill in user name and password - Go to the https://developer.twitter.com/en/apps/ and regenerate _Consumer API keys_ - Go to the Settings -&gt; Twitter and update values to the newly generated keys and click on Save - Go to the Connections -&gt; Twitter and click on Reconnect - Click on Validate button. The dialog "Could not authenticate you" is shown. ![image](https://user-images.githubusercontent.com/16251792/60596019-6a009380-9da8-11e9-8fb6-0975d0572a57.png) - Refresh the page and click on Validation button again. ![image](https://user-images.githubusercontent.com/16251792/60596041-784eaf80-9da8-11e9-9712-81f0db83b408.png)  Described also in #5763 </body>
		<created>2019-07-03 14:16:27</created>
		<closed>2019-09-07 10:49:48</closed>
	</bug>
	<bug>
		<id>6055</id>
		<title>Data tab needs a Tech Preview label</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11445**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The Data Virtualization part of Syndesis is Tech Preview in this release, but this is not reflected anywhere in the UI. I suggest a Tech Preview badge on the menu item itself, or in the Data Virtualization page header:  ![dv-tp](https://user-images.githubusercontent.com/9480152/60596802-02e3de80-9daa-11e9-9c8a-2ad7383dbaaa.png) </body>
		<created>2019-07-03 13:48:58</created>
		<closed>2019-09-07 11:39:46</closed>
	</bug>
	<bug>
		<id>6054</id>
		<title>No connections and integrations after db and server restart</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11406**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [b] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;    ## Description When syndesis is in state as described in : https://github.com/syndesisio/syndesis/issues/6052  All connections and integrations disappear after server and db restart.  ![screenshot_20190703_112552](https://user-images.githubusercontent.com/6814482/60581119-8ab7f180-9d86-11e9-87a5-5433e42c7c59.png)  Integrations are still working (pods are running and messages being sending).  logs (after restart:)  [syndesis-server-5-m6h4n.log](https://github.com/syndesisio/syndesis/files/3354913/syndesis-server-5-m6h4n.log) [syndesis-db-2-txn2v.log](https://github.com/syndesisio/syndesis/files/3354914/syndesis-db-2-txn2v.log) </body>
		<created>2019-07-03 12:19:52</created>
		<closed>2019-09-07 10:51:23</closed>
	</bug>
	<bug>
		<id>6053</id>
		<title>Datamapper - it's possible to map only 1 item from source</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Let's have an integration  DB -&gt; Datamapper -&gt; FHIR (I haven't checked on other integrations) I want to create 2 mappings from DB to FHIR create.  1. 1st mapping can be done normally. 2. 2nd mapping throws error when selecting item on target side 3. Only 1st mapping been saved when exiting datamapper.   EDIT: replaced by correct image ![datamapper37](https://user-images.githubusercontent.com/8707251/60582378-f8651d00-9d88-11e9-9322-673c8e98d3e6.png)  </body>
		<created>2019-07-03 09:29:24</created>
		<closed>2019-07-19 15:32:38</closed>
	</bug>
	<bug>
		<id>6052</id>
		<title>[1.7.8] No activities after small load (~80000 messages in 20hours)</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11407**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description After putting some small load (~3 messages /s ) for couple of hours no activities are listed in integrations. I hit this also on i-dev cluster and openshift pro. ![screenshot_20190703_111436](https://user-images.githubusercontent.com/6814482/60579647-d321e000-9d83-11e9-8a66-74d0f84ae2f7.png) `GET https://syndesis-test.b6ff.rh-idev.openshiftapps.com/api/v1/activity/integrations/i-LilthRWl7ZNNJJhTBQNz` results in `504 Gateway timeout`. Looks like connection to DB is really slow.  There is `syndesis-test` project on i-dev cluster that can be used for investigation.    </body>
		<created>2019-07-03 09:17:14</created>
		<closed>2019-09-07 10:52:06</closed>
	</bug>
	<bug>
		<id>6051</id>
		<title>[datamapper] data mapper is not loaded correctly on chrome</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I have seen similar issues raised but they were all solved by something else yet this issue is still present on chrome browser:  ![screenshot_20190703_104702](https://user-images.githubusercontent.com/14313995/60577593-e92da180-9d7f-11e9-8500-b6cb67a2e3e6.png)  The integration is: Database (select * from contact) -&gt; mapper -&gt; Todo connection (create task)  Todo connection was taken from [here](https://raw.githubusercontent.com/syndesisio/syndesis-qe/master/ui-tests/src/test/resources/swagger/connectors/todo.swagger.yaml) and created via customizations -&gt; upload swagger specification.  This issue is blocking some of QE automated tests.  </body>
		<created>2019-07-03 08:53:55</created>
		<closed>2019-09-07 11:44:23</closed>
	</bug>
	<bug>
		<id>6036</id>
		<title>[OAuth] Twitter connector validation unreadable error message</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11447**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description As a citizen integrator there is no way I can understand following error message:  ![screenshot_20190702_141312](https://user-images.githubusercontent.com/14313995/60511995-b3cb7a00-9cd3-11e9-839a-62f4d21ac8f7.png)  The message appears when I try to create twitter connector with invalid credentials.  </body>
		<created>2019-07-02 12:22:38</created>
		<closed>2019-09-07 11:44:57</closed>
	</bug>
	<bug>
		<id>6030</id>
		<title>API Provider integration restarts for no reason</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description After deploying a simple API Provider integration (just the todo api with a single implemented flow), it gets restarted every couple of minutes. The provided API itself works fine, except during the restart, when it's completely unavailable.  This is the log when the integration restarts:  ``` 2019-07-02 09:51:33.948  INFO 1 --- [       Thread-7] ationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2890c451: startup date [Tue Jul 02 09:49:08 UTC 2019]; root of context hierarchy 2019-07-02 09:51:33.951  INFO 1 --- [       Thread-7] o.s.c.support.DefaultLifecycleProcessor  : Stopping beans in phase 2147483647 2019-07-02 09:51:33.952  INFO 1 --- [       Thread-7] o.a.camel.spring.SpringCamelContext      : Apache Camel 2.21.0.fuse-740028 (CamelContext: todo-empty) is shutting down 2019-07-02 09:51:33.952  INFO 1 --- [       Thread-7] o.a.camel.impl.DefaultShutdownStrategy   : Starting to graceful shutdown 11 routes (timeout 300 seconds) 2019-07-02 09:51:33.966  INFO 1 --- [ - ShutdownTask] o.a.camel.impl.DefaultShutdownStrategy   : Route: i-Lim33GffTi8X3S51NMNz shutdown complete, was consuming from: direct://2a2f0185-3980-4167-af96-55cb4af5196e 2019-07-02 09:51:33.969  INFO 1 --- [ - ShutdownTask] o.a.camel.impl.DefaultShutdownStrategy   : Route: i-Lim33GefTi8X3S51NMKz shutdown complete, was consuming from: direct://d44d3329-31ed-482e-95cd-2415ac248ced 2019-07-02 09:51:33.969  INFO 1 --- [ - ShutdownTask] o.a.camel.impl.DefaultShutdownStrategy   : Route: i-Lim33GefTi8X3S51NMHz shutdown complete, was consuming from: direct://9bf8441f-0d65-4646-a418-71c0dda1c7f3 2019-07-02 09:51:33.969  INFO 1 --- [ - ShutdownTask] o.a.camel.impl.DefaultShutdownStrategy   : Route: i-Lim33GefTi8X3S51NMEz shutdown complete, was consuming from: direct://e6f15c45-b648-441e-b0a8-450d5155820b 2019-07-02 09:51:33.970  INFO 1 --- [ - ShutdownTask] o.a.camel.impl.DefaultShutdownStrategy   : Route: i-Lim33GdfTi8X3S51NMBz shutdown complete, was consuming from: direct://5513c8d7-58ae-4b68-9455-0481d9475c17 2019-07-02 09:51:33.973  INFO 1 --- [ - ShutdownTask] o.a.camel.impl.DefaultShutdownStrategy   : Route: 2a2f0185-3980-4167-af96-55cb4af5196e shutdown complete, was consuming from: servlet:/api/%7Bid%7D?headerFilterStrategy=syndesisHeaderStrategy&amp;httpMethodRestrict=DELETE 2019-07-02 09:51:33.973  INFO 1 --- [ - ShutdownTask] o.a.camel.impl.DefaultShutdownStrategy   : Route: d44d3329-31ed-482e-95cd-2415ac248ced shutdown complete, was consuming from: servlet:/api/%7Bid%7D?headerFilterStrategy=syndesisHeaderStrategy&amp;httpMethodRestrict=PUT 2019-07-02 09:51:33.973  INFO 1 --- [ - ShutdownTask] o.a.camel.impl.DefaultShutdownStrategy   : Route: 9bf8441f-0d65-4646-a418-71c0dda1c7f3 shutdown complete, was consuming from: servlet:/api/%7Bid%7D?headerFilterStrategy=syndesisHeaderStrategy&amp;httpMethodRestrict=GET 2019-07-02 09:51:33.973  INFO 1 --- [ - ShutdownTask] o.a.camel.impl.DefaultShutdownStrategy   : Route: e6f15c45-b648-441e-b0a8-450d5155820b shutdown complete, was consuming from: servlet:/api?headerFilterStrategy=syndesisHeaderStrategy&amp;httpMethodRestrict=POST 2019-07-02 09:51:33.976  INFO 1 --- [ - ShutdownTask] o.a.camel.impl.DefaultShutdownStrategy   : Route: 5513c8d7-58ae-4b68-9455-0481d9475c17 shutdown complete, was consuming from: servlet:/api?headerFilterStrategy=syndesisHeaderStrategy&amp;httpMethodRestrict=GET 2019-07-02 09:51:33.976  INFO 1 --- [ - ShutdownTask] o.a.camel.impl.DefaultShutdownStrategy   : Route: route1 shutdown complete, was consuming from: servlet:/openapi.json?headerFilterStrategy=syndesisHeaderStrategy&amp;httpMethodRestrict=GET 2019-07-02 09:51:33.977  INFO 1 --- [       Thread-7] o.a.camel.impl.DefaultShutdownStrategy   : Graceful shutdown of 11 routes completed in 0 seconds 2019-07-02 09:51:34.003 DEBUG 1 --- [       Thread-7] i.s.i.c.proxy.ComponentProxyComponent    : Stopping connector: direct-4-0 2019-07-02 09:51:34.004 DEBUG 1 --- [       Thread-7] i.s.i.c.proxy.ComponentProxyComponent    : Stopping connector: direct-3-0 2019-07-02 09:51:34.004 DEBUG 1 --- [       Thread-7] i.s.i.c.proxy.ComponentProxyComponent    : Stopping connector: direct-2-0 2019-07-02 09:51:34.004 DEBUG 1 --- [       Thread-7] i.s.i.c.proxy.ComponentProxyComponent    : Stopping connector: direct-1-0 2019-07-02 09:51:34.004 DEBUG 1 --- [       Thread-7] i.s.i.c.proxy.ComponentProxyComponent    : Stopping component: sql-sql-0-1 2019-07-02 09:51:34.004 DEBUG 1 --- [       Thread-7] i.s.i.c.proxy.ComponentProxyComponent    : Stopping connector: sql-0-1 2019-07-02 09:51:34.004 DEBUG 1 --- [       Thread-7] i.s.i.c.proxy.ComponentProxyComponent    : Stopping connector: bean-3-1 2019-07-02 09:51:34.004 DEBUG 1 --- [       Thread-7] i.s.i.c.proxy.ComponentProxyComponent    : Stopping connector: direct-0-0 2019-07-02 09:51:34.004 DEBUG 1 --- [       Thread-7] i.s.i.c.proxy.ComponentProxyComponent    : Stopping connector: bean-4-1 2019-07-02 09:51:34.004 DEBUG 1 --- [       Thread-7] i.s.i.c.proxy.ComponentProxyComponent    : Stopping connector: bean-1-1 2019-07-02 09:51:34.004 DEBUG 1 --- [       Thread-7] i.s.i.c.proxy.ComponentProxyComponent    : Stopping connector: bean-2-1 2019-07-02 09:51:34.004 DEBUG 1 --- [       Thread-7] i.s.i.c.proxy.ComponentProxyComponent    : Stopping connector: bean-0-3 2019-07-02 09:51:34.021  INFO 1 --- [       Thread-7] o.a.camel.spring.SpringCamelContext      : Apache Camel 2.21.0.fuse-740028 (CamelContext: todo-empty) uptime 2 minutes 2019-07-02 09:51:34.021  INFO 1 --- [       Thread-7] o.a.camel.spring.SpringCamelContext      : Apache Camel 2.21.0.fuse-740028 (CamelContext: todo-empty) is shutdown in 0.069 seconds 2019-07-02 09:51:34.021  INFO 1 --- [       Thread-7] o.s.c.support.DefaultLifecycleProcessor  : Stopping beans in phase 0 2019-07-02 09:51:34.026  INFO 1 --- [       Thread-7] o.s.j.e.a.AnnotationMBeanExporter        : Unregistering JMX-exposed beans on shutdown 2019-07-02 09:51:34.033  INFO 1 --- [       Thread-7] o.a.c.c.s.CamelHttpTransportServlet      : Destroyed CamelHttpTransportServlet[CamelServlet] ```</body>
		<created>2019-07-02 09:59:25</created>
		<closed>2019-07-19 09:47:55</closed>
	</bug>
	<bug>
		<id>6028</id>
		<title>Permission issues when installing from the template</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  When installing from template via `install-syndesis --legacy --tag 1.7.8 --project syndesis-test` on our staging cluster there are permission issues:   1. unable to create `syndesis-knative-reader` role and the role binding (as the role hasn't been created):  ```    error: roles.rbac.authorization.k8s.io "syndesis-knative-reader" is forbidden: attempt to grant extra privileges: [{[get] [serving.knative.dev] [services] [] []} {[list] [serving.knative.dev] [services] [] []} {[watch] [serving.knative.dev] [services] [] []} {[get] [eventing.knative.dev] [channels] [] []} {[list] [eventing.knative.dev] [channels] [] []} {[watch] [eventing.knative.dev] [channels] [] []}] user=&amp;{zregvart a87c1d5b-1c39-11e7-b66a-0e6aaf341bbf [dedicated-admins syndesis system:authenticated:oauth system:authenticated] map[scopes.authorization.openshift.io:[user:full]]} ownerrules=[{[get] [user.openshift.io ] [users] [~] []} {[list] [project.openshift.io ] [projectrequests] [] []} {[get list] [authorization.openshift.io ] [clusterroles] [] []} {[get list] [storage.k8s.io] [storageclasses] [] []} {[list watch] [project.openshift.io ] [projects] [] []} {[create] [authorization.openshift.io ] [selfsubjectrulesreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews] [] []} {[get] [rbac.authorization.k8s.io] [clusterroles] [] []} {[list] [rbac.authorization.k8s.io] [clusterroles] [] []} {[watch] [rbac.authorization.k8s.io] [clusterroles] [] []} {[get] [] [namespaces] [] []} {[get] [] [] [] [/healthz /healthz/*]} {[get] [] [] [] [/.well-known /.well-known/* /api /api/* /apis /apis/* /oapi /oapi/* /osapi /osapi/ /swagger.json /swaggerapi /swaggerapi/* /version /version/*]} {[get] [] [] [] [/]} {[get] [] [] [] [/swagger-2.0.0.pb-v1]} {[get] [] [] [] [/openapi/v2]} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [authorization.openshift.io ] [selfsubjectrulesreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectrulesreviews] [] []} {[create] [build.openshift.io ] [builds/custom] [] []} {[create] [build.openshift.io ] [builds/docker builds/optimizeddocker] [] []} {[create] [build.openshift.io ] [builds/jenkinspipeline] [] []} {[create] [build.openshift.io ] [builds/source] [] []} {[get] [] [] [] [/.well-known /.well-known/* /api /api/* /apis /apis/* /oapi /oapi/* /osapi /osapi/ /swagger.json /swaggerapi /swaggerapi/* /version /version/*]} {[get] [] [] [] [/]} {[get] [] [] [] [/swagger-2.0.0.pb-v1]} {[get] [] [] [] [/openapi/v2]} {[get] [] [] [] [/healthz]} {[get] [] [] [] [/openapi]} {[get] [] [] [] [/openapi/*]} {[get] [] [] [] [/.well-known /.well-known/* /api /api/* /apis /apis/* /oapi /oapi/* /osapi /osapi/ /swagger.json /swaggerapi /swaggerapi/* /version /version/*]} {[get] [] [] [] [/]} {[get] [] [] [] [/swagger-2.0.0.pb-v1]} {[get] [] [] [] [/openapi/v2]} {[get] [] [] [] [/healthz]} {[get] [] [] [] [/openapi]} {[get] [] [] [] [/openapi/*]} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[delete] [oauth.openshift.io ] [oauthaccesstokens oauthauthorizetokens] [] []} {[get] [] [] [] [/version /version/* /api /api/* /apis /apis/* /oapi /oapi/* /openapi/v2 /swaggerapi /swaggerapi/* /swagger.json /swagger-2.0.0.pb-v1 /osapi /osapi/ /.well-known /.well-known/* /]} {[impersonate] [authentication.k8s.io] [userextras/scopes.authorization.openshift.io] [] []} {[create get] [build.openshift.io ] [buildconfigs/webhooks] [] []} {[*] [camel.apache.org] [*] [] []} {[create delete deletecollection get list patch update watch] [] [pods pods/attach pods/exec pods/portforward pods/proxy] [] []} {[create delete deletecollection get list patch update watch] [] [configmaps endpoints persistentvolumeclaims replicationcontrollers replicationcontrollers/scale secrets serviceaccounts services services/proxy] [] []} {[get list watch] [] [bindings events limitranges namespaces/status pods/log pods/status replicationcontrollers/status resourcequotas resourcequotas/status] [] []} {[get list watch] [] [namespaces] [] []} {[impersonate] [] [serviceaccounts] [] []} {[create delete deletecollection get list patch update watch] [apps] [daemonsets deployments deployments/rollback deployments/scale replicasets replicasets/scale statefulsets] [] []} {[create delete deletecollection get list patch update watch] [autoscaling] [horizontalpodautoscalers] [] []} {[create delete deletecollection get list patch update watch] [batch] [cronjobs jobs] [] []} {[create delete deletecollection get list patch update watch] [extensions] [daemonsets deployments deployments/rollback deployments/scale ingresses replicasets replicasets/scale replicationcontrollers/scale] [] []} {[create delete deletecollection get list patch update watch] [policy] [poddisruptionbudgets] [] []} {[create] [authorization.k8s.io] [localsubjectaccessreviews] [] []} {[create delete deletecollection get list patch update watch] [rbac.authorization.k8s.io] [rolebindings roles] [] []} {[create] [apps] [statefulsets/scale] [] []} {[delete] [apps] [statefulsets/scale] [] []} {[deletecollection] [apps] [statefulsets/scale] [] []} {[get] [apps] [statefulsets/scale] [] []} {[list] [apps] [statefulsets/scale] [] []} {[patch] [apps] [statefulsets/scale] [] []} {[update] [apps] [statefulsets/scale] [] []} {[watch] [apps] [statefulsets/scale] [] []} {[create] [extensions] [networkpolicies] [] []} {[delete] [extensions] [networkpolicies] [] []} {[deletecollection] [extensions] [networkpolicies] [] []} {[get] [extensions] [networkpolicies] [] []} {[list] [extensions] [networkpolicies] [] []} {[patch] [extensions] [networkpolicies] [] []} {[update] [extensions] [networkpolicies] [] []} {[watch] [extensions] [networkpolicies] [] []} {[create] [networking.k8s.io] [networkpolicies] [] []} {[delete] [networking.k8s.io] [networkpolicies] [] []} {[deletecollection] [networking.k8s.io] [networkpolicies] [] []} {[get] [networking.k8s.io] [networkpolicies] [] []} {[list] [networking.k8s.io] [networkpolicies] [] []} {[patch] [networking.k8s.io] [networkpolicies] [] []} {[update] [networking.k8s.io] [networkpolicies] [] []} {[watch] [networking.k8s.io] [networkpolicies] [] []} {[get list watch] [] [bindings events limitranges namespaces namespaces/status pods/log pods/status replicationcontrollers/status resourcequotas resourcequotas/status] [] []} {[create delete deletecollection get list patch update watch] [batch] [cronjobs jobs scheduledjobs] [] []} {[create delete deletecollection get list patch update watch] [extensions] [deployments deployments/rollback deployments/scale horizontalpodautoscalers jobs networkpolicies replicasets replicasets/scale replicationcontrollers/scale] [] []} {[get list watch] [extensions] [daemonsets] [] []} {[create delete deletecollection get list patch update watch] [apps] [deployments deployments/scale deployments/status statefulsets] [] []} {[create delete deletecollection get list patch update watch] [authorization.openshift.io ] [rolebindings roles] [] []} {[create] [authorization.openshift.io ] [localresourceaccessreviews localsubjectaccessreviews subjectrulesreviews] [] []} {[create] [security.openshift.io ] [podsecuritypolicyreviews podsecuritypolicyselfsubjectreviews podsecuritypolicysubjectreviews] [] []} {[get list watch] [authorization.openshift.io ] [policies policybindings rolebindingrestrictions] [] []} {[create delete deletecollection get list patch update watch] [build.openshift.io ] [buildconfigs buildconfigs/webhooks builds] [] []} {[get list watch] [build.openshift.io ] [builds/log] [] []} {[create] [build.openshift.io ] [buildconfigs/instantiate buildconfigs/instantiatebinary builds/clone] [] []} {[update] [build.openshift.io ] [builds/details] [] []} {[admin edit view] [build.openshift.io] [jenkins] [] []} {[create delete deletecollection get list patch update watch] [apps.openshift.io ] [deploymentconfigs deploymentconfigs/scale generatedeploymentconfigs] [] []} {[create] [apps.openshift.io ] [deploymentconfigrollbacks deploymentconfigs/instantiate deploymentconfigs/rollback] [] []} {[get list watch] [apps.openshift.io ] [deploymentconfigs/log deploymentconfigs/status] [] []} {[create delete deletecollection get list patch update watch] [image.openshift.io ] [imagestreamimages imagestreammappings imagestreams imagestreams/secrets imagestreamtags] [] []} {[get list watch] [image.openshift.io ] [imagestreams/status] [] []} {[get update] [image.openshift.io ] [imagestreams/layers] [] []} {[create] [image.openshift.io ] [imagestreamimports] [] []} {[delete get patch update] [project.openshift.io ] [projects] [] []} {[get list watch] [quota.openshift.io ] [appliedclusterresourcequotas] [] []} {[create delete deletecollection get list patch update watch] [route.openshift.io ] [routes] [] []} {[create] [route.openshift.io ] [routes/custom-host] [] []} {[get list watch] [route.openshift.io ] [routes/status] [] []} {[update] [route.openshift.io ] [routes/status] [] []} {[create delete deletecollection get list patch update watch] [template.openshift.io ] [processedtemplates templateconfigs templateinstances templates] [] []} {[create delete deletecollection get list patch update watch] [build.openshift.io ] [buildlogs] [] []} {[get list watch] [] [resourcequotausages] [] []} {[create] [authorization.openshift.io ] [resourceaccessreviews subjectaccessreviews] [] []} {[patch] [apps] [petsets] [] []} {[update] [apps] [petsets] [] []} {[watch] [apps] [petsets] [] []} {[create] [apps] [petsets] [] []} {[delete] [apps] [petsets] [] []} {[deletecollection] [apps] [petsets] [] []} {[get] [apps] [petsets] [] []} {[list] [apps] [petsets] [] []} {[patch] [] [deploymentconfigrollbacks] [] []} {[update] [] [deploymentconfigrollbacks] [] []} {[watch] [] [deploymentconfigrollbacks] [] []} {[delete] [] [deploymentconfigrollbacks] [] []} {[deletecollection] [] [deploymentconfigrollbacks] [] []} {[get] [] [deploymentconfigrollbacks] [] []} {[list] [] [deploymentconfigrollbacks] [] []} {[list] [] [deploymentconfigs/rollback] [] []} {[patch] [] [deploymentconfigs/rollback] [] []} {[update] [] [deploymentconfigs/rollback] [] []} {[watch] [] [deploymentconfigs/rollback] [] []} {[delete] [] [deploymentconfigs/rollback] [] []} {[deletecollection] [] [deploymentconfigs/rollback] [] []} {[get] [] [deploymentconfigs/rollback] [] []} {[create] [] [pods/log] [] []} {[delete] [] [pods/log] [] []} {[deletecollection] [] [pods/log] [] []} {[patch] [] [pods/log] [] []} {[update] [] [pods/log] [] []} {[update] [] [deploymentconfigs/log] [] []} {[create] [] [deploymentconfigs/log] [] []} {[delete] [] [deploymentconfigs/log] [] []} {[deletecollection] [] [deploymentconfigs/log] [] []} {[patch] [] [deploymentconfigs/log] [] []} {[list] [] [deployments] [] []} {[patch] [] [deployments] [] []} {[update] [] [deployments] [] []} {[watch] [] [deployments] [] []} {[create] [] [deployments] [] []} {[delete] [] [deployments] [] []} {[deletecollection] [] [deployments] [] []} {[get] [] [deployments] [] []} {[list] [] [subjectaccessreviews] [] []} {[patch] [] [subjectaccessreviews] [] []} {[update] [] [subjectaccessreviews] [] []} {[watch] [] [subjectaccessreviews] [] []} {[delete] [] [subjectaccessreviews] [] []} {[deletecollection] [] [subjectaccessreviews] [] []} {[get] [] [subjectaccessreviews] [] []} {[list] [] [buildconfigs/instantiatebinary] [] []} {[patch] [] [buildconfigs/instantiatebinary] [] []} {[update] [] [buildconfigs/instantiatebinary] [] []} {[watch] [] [buildconfigs/instantiatebinary] [] []} {[delete] [] [buildconfigs/instantiatebinary] [] []} {[deletecollection] [] [buildconfigs/instantiatebinary] [] []} {[get] [] [buildconfigs/instantiatebinary] [] []} {[delete] [] [localresourceaccessreviews] [] []} {[deletecollection] [] [localresourceaccessreviews] [] []} {[get] [] [localresourceaccessreviews] [] []} {[list] [] [localresourceaccessreviews] [] []} {[patch] [] [localresourceaccessreviews] [] []} {[update] [] [localresourceaccessreviews] [] []} {[watch] [] [localresourceaccessreviews] [] []} {[deletecollection] [] [projects] [] []} {[list] [] [projects] [] []} {[watch] [] [projects] [] []} {[create] [] [projects] [] []} {[patch] [] [resourceaccessreviews] [] []} {[update] [] [resourceaccessreviews] [] []} {[watch] [] [resourceaccessreviews] [] []} {[delete] [] [resourceaccessreviews] [] []} {[deletecollection] [] [resourceaccessreviews] [] []} {[get] [] [resourceaccessreviews] [] []} {[list] [] [resourceaccessreviews] [] []} {[deletecollection] [] [buildconfigs/instantiate] [] []} {[get] [] [buildconfigs/instantiate] [] []} {[list] [] [buildconfigs/instantiate] [] []} {[patch] [] [buildconfigs/instantiate] [] []} {[update] [] [buildconfigs/instantiate] [] []} {[watch] [] [buildconfigs/instantiate] [] []} {[delete] [] [buildconfigs/instantiate] [] []} {[patch] [] [builds/log] [] []} {[update] [] [builds/log] [] []} {[create] [] [builds/log] [] []} {[delete] [] [builds/log] [] []} {[deletecollection] [] [builds/log] [] []} {[watch] [] [imagestreamimports] [] []} {[delete] [] [imagestreamimports] [] []} {[deletecollection] [] [imagestreamimports] [] []} {[get] [] [imagestreamimports] [] []} {[list] [] [imagestreamimports] [] []} {[patch] [] [imagestreamimports] [] []} {[update] [] [imagestreamimports] [] []} {[patch] [] [builds/clone] [] []} {[update] [] [builds/clone] [] []} {[watch] [] [builds/clone] [] []} {[delete] [] [builds/clone] [] []} {[deletecollection] [] [builds/clone] [] []} {[get] [] [builds/clone] [] []} {[list] [] [builds/clone] [] []} {[watch] [] [localsubjectaccessreviews] [] []} {[delete] [] [localsubjectaccessreviews] [] []} {[deletecollection] [] [localsubjectaccessreviews] [] []} {[get] [] [localsubjectaccessreviews] [] []} {[list] [] [localsubjectaccessreviews] [] []} {[patch] [] [localsubjectaccessreviews] [] []} {[update] [] [localsubjectaccessreviews] [] []} {[get] [] [securitycontextconstraints] [] []} {[list] [] [securitycontextconstraints] [] []} {[watch] [] [securitycontextconstraints] [] []} {[get] [] [minions] [] []} {[list] [] [minions] [] []} {[watch] [] [minions] [] []} {[get] [] [nodes] [] []} {[list] [] [nodes] [] []} {[watch] [] [nodes] [] []} {[get] [] [persistentvolumes] [] []} {[list] [] [persistentvolumes] [] []} {[watch] [] [persistentvolumes] [] []} {[create] [rbac.authorization.k8s.io] [rolebindings] [] []} {[delete] [rbac.authorization.k8s.io] [rolebindings] [] []} {[deletecollection] [rbac.authorization.k8s.io] [rolebindings] [] []} {[get] [rbac.authorization.k8s.io] [rolebindings] [] []} {[list] [rbac.authorization.k8s.io] [rolebindings] [] []} {[patch] [rbac.authorization.k8s.io] [rolebindings] [] []} {[update] [rbac.authorization.k8s.io] [rolebindings] [] []} {[watch] [rbac.authorization.k8s.io] [rolebindings] [] []} {[create] [rbac.authorization.k8s.io] [roles] [] []} {[delete] [rbac.authorization.k8s.io] [roles] [] []} {[deletecollection] [rbac.authorization.k8s.io] [roles] [] []} {[get] [rbac.authorization.k8s.io] [roles] [] []} {[list] [rbac.authorization.k8s.io] [roles] [] []} {[patch] [rbac.authorization.k8s.io] [roles] [] []} {[update] [rbac.authorization.k8s.io] [roles] [] []} {[watch] [rbac.authorization.k8s.io] [roles] [] []} {[create] [apps] [deployments/rollback] [] []} {[delete] [apps] [deployments/rollback] [] []} {[deletecollection] [apps] [deployments/rollback] [] []} {[get] [apps] [deployments/rollback] [] []} {[list] [apps] [deployments/rollback] [] []} {[patch] [apps] [deployments/rollback] [] []} {[update] [apps] [deployments/rollback] [] []} {[watch] [apps] [deployments/rollback] [] []} {[create] [apps] [replicasets] [] []} {[delete] [apps] [replicasets] [] []} {[deletecollection] [apps] [replicasets] [] []} {[get] [apps] [replicasets] [] []} {[list] [apps] [replicasets] [] []} {[patch] [apps] [replicasets] [] []} {[update] [apps] [replicasets] [] []} {[watch] [apps] [replicasets] [] []} {[create] [apps] [replicasets/scale] [] []} {[delete] [apps] [replicasets/scale] [] []} {[deletecollection] [apps] [replicasets/scale] [] []} {[get] [apps] [replicasets/scale] [] []} {[list] [apps] [replicasets/scale] [] []} {[patch] [apps] [replicasets/scale] [] []} {[update] [apps] [replicasets/scale] [] []} {[watch] [apps] [replicasets/scale] [] []} {[create] [apps] [replicationcontrollers/scale] [] []} {[delete] [apps] [replicationcontrollers/scale] [] []} {[deletecollection] [apps] [replicationcontrollers/scale] [] []} {[get] [apps] [replicationcontrollers/scale] [] []} {[list] [apps] [replicationcontrollers/scale] [] []} {[patch] [apps] [replicationcontrollers/scale] [] []} {[update] [apps] [replicationcontrollers/scale] [] []} {[watch] [apps] [replicationcontrollers/scale] [] []} {[get] [apps] [daemonsets] [] []} {[list] [apps] [daemonsets] [] []} {[watch] [apps] [daemonsets] [] []} {[create update delete get list watch patch] [servicecatalog.k8s.io] [serviceinstances servicebindings] [] []} {[create update delete get list watch] [settings.k8s.io] [podpresets] [] []}] ruleResolutionErrors=[]     error: roles.rbac.authorization.k8s.io "syndesis-knative-reader" not found ```   2. unable to create `syndesis-editor` role:  ```     error: roles.rbac.authorization.k8s.io "syndesis-editor" is forbidden: attempt to grant extra privileges: [{[create] [] [replicationcontrollers/status] [] []} {[update] [] [replicationcontrollers/status] [] []} {[delete] [] [replicationcontrollers/status] [] []} {[deletecollection] [] [replicationcontrollers/status] [] []} {[get] [] [builds/details] [] []} {[list] [] [builds/details] [] []} {[create] [] [builds/details] [] []} {[delete] [] [builds/details] [] []} {[deletecollection] [] [builds/details] [] []} {[watch] [] [builds/details] [] []} {[get] [build.openshift.io] [builds/details] [] []} {[list] [build.openshift.io] [builds/details] [] []} {[create] [build.openshift.io] [builds/details] [] []} {[delete] [build.openshift.io] [builds/details] [] []} {[deletecollection] [build.openshift.io] [builds/details] [] []} {[watch] [build.openshift.io] [builds/details] [] []} {[get] [build.openshift.io] [buildconfigs/instantiatebinary] [] []} {[list] [build.openshift.io] [buildconfigs/instantiatebinary] [] []} {[update] [build.openshift.io] [buildconfigs/instantiatebinary] [] []} {[delete] [build.openshift.io] [buildconfigs/instantiatebinary] [] []} {[deletecollection] [build.openshift.io] [buildconfigs/instantiatebinary] [] []} {[watch] [build.openshift.io] [buildconfigs/instantiatebinary] [] []} {[create] [build.openshift.io] [builds/log] [] []} {[update] [build.openshift.io] [builds/log] [] []} {[delete] [build.openshift.io] [builds/log] [] []} {[deletecollection] [build.openshift.io] [builds/log] [] []} {[get] [image.openshift.io] [imagestreamimports] [] []} {[list] [image.openshift.io] [imagestreamimports] [] []} {[watch] [image.openshift.io] [imagestreamimports] [] []}] user=&amp;{zregvart a87c1d5b-1c39-11e7-b66a-0e6aaf341bbf [dedicated-admins syndesis system:authenticated:oauth system:authenticated] map[scopes.authorization.openshift.io:[user:full]]} ownerrules=[{[get] [user.openshift.io ] [users] [~] []} {[list] [project.openshift.io ] [projectrequests] [] []} {[get list] [authorization.openshift.io ] [clusterroles] [] []} {[get list] [storage.k8s.io] [storageclasses] [] []} {[list watch] [project.openshift.io ] [projects] [] []} {[create] [authorization.openshift.io ] [selfsubjectrulesreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews] [] []} {[get] [rbac.authorization.k8s.io] [clusterroles] [] []} {[list] [rbac.authorization.k8s.io] [clusterroles] [] []} {[watch] [rbac.authorization.k8s.io] [clusterroles] [] []} {[get] [] [namespaces] [] []} {[get] [] [] [] [/healthz /healthz/*]} {[get] [] [] [] [/.well-known /.well-known/* /api /api/* /apis /apis/* /oapi /oapi/* /osapi /osapi/ /swagger.json /swaggerapi /swaggerapi/* /version /version/*]} {[get] [] [] [] [/]} {[get] [] [] [] [/swagger-2.0.0.pb-v1]} {[get] [] [] [] [/openapi/v2]} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create delete get list patch update watch] [ user.openshift.io] [groups identities useridentitymappings users] [] []} {[create delete get list patch update watch] [ authorization.openshift.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [rbac.authorization.k8s.io] [clusterrolebindings rolebindings] [] []} {[create delete get list patch update watch] [ oauth.openshift.io] [oauthclients] [] []} {[delete get list watch] [ oauth.openshift.io] [oauthclientauthorizations] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [authorization.k8s.io] [subjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[get list watch] [] [events minions nodes persistentvolumes pods] [] []} {[get list watch] [ security.openshift.io] [securitycontextconstraints] [] []} {[get list watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[get list] [ authorization.openshift.io] [clusterpolicybindings] [] []} {[get list watch] [ image.openshift.io] [images imagestreamtags] [] []} {[get list update] [ network.openshift.io] [netnamespaces] [] []} {[get list] [ network.openshift.io] [clusternetworks] [] []} {[get list watch] [ build.openshift.io] [buildconfigs builds] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [authorization.openshift.io ] [selfsubjectrulesreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectrulesreviews] [] []} {[create] [build.openshift.io ] [builds/custom] [] []} {[create] [build.openshift.io ] [builds/docker builds/optimizeddocker] [] []} {[create] [build.openshift.io ] [builds/jenkinspipeline] [] []} {[create] [build.openshift.io ] [builds/source] [] []} {[get] [] [] [] [/.well-known /.well-known/* /api /api/* /apis /apis/* /oapi /oapi/* /osapi /osapi/ /swagger.json /swaggerapi /swaggerapi/* /version /version/*]} {[get] [] [] [] [/]} {[get] [] [] [] [/swagger-2.0.0.pb-v1]} {[get] [] [] [] [/openapi/v2]} {[get] [] [] [] [/healthz]} {[get] [] [] [] [/openapi]} {[get] [] [] [] [/openapi/*]} {[get] [] [] [] [/.well-known /.well-known/* /api /api/* /apis /apis/* /oapi /oapi/* /osapi /osapi/ /swagger.json /swaggerapi /swaggerapi/* /version /version/*]} {[get] [] [] [] [/]} {[get] [] [] [] [/swagger-2.0.0.pb-v1]} {[get] [] [] [] [/openapi/v2]} {[get] [] [] [] [/healthz]} {[get] [] [] [] [/openapi]} {[get] [] [] [] [/openapi/*]} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get list watch] [] [nodes] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[delete] [oauth.openshift.io ] [oauthaccesstokens oauthauthorizetokens] [] []} {[get] [] [] [] [/version /version/* /api /api/* /apis /apis/* /oapi /oapi/* /openapi/v2 /swaggerapi /swaggerapi/* /swagger.json /swagger-2.0.0.pb-v1 /osapi /osapi/ /.well-known /.well-known/* /]} {[impersonate] [authentication.k8s.io] [userextras/scopes.authorization.openshift.io] [] []} {[create get] [build.openshift.io ] [buildconfigs/webhooks] [] []} {[*] [camel.apache.org] [*] [] []} {[create delete deletecollection get list patch update watch] [] [pods pods/attach pods/exec pods/portforward pods/proxy] [] []} {[create delete deletecollection get list patch update watch] [] [configmaps endpoints persistentvolumeclaims replicationcontrollers replicationcontrollers/scale secrets serviceaccounts services services/proxy] [] []} {[get list watch] [] [bindings events limitranges namespaces/status pods/log pods/status replicationcontrollers/status resourcequotas resourcequotas/status] [] []} {[get list watch] [] [namespaces] [] []} {[impersonate] [] [serviceaccounts] [] []} {[create delete deletecollection get list patch update watch] [apps] [daemonsets deployments deployments/rollback deployments/scale replicasets replicasets/scale statefulsets] [] []} {[create delete deletecollection get list patch update watch] [autoscaling] [horizontalpodautoscalers] [] []} {[create delete deletecollection get list patch update watch] [batch] [cronjobs jobs] [] []} {[create delete deletecollection get list patch update watch] [extensions] [daemonsets deployments deployments/rollback deployments/scale ingresses replicasets replicasets/scale replicationcontrollers/scale] [] []} {[create delete deletecollection get list patch update watch] [policy] [poddisruptionbudgets] [] []} {[create] [authorization.k8s.io] [localsubjectaccessreviews] [] []} {[create delete deletecollection get list patch update watch] [rbac.authorization.k8s.io] [rolebindings roles] [] []} {[create] [apps] [statefulsets/scale] [] []} {[delete] [apps] [statefulsets/scale] [] []} {[deletecollection] [apps] [statefulsets/scale] [] []} {[get] [apps] [statefulsets/scale] [] []} {[list] [apps] [statefulsets/scale] [] []} {[patch] [apps] [statefulsets/scale] [] []} {[update] [apps] [statefulsets/scale] [] []} {[watch] [apps] [statefulsets/scale] [] []} {[create] [extensions] [networkpolicies] [] []} {[delete] [extensions] [networkpolicies] [] []} {[deletecollection] [extensions] [networkpolicies] [] []} {[get] [extensions] [networkpolicies] [] []} {[list] [extensions] [networkpolicies] [] []} {[patch] [extensions] [networkpolicies] [] []} {[update] [extensions] [networkpolicies] [] []} {[watch] [extensions] [networkpolicies] [] []} {[create] [networking.k8s.io] [networkpolicies] [] []} {[delete] [networking.k8s.io] [networkpolicies] [] []} {[deletecollection] [networking.k8s.io] [networkpolicies] [] []} {[get] [networking.k8s.io] [networkpolicies] [] []} {[list] [networking.k8s.io] [networkpolicies] [] []} {[patch] [networking.k8s.io] [networkpolicies] [] []} {[update] [networking.k8s.io] [networkpolicies] [] []} {[watch] [networking.k8s.io] [networkpolicies] [] []} {[get list watch] [] [bindings events limitranges namespaces namespaces/status pods/log pods/status replicationcontrollers/status resourcequotas resourcequotas/status] [] []} {[create delete deletecollection get list patch update watch] [batch] [cronjobs jobs scheduledjobs] [] []} {[create delete deletecollection get list patch update watch] [extensions] [deployments deployments/rollback deployments/scale horizontalpodautoscalers jobs networkpolicies replicasets replicasets/scale replicationcontrollers/scale] [] []} {[get list watch] [extensions] [daemonsets] [] []} {[create delete deletecollection get list patch update watch] [apps] [deployments deployments/scale deployments/status statefulsets] [] []} {[create delete deletecollection get list patch update watch] [authorization.openshift.io ] [rolebindings roles] [] []} {[create] [authorization.openshift.io ] [localresourceaccessreviews localsubjectaccessreviews subjectrulesreviews] [] []} {[create] [security.openshift.io ] [podsecuritypolicyreviews podsecuritypolicyselfsubjectreviews podsecuritypolicysubjectreviews] [] []} {[get list watch] [authorization.openshift.io ] [policies policybindings rolebindingrestrictions] [] []} {[create delete deletecollection get list patch update watch] [build.openshift.io ] [buildconfigs buildconfigs/webhooks builds] [] []} {[get list watch] [build.openshift.io ] [builds/log] [] []} {[create] [build.openshift.io ] [buildconfigs/instantiate buildconfigs/instantiatebinary builds/clone] [] []} {[update] [build.openshift.io ] [builds/details] [] []} {[admin edit view] [build.openshift.io] [jenkins] [] []} {[create delete deletecollection get list patch update watch] [apps.openshift.io ] [deploymentconfigs deploymentconfigs/scale generatedeploymentconfigs] [] []} {[create] [apps.openshift.io ] [deploymentconfigrollbacks deploymentconfigs/instantiate deploymentconfigs/rollback] [] []} {[get list watch] [apps.openshift.io ] [deploymentconfigs/log deploymentconfigs/status] [] []} {[create delete deletecollection get list patch update watch] [image.openshift.io ] [imagestreamimages imagestreammappings imagestreams imagestreams/secrets imagestreamtags] [] []} {[get list watch] [image.openshift.io ] [imagestreams/status] [] []} {[get update] [image.openshift.io ] [imagestreams/layers] [] []} {[create] [image.openshift.io ] [imagestreamimports] [] []} {[delete get patch update] [project.openshift.io ] [projects] [] []} {[get list watch] [quota.openshift.io ] [appliedclusterresourcequotas] [] []} {[create delete deletecollection get list patch update watch] [route.openshift.io ] [routes] [] []} {[create] [route.openshift.io ] [routes/custom-host] [] []} {[get list watch] [route.openshift.io ] [routes/status] [] []} {[update] [route.openshift.io ] [routes/status] [] []} {[create delete deletecollection get list patch update watch] [template.openshift.io ] [processedtemplates templateconfigs templateinstances templates] [] []} {[create delete deletecollection get list patch update watch] [build.openshift.io ] [buildlogs] [] []} {[get list watch] [] [resourcequotausages] [] []} {[create] [authorization.openshift.io ] [resourceaccessreviews subjectaccessreviews] [] []} {[patch] [apps] [petsets] [] []} {[update] [apps] [petsets] [] []} {[watch] [apps] [petsets] [] []} {[create] [apps] [petsets] [] []} {[delete] [apps] [petsets] [] []} {[deletecollection] [apps] [petsets] [] []} {[get] [apps] [petsets] [] []} {[list] [apps] [petsets] [] []} {[patch] [] [deploymentconfigrollbacks] [] []} {[update] [] [deploymentconfigrollbacks] [] []} {[watch] [] [deploymentconfigrollbacks] [] []} {[delete] [] [deploymentconfigrollbacks] [] []} {[deletecollection] [] [deploymentconfigrollbacks] [] []} {[get] [] [deploymentconfigrollbacks] [] []} {[list] [] [deploymentconfigrollbacks] [] []} {[list] [] [deploymentconfigs/rollback] [] []} {[patch] [] [deploymentconfigs/rollback] [] []} {[update] [] [deploymentconfigs/rollback] [] []} {[watch] [] [deploymentconfigs/rollback] [] []} {[delete] [] [deploymentconfigs/rollback] [] []} {[deletecollection] [] [deploymentconfigs/rollback] [] []} {[get] [] [deploymentconfigs/rollback] [] []} {[create] [] [pods/log] [] []} {[delete] [] [pods/log] [] []} {[deletecollection] [] [pods/log] [] []} {[patch] [] [pods/log] [] []} {[update] [] [pods/log] [] []} {[update] [] [deploymentconfigs/log] [] []} {[create] [] [deploymentconfigs/log] [] []} {[delete] [] [deploymentconfigs/log] [] []} {[deletecollection] [] [deploymentconfigs/log] [] []} {[patch] [] [deploymentconfigs/log] [] []} {[list] [] [deployments] [] []} {[patch] [] [deployments] [] []} {[update] [] [deployments] [] []} {[watch] [] [deployments] [] []} {[create] [] [deployments] [] []} {[delete] [] [deployments] [] []} {[deletecollection] [] [deployments] [] []} {[get] [] [deployments] [] []} {[list] [] [subjectaccessreviews] [] []} {[patch] [] [subjectaccessreviews] [] []} {[update] [] [subjectaccessreviews] [] []} {[watch] [] [subjectaccessreviews] [] []} {[delete] [] [subjectaccessreviews] [] []} {[deletecollection] [] [subjectaccessreviews] [] []} {[get] [] [subjectaccessreviews] [] []} {[list] [] [buildconfigs/instantiatebinary] [] []} {[patch] [] [buildconfigs/instantiatebinary] [] []} {[update] [] [buildconfigs/instantiatebinary] [] []} {[watch] [] [buildconfigs/instantiatebinary] [] []} {[delete] [] [buildconfigs/instantiatebinary] [] []} {[deletecollection] [] [buildconfigs/instantiatebinary] [] []} {[get] [] [buildconfigs/instantiatebinary] [] []} {[delete] [] [localresourceaccessreviews] [] []} {[deletecollection] [] [localresourceaccessreviews] [] []} {[get] [] [localresourceaccessreviews] [] []} {[list] [] [localresourceaccessreviews] [] []} {[patch] [] [localresourceaccessreviews] [] []} {[update] [] [localresourceaccessreviews] [] []} {[watch] [] [localresourceaccessreviews] [] []} {[deletecollection] [] [projects] [] []} {[list] [] [projects] [] []} {[watch] [] [projects] [] []} {[create] [] [projects] [] []} {[patch] [] [resourceaccessreviews] [] []} {[update] [] [resourceaccessreviews] [] []} {[watch] [] [resourceaccessreviews] [] []} {[delete] [] [resourceaccessreviews] [] []} {[deletecollection] [] [resourceaccessreviews] [] []} {[get] [] [resourceaccessreviews] [] []} {[list] [] [resourceaccessreviews] [] []} {[deletecollection] [] [buildconfigs/instantiate] [] []} {[get] [] [buildconfigs/instantiate] [] []} {[list] [] [buildconfigs/instantiate] [] []} {[patch] [] [buildconfigs/instantiate] [] []} {[update] [] [buildconfigs/instantiate] [] []} {[watch] [] [buildconfigs/instantiate] [] []} {[delete] [] [buildconfigs/instantiate] [] []} {[patch] [] [builds/log] [] []} {[update] [] [builds/log] [] []} {[create] [] [builds/log] [] []} {[delete] [] [builds/log] [] []} {[deletecollection] [] [builds/log] [] []} {[watch] [] [imagestreamimports] [] []} {[delete] [] [imagestreamimports] [] []} {[deletecollection] [] [imagestreamimports] [] []} {[get] [] [imagestreamimports] [] []} {[list] [] [imagestreamimports] [] []} {[patch] [] [imagestreamimports] [] []} {[update] [] [imagestreamimports] [] []} {[patch] [] [builds/clone] [] []} {[update] [] [builds/clone] [] []} {[watch] [] [builds/clone] [] []} {[delete] [] [builds/clone] [] []} {[deletecollection] [] [builds/clone] [] []} {[get] [] [builds/clone] [] []} {[list] [] [builds/clone] [] []} {[watch] [] [localsubjectaccessreviews] [] []} {[delete] [] [localsubjectaccessreviews] [] []} {[deletecollection] [] [localsubjectaccessreviews] [] []} {[get] [] [localsubjectaccessreviews] [] []} {[list] [] [localsubjectaccessreviews] [] []} {[patch] [] [localsubjectaccessreviews] [] []} {[update] [] [localsubjectaccessreviews] [] []} {[get] [] [securitycontextconstraints] [] []} {[list] [] [securitycontextconstraints] [] []} {[watch] [] [securitycontextconstraints] [] []} {[get] [] [minions] [] []} {[list] [] [minions] [] []} {[watch] [] [minions] [] []} {[get] [] [nodes] [] []} {[list] [] [nodes] [] []} {[watch] [] [nodes] [] []} {[get] [] [persistentvolumes] [] []} {[list] [] [persistentvolumes] [] []} {[watch] [] [persistentvolumes] [] []} {[create] [rbac.authorization.k8s.io] [rolebindings] [] []} {[delete] [rbac.authorization.k8s.io] [rolebindings] [] []} {[deletecollection] [rbac.authorization.k8s.io] [rolebindings] [] []} {[get] [rbac.authorization.k8s.io] [rolebindings] [] []} {[list] [rbac.authorization.k8s.io] [rolebindings] [] []} {[patch] [rbac.authorization.k8s.io] [rolebindings] [] []} {[update] [rbac.authorization.k8s.io] [rolebindings] [] []} {[watch] [rbac.authorization.k8s.io] [rolebindings] [] []} {[create] [rbac.authorization.k8s.io] [roles] [] []} {[delete] [rbac.authorization.k8s.io] [roles] [] []} {[deletecollection] [rbac.authorization.k8s.io] [roles] [] []} {[get] [rbac.authorization.k8s.io] [roles] [] []} {[list] [rbac.authorization.k8s.io] [roles] [] []} {[patch] [rbac.authorization.k8s.io] [roles] [] []} {[update] [rbac.authorization.k8s.io] [roles] [] []} {[watch] [rbac.authorization.k8s.io] [roles] [] []} {[create] [apps] [deployments/rollback] [] []} {[delete] [apps] [deployments/rollback] [] []} {[deletecollection] [apps] [deployments/rollback] [] []} {[get] [apps] [deployments/rollback] [] []} {[list] [apps] [deployments/rollback] [] []} {[patch] [apps] [deployments/rollback] [] []} {[update] [apps] [deployments/rollback] [] []} {[watch] [apps] [deployments/rollback] [] []} {[create] [apps] [replicasets] [] []} {[delete] [apps] [replicasets] [] []} {[deletecollection] [apps] [replicasets] [] []} {[get] [apps] [replicasets] [] []} {[list] [apps] [replicasets] [] []} {[patch] [apps] [replicasets] [] []} {[update] [apps] [replicasets] [] []} {[watch] [apps] [replicasets] [] []} {[create] [apps] [replicasets/scale] [] []} {[delete] [apps] [replicasets/scale] [] []} {[deletecollection] [apps] [replicasets/scale] [] []} {[get] [apps] [replicasets/scale] [] []} {[list] [apps] [replicasets/scale] [] []} {[patch] [apps] [replicasets/scale] [] []} {[update] [apps] [replicasets/scale] [] []} {[watch] [apps] [replicasets/scale] [] []} {[create] [apps] [replicationcontrollers/scale] [] []} {[delete] [apps] [replicationcontrollers/scale] [] []} {[deletecollection] [apps] [replicationcontrollers/scale] [] []} {[get] [apps] [replicationcontrollers/scale] [] []} {[list] [apps] [replicationcontrollers/scale] [] []} {[patch] [apps] [replicationcontrollers/scale] [] []} {[update] [apps] [replicationcontrollers/scale] [] []} {[watch] [apps] [replicationcontrollers/scale] [] []} {[get] [apps] [daemonsets] [] []} {[list] [apps] [daemonsets] [] []} {[watch] [apps] [daemonsets] [] []} {[create update delete get list watch patch] [servicecatalog.k8s.io] [serviceinstances servicebindings] [] []} {[create update delete get list watch] [settings.k8s.io] [podpresets] [] []}] ruleResolutionErrors=[]     error: roles.rbac.authorization.k8s.io "syndesis-editor" not found ```   3. This leads to inability to publish integrations (the status remains Assembling) due to:  ``` 2019-07-02 07:09:55.006  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.i.online.PublishHandler          : Integration [logger]: Created project files and starting build 2019-07-02 07:09:55.908 ERROR [-,,,] 1 --- [tion Controller] i.s.s.c.i.online.PublishHandler          : Integration [logger]: [ERROR] Activation failure  io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://kubernetes.default.svc/apis/image.openshift.io/v1/namespaces/syndesis-test/imagestreams. Message: Forbidden!Configured service account doesn't have access. Service account may have been revoked. imagestreams.image.openshift.io is forbidden: User "system:serviceaccount:syndesis-test:syndesis-server" cannot create imagestreams.image.openshift.io in the namespace "syndesis-test": no RBAC policy matched. at io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:472) ~[kubernetes-client-3.1.12.fuse-730022.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:409) ~[kubernetes-client-3.1.12.fuse-730022.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:381) ~[kubernetes-client-3.1.12.fuse-730022.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:344) ~[kubernetes-client-3.1.12.fuse-730022.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:227) ~[kubernetes-client-3.1.12.fuse-730022.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:766) ~[kubernetes-client-3.1.12.fuse-730022.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:335) ~[kubernetes-client-3.1.12.fuse-730022.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.BaseOperation.createOrReplace(BaseOperation.java:404) ~[kubernetes-client-3.1.12.fuse-730022.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.BaseOperation$2.apply(BaseOperation.java:373) ~[kubernetes-client-3.1.12.fuse-730022.jar!/:na] at io.fabric8.openshift.api.model.DoneableImageStream.done(DoneableImageStream.java:27) ~[kubernetes-model-2.0.10.jar!/:2.0.10] at io.syndesis.server.openshift.OpenShiftServiceImpl.ensureImageStreams(OpenShiftServiceImpl.java:213) ~[server-openshift-1.7.8.jar!/:1.7.8] at io.syndesis.server.openshift.OpenShiftServiceImpl.build(OpenShiftServiceImpl.java:80) ~[server-openshift-1.7.8.jar!/:1.7.8] at io.syndesis.server.controller.integration.online.PublishHandler.build(PublishHandler.java:173) ~[server-controller-1.7.8.jar!/:1.7.8] at io.syndesis.server.controller.integration.online.PublishHandler$BuildStepOncePerformer.perform(PublishHandler.java:284) ~[server-controller-1.7.8.jar!/:1.7.8] at io.syndesis.server.controller.integration.online.PublishHandler.execute(PublishHandler.java:101) ~[server-controller-1.7.8.jar!/:1.7.8] at io.syndesis.server.controller.StateChangeHandler.execute(StateChangeHandler.java:33) [server-controller-1.7.8.jar!/:1.7.8] at io.syndesis.server.controller.integration.BaseIntegrationController.lambda$callStateChangeHandler$10(BaseIntegrationController.java:220) [server-controller-1.7.8.jar!/:1.7.8] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_151] at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_151] ```  Can you help with this one @lgarciaaco?</body>
		<created>2019-07-02 07:56:56</created>
		<closed>2019-07-07 07:35:01</closed>
	</bug>
	<bug>
		<id>6017</id>
		<title>Twitter direct message doesn't work (atlas exception)</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When creating integration with the new twitter direct message feature, I get an error. Deployed integration doesn't receive any new direct messages, and instead prints this into the log:  ``` io.atlasmap.api.AtlasException: Errors: [Unexpected exception is thrown while reading source field: java.lang.reflect.InvocationTargetException: docId='-LihpxxpuOg_BQwrUERj', path='/senderScreenName'], at org.apache.camel.component.atlasmap.AtlasEndpoint.onExchange(AtlasEndpoint.java:262) ~[camel-atlasmap-1.40.0.jar!/:1.40.0] at org.apache.camel.impl.ProcessorEndpoint$1.process(ProcessorEndpoint.java:71) ~[camel-core-2.21.0.fuse-740028.jar!/:2.21.0.fuse-740028] at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.21.0.fuse-740028.jar!/:2.21.0.fuse-740028] at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) ~[camel-core-2.21.0.fuse-740028.jar!/:2.21.0.fuse-740028] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-740028.jar!/:2.21.0.fuse-740028] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-740028.jar!/:2.21.0.fuse-740028] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-740028.jar!/:2.21.0.fuse-740028] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-740028.jar!/:2.21.0.fuse-740028] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-740028.jar!/:2.21.0.fuse-740028] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-740028.jar!/:2.21.0.fuse-740028] at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$TrackDoneEventProcessor.process(ActivityTrackingInterceptStrategy.java:121) [integration-runtime-1.7.6.jar!/:1.7.6] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-740028.jar!/:2.21.0.fuse-740028] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-740028.jar!/:2.21.0.fuse-740028] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-740028.jar!/:2.21.0.fuse-740028] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-740028.jar!/:2.21.0.fuse-740028] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-740028.jar!/:2.21.0.fuse-740028] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-740028.jar!/:2.21.0.fuse-740028] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-740028.jar!/:2.21.0.fuse-740028] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-740028.jar!/:2.21.0.fuse-740028] at org.apache.camel.util.AsyncProcessorHelper.process(AsyncProcessorHelper.java:109) [camel-core-2.21.0.fuse-740028.jar!/:2.21.0.fuse-740028] at org.apache.camel.processor.Pipeline.process(Pipeline.java:80) [camel-core-2.21.0.fuse-740028.jar!/:2.21.0.fuse-740028] at org.apache.camel.component.twitter.consumer.DefaultTwitterConsumer.poll(DefaultTwitterConsumer.java:98) [camel-twitter-2.21.0.fuse-740028.jar!/:2.21.0.fuse-740028] at org.apache.camel.impl.ScheduledPollConsumer.doRun(ScheduledPollConsumer.java:174) [camel-core-2.21.0.fuse-740028.jar!/:2.21.0.fuse-740028] at org.apache.camel.impl.ScheduledPollConsumer.run(ScheduledPollConsumer.java:101) [camel-core-2.21.0.fuse-740028.jar!/:2.21.0.fuse-740028] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_191] at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [na:1.8.0_191] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [na:1.8.0_191] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [na:1.8.0_191] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_191] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_191] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_191] ```  The same problem happens when I try to use the `/sender/screenName` instead. Feature is being developed here: https://github.com/syndesisio/syndesis/issues/3521</body>
		<created>2019-07-01 14:32:13</created>
		<closed>2019-08-06 20:35:25</closed>
	</bug>
	<bug>
		<id>6015</id>
		<title>[#Error report] Data Virtualizations - Error: Bad Gateway</title>
		<body>## Data Virtualizations - Error: Bad Gateway ## Description I just ran the command : bash &lt;(curl -sL https://syndes.is/start) As soon as the installation was done, I went to the Syndesis GUI and click on Data tabulation. I got the  "Something is wrong An error occurred while talking with the server. Please check your internet connection." error message.  Regards Frederic</body>
		<created>2019-07-01 13:03:27</created>
		<closed>2019-08-19 09:26:37</closed>
	</bug>
	<bug>
		<id>6014</id>
		<title>SQL connector cannot access the sampledb tables in 1.8-SNAPSHOT</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Same issue as https://github.com/syndesisio/syndesis/issues/5603, the tables are in public schema and syndesis can't find them. When I tried to do `SELECT * FROM todo` and click the next button, it says `Table 'TODO' does not exist in schema 'sampledb'. Unable to fetch and process metadata`.  The database shows this ``` sampledb=&gt; \dt           List of relations  Schema |  Name   | Type  |  Owner --------+---------+-------+----------  public | contact | table | sampledb  public | todo    | table | sampledb (2 rows) ```  after changing the schema to `sampledb`, it works as supposed.  Reporting this again because it only occurs in 1.8-SNAPSHOT, </body>
		<created>2019-07-01 12:33:25</created>
		<closed>2019-07-15 10:51:04</closed>
	</bug>
	<bug>
		<id>6005</id>
		<title>Cannot create any oauth connections</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The `connect *connector type*` button doesn't show up when creating new connections which require oauth, instead a message that user needs to input oauth settings is displayed, although it's already set up. ![Peek 2019-07-01 08-36](https://user-images.githubusercontent.com/46345469/60415466-83a0b000-9bdb-11e9-9e66-2d594966477e.gif)  </body>
		<created>2019-07-01 06:39:40</created>
		<closed>2019-07-03 07:49:52</closed>
	</bug>
	<bug>
		<id>6004</id>
		<title>The title isn't updated</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11408**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description In some cases, the title isn't properly updated when navigating between various pages. Most notably it probably doesn't update ever when user clicks on the Syndesis logo in the top left. Steps to reproduce are captured in the GIF attached. ![Peek 2019-07-01 07-47](https://user-images.githubusercontent.com/46345469/60413517-7f719400-9bd5-11e9-8278-f8a08a5502ba.gif)  </body>
		<created>2019-07-01 05:55:26</created>
		<closed>2019-09-07 10:52:13</closed>
	</bug>
	<bug>
		<id>6001</id>
		<title>Connection Edit Issues</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem After the first time connection is created in syndesis, then click edit the connection, and then modify couple fields then hit cancel. The modified fields are kept as new values  ## Expected behavior Revert the properties to original values  </body>
		<created>2019-06-28 21:50:02</created>
		<closed>2019-07-10 09:12:17</closed>
	</bug>
	<bug>
		<id>5996</id>
		<title>Display the statusMessage when try to start an integration</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## The problem There is one integration running on minishift, when I try to start another integration, it shows the popup `Starting integration. Your integration will start running in a few moments.` but the integration doesn't start.   The http response is `statusMessage: WARNING: User has currently 1 deployments, while the maximum allowed number is 1.` but this `statusMessage` is not displayed in the browser as popup for the user.  ## Expected behavior Display the statusMessage value as a popup.  ## How to reproduce Create two timer2log integrations and start them. </body>
		<created>2019-06-28 18:56:31</created>
		<closed>2019-12-24 11:19:00</closed>
	</bug>
	<bug>
		<id>5992</id>
		<title>komodo-server deloyment config points to  incorrect BUILD_IMAGE_STREAM </title>
		<body>## This is bug  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When product builds are run they refer to a specific version "syndesis-s2i" servers through BUILD_IMAGE_STREAM env property. However, the deployment config for komodo-server always points to "syndesis-s2i:latest" which is incorrect. This needs to be corrected in teiid-komodo-server.yml.mustache file. </body>
		<created>2019-06-28 16:35:43</created>
		<closed>2019-07-01 18:28:13</closed>
	</bug>
	<bug>
		<id>5989</id>
		<title>Gateway timeouts on staging when requesting integrations</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description It's time we talk about this :smile:   On staging there's probably 10 or so integrations.  And currently we've a 30 second (apparently) proxy timeout set up for oauth proxy.  It appears that periodically the request handling for the `/api/v1/integrations` takes longer than the timeout, and in fact what I'm seeing is that other endpoints also can take 10-12 seconds while I'm seeing gateway timeouts.  I did however notice that sometimes the request to `/api/v1/integrations` can complete in a lot less time.  Until I decided to start an integration and then guess what, moar timeout responses.  One thing to note is that the UI currently ensures it debounces incoming change events, and the UI also really tries to avoid sending multiple requests when fetching integrations.  For example, here's while I'm typing this:  ![image](https://user-images.githubusercontent.com/351660/60350421-7bedcb00-9991-11e9-894a-d6ba7f9b3ac2.png)  The successful requests are to the monitoring endpoint for the detailed status data, the two red items there are timed out requests to fetch integrations.  </body>
		<created>2019-06-28 14:43:42</created>
		<closed>2019-08-19 14:32:08</closed>
	</bug>
	<bug>
		<id>5987</id>
		<title>Operator generates invalid config.json (on `master`)</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Operator seems to be using single quotes in JSON, which doesn't parse on the UI.</body>
		<created>2019-06-28 14:35:11</created>
		<closed>2019-07-01 08:36:58</closed>
	</bug>
	<bug>
		<id>5981</id>
		<title>Improve error reporting in UI</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Several times now I've found myself unable to troubleshoot an issue in the UI here's what usually happens: I get the _**Something is wrong** An error occurred while talking with the server. Please check your internet connection._, there's no error that can be seen in the Network or in the Console tabs of the developer tools.  Obviously some error occurred, doubtfully it has anything to do with the the server, I'm left with nothing to troubleshoot this. I wonder what happens when we get users reaching error states and we can't offer any ways to help them provide us with enough information to troubleshoot issues.  To me this is a blocking issue.</body>
		<created>2019-06-28 10:12:32</created>
		<closed>2019-07-24 14:26:28</closed>
	</bug>
	<bug>
		<id>5975</id>
		<title>Operator fails to install Syndesis (on `master`)</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Getting this on `syndesis minishift --install` in the operator pod log:  ``` {"level":"info","ts":1561661306.0571632,"logger":"action","msg":"Installing Syndesis resource","type":"install","name":"app"} {"level":"error","ts":1561661326.2006292,"logger":"controller","msg":"Error reconciling","action":"*action.installAction","phase":"Installing","error":"rolebindings.authorization.openshift.io \"syndesis:editors\" is forbidden: attempt to grant extra privileges: [{[patch] [] [pods] [] []} {[create] [] [pods/attach] [] []} {[delete] [] [pods/attach] [] []} {[deletecollection] [] [pods/attach] [] []} {[get] [] [pods/attach] [] []} {[list] [] [pods/attach] [] []} {[patch] [] [pods/attach] [] []} {[update] [] [pods/attach] [] []} {[watch] [] [pods/attach] [] []} {[create] [] [pods/exec] [] []} {[delete] [] [pods/exec] [] []} {[deletecollection] [] [pods/exec] [] []} {[get] [] [pods/exec] [] []} {[list] [] [pods/exec] [] []} {[patch] [] [pods/exec] [] []} {[update] [] [pods/exec] [] []} {[watch] [] [pods/exec] [] []} {[create] [] [pods/portforward] [] []} {[delete] [] [pods/portforward] [] []} {[deletecollection] [] [pods/portforward] [] []} {[get] [] [pods/portforward] [] []} {[list] [] [pods/portforward] [] []} {[patch] [] [pods/portforward] [] []} {[update] [] [pods/portforward] [] []} {[watch] [] [pods/portforward] [] []} {[create] [] [pods/proxy] [] []} {[delete] [] [pods/proxy] [] []} {[deletecollection] [] [pods/proxy] [] []} {[get] [] [pods/proxy] [] []} {[list] [] [pods/proxy] [] []} {[patch] [] [pods/proxy] [] []} {[update] [] [pods/proxy] [] []} {[watch] [] [pods/proxy] [] []} {[patch] [] [configmaps] [] []} {[patch] [] [endpoints] [] []} {[patch] [] [persistentvolumeclaims] [] []} {[patch] [] [replicationcontrollers] [] []} {[patch] [] [replicationcontrollers/scale] [] []} {[patch] [] [secrets] [] []} {[patch] [] [serviceaccounts] [] []} {[patch] [] [services] [] []} {[create] [] [services/proxy] [] []} {[delete] [] [services/proxy] [] []} {[deletecollection] [] [services/proxy] [] []} {[get] [] [services/proxy] [] []} {[list] [] [services/proxy] [] []} {[patch] [] [services/proxy] [] []} {[update] [] [services/proxy] [] []} {[watch] [] [services/proxy] [] []} {[get] [] [bindings] [] []} {[list] [] [bindings] [] []} {[watch] [] [bindings] [] []} {[watch] [] [events] [] []} {[get] [] [limitranges] [] []} {[list] [] [limitranges] [] []} {[watch] [] [limitranges] [] []} {[get] [] [namespaces/status] [] []} {[list] [] [namespaces/status] [] []} {[watch] [] [namespaces/status] [] []} {[list] [] [pods/log] [] []} {[watch] [] [pods/log] [] []} {[get] [] [pods/status] [] []} {[list] [] [pods/status] [] []} {[watch] [] [pods/status] [] []} {[get] [] [resourcequotas] [] []} {[list] [] [resourcequotas] [] []} {[watch] [] [resourcequotas] [] []} {[get] [] [resourcequotas/status] [] []} {[list] [] [resourcequotas/status] [] []} {[watch] [] [resourcequotas/status] [] []} {[get] [] [namespaces] [] []} {[list] [] [namespaces] [] []} {[watch] [] [namespaces] [] []} {[impersonate] [] [serviceaccounts] [] []} {[create] [apps] [daemonsets] [] []} {[delete] [apps] [daemonsets] [] []} {[deletecollection] [apps] [daemonsets] [] []} {[get] [apps] [daemonsets] [] []} {[list] [apps] [daemonsets] [] []} {[patch] [apps] [daemonsets] [] []} {[update] [apps] [daemonsets] [] []} {[watch] [apps] [daemonsets] [] []} {[create] [apps] [deployments] [] []} {[delete] [apps] [deployments] [] []} {[deletecollection] [apps] [deployments] [] []} {[get] [apps] [deployments] [] []} {[list] [apps] [deployments] [] []} {[patch] [apps] [deployments] [] []} {[update] [apps] [deployments] [] []} {[watch] [apps] [deployments] [] []} {[create] [apps] [deployments/rollback] [] []} {[delete] [apps] [deployments/rollback] [] []} {[deletecollection] [apps] [deployments/rollback] [] []} {[get] [apps] [deployments/rollback] [] []} {[list] [apps] [deployments/rollback] [] []} {[patch] [apps] [deployments/rollback] [] []} {[update] [apps] [deployments/rollback] [] []} {[watch] [apps] [deployments/rollback] [] []} {[create] [apps] [deployments/scale] [] []} {[delete] [apps] [deployments/scale] [] []} {[deletecollection] [apps] [deployments/scale] [] []} {[get] [apps] [deployments/scale] [] []} {[list] [apps] [deployments/scale] [] []} {[patch] [apps] [deployments/scale] [] []} {[update] [apps] [deployments/scale] [] []} {[watch] [apps] [deployments/scale] [] []} {[create] [apps] [replicasets] [] []} {[delete] [apps] [replicasets] [] []} {[deletecollection] [apps] [replicasets] [] []} {[get] [apps] [replicasets] [] []} {[list] [apps] [replicasets] [] []} {[patch] [apps] [replicasets] [] []} {[update] [apps] [replicasets] [] []} {[watch] [apps] [replicasets] [] []} {[create] [apps] [replicasets/scale] [] []} {[delete] [apps] [replicasets/scale] [] []} {[deletecollection] [apps] [replicasets/scale] [] []} {[get] [apps] [replicasets/scale] [] []} {[list] [apps] [replicasets/scale] [] []} {[patch] [apps] [replicasets/scale] [] []} {[update] [apps] [replicasets/scale] [] []} {[watch] [apps] [replicasets/scale] [] []} {[create] [apps] [statefulsets] [] []} {[delete] [apps] [statefulsets] [] []} {[deletecollection] [apps] [statefulsets] [] []} {[get] [apps] [statefulsets] [] []} {[list] [apps] [statefulsets] [] []} {[patch] [apps] [statefulsets] [] []} {[update] [apps] [statefulsets] [] []} {[watch] [apps] [statefulsets] [] []} {[create] [apps] [statefulsets/scale] [] []} {[delete] [apps] [statefulsets/scale] [] []} {[deletecollection] [apps] [statefulsets/scale] [] []} {[get] [apps] [statefulsets/scale] [] []} {[list] [apps] [statefulsets/scale] [] []} {[patch] [apps] [statefulsets/scale] [] []} {[update] [apps] [statefulsets/scale] [] []} {[watch] [apps] [statefulsets/scale] [] []} {[create] [autoscaling] [horizontalpodautoscalers] [] []} {[delete] [autoscaling] [horizontalpodautoscalers] [] []} {[deletecollection] [autoscaling] [horizontalpodautoscalers] [] []} {[get] [autoscaling] [horizontalpodautoscalers] [] []} {[list] [autoscaling] [horizontalpodautoscalers] [] []} {[patch] [autoscaling] [horizontalpodautoscalers] [] []} {[update] [autoscaling] [horizontalpodautoscalers] [] []} {[watch] [autoscaling] [horizontalpodautoscalers] [] []} {[create] [batch] [cronjobs] [] []} {[delete] [batch] [cronjobs] [] []} {[deletecollection] [batch] [cronjobs] [] []} {[get] [batch] [cronjobs] [] []} {[list] [batch] [cronjobs] [] []} {[patch] [batch] [cronjobs] [] []} {[update] [batch] [cronjobs] [] []} {[watch] [batch] [cronjobs] [] []} {[create] [batch] [jobs] [] []} {[delete] [batch] [jobs] [] []} {[deletecollection] [batch] [jobs] [] []} {[get] [batch] [jobs] [] []} {[list] [batch] [jobs] [] []} {[patch] [batch] [jobs] [] []} {[update] [batch] [jobs] [] []} {[watch] [batch] [jobs] [] []} {[create] [extensions] [daemonsets] [] []} {[delete] [extensions] [daemonsets] [] []} {[deletecollection] [extensions] [daemonsets] [] []} {[get] [extensions] [daemonsets] [] []} {[list] [extensions] [daemonsets] [] []} {[patch] [extensions] [daemonsets] [] []} {[update] [extensions] [daemonsets] [] []} {[watch] [extensions] [daemonsets] [] []} {[create] [extensions] [deployments] [] []} {[delete] [extensions] [deployments] [] []} {[deletecollection] [extensions] [deployments] [] []} {[get] [extensions] [deployments] [] []} {[list] [extensions] [deployments] [] []} {[patch] [extensions] [deployments] [] []} {[update] [extensions] [deployments] [] []} {[watch] [extensions] [deployments] [] []} {[create] [extensions] [deployments/rollback] [] []} {[delete] [extensions] [deployments/rollback] [] []} {[deletecollection] [extensions] [deployments/rollback] [] []} {[get] [extensions] [deployments/rollback] [] []} {[list] [extensions] [deployments/rollback] [] []} {[patch] [extensions] [deployments/rollback] [] []} {[update] [extensions] [deployments/rollback] [] []} {[watch] [extensions] [deployments/rollback] [] []} {[create] [extensions] [deployments/scale] [] []} {[delete] [extensions] [deployments/scale] [] []} {[deletecollection] [extensions] [deployments/scale] [] []} {[get] [extensions] [deployments/scale] [] []} {[list] [extensions] [deployments/scale] [] []} {[patch] [extensions] [deployments/scale] [] []} {[update] [extensions] [deployments/scale] [] []} {[watch] [extensions] [deployments/scale] [] []} {[create] [extensions] [ingresses] [] []} {[delete] [extensions] [ingresses] [] []} {[deletecollection] [extensions] [ingresses] [] []} {[get] [extensions] [ingresses] [] []} {[list] [extensions] [ingresses] [] []} {[patch] [extensions] [ingresses] [] []} {[update] [extensions] [ingresses] [] []} {[watch] [extensions] [ingresses] [] []} {[create] [extensions] [networkpolicies] [] []} {[delete] [extensions] [networkpolicies] [] []} {[deletecollection] [extensions] [networkpolicies] [] []} {[get] [extensions] [networkpolicies] [] []} {[list] [extensions] [networkpolicies] [] []} {[patch] [extensions] [networkpolicies] [] []} {[update] [extensions] [networkpolicies] [] []} {[watch] [extensions] [networkpolicies] [] []} {[create] [extensions] [replicasets] [] []} {[delete] [extensions] [replicasets] [] []} {[deletecollection] [extensions] [replicasets] [] []} {[get] [extensions] [replicasets] [] []} {[list] [extensions] [replicasets] [] []} {[patch] [extensions] [replicasets] [] []} {[update] [extensions] [replicasets] [] []} {[watch] [extensions] [replicasets] [] []} {[create] [extensions] [replicasets/scale] [] []} {[delete] [extensions] [replicasets/scale] [] []} {[deletecollection] [extensions] [replicasets/scale] [] []} {[get] [extensions] [replicasets/scale] [] []} {[list] [extensions] [replicasets/scale] [] []} {[patch] [extensions] [replicasets/scale] [] []} {[update] [extensions] [replicasets/scale] [] []} {[watch] [extensions] [replicasets/scale] [] []} {[create] [extensions] [replicationcontrollers/scale] [] []} {[delete] [extensions] [replicationcontrollers/scale] [] []} {[deletecollection] [extensions] [replicationcontrollers/scale] [] []} {[get] [extensions] [replicationcontrollers/scale] [] []} {[list] [extensions] [replicationcontrollers/scale] [] []} {[patch] [extensions] [replicationcontrollers/scale] [] []} {[update] [extensions] [replicationcontrollers/scale] [] []} {[watch] [extensions] [replicationcontrollers/scale] [] []} {[create] [policy] [poddisruptionbudgets] [] []} {[delete] [policy] [poddisruptionbudgets] [] []} {[deletecollection] [policy] [poddisruptionbudgets] [] []} {[get] [policy] [poddisruptionbudgets] [] []} {[list] [policy] [poddisruptionbudgets] [] []} {[patch] [policy] [poddisruptionbudgets] [] []} {[update] [policy] [poddisruptionbudgets] [] []} {[watch] [policy] [poddisruptionbudgets] [] []} {[create] [networking.k8s.io] [networkpolicies] [] []} {[delete] [networking.k8s.io] [networkpolicies] [] []} {[deletecollection] [networking.k8s.io] [networkpolicies] [] []} {[get] [networking.k8s.io] [networkpolicies] [] []} {[list] [networking.k8s.io] [networkpolicies] [] []} {[patch] [networking.k8s.io] [networkpolicies] [] []} {[update] [networking.k8s.io] [networkpolicies] [] []} {[watch] [networking.k8s.io] [networkpolicies] [] []} {[patch] [] [buildconfigs] [] []} {[patch] [] [buildconfigs/webhooks] [] []} {[patch] [] [builds] [] []} {[patch] [build.openshift.io] [buildconfigs] [] []} {[patch] [build.openshift.io] [buildconfigs/webhooks] [] []} {[patch] [build.openshift.io] [builds] [] []} {[create] [] [buildconfigs/instantiate] [] []} {[create] [] [builds/clone] [] []} {[create] [build.openshift.io] [buildconfigs/instantiate] [] []} {[create] [build.openshift.io] [builds/clone] [] []} {[edit] [build.openshift.io] [jenkins] [] []} {[view] [build.openshift.io] [jenkins] [] []} {[update] [] [imagestreams/layers] [] []} {[update] [image.openshift.io] [imagestreams/layers] [] []} {[create] [] [imagestreamimports] [] []} {[create] [image.openshift.io] [imagestreamimports] [] []} {[get] [] [projects] [] []} {[get] [project.openshift.io] [projects] [] []} {[get] [] [appliedclusterresourcequotas] [] []} {[list] [] [appliedclusterresourcequotas] [] []} {[watch] [] [appliedclusterresourcequotas] [] []} {[get] [quota.openshift.io] [appliedclusterresourcequotas] [] []} {[list] [quota.openshift.io] [appliedclusterresourcequotas] [] []} {[watch] [quota.openshift.io] [appliedclusterresourcequotas] [] []} {[create] [] [routes] [] []} {[delete] [] [routes] [] []} {[deletecollection] [] [routes] [] []} {[get] [] [routes] [] []} {[list] [] [routes] [] []} {[patch] [] [routes] [] []} {[update] [] [routes] [] []} {[watch] [] [routes] [] []} {[create] [] [routes/custom-host] [] []} {[get] [] [routes/status] [] []} {[list] [] [routes/status] [] []} {[watch] [] [routes/status] [] []} {[get] [route.openshift.io] [routes/status] [] []} {[list] [route.openshift.io] [routes/status] [] []} {[watch] [route.openshift.io] [routes/status] [] []} {[create] [extensions] [networkpolicies] [] []} {[delete] [extensions] [networkpolicies] [] []} {[deletecollection] [extensions] [networkpolicies] [] []} {[get] [extensions] [networkpolicies] [] []} {[list] [extensions] [networkpolicies] [] []} {[patch] [extensions] [networkpolicies] [] []} {[update] [extensions] [networkpolicies] [] []} {[watch] [extensions] [networkpolicies] [] []} {[create] [networking.k8s.io] [networkpolicies] [] []} {[delete] [networking.k8s.io] [networkpolicies] [] []} {[deletecollection] [networking.k8s.io] [networkpolicies] [] []} {[get] [networking.k8s.io] [networkpolicies] [] []} {[list] [networking.k8s.io] [networkpolicies] [] []} {[patch] [networking.k8s.io] [networkpolicies] [] []} {[update] [networking.k8s.io] [networkpolicies] [] []} {[watch] [networking.k8s.io] [networkpolicies] [] []} {[create] [] [buildlogs] [] []} {[delete] [] [buildlogs] [] []} {[deletecollection] [] [buildlogs] [] []} {[get] [] [buildlogs] [] []} {[list] [] [buildlogs] [] []} {[patch] [] [buildlogs] [] []} {[update] [] [buildlogs] [] []} {[watch] [] [buildlogs] [] []} {[create] [build.openshift.io] [buildlogs] [] []} {[delete] [build.openshift.io] [buildlogs] [] []} {[deletecollection] [build.openshift.io] [buildlogs] [] []} {[get] [build.openshift.io] [buildlogs] [] []} {[list] [build.openshift.io] [buildlogs] [] []} {[patch] [build.openshift.io] [buildlogs] [] []} {[update] [build.openshift.io] [buildlogs] [] []} {[watch] [build.openshift.io] [buildlogs] [] []} {[get] [] [resourcequotausages] [] []} {[list] [] [resourcequotausages] [] []} {[watch] [] [resourcequotausages] [] []}] user=&amp;{system:serviceaccount:myproject:syndesis-operator  [system:serviceaccounts system:serviceaccounts:myproject system:authenticated] map[]} ownerrules=[{[get] [ user.openshift.io] [users] [~] []} {[list] [ project.openshift.io] [projectrequests] [] []} {[get list] [ authorization.openshift.io] [clusterroles] [] []} {[get list watch] [rbac.authorization.k8s.io] [clusterroles] [] []} {[get list] [storage.k8s.io] [storageclasses] [] []} {[list watch] [ project.openshift.io] [projects] [] []} {[create] [ authorization.openshift.io] [selfsubjectrulesreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews] [] []} {[get] [] [] [] [/healthz /healthz/*]} {[get] [] [] [] [/version /version/* /api /api/* /apis /apis/* /oapi /oapi/* /openapi/v2 /swaggerapi /swaggerapi/* /swagger.json /swagger-2.0.0.pb-v1 /osapi /osapi/ /.well-known /.well-known/* /]} {[create] [ authorization.openshift.io] [selfsubjectrulesreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews selfsubjectrulesreviews] [] []} {[create] [ build.openshift.io] [builds/docker builds/optimizeddocker] [] []} {[create] [ build.openshift.io] [builds/jenkinspipeline] [] []} {[create] [ build.openshift.io] [builds/source] [] []} {[get] [] [] [] [/api /api/* /apis /apis/* /healthz /openapi /openapi/* /swagger-2.0.0.pb-v1 /swagger.json /swaggerapi /swaggerapi/* /version /version/]} {[delete] [ oauth.openshift.io] [oauthaccesstokens oauthauthorizetokens] [] []} {[get] [] [] [] [/version /version/* /api /api/* /apis /apis/* /oapi /oapi/* /openapi/v2 /swaggerapi /swaggerapi/* /swagger.json /swagger-2.0.0.pb-v1 /osapi /osapi/ /.well-known /.well-known/* /]} {[impersonate] [authentication.k8s.io] [userextras/scopes.authorization.openshift.io] [] []} {[create get] [ build.openshift.io] [buildconfigs/webhooks] [] []} {[get list create update delete deletecollection watch] [syndesis.io] [* */finalizers] [] []} {[get list create update delete deletecollection watch] [] [pods services endpoints persistentvolumeclaims configmaps secrets serviceaccounts] [] []} {[get] [] [pods/log] [] []} {[get list create update delete deletecollection watch] [] [replicationcontrollers replicationcontrollers/scale replicationcontrollers/status] [] []} {[get list create update delete deletecollection watch] [ build.openshift.io] [builds buildconfigs builds/details buildconfigs/webhooks buildconfigs/instantiatebinary builds/log] [] []} {[get list create update delete deletecollection watch patch] [ apps.openshift.io] [deploymentconfigs deploymentconfigs/scale] [] []} {[create] [ apps.openshift.io] [deploymentconfigrollbacks deploymentconfigs/instantiate deploymentconfigs/rollback] [] []} {[get list watch] [ apps.openshift.io] [deploymentconfigs/log deploymentconfigs/status] [] []} {[get list create update delete deletecollection watch patch] [ image.openshift.io] [imagestreams imagestreamimages imagestreammappings imagestreams/secrets imagestreamtags] [] []} {[get list watch] [ image.openshift.io] [imagestreams/status imagestreamimports] [] []} {[get list] [] [events] [] []} {[get list create update delete deletecollection watch] [rbac.authorization.k8s.io] [roles rolebindings] [] []} {[get list create update delete deletecollection watch patch] [ template.openshift.io] [processedtemplates templateconfigs templateinstances templates] [] []} {[get list create update delete deletecollection watch] [authorization.openshift.io] [rolebindings] [] []} {[get list create update delete deletecollection watch patch] [route.openshift.io] [routes routes/custom-host] [] []} {[get list create update delete deletecollection watch] [camel.apache.org] [*] [] []} {[get list create update delete deletecollection watch] [monitoring.coreos.com] [alertmanagers prometheuses servicemonitors prometheusrules] [] []} {[get list create update delete deletecollection watch] [integreatly.org] [grafanadashboards] [] []} {[get list watch] [serving.knative.dev] [services] [] []} {[get list watch] [eventing.knative.dev] [channels] [] []} {[get] [ image.openshift.io] [imagestreams/layers] [] []}] ruleResolutionErrors=[]","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/home/circleci/project/install/operator/vendor/github.com/go-logr/zapr/zapr.go:128\ngithub.com/syndesisio/syndesis/install/operator/pkg/controller/syndesis.(*ReconcileSyndesis).Reconcile\n\t/home/circleci/project/install/operator/pkg/controller/syndesis/syndesis_controller.go:120\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/home/circleci/project/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:215\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func1\n\t/home/circleci/project/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:158\nk8s.io/apimachinery/pkg/util/wait.JitterUntil.func1\n\t/home/circleci/project/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/home/circleci/project/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:134\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/home/circleci/project/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:88"} {"level":"error","ts":1561661326.2015996,"logger":"kubebuilder.controller","msg":"Reconciler error","controller":"syndesis-controller","request":"myproject/app","error":"rolebindings.authorization.openshift.io \"syndesis:editors\" is forbidden: attempt to grant extra privileges: [{[patch] [] [pods] [] []} {[create] [] [pods/attach] [] []} {[delete] [] [pods/attach] [] []} {[deletecollection] [] [pods/attach] [] []} {[get] [] [pods/attach] [] []} {[list] [] [pods/attach] [] []} {[patch] [] [pods/attach] [] []} {[update] [] [pods/attach] [] []} {[watch] [] [pods/attach] [] []} {[create] [] [pods/exec] [] []} {[delete] [] [pods/exec] [] []} {[deletecollection] [] [pods/exec] [] []} {[get] [] [pods/exec] [] []} {[list] [] [pods/exec] [] []} {[patch] [] [pods/exec] [] []} {[update] [] [pods/exec] [] []} {[watch] [] [pods/exec] [] []} {[create] [] [pods/portforward] [] []} {[delete] [] [pods/portforward] [] []} {[deletecollection] [] [pods/portforward] [] []} {[get] [] [pods/portforward] [] []} {[list] [] [pods/portforward] [] []} {[patch] [] [pods/portforward] [] []} {[update] [] [pods/portforward] [] []} {[watch] [] [pods/portforward] [] []} {[create] [] [pods/proxy] [] []} {[delete] [] [pods/proxy] [] []} {[deletecollection] [] [pods/proxy] [] []} {[get] [] [pods/proxy] [] []} {[list] [] [pods/proxy] [] []} {[patch] [] [pods/proxy] [] []} {[update] [] [pods/proxy] [] []} {[watch] [] [pods/proxy] [] []} {[patch] [] [configmaps] [] []} {[patch] [] [endpoints] [] []} {[patch] [] [persistentvolumeclaims] [] []} {[patch] [] [replicationcontrollers] [] []} {[patch] [] [replicationcontrollers/scale] [] []} {[patch] [] [secrets] [] []} {[patch] [] [serviceaccounts] [] []} {[patch] [] [services] [] []} {[create] [] [services/proxy] [] []} {[delete] [] [services/proxy] [] []} {[deletecollection] [] [services/proxy] [] []} {[get] [] [services/proxy] [] []} {[list] [] [services/proxy] [] []} {[patch] [] [services/proxy] [] []} {[update] [] [services/proxy] [] []} {[watch] [] [services/proxy] [] []} {[get] [] [bindings] [] []} {[list] [] [bindings] [] []} {[watch] [] [bindings] [] []} {[watch] [] [events] [] []} {[get] [] [limitranges] [] []} {[list] [] [limitranges] [] []} {[watch] [] [limitranges] [] []} {[get] [] [namespaces/status] [] []} {[list] [] [namespaces/status] [] []} {[watch] [] [namespaces/status] [] []} {[list] [] [pods/log] [] []} {[watch] [] [pods/log] [] []} {[get] [] [pods/status] [] []} {[list] [] [pods/status] [] []} {[watch] [] [pods/status] [] []} {[get] [] [resourcequotas] [] []} {[list] [] [resourcequotas] [] []} {[watch] [] [resourcequotas] [] []} {[get] [] [resourcequotas/status] [] []} {[list] [] [resourcequotas/status] [] []} {[watch] [] [resourcequotas/status] [] []} {[get] [] [namespaces] [] []} {[list] [] [namespaces] [] []} {[watch] [] [namespaces] [] []} {[impersonate] [] [serviceaccounts] [] []} {[create] [apps] [daemonsets] [] []} {[delete] [apps] [daemonsets] [] []} {[deletecollection] [apps] [daemonsets] [] []} {[get] [apps] [daemonsets] [] []} {[list] [apps] [daemonsets] [] []} {[patch] [apps] [daemonsets] [] []} {[update] [apps] [daemonsets] [] []} {[watch] [apps] [daemonsets] [] []} {[create] [apps] [deployments] [] []} {[delete] [apps] [deployments] [] []} {[deletecollection] [apps] [deployments] [] []} {[get] [apps] [deployments] [] []} {[list] [apps] [deployments] [] []} {[patch] [apps] [deployments] [] []} {[update] [apps] [deployments] [] []} {[watch] [apps] [deployments] [] []} {[create] [apps] [deployments/rollback] [] []} {[delete] [apps] [deployments/rollback] [] []} {[deletecollection] [apps] [deployments/rollback] [] []} {[get] [apps] [deployments/rollback] [] []} {[list] [apps] [deployments/rollback] [] []} {[patch] [apps] [deployments/rollback] [] []} {[update] [apps] [deployments/rollback] [] []} {[watch] [apps] [deployments/rollback] [] []} {[create] [apps] [deployments/scale] [] []} {[delete] [apps] [deployments/scale] [] []} {[deletecollection] [apps] [deployments/scale] [] []} {[get] [apps] [deployments/scale] [] []} {[list] [apps] [deployments/scale] [] []} {[patch] [apps] [deployments/scale] [] []} {[update] [apps] [deployments/scale] [] []} {[watch] [apps] [deployments/scale] [] []} {[create] [apps] [replicasets] [] []} {[delete] [apps] [replicasets] [] []} {[deletecollection] [apps] [replicasets] [] []} {[get] [apps] [replicasets] [] []} {[list] [apps] [replicasets] [] []} {[patch] [apps] [replicasets] [] []} {[update] [apps] [replicasets] [] []} {[watch] [apps] [replicasets] [] []} {[create] [apps] [replicasets/scale] [] []} {[delete] [apps] [replicasets/scale] [] []} {[deletecollection] [apps] [replicasets/scale] [] []} {[get] [apps] [replicasets/scale] [] []} {[list] [apps] [replicasets/scale] [] []} {[patch] [apps] [replicasets/scale] [] []} {[update] [apps] [replicasets/scale] [] []} {[watch] [apps] [replicasets/scale] [] []} {[create] [apps] [statefulsets] [] []} {[delete] [apps] [statefulsets] [] []} {[deletecollection] [apps] [statefulsets] [] []} {[get] [apps] [statefulsets] [] []} {[list] [apps] [statefulsets] [] []} {[patch] [apps] [statefulsets] [] []} {[update] [apps] [statefulsets] [] []} {[watch] [apps] [statefulsets] [] []} {[create] [apps] [statefulsets/scale] [] []} {[delete] [apps] [statefulsets/scale] [] []} {[deletecollection] [apps] [statefulsets/scale] [] []} {[get] [apps] [statefulsets/scale] [] []} {[list] [apps] [statefulsets/scale] [] []} {[patch] [apps] [statefulsets/scale] [] []} {[update] [apps] [statefulsets/scale] [] []} {[watch] [apps] [statefulsets/scale] [] []} {[create] [autoscaling] [horizontalpodautoscalers] [] []} {[delete] [autoscaling] [horizontalpodautoscalers] [] []} {[deletecollection] [autoscaling] [horizontalpodautoscalers] [] []} {[get] [autoscaling] [horizontalpodautoscalers] [] []} {[list] [autoscaling] [horizontalpodautoscalers] [] []} {[patch] [autoscaling] [horizontalpodautoscalers] [] []} {[update] [autoscaling] [horizontalpodautoscalers] [] []} {[watch] [autoscaling] [horizontalpodautoscalers] [] []} {[create] [batch] [cronjobs] [] []} {[delete] [batch] [cronjobs] [] []} {[deletecollection] [batch] [cronjobs] [] []} {[get] [batch] [cronjobs] [] []} {[list] [batch] [cronjobs] [] []} {[patch] [batch] [cronjobs] [] []} {[update] [batch] [cronjobs] [] []} {[watch] [batch] [cronjobs] [] []} {[create] [batch] [jobs] [] []} {[delete] [batch] [jobs] [] []} {[deletecollection] [batch] [jobs] [] []} {[get] [batch] [jobs] [] []} {[list] [batch] [jobs] [] []} {[patch] [batch] [jobs] [] []} {[update] [batch] [jobs] [] []} {[watch] [batch] [jobs] [] []} {[create] [extensions] [daemonsets] [] []} {[delete] [extensions] [daemonsets] [] []} {[deletecollection] [extensions] [daemonsets] [] []} {[get] [extensions] [daemonsets] [] []} {[list] [extensions] [daemonsets] [] []} {[patch] [extensions] [daemonsets] [] []} {[update] [extensions] [daemonsets] [] []} {[watch] [extensions] [daemonsets] [] []} {[create] [extensions] [deployments] [] []} {[delete] [extensions] [deployments] [] []} {[deletecollection] [extensions] [deployments] [] []} {[get] [extensions] [deployments] [] []} {[list] [extensions] [deployments] [] []} {[patch] [extensions] [deployments] [] []} {[update] [extensions] [deployments] [] []} {[watch] [extensions] [deployments] [] []} {[create] [extensions] [deployments/rollback] [] []} {[delete] [extensions] [deployments/rollback] [] []} {[deletecollection] [extensions] [deployments/rollback] [] []} {[get] [extensions] [deployments/rollback] [] []} {[list] [extensions] [deployments/rollback] [] []} {[patch] [extensions] [deployments/rollback] [] []} {[update] [extensions] [deployments/rollback] [] []} {[watch] [extensions] [deployments/rollback] [] []} {[create] [extensions] [deployments/scale] [] []} {[delete] [extensions] [deployments/scale] [] []} {[deletecollection] [extensions] [deployments/scale] [] []} {[get] [extensions] [deployments/scale] [] []} {[list] [extensions] [deployments/scale] [] []} {[patch] [extensions] [deployments/scale] [] []} {[update] [extensions] [deployments/scale] [] []} {[watch] [extensions] [deployments/scale] [] []} {[create] [extensions] [ingresses] [] []} {[delete] [extensions] [ingresses] [] []} {[deletecollection] [extensions] [ingresses] [] []} {[get] [extensions] [ingresses] [] []} {[list] [extensions] [ingresses] [] []} {[patch] [extensions] [ingresses] [] []} {[update] [extensions] [ingresses] [] []} {[watch] [extensions] [ingresses] [] []} {[create] [extensions] [networkpolicies] [] []} {[delete] [extensions] [networkpolicies] [] []} {[deletecollection] [extensions] [networkpolicies] [] []} {[get] [extensions] [networkpolicies] [] []} {[list] [extensions] [networkpolicies] [] []} {[patch] [extensions] [networkpolicies] [] []} {[update] [extensions] [networkpolicies] [] []} {[watch] [extensions] [networkpolicies] [] []} {[create] [extensions] [replicasets] [] []} {[delete] [extensions] [replicasets] [] []} {[deletecollection] [extensions] [replicasets] [] []} {[get] [extensions] [replicasets] [] []} {[list] [extensions] [replicasets] [] []} {[patch] [extensions] [replicasets] [] []} {[update] [extensions] [replicasets] [] []} {[watch] [extensions] [replicasets] [] []} {[create] [extensions] [replicasets/scale] [] []} {[delete] [extensions] [replicasets/scale] [] []} {[deletecollection] [extensions] [replicasets/scale] [] []} {[get] [extensions] [replicasets/scale] [] []} {[list] [extensions] [replicasets/scale] [] []} {[patch] [extensions] [replicasets/scale] [] []} {[update] [extensions] [replicasets/scale] [] []} {[watch] [extensions] [replicasets/scale] [] []} {[create] [extensions] [replicationcontrollers/scale] [] []} {[delete] [extensions] [replicationcontrollers/scale] [] []} {[deletecollection] [extensions] [replicationcontrollers/scale] [] []} {[get] [extensions] [replicationcontrollers/scale] [] []} {[list] [extensions] [replicationcontrollers/scale] [] []} {[patch] [extensions] [replicationcontrollers/scale] [] []} {[update] [extensions] [replicationcontrollers/scale] [] []} {[watch] [extensions] [replicationcontrollers/scale] [] []} {[create] [policy] [poddisruptionbudgets] [] []} {[delete] [policy] [poddisruptionbudgets] [] []} {[deletecollection] [policy] [poddisruptionbudgets] [] []} {[get] [policy] [poddisruptionbudgets] [] []} {[list] [policy] [poddisruptionbudgets] [] []} {[patch] [policy] [poddisruptionbudgets] [] []} {[update] [policy] [poddisruptionbudgets] [] []} {[watch] [policy] [poddisruptionbudgets] [] []} {[create] [networking.k8s.io] [networkpolicies] [] []} {[delete] [networking.k8s.io] [networkpolicies] [] []} {[deletecollection] [networking.k8s.io] [networkpolicies] [] []} {[get] [networking.k8s.io] [networkpolicies] [] []} {[list] [networking.k8s.io] [networkpolicies] [] []} {[patch] [networking.k8s.io] [networkpolicies] [] []} {[update] [networking.k8s.io] [networkpolicies] [] []} {[watch] [networking.k8s.io] [networkpolicies] [] []} {[patch] [] [buildconfigs] [] []} {[patch] [] [buildconfigs/webhooks] [] []} {[patch] [] [builds] [] []} {[patch] [build.openshift.io] [buildconfigs] [] []} {[patch] [build.openshift.io] [buildconfigs/webhooks] [] []} {[patch] [build.openshift.io] [builds] [] []} {[create] [] [buildconfigs/instantiate] [] []} {[create] [] [builds/clone] [] []} {[create] [build.openshift.io] [buildconfigs/instantiate] [] []} {[create] [build.openshift.io] [builds/clone] [] []} {[edit] [build.openshift.io] [jenkins] [] []} {[view] [build.openshift.io] [jenkins] [] []} {[update] [] [imagestreams/layers] [] []} {[update] [image.openshift.io] [imagestreams/layers] [] []} {[create] [] [imagestreamimports] [] []} {[create] [image.openshift.io] [imagestreamimports] [] []} {[get] [] [projects] [] []} {[get] [project.openshift.io] [projects] [] []} {[get] [] [appliedclusterresourcequotas] [] []} {[list] [] [appliedclusterresourcequotas] [] []} {[watch] [] [appliedclusterresourcequotas] [] []} {[get] [quota.openshift.io] [appliedclusterresourcequotas] [] []} {[list] [quota.openshift.io] [appliedclusterresourcequotas] [] []} {[watch] [quota.openshift.io] [appliedclusterresourcequotas] [] []} {[create] [] [routes] [] []} {[delete] [] [routes] [] []} {[deletecollection] [] [routes] [] []} {[get] [] [routes] [] []} {[list] [] [routes] [] []} {[patch] [] [routes] [] []} {[update] [] [routes] [] []} {[watch] [] [routes] [] []} {[create] [] [routes/custom-host] [] []} {[get] [] [routes/status] [] []} {[list] [] [routes/status] [] []} {[watch] [] [routes/status] [] []} {[get] [route.openshift.io] [routes/status] [] []} {[list] [route.openshift.io] [routes/status] [] []} {[watch] [route.openshift.io] [routes/status] [] []} {[create] [extensions] [networkpolicies] [] []} {[delete] [extensions] [networkpolicies] [] []} {[deletecollection] [extensions] [networkpolicies] [] []} {[get] [extensions] [networkpolicies] [] []} {[list] [extensions] [networkpolicies] [] []} {[patch] [extensions] [networkpolicies] [] []} {[update] [extensions] [networkpolicies] [] []} {[watch] [extensions] [networkpolicies] [] []} {[create] [networking.k8s.io] [networkpolicies] [] []} {[delete] [networking.k8s.io] [networkpolicies] [] []} {[deletecollection] [networking.k8s.io] [networkpolicies] [] []} {[get] [networking.k8s.io] [networkpolicies] [] []} {[list] [networking.k8s.io] [networkpolicies] [] []} {[patch] [networking.k8s.io] [networkpolicies] [] []} {[update] [networking.k8s.io] [networkpolicies] [] []} {[watch] [networking.k8s.io] [networkpolicies] [] []} {[create] [] [buildlogs] [] []} {[delete] [] [buildlogs] [] []} {[deletecollection] [] [buildlogs] [] []} {[get] [] [buildlogs] [] []} {[list] [] [buildlogs] [] []} {[patch] [] [buildlogs] [] []} {[update] [] [buildlogs] [] []} {[watch] [] [buildlogs] [] []} {[create] [build.openshift.io] [buildlogs] [] []} {[delete] [build.openshift.io] [buildlogs] [] []} {[deletecollection] [build.openshift.io] [buildlogs] [] []} {[get] [build.openshift.io] [buildlogs] [] []} {[list] [build.openshift.io] [buildlogs] [] []} {[patch] [build.openshift.io] [buildlogs] [] []} {[update] [build.openshift.io] [buildlogs] [] []} {[watch] [build.openshift.io] [buildlogs] [] []} {[get] [] [resourcequotausages] [] []} {[list] [] [resourcequotausages] [] []} {[watch] [] [resourcequotausages] [] []}] user=&amp;{system:serviceaccount:myproject:syndesis-operator  [system:serviceaccounts system:serviceaccounts:myproject system:authenticated] map[]} ownerrules=[{[get] [ user.openshift.io] [users] [~] []} {[list] [ project.openshift.io] [projectrequests] [] []} {[get list] [ authorization.openshift.io] [clusterroles] [] []} {[get list watch] [rbac.authorization.k8s.io] [clusterroles] [] []} {[get list] [storage.k8s.io] [storageclasses] [] []} {[list watch] [ project.openshift.io] [projects] [] []} {[create] [ authorization.openshift.io] [selfsubjectrulesreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews] [] []} {[get] [] [] [] [/healthz /healthz/*]} {[get] [] [] [] [/version /version/* /api /api/* /apis /apis/* /oapi /oapi/* /openapi/v2 /swaggerapi /swaggerapi/* /swagger.json /swagger-2.0.0.pb-v1 /osapi /osapi/ /.well-known /.well-known/* /]} {[create] [ authorization.openshift.io] [selfsubjectrulesreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews selfsubjectrulesreviews] [] []} {[create] [ build.openshift.io] [builds/docker builds/optimizeddocker] [] []} {[create] [ build.openshift.io] [builds/jenkinspipeline] [] []} {[create] [ build.openshift.io] [builds/source] [] []} {[get] [] [] [] [/api /api/* /apis /apis/* /healthz /openapi /openapi/* /swagger-2.0.0.pb-v1 /swagger.json /swaggerapi /swaggerapi/* /version /version/]} {[delete] [ oauth.openshift.io] [oauthaccesstokens oauthauthorizetokens] [] []} {[get] [] [] [] [/version /version/* /api /api/* /apis /apis/* /oapi /oapi/* /openapi/v2 /swaggerapi /swaggerapi/* /swagger.json /swagger-2.0.0.pb-v1 /osapi /osapi/ /.well-known /.well-known/* /]} {[impersonate] [authentication.k8s.io] [userextras/scopes.authorization.openshift.io] [] []} {[create get] [ build.openshift.io] [buildconfigs/webhooks] [] []} {[get list create update delete deletecollection watch] [syndesis.io] [* */finalizers] [] []} {[get list create update delete deletecollection watch] [] [pods services endpoints persistentvolumeclaims configmaps secrets serviceaccounts] [] []} {[get] [] [pods/log] [] []} {[get list create update delete deletecollection watch] [] [replicationcontrollers replicationcontrollers/scale replicationcontrollers/status] [] []} {[get list create update delete deletecollection watch] [ build.openshift.io] [builds buildconfigs builds/details buildconfigs/webhooks buildconfigs/instantiatebinary builds/log] [] []} {[get list create update delete deletecollection watch patch] [ apps.openshift.io] [deploymentconfigs deploymentconfigs/scale] [] []} {[create] [ apps.openshift.io] [deploymentconfigrollbacks deploymentconfigs/instantiate deploymentconfigs/rollback] [] []} {[get list watch] [ apps.openshift.io] [deploymentconfigs/log deploymentconfigs/status] [] []} {[get list create update delete deletecollection watch patch] [ image.openshift.io] [imagestreams imagestreamimages imagestreammappings imagestreams/secrets imagestreamtags] [] []} {[get list watch] [ image.openshift.io] [imagestreams/status imagestreamimports] [] []} {[get list] [] [events] [] []} {[get list create update delete deletecollection watch] [rbac.authorization.k8s.io] [roles rolebindings] [] []} {[get list create update delete deletecollection watch patch] [ template.openshift.io] [processedtemplates templateconfigs templateinstances templates] [] []} {[get list create update delete deletecollection watch] [authorization.openshift.io] [rolebindings] [] []} {[get list create update delete deletecollection watch patch] [route.openshift.io] [routes routes/custom-host] [] []} {[get list create update delete deletecollection watch] [camel.apache.org] [*] [] []} {[get list create update delete deletecollection watch] [monitoring.coreos.com] [alertmanagers prometheuses servicemonitors prometheusrules] [] []} {[get list create update delete deletecollection watch] [integreatly.org] [grafanadashboards] [] []} {[get list watch] [serving.knative.dev] [services] [] []} {[get list watch] [eventing.knative.dev] [channels] [] []} {[get] [ image.openshift.io] [imagestreams/layers] [] []}] ruleResolutionErrors=[]","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/home/circleci/project/install/operator/vendor/github.com/go-logr/zapr/zapr.go:128\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/home/circleci/project/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:217\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func1\n\t/home/circleci/project/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:158\nk8s.io/apimachinery/pkg/util/wait.JitterUntil.func1\n\t/home/circleci/project/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/home/circleci/project/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:134\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/home/circleci/project/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:88"} Failed to create or replace resource: apiVersion: authorization.openshift.io/v1 groupNames: null kind: RoleBinding metadata:   creationTimestamp: null   labels:     app: syndesis     syndesis.io/app: syndesis     syndesis.io/type: infrastructure   name: syndesis:editors   namespace: myproject   ownerReferences:   - apiVersion: syndesis.io/v1alpha1     blockOwnerDeletion: true     controller: true     kind: Syndesis     name: app     uid: 8f4fff8f-990b-11e9-987b-5254001cc54c roleRef:   name: edit subjects: - kind: ServiceAccount   name: syndesis-server userNames: null ```</body>
		<created>2019-06-27 18:51:00</created>
		<closed>2019-07-03 13:33:43</closed>
	</bug>
	<bug>
		<id>5973</id>
		<title>syndesis command line tool ignores --project parameter</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description `syndesis` command line tool ignores `--project` parameter and always installs Syndesis in the `myproject` project.  ## Output ``` $ syndesis minishift --install -p syndesis Creating project syndesis Now using project "myproject" from context named "syndesis" on server "https://192.168.42.58:8443". Switching to project "syndesis" Already on project "myproject" on server "https://192.168.42.58:8443". Installing Syndesis CRD cluster role "syndesis-extra-permissions" added: "developer" Deploying Syndesis operator Switching to project "syndesis" Login successful.  You have access to the following projects and can switch between them with 'oc project &lt;projectname&gt;':      application-monitoring     default     kube-dns     kube-proxy     kube-public     kube-system   * myproject     openshift     openshift-apiserver     openshift-controller-manager     openshift-core-operators     openshift-infra     openshift-node     openshift-service-cert-signer     openshift-web-console     syndesis  Using project "myproject". Waiting for syndesis-operator to be scaled to 1 Sleeping 10s ... NAME                         READY     STATUS    RESTARTS   AGE syndesis-operator-1-deploy   0/1       Pending   0          0s syndesis-operator-1-deploy   0/1       Pending   0         0s syndesis-operator-1-deploy   0/1       ContainerCreating   0         1s syndesis-operator-1-c9z4r   0/1       Pending   0         0s syndesis-operator-1-c9z4r   0/1       Pending   0         0s syndesis-operator-1-c9z4r   0/1       ContainerCreating   0         0s syndesis-operator-1-deploy   1/1       Running   0         4s Sleeping 10s ... Sleeping 10s ... Sleeping 10s ... Sleeping 10s ... ```</body>
		<created>2019-06-27 18:41:58</created>
		<closed>2019-08-07 11:29:20</closed>
	</bug>
	<bug>
		<id>5967</id>
		<title>Rebuilding the operator and installing ...</title>
		<body>After deleting syndesis project, spent time trying to reinstall. Made some progress but now stuck.  Observations &amp; Potential Issues 1. Building the operator: ``` export GOPATH=~/programming/java/syndesis syndesis build --local -m operator -f ``` - The build requires go &amp; the operator-sdk. Once both are installed and correctly configured, ie. GOPATH is correct, the following error occurs and aborts the build: ``` INFO[0004] Running deepcopy code-generation for Custom Resource group versions: [syndesis:[v1alpha1], ]  INFO[0009] Code-generation complete.                     INFO[0002] Running OpenAPI code-generation for Custom Resource group versions: [syndesis:[v1alpha1], ]  API rule violation: names_match,github.com/syndesisio/syndesis/install/operator/pkg/apis/syndesis/v1alpha1,SyndesisSpec,RouteHostName 2019/06/27 16:00:04 OpenAPI code generation error: Failed executing generator: some packages had errors: API rule violations exist Error: failed to perform openapi code-generation: failed to exec []string{"/home/phantomjinx/programming/go/src/github.com/syndesisio/syndesis/install/operator/build/_output/bin/openapi-gen", "--input-dirs", "github.com/syndesisio/syndesis/install/operator/pkg/apis/syndesis/v1alpha1", "--output-package", "github.com/syndesisio/syndesis/install/operator/pkg/apis/syndesis/v1alpha1", "--output-file-base", "zz_generated.openapi", "--go-header-file", "/tmp/685499015"}: exit status 1 Usage:   operator-sdk generate openapi [flags] ``` - By changing the GOPATH (with use of softlinks) it is possible to bypass this error and move on to building the operator. The error doesn't seem to hinder the operator being built. - Until recently, the _-i_ switch was used to cause the creation of an image, eg. _syndesis build -m meta -f -i_. If this switch is used with the operator then local docker building is chosen. This works correctly except it builds the image literally on my installed local docker instance. When using minishift, this is the wrong docker instance and hence the new image is not available to openshift. There is no clue that this is the case unless really hunted for. - Without using _-i_, the s2i version is used which does require openshift. However, this currently errors out [here](https://github.com/syndesisio/syndesis/blob/master/install/operator/.lib.sh#L157). On Fedora, _mktemp_ complains about lacking 'XXX' [symbols](https://github.com/rtomayko/shocco/issues/5) in its command. This causes the tar archive to be named '.tar' and the s2i build immediately errors out. The line can be changed to the following and the build works correctly: ``` local arch="$(mktemp -t ${S2I_STREAM_NAME}-dockerXXX).tar" ```  2. Running syndesis All pods have been deployed and all running correctly: ``` NAME                          READY     STATUS      RESTARTS   AGE syndesis-db-1-8p5vr           2/2       Running     0          26m syndesis-meta-2-gw6n4         1/1       Running     0          17m syndesis-oauthproxy-1-2hnqt   1/1       Running     0          26m syndesis-operator-1-tm45d     1/1       Running     0          28m syndesis-operator-5-build     0/1       Completed   0          33m syndesis-prometheus-1-jmjgb   1/1       Running     0          26m syndesis-server-2-6b567       1/1       Running     0          2m syndesis-ui-1-4r6sf           1/1       Running     0          26m ``` However, the syndesis home page fails to appear. Rather, I have  ![Screenshot_20190627_170803](https://user-images.githubusercontent.com/1634180/60282151-2c11f400-98fe-11e9-818c-56617e14d491.png) - Unfortunately, I have no errors in the console, pods logs or events to determine the problem.</body>
		<created>2019-06-27 16:12:34</created>
		<closed>2019-07-03 20:09:15</closed>
	</bug>
	<bug>
		<id>5963</id>
		<title>Drop integration id and operation id from the flow id</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Currently we're creating flow id of the API provider generated flows by concatenating `integration id`, `:flows:` and `operation id` (of the OpenAPI operation).  We should store the operation id in the flow metadata, and modify the logic to match the operation with the flow based on the metadata.  The existing flows need to be migrated such that flow ids are regenerated and the operation id from the flow id is placed into the metadata of the flow.</body>
		<created>2019-06-27 14:16:12</created>
		<closed>2019-07-03 14:15:36</closed>
	</bug>
	<bug>
		<id>5960</id>
		<title>[about page] build id is empty</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11448**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Build id is empty, is that expected?  ![screenshot_20190627_143031](https://user-images.githubusercontent.com/14313995/60266327-201b3780-98e8-11e9-9ec4-a9f5d6e64371.png)  </body>
		<created>2019-06-27 12:31:09</created>
		<closed>2019-09-07 11:45:03</closed>
	</bug>
	<bug>
		<id>5959</id>
		<title>Release script no longer working</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Seems that the last operator refactoring broke the release script:  ``` /mnt/hudson_workspace/workspace/syndesis-release-daily/tools/bin/commands/release: line 58: /mnt/hudson_workspace/workspace/syndesis-release-daily/tools/bin/commands/util/operator_funcs: No such file or directory ```  @chirino what would be the new way of building/releasing the operator?</body>
		<created>2019-06-27 12:26:43</created>
		<closed>2019-07-18 07:52:12</closed>
	</bug>
	<bug>
		<id>5957</id>
		<title>git hooks assumes `syndesis` binary on PATH</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Git hooks assume to find `syndesis` binary on path, which is not a strict requirement. Hooks should not make this assumption or degrade gracefully otherwise. </body>
		<created>2019-06-27 12:16:30</created>
		<closed>2019-08-09 13:06:14</closed>
	</bug>
	<bug>
		<id>5955</id>
		<title>Template type change results in errors </title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When I input a correct template in a specific template type, the Done button results in errors in the browsers console. Only time I am allowed to continue with the integration creation process is if I stick with Mustache and don't try to change the type at all, after the type is changed once, every click **even with correct template type** produces error.  Here you can see it: ![Peek 2019-06-27 13-31](https://user-images.githubusercontent.com/46345469/60263100-17266800-98e0-11e9-8e16-f58615975d47.gif)  What is strange is that the Freemarker template was valid even as a Velocity template... and was valid only after clicking from Velocity.  The error message in console is: ``` Error: Bad Request api.js:3285 ```</body>
		<created>2019-06-27 11:35:26</created>
		<closed>2019-08-06 08:06:21</closed>
	</bug>
	<bug>
		<id>5936</id>
		<title>Implement endpoint to fetch the OpenAPI resource by id</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [x] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  The React UI needs to access the OpenAPI document resource by id. This is because until the user opts to save the integration the integration will not be stored on the server and the `GET /apis/v1/integrations/{id}/specification` endpoint is not applicable.  When generator API is invoked either via `POST /apis/v1/apis/generator` or via `PUT /apis/v1/apis/generator` the server stores the OpenAPI resource.  The id of the stored OpenAPI resource is set in the `resources` property of the Integration, and can be identified by searching for the resource with `kind` that equals `open-api`.  The new endpoint should be at `GET /apis/v1/resources/{kind}/{id}`.</body>
		<created>2019-06-26 08:29:10</created>
		<closed>2019-07-19 14:15:25</closed>
	</bug>
	<bug>
		<id>5934</id>
		<title>Unable to deploy from master or 1.7.5</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description ``` syndesis install --project syndesis -y --test-support ```  or   ``` syndesis install --project syndesis -y --test-support --tag 1.7.5 ```  results in:  ``` {"level":"info","ts":1561527728.6437426,"logger":"action","msg":"Installing Syndesis resource","type":"install","name":"app"} {"level":"error","ts":1561527730.759161,"logger":"controller","msg":"Error reconciling","action":"*action.installAction","phase":"Installing","error":"roles.rbac.authorization.k8s.io \"syndesis-editor\" is forbidden: attempt to grant extra privileges: [{[patch] [route.openshift.io] [routes] [] []}] user=&amp;{system:serviceaccount:syndesis:syndesis-operator 15826dc1-97d5-11e9-9182-080027adcef5 [system:serviceaccounts system:serviceaccounts:syndesis system:authenticated] map[]} ownerrules=[{[get] [ user.openshift.io] [users] [~] []} {[list] [ project.openshift.io] [projectrequests] [] []} {[get list] [ authorization.openshift.io] [clusterroles] [] []} {[get list watch] [rbac.authorization.k8s.io] [clusterroles] [] []} {[get list] [storage.k8s.io] [storageclasses] [] []} {[list watch] [ project.openshift.io] [projects] [] []} {[create] [ authorization.openshift.io] [selfsubjectrulesreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews] [] []} {[get] [] [] [] [/healthz /healthz/*]} {[get] [] [] [] [/version /version/* /api /api/* /apis /apis/* /oapi /oapi/* /openapi/v2 /swaggerapi /swaggerapi/* /swagger.json /swagger-2.0.0.pb-v1 /osapi /osapi/ /.well-known /.well-known/* /]} {[create] [ authorization.openshift.io] [selfsubjectrulesreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews selfsubjectrulesreviews] [] []} {[create] [ build.openshift.io] [builds/docker builds/optimizeddocker] [] []} {[create] [ build.openshift.io] [builds/jenkinspipeline] [] []} {[create] [ build.openshift.io] [builds/source] [] []} {[get] [] [] [] [/api /api/* /apis /apis/* /healthz /openapi /openapi/* /swagger-2.0.0.pb-v1 /swagger.json /swaggerapi /swaggerapi/* /version /version/]} {[delete] [ oauth.openshift.io] [oauthaccesstokens oauthauthorizetokens] [] []} {[get] [] [] [] [/version /version/* /api /api/* /apis /apis/* /oapi /oapi/* /openapi/v2 /swaggerapi /swaggerapi/* /swagger.json /swagger-2.0.0.pb-v1 /osapi /osapi/ /.well-known /.well-known/* /]} {[impersonate] [authentication.k8s.io] [userextras/scopes.authorization.openshift.io] [] []} {[create get] [ build.openshift.io] [buildconfigs/webhooks] [] []} {[get list create update delete deletecollection watch] [syndesis.io] [* */finalizers] [] []} {[get list create update delete deletecollection watch] [] [pods services endpoints persistentvolumeclaims configmaps secrets serviceaccounts] [] []} {[get] [] [pods/log] [] []} {[get list create update delete deletecollection watch] [] [replicationcontrollers replicationcontrollers/scale replicationcontrollers/status] [] []} {[get list create update delete deletecollection watch] [ build.openshift.io] [builds buildconfigs builds/details buildconfigs/webhooks buildconfigs/instantiatebinary builds/log] [] []} {[get list create update delete deletecollection watch patch] [ apps.openshift.io] [deploymentconfigs deploymentconfigs/scale] [] []} {[create] [ apps.openshift.io] [deploymentconfigrollbacks deploymentconfigs/instantiate deploymentconfigs/rollback] [] []} {[get list watch] [ apps.openshift.io] [deploymentconfigs/log deploymentconfigs/status] [] []} {[get list create update delete deletecollection watch patch] [ image.openshift.io] [imagestreams imagestreamimages imagestreammappings imagestreams/secrets imagestreamtags] [] []} {[get list watch] [ image.openshift.io] [imagestreams/status imagestreamimports] [] []} {[get list] [] [events] [] []} {[get list create update delete deletecollection watch] [rbac.authorization.k8s.io] [roles rolebindings] [] []} {[get list create update delete deletecollection watch patch] [ template.openshift.io] [processedtemplates templateconfigs templateinstances templates] [] []} {[get list create update delete deletecollection watch] [authorization.openshift.io] [rolebindings] [] []} {[get list create update delete deletecollection watch] [route.openshift.io] [routes routes/custom-host] [] []} {[get list create update delete deletecollection watch] [camel.apache.org] [*] [] []} {[get list create update delete deletecollection watch] [monitoring.coreos.com] [alertmanagers prometheuses servicemonitors prometheusrules] [] []} {[get list create update delete deletecollection watch] [integreatly.org] [grafanadashboards] [] []} {[get list watch] [serving.knative.dev] [services] [] []} {[get list watch] [eventing.knative.dev] [channels] [] []} {[get] [ image.openshift.io] [imagestreams/layers] [] []}] ruleResolutionErrors=[]","stacktrace":"github.com/syndesisio/syndesis/install/operator/vendor/github.com/go-logr/zapr.(*zapLogger).Error\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/github.com/go-logr/zapr/zapr.go:128\ngithub.com/syndesisio/syndesis/install/operator/pkg/controller/syndesis.(*ReconcileSyndesis).Reconcile\n\t/go/src/github.com/syndesisio/syndesis/install/operator/pkg/controller/syndesis/syndesis_controller.go:120\ngithub.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:215\ngithub.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func1\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:158\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.JitterUntil.func1\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:133\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:134\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.Until\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:88"} {"level":"error","ts":1561527730.7593424,"logger":"kubebuilder.controller","msg":"Reconciler error","controller":"syndesis-controller","request":"syndesis/app","error":"roles.rbac.authorization.k8s.io \"syndesis-editor\" is forbidden: attempt to grant extra privileges: [{[patch] [route.openshift.io] [routes] [] []}] user=&amp;{system:serviceaccount:syndesis:syndesis-operator 15826dc1-97d5-11e9-9182-080027adcef5 [system:serviceaccounts system:serviceaccounts:syndesis system:authenticated] map[]} ownerrules=[{[get] [ user.openshift.io] [users] [~] []} {[list] [ project.openshift.io] [projectrequests] [] []} {[get list] [ authorization.openshift.io] [clusterroles] [] []} {[get list watch] [rbac.authorization.k8s.io] [clusterroles] [] []} {[get list] [storage.k8s.io] [storageclasses] [] []} {[list watch] [ project.openshift.io] [projects] [] []} {[create] [ authorization.openshift.io] [selfsubjectrulesreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews] [] []} {[get] [] [] [] [/healthz /healthz/*]} {[get] [] [] [] [/version /version/* /api /api/* /apis /apis/* /oapi /oapi/* /openapi/v2 /swaggerapi /swaggerapi/* /swagger.json /swagger-2.0.0.pb-v1 /osapi /osapi/ /.well-known /.well-known/* /]} {[create] [ authorization.openshift.io] [selfsubjectrulesreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews selfsubjectrulesreviews] [] []} {[create] [ build.openshift.io] [builds/docker builds/optimizeddocker] [] []} {[create] [ build.openshift.io] [builds/jenkinspipeline] [] []} {[create] [ build.openshift.io] [builds/source] [] []} {[get] [] [] [] [/api /api/* /apis /apis/* /healthz /openapi /openapi/* /swagger-2.0.0.pb-v1 /swagger.json /swaggerapi /swaggerapi/* /version /version/]} {[delete] [ oauth.openshift.io] [oauthaccesstokens oauthauthorizetokens] [] []} {[get] [] [] [] [/version /version/* /api /api/* /apis /apis/* /oapi /oapi/* /openapi/v2 /swaggerapi /swaggerapi/* /swagger.json /swagger-2.0.0.pb-v1 /osapi /osapi/ /.well-known /.well-known/* /]} {[impersonate] [authentication.k8s.io] [userextras/scopes.authorization.openshift.io] [] []} {[create get] [ build.openshift.io] [buildconfigs/webhooks] [] []} {[get list create update delete deletecollection watch] [syndesis.io] [* */finalizers] [] []} {[get list create update delete deletecollection watch] [] [pods services endpoints persistentvolumeclaims configmaps secrets serviceaccounts] [] []} {[get] [] [pods/log] [] []} {[get list create update delete deletecollection watch] [] [replicationcontrollers replicationcontrollers/scale replicationcontrollers/status] [] []} {[get list create update delete deletecollection watch] [ build.openshift.io] [builds buildconfigs builds/details buildconfigs/webhooks buildconfigs/instantiatebinary builds/log] [] []} {[get list create update delete deletecollection watch patch] [ apps.openshift.io] [deploymentconfigs deploymentconfigs/scale] [] []} {[create] [ apps.openshift.io] [deploymentconfigrollbacks deploymentconfigs/instantiate deploymentconfigs/rollback] [] []} {[get list watch] [ apps.openshift.io] [deploymentconfigs/log deploymentconfigs/status] [] []} {[get list create update delete deletecollection watch patch] [ image.openshift.io] [imagestreams imagestreamimages imagestreammappings imagestreams/secrets imagestreamtags] [] []} {[get list watch] [ image.openshift.io] [imagestreams/status imagestreamimports] [] []} {[get list] [] [events] [] []} {[get list create update delete deletecollection watch] [rbac.authorization.k8s.io] [roles rolebindings] [] []} {[get list create update delete deletecollection watch patch] [ template.openshift.io] [processedtemplates templateconfigs templateinstances templates] [] []} {[get list create update delete deletecollection watch] [authorization.openshift.io] [rolebindings] [] []} {[get list create update delete deletecollection watch] [route.openshift.io] [routes routes/custom-host] [] []} {[get list create update delete deletecollection watch] [camel.apache.org] [*] [] []} {[get list create update delete deletecollection watch] [monitoring.coreos.com] [alertmanagers prometheuses servicemonitors prometheusrules] [] []} {[get list create update delete deletecollection watch] [integreatly.org] [grafanadashboards] [] []} {[get list watch] [serving.knative.dev] [services] [] []} {[get list watch] [eventing.knative.dev] [channels] [] []} {[get] [ image.openshift.io] [imagestreams/layers] [] []}] ruleResolutionErrors=[]","stacktrace":"github.com/syndesisio/syndesis/install/operator/vendor/github.com/go-logr/zapr.(*zapLogger).Error\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/github.com/go-logr/zapr/zapr.go:128\ngithub.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:217\ngithub.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func1\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:158\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.JitterUntil.func1\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:133\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:134\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.Until\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:88"} ``` </body>
		<created>2019-06-26 05:45:15</created>
		<closed>2019-07-04 12:48:50</closed>
	</bug>
	<bug>
		<id>5925</id>
		<title>Failed to install from operatorhub</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Currently fuse-online is installed via https://github.com/syndesisio/fuse-online-install, which takes care that the ImageStreams are present with the correct version: https://github.com/syndesisio/fuse-online-install/blob/d0190189b85ad0a43e93cea0beb48326e14e8867/install_ocp.sh#L925.  For the operatorhub integration, we have to move this logic (creating ImageStreams) to the operator.  After discussing with @nicolaferraro and @heiko-braun, it seems that the best solution for this release would be to give the user the possibility to download the complete `syndesis-template.yaml` from the fuse-online repository.</body>
		<created>2019-06-25 17:35:22</created>
		<closed>2019-07-23 14:06:14</closed>
	</bug>
	<bug>
		<id>5924</id>
		<title>Server OpenAPI document contains different values for Kind</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Seems that the OpenAPI document generate by the server runtime lists values of `Kind` as camel case, whereas we store as dash-ed snake case in JSONDB.  Seems like the most correct approach would be to try to customize the OpenAPI document generation so it uses `name` for enum values instead of `value` of the Kind enum.</body>
		<created>2019-06-25 16:58:47</created>
		<closed>2019-07-19 14:24:48</closed>
	</bug>
	<bug>
		<id>5923</id>
		<title>Number of usages a tag is incorrect in some cases</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I have a tag "tag12" and three integration (_integration1_, _integration2_ and _integration3_). Only _integration1_ and _integration2_ are tagged by the tag _tag12_.  `GET .../public/integrations/integration1/tags` returns `{"tag12":..}` `GET .../public/integrations/integration2/tags` returns `{"tag12":..}` `GET .../public/environments?withUses=true` returns `{"name":"tag12","uses":2}` The integration3 is not tagged by any tag. `GET .../public/integrations/integration3/tags` returns `{}`  After that, I call the endpoint for exporting all integration,  `GET .../public/public/integrations/staging/export.zip?all=true -o export.zip` so the tag is added to the integration3 too. `GET .../public/integrations/integration1/tags` returns `{"tag12":...}` `GET .../public/integrations/integration2/tags` returns `{"tag12":...}` `GET .../public/integrations/integration3/tags` returns `{"tag12":...}` However, the number of usages is wrong, should be 3 but is 2: `GET .../public/environments?withUses=true` returns `{"name":"tag12","uses":2}`  I am able to reproduce it on the tag 1.7.4.  ![output](https://user-images.githubusercontent.com/16251792/60114842-f1308480-9774-11e9-8afd-7177f1726f9a.gif)  Step to **reproduce:**  - Create tag _tag12_ - Create simple integration Timer-to-log with name integration1 - Create simple integration Timer-to-log with name integration2 - Create simple integration Timer-to-log with name integration3 - Check _tag12_ in the integration1 - Check _tag12_ in the integration2 - Verify that _tag12_ is not checked in the CI/CD dialog in the integration3 - Verify that _tag12_ is used only twice `GET .../api/v1/public/environments?withUses=true` -&gt; `[{"name":"tag12","uses":2}]` - Export all integrations `GET .../public/public/integrations/tag12/export.zip?all=true -o export.zip` - Verify that _tag12_ is now checked in the CI/CD dialog in the integration3 - The endpoint `GET .../api/v1/public/environments?withUses=true` still returns twice `[{"name":"tag12","uses":2}]`</body>
		<created>2019-06-25 16:14:07</created>
		<closed>2019-07-01 07:30:04</closed>
	</bug>
	<bug>
		<id>5917</id>
		<title>Delete integration causes that associated tag is deleted too</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When I have a tag which is associated only to the one integration and I delete that integration, the tag is automatically deleted too. Shouldn't the tag stay in the Syndesis when the tag lifecycle is managed in the Manage CI/CD view?  A similar case as with https://github.com/syndesisio/syndesis/issues/5266 In my POV, for consistency, the deletion of the tag should be able only in the Manage CI/CD view. </body>
		<created>2019-06-25 12:50:45</created>
		<closed>2019-08-12 14:39:31</closed>
	</bug>
	<bug>
		<id>5914</id>
		<title>Metrics tab doesn't show correct data</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Metrics tab doesn't show correct data.  - A number of Total Messages is still 0 however the activity log contains some items. - Uptime still shows as "No Data Available". - Last Processed date shows a date (with time) when I refresh the page, not when the last message was processed. </body>
		<created>2019-06-25 12:04:09</created>
		<closed>2019-07-07 07:35:01</closed>
	</bug>
	<bug>
		<id>5912</id>
		<title>Nothing gets loaded on freshly deployed Syndesis</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11409**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description After deploying Syndesis, everything I get are placeholders. Simple refresh fixes these problems but all of QE tests expect that the UI will get loaded. Refreshing in every test becomes cumbersome and it's not a good UX having to refresh to load the UI.  ![Peek 2019-06-25 12-34](https://user-images.githubusercontent.com/46345469/60092254-dd6e2980-9746-11e9-8173-69f432cbcfae.gif)  ## Steps to reproduce 1. deploy Syndesis 2. click on connections/settings/integrations 3. to fix it click on refresh  </body>
		<created>2019-06-25 10:45:37</created>
		<closed>2019-09-07 10:52:26</closed>
	</bug>
	<bug>
		<id>5906</id>
		<title>Tagging process misses changing versions in app/extension</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  The syndesis tagging process misses changing the versions of these two files-   app/extension/example/log-step/pom.xml app/extension/example/simple-action-step/pom.xml  The result is a tag that does not build correctly.</body>
		<created>2019-06-24 18:42:32</created>
		<closed>2019-07-01 13:07:34</closed>
	</bug>
	<bug>
		<id>5901</id>
		<title>The CI/CD dialog saves only one checked the tag</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Let's say that I have 3 tags. When I want to check it all in the CI/CD dialog and click on save. Only one tag is checked. The next time when I check all tags, the only one which is not associated with the integration is added. So for 3 tags, I have to open dialog, check all tags and save dialog three times. Same situation for unchecking. ![output](https://user-images.githubusercontent.com/16251792/60030358-2076c100-96a3-11e9-8d57-1876ece6fc41.gif)  I noticed in a console that the UI first time sends only one tag after saving to the endpoint `PUT .../public/integrations/&lt;integration&gt;/tags` instead of all checked. The second time the UI sends two tags etc.</body>
		<created>2019-06-24 15:21:01</created>
		<closed>2019-06-26 13:36:04</closed>
	</bug>
	<bug>
		<id>5892</id>
		<title>A route for WebHook is not created automatically</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description After deployed the integration with WebHook, the route is not created automatically as before. Because of that, the UI doesn't contain the URL either.  Version: (`syndesis minishift --install --tag 1.7`) Syndesis: 1.7.3 Commit ID: ef7b10dfca7246c95ab685eeddc16d61f73e6d34</body>
		<created>2019-06-24 10:48:51</created>
		<closed>2019-07-01 13:39:20</closed>
	</bug>
	<bug>
		<id>5889</id>
		<title>[Box] "id" mapped from response is empty</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description After https://github.com/syndesisio/syndesis/pull/5723 there is a possibility to map `content`, `id`, `size` - however, the `id` is always empty.  Integration: `timer -&gt; box download -&gt; datamapper (combine content-id-size -&gt; task) -&gt; sql (insert into todo(task) values (:#task)`  The resulting record in todo app is `Hello integration!--18` - the id is empty </body>
		<created>2019-06-24 10:27:01</created>
		<closed>2019-08-19 15:07:07</closed>
	</bug>
	<bug>
		<id>5888</id>
		<title>Operator unable to start</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Seems like the changes merged in #5712 (on master) are causing issues with operator starting.  ``` $ docker run -it docker.io/syndesis/syndesis-operator ... Status: Downloaded newer image for syndesis/syndesis-operator:latest panic: could not find the root module directory  goroutine 1 [running]: github.com/syndesisio/syndesis/install/operator/pkg/build.init.0() /home/circleci/project/install/operator/pkg/build/pkg.go:45 +0x24d ```  @chirino can you take a look?</body>
		<created>2019-06-24 09:38:06</created>
		<closed>2019-07-26 20:10:10</closed>
	</bug>
	<bug>
		<id>5887</id>
		<title>Get operation in API provider with conditional flow results in white screen</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When creating new API provider (used petstore swagger json) - when I select one of the GET operations (POST, PUT and DELETE work OK) and select conditional flow step - the integration ends in white screen. See the attached recording.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlisting the acceptance criteria. --&gt; The UI shouldn't end in white screen - if this is not a valid use case, it should be handled in some more user friendly way.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![out](https://user-images.githubusercontent.com/4180208/60007068-e50fce80-9671-11e9-8d2e-fe4cc5c8b97e.gif)  The web console output:  ![Screenshot from 2019-06-24 11-17-29](https://user-images.githubusercontent.com/4180208/60007108-f78a0800-9671-11e9-8927-3fbfd8fe82f9.png)  ## Request and Response Data &lt;!-- Many issues involve both the UI and its backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create API provider (petstore.json) 2. Select one of the GET operations 3. Select Conditional flow as the middle step 4. Observe white screen </body>
		<created>2019-06-24 09:21:05</created>
		<closed>2019-07-02 11:28:49</closed>
	</bug>
	<bug>
		<id>5886</id>
		<title>Box icon in the integration summary not centered</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description It looks weird that the box icon is not in the center: ![image](https://user-images.githubusercontent.com/7081216/60000901-79bfff80-9665-11e9-8685-d64ca91d6ca5.png)  </body>
		<created>2019-06-24 07:50:43</created>
		<closed>2019-08-19 10:32:08</closed>
	</bug>
	<bug>
		<id>5885</id>
		<title>[UI] Tooltip close button selection overlaps with text + button not aligned</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11410**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When I click on some tooltip to get some help about the field, it comes with the "X" button selected and it overlaps with the text: ![screenshot-2019-06-24_09:41:41](https://user-images.githubusercontent.com/7081216/60000415-7710da80-9664-11e9-990b-9790ce60cb63.png)  Also the button is not aligned with the text ![screenshot-2019-06-24_09:44:09](https://user-images.githubusercontent.com/7081216/60000467-97409980-9664-11e9-860c-f3bc941cfcb2.png)  </body>
		<created>2019-06-24 07:44:23</created>
		<closed>2019-09-07 10:52:36</closed>
	</bug>
	<bug>
		<id>5883</id>
		<title>Replace of start/finish connection in integration - the old connection still showing up</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11411**  ## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When editing the start or finish connection in integration - the old connection, which is being updated is still showing, as you can see in the recording. The "clean" start/stop icon there would be much more intuitive (image attached).  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![out](https://user-images.githubusercontent.com/4180208/59997420-5729e880-965d-11e9-8a77-3820c25f0e50.gif)  ![Screenshot from 2019-06-24 08-51-00](https://user-images.githubusercontent.com/4180208/59997480-7aed2e80-965d-11e9-95e4-03c592c4e50f.png)   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create integration with start and stop connection 2. Select delete one of these connections 3. See that the old connection is still showing on the place of connection which is updated  </body>
		<created>2019-06-24 06:55:12</created>
		<closed>2019-09-07 10:52:44</closed>
	</bug>
	<bug>
		<id>5869</id>
		<title>Provide a description for the integration page</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Currently on the Integration page the heading has "This description has not yet been actually defined, please send help."  ![Screenshot_2019-06-21 Integrations - Syndesis](https://user-images.githubusercontent.com/1306050/59932984-bcf15700-9448-11e9-9d4e-e964629b2585.png)  I would mark this as `p0` as it is in a very prominent place and it's super embarrassing. What do you think @paoloantinori?  @TovaCohen @dongniwang can you advise on the text here, we can leave it blank if needed.</body>
		<created>2019-06-21 15:22:00</created>
		<closed>2019-06-21 21:27:55</closed>
	</bug>
	<bug>
		<id>5856</id>
		<title>Default name has to be changed to create a connection</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description ![image](https://user-images.githubusercontent.com/46345469/59905514-b93ce080-9406-11e9-81f2-920ec7b0de12.png) Default name is present, but it's not possible to create the connection using the default name, even when I remove one letter and type it again the button gets disabled again.  </body>
		<created>2019-06-21 07:28:13</created>
		<closed>2019-07-01 07:59:02</closed>
	</bug>
	<bug>
		<id>5855</id>
		<title>No way to specify security values when creating API connection</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Currently the API client requires only input for Host and Base path, but there is no way to specify what username &amp; password or api key to use. I don't remember clearly if there was another page in this process or everything was in the same form.  ![image](https://user-images.githubusercontent.com/46345469/59904523-0d929100-9404-11e9-82b0-c2d9ebbf1988.png)  Sample API specifications to try this out:  [todo.txt](https://github.com/syndesisio/syndesis/files/3313358/todo.txt) (basic http auth) [petstore-test.txt](https://github.com/syndesisio/syndesis/files/3313359/petstore-test.txt) (api key)   </body>
		<created>2019-06-21 07:10:04</created>
		<closed>2019-06-25 06:35:21</closed>
	</bug>
	<bug>
		<id>5835</id>
		<title>Import extension: "Something is wrong" dialog appears, extension not imported</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Customizations - Extensions - Import Extension Select an extension and this happens: ![importextension](https://user-images.githubusercontent.com/8707251/59842699-580a0400-9357-11e9-95b9-628489bda233.png)  No extension is imported when I check it on Extensions page. </body>
		<created>2019-06-20 10:32:56</created>
		<closed>2019-07-02 13:51:35</closed>
	</bug>
	<bug>
		<id>5832</id>
		<title>"Foreign" characters aren't logged correctly</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11412**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Encountered this behavior using Twitter connector, so it might be an issue of just that connector. I found that japanese characters are rendered as "?", but in the Openshift log they can be rendered correctly.  ## Screenshots ![image](https://user-images.githubusercontent.com/46345469/59827013-e2db0680-9337-11e9-93ad-eaf4e594af74.png) ![image](https://user-images.githubusercontent.com/46345469/59827053-f9815d80-9337-11e9-9b90-b5de83613ec3.png)  ## Steps to reproduce 1. Create a twitter connector 2. Start with search with query "from:nintendo" 3. End with log step </body>
		<created>2019-06-20 06:48:17</created>
		<closed>2019-09-07 10:52:51</closed>
	</bug>
	<bug>
		<id>5831</id>
		<title>[1.7.1] Unable to create any connection</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When trying to create any connection in the ui, the "configure connection" always ends with `Something is wrong` page:  ![screenshot-2019-06-20_08:31:37](https://user-images.githubusercontent.com/7081216/59826180-0c932e00-9336-11e9-8a73-72cd2372ba17.png) ![screenshot-2019-06-20_08:32:54](https://user-images.githubusercontent.com/7081216/59826181-0e5cf180-9336-11e9-8d70-1a9ff6da0564.png) ![screenshot-2019-06-20_08:33:17](https://user-images.githubusercontent.com/7081216/59826185-1026b500-9336-11e9-8f50-8373e7a0ff82.png)  </body>
		<created>2019-06-20 06:34:06</created>
		<closed>2019-06-24 07:44:39</closed>
	</bug>
	<bug>
		<id>5828</id>
		<title>Checking the tag causes that tag is duplicated</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I have created a tag in the Manage CI/CD view. When I want to check this tag on the particular integration, the duplicated tag is created.  ![output](https://user-images.githubusercontent.com/16251792/59783060-8fc56d00-92bf-11e9-96a0-aa392dfebeca.gif)  The PUT endpoint (and PATCH too) `...public/integrations/&lt;ID&gt;/tags` calls [tagForRelease](https://github.com/syndesisio/syndesis/blob/8cd2a418256c0b6b18144a940f2a217d398576cd/app/server/endpoint/src/main/java/io/syndesis/server/endpoint/v1/handler/external/PublicApiHandler.java#L338) function which creates the tag in the backend. When the endpoint for returns all tags is called `...public/environments`, it returns both tags, which is in the queue and in the backend.  So the tag should be deleted from in-memory cached when it is assigned to the integration (and returns there when no integration contains it) or the endpoint `/environments` should ignore the tags which have the same name and return they only once. </body>
		<created>2019-06-19 16:32:40</created>
		<closed>2019-06-21 09:50:11</closed>
	</bug>
	<bug>
		<id>5804</id>
		<title>Problem with privileges during installation</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The installation of Syndesis from the tag _1.8.1-20190618_ or _1.7.0_ doesn't work. `syndesis minishift --install --project syndesis --tag 1.8.1-20190618` `syndesis minishift --install --project syndesis --tag 1.7.0` All pods are terminating and creating in a loop. The operator contains lots of errors like: ``` {"level":"error","ts":1560864997.8587072,"logger":"kubebuilder.controller","msg":"Reconciler error","controller":"syndesis-controller","request":"syndesis/app","error":"roles.rbac.authorization.k8s.io \"syndesis-editor\" is forbidden: attempt to grant extra privileges: ... ``` The full log: [syndesis-operator-1-xh9gj.log](https://github.com/syndesisio/syndesis/files/3301721/syndesis-operator-1-xh9gj.log)  After some time, the pods look ready, however in the server is an issue: ``` 2019-06-18 13:47:13.319 ERROR [-,,,] 1 --- [ning]: pollPods] i.s.s.l.j.c.ActivityTrackingController   : Unexpected Error occurred. io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: GET at: https://kubernetes.default.svc/api/v1/namespaces/syndesis/pods?labelSelector=syndesis.io/component%3Dintegration . Message: Forbidden!Configured service account doesn't have access. Service account may have been revoked. pods is forbidden: User "system:serviceaccount:syndesis:syndesis-server" cannot list pods in the namespace "syndesis": no RBAC policy matched. at io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:472) ~[kubernetes-client-3.1.12.fuse-730022.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:409) ~[kubernetes-client-3.1.12.fuse-730022.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:381) ~[kubernetes-client-3.1.12.fuse-730022.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:344) ~[kubernetes-client-3.1.12.fuse-730022.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:328) ~[kubernetes-client-3.1.12.fuse-730022.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.BaseOperation.list(BaseOperation.java:584) ~[kubernetes-client-3.1.12.fuse-730022.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.BaseOperation.list(BaseOperation.java:49) ~[kubernetes-client-3.1.12.fuse-730022.jar!/:na] at io.syndesis.server.logging.jsondb.controller.ActivityTrackingController.listPods(ActivityTrackingController.java:327) ~[server-logging-jsondb-1.7.0.jar!/:1.7.0] at io.syndesis.server.logging.jsondb.controller.ActivityTrackingController.pollPods(ActivityTrackingController.java:271) ~[server-logging-jsondb-1.7.0.jar!/:1.7.0] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_151] at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) ~[na:1.8.0_151] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) ~[na:1.8.0_151] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) ~[na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_151] at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_151] ```  The symptoms look similar to https://github.com/syndesisio/syndesis/issues/4717  QE testing is blocked by this  </body>
		<created>2019-06-18 13:52:02</created>
		<closed>2019-06-19 15:46:17</closed>
	</bug>
	<bug>
		<id>5780</id>
		<title>EMail Send Connector generates unknown protocol error</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When creating an integration using a send-email connector, the metadata retrieval checks for the email protocol. However, since the protocol property is not yet available for send (as it is a configuredProperty only), an error is thrown: _'Email connector protocol cannot be identified. Unable to fetch and process metadata'_.  The EmailMetadata class does not provide any help to the integrations other than doing checks on the protocol. These checks, in turn, are no longer necessary since it is impossible to mix up the protocols due to there being separate connector for _send_ and _receive_.  </body>
		<created>2019-06-17 12:55:19</created>
		<closed>2019-08-21 10:07:35</closed>
	</bug>
	<bug>
		<id>5771</id>
		<title>No connections are displayed on master</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description It is currently not possible to create any integrations nor any new connections on the master branch.  This is what's displayed: ![image](https://user-images.githubusercontent.com/46345469/59585846-b5951b00-90e1-11e9-80b1-762b32528883.png)  I get this exception on the server pod: [syndesis-server-1.log](https://github.com/syndesisio/syndesis/files/3295651/syndesis-server-1.log) </body>
		<created>2019-06-17 07:25:08</created>
		<closed>2019-06-20 06:10:09</closed>
	</bug>
	<bug>
		<id>5766</id>
		<title>Choose a Connection title incorrectly appears: should be Choose a Step</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; On the staging site, I added the start and finish connections to a simple integration. So far I have this:  ![image](https://user-images.githubusercontent.com/25067106/59556686-a81e4a80-8f94-11e9-9d95-9775f1f88adf.png)  When I click the plus sign, I expect to get a page that prompts me to Choose a Step. But instead I get:   ![image](https://user-images.githubusercontent.com/25067106/59556693-d734bc00-8f94-11e9-888d-f6dcdb9a9969.png)  As you can see, it is prompting me to add the finish connection. But the finish connection is already in place.  This is the behavior no matter how many steps I already have in the simple integration.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlisting the acceptance criteria. --&gt;  There should be a "Choose a Step" page.   ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and its backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2019-06-15 21:44:05</created>
		<closed>2019-10-28 13:45:07</closed>
	</bug>
	<bug>
		<id>5763</id>
		<title>[ui] Connections are not updated after credentials are changed in Settings pane. </title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  User may update OAuth settings like Twitter API Key and Secret Key for various reasons, e.g. keys were regenerated in Twitter, a connection was imported from another Syndesis instance, so the keys in connection don't match what's in instance's OAuth configuration.   When user changes the secrets in Settings page, UI doesn't show a bulletin for updating the now stale connection. Importing a connection from another instance does show a warning in Connections page.   User edits connection and clicks on `Reconnect`, which goes through the OAuth flow, and validates new secrets from Settings. But, this never results in a Connection update on the backend, which still has the stale secrets. This can be verified by clicking on `Validate`, which fails due to an authentication error.   I am not entirely sure whether this is simply a UI issue where a call to update Connection is missing, or the OAuth flow is supposed to update the Connection on its own in the backend.   ## Expected Behavior  1. After user edits OAuth secrets in Settings page, affected Connections must show a warning that they need to reconnect.  2. After user reconnects in Connection Edit page, it should update the Connection in the backend with the updated secrets and updated OAuth tokens obtained from clicking `Reconnect`.  3. Clicking `Validate` should use updated Connection properties.   ## Steps to recreate issue  1. Create a Twitter app 2. Set secrets in Settings page 3. Create Twitter Connection 4. Re-generate new secrets in Twitter app 5. Update secrets in Settings page 6. Edit Twitter connection. `Reconnect` works, but `Validate` fails. </body>
		<created>2019-06-15 18:49:44</created>
		<closed>2019-07-03 13:58:23</closed>
	</bug>
	<bug>
		<id>5762</id>
		<title>[ui] [react] Salesforce connection validation is broken for username password connections</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  When creating a new Salesforce connection with a username and password, validation fails due to an empty `refreshToken` property being sent to the verifier endpoint.  This is also an issue for imported connections, where the stale imported `refreshToken` is sent to the verifier and fails.  Also, when saving the connection after updating secrets in an imported connection, only user provided properties should be saved, as any generated secrets like `refreshToken` need to be regenerated using user provided `password` and `clientSecret`.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlisting the acceptance criteria. --&gt; The backend generated property (not provided by user) should be removed when validating and saving a connection after other properties are updated by user.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; &lt;img width="1407" alt="Screen Shot 2019-06-14 at 9 20 52 PM" src="https://user-images.githubusercontent.com/181691/59546951-65ecfe80-8eeb-11e9-87ce-7aa31f2e432f.png"&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and its backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1.Create new Salesforce connection 2.Provide username, password, clientId and clientSecret 3.Click validate 4.See unparsed error on the top of the connection properties, see error response details in network pane of inspect window.  </body>
		<created>2019-06-15 04:31:17</created>
		<closed>2019-06-15 06:08:54</closed>
	</bug>
	<bug>
		<id>5754</id>
		<title>Trailing right arrow at end of breadcrumbs</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem There is an extra `&gt;` at the end of the breadcrumbs  ## Expected behavior Should be no `&gt;` after the last breadcrumb item  ## Screenshot &lt;img width="343" alt="Screen Shot 2019-06-14 at 12 09 24 PM" src="https://user-images.githubusercontent.com/35148959/59525985-6b235c80-8e9d-11e9-8254-6b394fe382db.png"&gt; &lt;img width="397" alt="Screen Shot 2019-06-14 at 12 09 17 PM" src="https://user-images.githubusercontent.com/35148959/59525986-6b235c80-8e9d-11e9-8b6e-fea8bd174f86.png"&gt; &lt;img width="396" alt="Screen Shot 2019-06-14 at 12 09 11 PM" src="https://user-images.githubusercontent.com/35148959/59525987-6b235c80-8e9d-11e9-9d33-37f620fc0f9e.png"&gt;  cc @syndesisio/uxd </body>
		<created>2019-06-14 17:11:03</created>
		<closed>2019-07-03 13:28:15</closed>
	</bug>
	<bug>
		<id>5746</id>
		<title>Mismatch in port labels in monitoring resources addons</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When importing the monitoring addon resources in ``install/addons``, the dashboards show up empty. This appears to be because there is a mismatch in the lables in monitoring addon resources.``metrics`` vs ``prometheus``  see: https://github.com/syndesisio/syndesis/blob/master/install/addons/syndesis-db-servicemonitor.yml#L14 and: https://github.com/syndesisio/fuse-online-install/blob/1.6.20/resources/fuse-online-template.yml#L718  As examples. </body>
		<created>2019-06-14 13:11:54</created>
		<closed>2019-06-20 14:55:42</closed>
	</bug>
	<bug>
		<id>5737</id>
		<title>Split not able to work with FTP connector</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Split step is not able to handle data coming from FTP connector. The FTP connector's outcome is a RemoteFile object and split step is not able to handle this in order to split the data.  Expected behavior: When FTP connector defines a collection JSON data shape the split should be able to handle that. </body>
		<created>2019-06-14 07:08:30</created>
		<closed>2019-12-01 15:33:48</closed>
	</bug>
	<bug>
		<id>5732</id>
		<title>[React-UI] base style management</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem Adding/removing a package that does the bulk of importing of third-party styling libs (syndesis/ui) in another sub-package changes the order in which styles are injected into the DOM for the app as a whole. So at the moment, the problem looks like the pf4 reset is coming after all the other styles. Seems like the app's base styles shouldn't be impacted by changes like this.  The problem is compounded by the fact that patternfly's react-core automatically injects every component stylesheet into the DOM regardless of it being used or not. Not a problem in production builds, but it's quite painful in dev mode when trying to debug styling issues.  I suppose I'm maybe making a case for introducing a null-loader to prevent packages from importing the pf4 react-core styles automatically just because they want to use one of the PF4 react components, and instead loading all the component/utility/layout styles directly from core. We could do this from the ui package only, and that way other sub packages could be dependent on it or not and in theory it wouldn't change anything about the styles  ## Expected behavior Making a package dependent or no longer dependent on another package shouldn't affect the cascade of the base ui styles.  ## Screenshot &lt;img width="1038" alt="Screen Shot 2019-06-13 at 11 27 00 AM" src="https://user-images.githubusercontent.com/5942899/59457180-f0e3d100-8de5-11e9-8503-fc139d3ed621.png"&gt;    </body>
		<created>2019-06-13 18:24:01</created>
		<closed>2019-06-17 17:29:25</closed>
	</bug>
	<bug>
		<id>5729</id>
		<title>Invalid date as Last Processed value in the Metric tab</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When the integration has not been triggered yet, the Last Processed card in the Metrics tab contains 'Invalid date'. In the old UI, it contains 'n/a'. In my POV, 'Invalid data' value can be confusing for the user. There should be something like "No triggered yet" or something like that.  ![image](https://user-images.githubusercontent.com/16251792/59437084-29d57300-8df1-11e9-9cad-a1aee2c3123b.png) </body>
		<created>2019-06-13 13:43:21</created>
		<closed>2019-07-10 12:04:06</closed>
	</bug>
	<bug>
		<id>5721</id>
		<title>Missing space in the ErrorsFound label</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When the integration activity contains error, the Errors found label is displayed however space is missing. ![image](https://user-images.githubusercontent.com/16251792/59419717-c1c06600-8dcb-11e9-8736-cd48a42098c7.png)  </body>
		<created>2019-06-13 09:10:29</created>
		<closed>2019-08-12 12:51:49</closed>
	</bug>
	<bug>
		<id>5720</id>
		<title>[About page] Accessing about page when creating integration breaks syndesis</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Accessing about page when creating integration breaks syndesis:  ![out](https://user-images.githubusercontent.com/14313995/59419466-4bbbff00-8dcb-11e9-83fe-be1e7a7ee011.gif)   </body>
		<created>2019-06-13 09:07:16</created>
		<closed>2019-06-26 12:34:48</closed>
	</bug>
	<bug>
		<id>5716</id>
		<title>[Conditional flow] It is not possible to add conditional flow step after split step</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Adding conditional flow step after split step results in `Done` button doing nothing and an error in console: `Error: Cannot create conditional flow for a step with no ID set`.   ![screenshot_20190613_101918](https://user-images.githubusercontent.com/14313995/59415918-bb7abb80-8dc4-11e9-9798-476bc4152bb8.png)  </body>
		<created>2019-06-13 08:21:06</created>
		<closed>2019-06-26 12:42:51</closed>
	</bug>
	<bug>
		<id>5715</id>
		<title>NaN duration in the activity log</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The Advanced Filter and Basic Filter have _NaN_ Duration in the activity log. ![image](https://user-images.githubusercontent.com/16251792/59415116-27f4bb00-8dc3-11e9-94fb-1f8c649de33c.png) The back-end returns _0_ as a duration: ![image](https://user-images.githubusercontent.com/16251792/59415344-933e8d00-8dc3-11e9-88b0-964ae678d3a3.png) </body>
		<created>2019-06-13 08:09:18</created>
		<closed>2019-06-25 12:22:49</closed>
	</bug>
	<bug>
		<id>5714</id>
		<title>[UI] Don't require click on the tooltip to display it</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Currently when there is a tooltip in the UI, user needs to click on the "?" icon to display the tooltip. It would be better to display the tooltip on hover action ![out](https://user-images.githubusercontent.com/7081216/59414035-127e9180-8dc1-11e9-96a4-5b91af93a5d4.gif)   </body>
		<created>2019-06-13 07:54:22</created>
		<closed>2019-06-27 13:47:52</closed>
	</bug>
	<bug>
		<id>5704</id>
		<title>Add Technology Preview label for Amazon SQS, SNS, BOX, KNative connectors</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Add Technology Preview label for Amazon SQS, SNS, BOX, KNative connectors - these should be marked as TP for this release.</body>
		<created>2019-06-12 14:49:52</created>
		<closed>2019-06-15 10:07:53</closed>
	</bug>
	<bug>
		<id>5702</id>
		<title>not equals condition cannot be chosen in the Basic Filter</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description In the Basic Filter, when I choose `not equals`, the `equals` condition is chosen. ![output](https://user-images.githubusercontent.com/16251792/59356215-b9fbb580-8d28-11e9-8173-6e6e9409aacf.gif) </body>
		<created>2019-06-12 13:43:32</created>
		<closed>2019-06-24 06:55:29</closed>
	</bug>
	<bug>
		<id>5701</id>
		<title>Basic Filter cannot continue with a predefined condition</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Basic Filter has predefined `equals` condition. When I fill in values to the Basic Filter step, the Done button is still disabled. I have to choose another condition and set equals back. ![output](https://user-images.githubusercontent.com/16251792/59355818-fda1ef80-8d27-11e9-8f5e-75ecccedee67.gif)   </body>
		<created>2019-06-12 13:40:16</created>
		<closed>2019-06-13 11:52:06</closed>
	</bug>
	<bug>
		<id>5697</id>
		<title>API provider definition can't be edited after creating the integration</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description After creating an API provider integration, the definition cannot be changed. Any changes made are just ignored. This blocks me to verify #5332 because nothing can be reflected in the UI since nothing can be changed.  ![Peek 2019-06-12 14-31](https://user-images.githubusercontent.com/46345469/59351570-fcb89000-8d1e-11e9-8b51-0432ddebddc9.gif)  </body>
		<created>2019-06-12 12:39:03</created>
		<closed>2019-07-10 14:54:11</closed>
	</bug>
	<bug>
		<id>5693</id>
		<title>Errors in integrations cause the activity page to be misaligned</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11413**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The image speaks for itself:  ![image](https://user-images.githubusercontent.com/46345469/59346064-bf013a80-8d11-11e9-83e4-0881078eb93e.png)  </body>
		<created>2019-06-12 10:59:09</created>
		<closed>2019-09-07 10:52:58</closed>
	</bug>
	<bug>
		<id>5692</id>
		<title>[camel-k] API provider displays URL with https but the default route is just http</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11414**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The API provider displays URL where the integration is reachable, but the route is created using HTTP not HTTPS which causes most requests to that displayed URL to the `Application is not available` page, but when I use the URL with just http, it works fine.  ![Peek 2019-06-12 12-52](https://user-images.githubusercontent.com/46345469/59345727-0affaf80-8d11-11e9-88c7-aafdb896492f.gif) </body>
		<created>2019-06-12 10:53:20</created>
		<closed>2019-09-07 10:53:13</closed>
	</bug>
	<bug>
		<id>5691</id>
		<title>[Conditional flow] rewriting the condition breaks flow dropdown</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Rewriting the condition creates duplicates in flow dropdown:  ![out](https://user-images.githubusercontent.com/14313995/59345460-68473100-8d10-11e9-87c4-c5b763300566.gif)    </body>
		<created>2019-06-12 10:49:54</created>
		<closed>2019-06-12 17:06:04</closed>
	</bug>
	<bug>
		<id>5690</id>
		<title>DB procedure name changed to text input instead of dropdown</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description In angular the procedure name input was a dropdown that offered all available procedures within the DB. Now it's just a text input, which is more inconvenient for users to fill in and is quite error prone.  ![image](https://user-images.githubusercontent.com/46345469/59343208-9bd38c80-8d0b-11e9-9134-63d859e6f5a0.png)  </body>
		<created>2019-06-12 10:14:32</created>
		<closed>2019-08-06 12:41:30</closed>
	</bug>
	<bug>
		<id>5689</id>
		<title>Property descriptions missing</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  From #4878, we seem to be missing property descriptions in the React UI, i.e. it seems that this:  https://github.com/syndesisio/syndesis/blob/25f4d4759b7828682752f9f6774d25f57033bbd9/app/connector/sql/src/main/resources/META-INF/syndesis/connector/sql.json#L61  is not shown in the UI.</body>
		<created>2019-06-12 08:50:31</created>
		<closed>2019-07-25 18:04:39</closed>
	</bug>
	<bug>
		<id>5686</id>
		<title>SQL statement contains text from the previous step</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11415**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Every time when I add Database step before another Database step, the Invoke SQL is predefined according to the existing Database step.  When I want to create DB step for Invoke SQL, and I have already defined another Invoke SQL step which is before that step, the SQL statement is automatically predefined and it is same as SQL statement in the step which was defined before. ![output](https://user-images.githubusercontent.com/16251792/59333247-3de97980-8cf8-11e9-96b1-5196bcdc0db2.gif) When I add another step between them, e.g. log step, the SQL statement is empty. ![output](https://user-images.githubusercontent.com/16251792/59333272-49d53b80-8cf8-11e9-9d15-4212065484e7.gif) </body>
		<created>2019-06-12 08:02:07</created>
		<closed>2019-09-07 10:53:22</closed>
	</bug>
	<bug>
		<id>5679</id>
		<title>[camel-k] All integrations create a route for themselves </title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description All integrations created in Syndesis using camel-k create a route for themselves and display this route in integration details. The route leads nowhere and is quite confusing as to what I as a user should be using that route for.  ![image](https://user-images.githubusercontent.com/46345469/59278000-7c802500-8c61-11e9-8737-9a1a8be6d6c0.png)  The route is created in Openshift as well, with Openshift informing the user that the target pod is http but the route has no port with that name. </body>
		<created>2019-06-11 13:57:51</created>
		<closed>2019-08-08 13:11:15</closed>
	</bug>
	<bug>
		<id>5678</id>
		<title>Atlasmap doesn't save configured mappings </title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I am able to create a mapping inside atlasmap but it doesn't save. Trying to get more information if it's only camel-k behavior or happens even on "normal" version.  This GIF describes the issue better then I could:  ![Peek 2019-06-11 15-36](https://user-images.githubusercontent.com/46345469/59277448-86edef00-8c60-11e9-9873-07f348f055a9.gif)  No traceable logs found in server neither in browser console.</body>
		<created>2019-06-11 13:52:53</created>
		<closed>2019-07-01 07:57:35</closed>
	</bug>
	<bug>
		<id>5677</id>
		<title>[camel-k] kamel install command uses wrong repository for camel-k image</title>
		<body>Placeholder for https://issues.jboss.org/browse/ENTESB-10531</body>
		<created>2019-06-11 13:31:46</created>
		<closed>2019-09-22 14:33:15</closed>
	</bug>
	<bug>
		<id>5676</id>
		<title>[Conditional flow] Condition manipulation icons are broken</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The behavior is unpredictable:  ![out](https://user-images.githubusercontent.com/14313995/59273508-aa14a080-8c58-11e9-8e13-1b33fe695203.gif)  ![out](https://user-images.githubusercontent.com/14313995/59273562-c87a9c00-8c58-11e9-828a-4b52e80d7e0a.gif)  ![out](https://user-images.githubusercontent.com/14313995/59273619-ecd67880-8c58-11e9-8c9a-e6611bace2b9.gif)    </body>
		<created>2019-06-11 12:56:37</created>
		<closed>2019-06-13 15:42:00</closed>
	</bug>
	<bug>
		<id>5670</id>
		<title>[api client connector] specify security block is not centered correctly</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description ![screenshot_20190611_132057](https://user-images.githubusercontent.com/14313995/59268097-471d0c80-8c4c-11e9-8f75-95c95a1e5196.png)  Edit: Also the radio element is not aligned with the label.   </body>
		<created>2019-06-11 11:26:41</created>
		<closed>2019-09-07 10:54:18</closed>
	</bug>
	<bug>
		<id>5669</id>
		<title>[api client connector] basic authentication does not work</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Basic authentication is selected by default but `Next` button is disabled:  ![screenshot_20190611_132057](https://user-images.githubusercontent.com/14313995/59267952-d544c300-8c4b-11e9-9071-b4ff0fe823c1.png)   Adding two Basic authentication options is broken - it has the same name, selecting them does not work - the same bug as above:  ![screenshot_20190611_132220](https://user-images.githubusercontent.com/14313995/59268021-11782380-8c4c-11e9-83ab-9695ea61f2c6.png)  </body>
		<created>2019-06-11 11:23:46</created>
		<closed>2019-06-24 13:05:17</closed>
	</bug>
	<bug>
		<id>5668</id>
		<title>[api client connector] swagger file name reaches out of frame</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11417**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description After uploading swagger in api client connectors, the name reaches out of the frame:  ![screenshot_20190611_131521](https://user-images.githubusercontent.com/14313995/59267710-2dc79080-8c4b-11e9-850c-f2e678edf7cd.png)  </body>
		<created>2019-06-11 11:19:23</created>
		<closed>2019-09-07 10:58:33</closed>
	</bug>
	<bug>
		<id>5661</id>
		<title>Pause icon can't be "played"</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ x] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  We have a cool pause icon, but you cant start the integration by clicking "play"  ![image](https://user-images.githubusercontent.com/674767/59206043-17013b00-8b72-11e9-9fe0-8243c7e6b4a5.png) </body>
		<created>2019-06-10 15:22:56</created>
		<closed>2019-06-14 15:10:16</closed>
	</bug>
	<bug>
		<id>5657</id>
		<title>Remove Tech Preview banner from OData and FHIR connector cards</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description In 7.4, the FHIR and OData connectors are supported. But in the staging and staging-2 sites, the cards for these connectors still display a Technology Preview banner:   ![image](https://user-images.githubusercontent.com/25067106/59203414-8b38e000-8b6c-11e9-8b46-07b96aa5d67b.png)   </body>
		<created>2019-06-10 14:43:27</created>
		<closed>2019-06-13 16:00:07</closed>
	</bug>
	<bug>
		<id>5652</id>
		<title>Datamapper to Template step leads to blank screen</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Whenever I try to create a mapping to template step the whole page goes white and reports this error in console:   ``` Error: "output document shape kind not supported"     m utils.ts:184     pr utils.ts:160     render utils.js:753     React 8          render          La          qi          Yi          jc          zc          Ac          En react-dom.production.min.js:4408 Error: "output document shape kind not supported"     m utils.ts:184     pr utils.ts:160     render utils.js:753     React 8 react-dom.production.min.js:4408 Error: output document shape kind not supported utils.ts:184:10     m utils.ts:184     pr utils.ts:160     render utils.js:753     React 8     En (index):1019 ``` </body>
		<created>2019-06-10 09:48:02</created>
		<closed>2019-06-18 12:04:45</closed>
	</bug>
	<bug>
		<id>5651</id>
		<title>[react-ui] CodeMirror doesn't highlight syntax</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The CodeMirror text editor stopped highlighting syntax for the template editor after the switch to react ui.  Angular: ![image](https://user-images.githubusercontent.com/46345469/59183734-e2d74b80-8b6c-11e9-9ca3-367ce37f298e.png) React: ![image](https://user-images.githubusercontent.com/46345469/59183759-f2ef2b00-8b6c-11e9-961c-230056dcbd43.png)  </body>
		<created>2019-06-10 08:46:22</created>
		<closed>2019-06-18 12:02:46</closed>
	</bug>
	<bug>
		<id>5649</id>
		<title>CodeMirror editor resets cursor position</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description While editing text inside the CodeMirror text editor and try to move somewhere else, you can only write one character and then the cursor is moved at the end of the text. Which makes editing files quite difficult.  GIF showing current behavior: ![Peek 2019-06-10 10-33](https://user-images.githubusercontent.com/46345469/59183055-8b84ab80-8b6b-11e9-868c-c690a43e6a8b.gif) </body>
		<created>2019-06-10 08:36:08</created>
		<closed>2019-06-18 12:03:19</closed>
	</bug>
	<bug>
		<id>5647</id>
		<title>Mapping from JSON broke</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [*] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Trying to run this quickstart https://github.com/syndesisio/syndesis-quickstarts/tree/master/webhook-2-db   reveals 2 issues: 1. The mapping from task -&gt; task does no longer work   curl -k --header "Content-Type: application/json" --request POST --data '{ "task":"my new task!"}' $externalURL org.apache.camel.RuntimeExchangeException: Cannot find key [task] in message body or headers to use when setting named parameter in query [INSERT INTO TODO (task) VALUES (:?task)] on the exchange: Exchange[i-Lgn8J2vEYFPQxsgGnKAz]  2. The externalUrl field no longer shows up after publishing.   </body>
		<created>2019-06-07 18:20:42</created>
		<closed>2019-08-07 08:31:50</closed>
	</bug>
	<bug>
		<id>5628</id>
		<title>Metrics tag shows Invalid Date</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11570**  ## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ![image](https://user-images.githubusercontent.com/674767/59058391-87eedd00-886a-11e9-8b29-4e177e7935fd.png)  </body>
		<created>2019-06-06 18:51:36</created>
		<closed>2019-09-07 12:47:26</closed>
	</bug>
	<bug>
		<id>5627</id>
		<title> API Provider operation list alignment</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  When you implement a flow in API provide the alignment on that operation is off  ![image](https://user-images.githubusercontent.com/674767/59057858-5c1f2780-8869-11e9-9345-79a9fbb532c9.png)  </body>
		<created>2019-06-06 18:43:16</created>
		<closed>2019-08-19 08:03:55</closed>
	</bug>
	<bug>
		<id>5626</id>
		<title>404 when click on "Define the data type" warning link</title>
		<body>&lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  Steps to reproduce: 1. create a twitter connection 2. create a ftp connection 3. create an integration 3.1 add the ftp connection / Download. Finish with the twitter connection / Send a direct message (type any value in the form)   The integration steps are displayed, the twitter step shows a warning icon, click on it to open the data mapping window  ![1_actions](https://user-images.githubusercontent.com/836543/59053919-e74bed80-8868-11e9-981c-d4b0442f9c39.png)  It shows this error page  ![2_fail_404](https://user-images.githubusercontent.com/836543/59053918-e74bed80-8868-11e9-99aa-4b451b011037.png)   </body>
		<created>2019-06-06 17:45:27</created>
		<closed>2019-08-22 09:01:42</closed>
	</bug>
	<bug>
		<id>5622</id>
		<title>Atlas Map step fails to load in some cases</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Trying to add a data mapper step between a `Get a specific Event` and `Create Event`, an error message is shown instead of the data mapper ui:  `Data Mapper UI Initialization Error: Could not load Maven class path: undefined undefined`  ![2019-06-06-133925_sel_grim](https://user-images.githubusercontent.com/9480152/59030610-bc11d000-8861-11e9-8474-60d4b7176ae1.png)  ## Steps to reproduce: 1. Start step: timer 2. Finish step: Create Event 3. Add a Get a specific Event in between 4. Try to add a data mapper step between the two google calendar steps </body>
		<created>2019-06-06 11:50:25</created>
		<closed>2019-07-02 11:46:50</closed>
	</bug>
	<bug>
		<id>5619</id>
		<title>No confirmation dialog shows up when leaving the integration</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11418**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When leaving the integration creation process, there was a confirmation dialog displayed if user really wants to leave the process. Now it just allows them to leave without any second confirmation, which can lead to losing WIP integrations.  </body>
		<created>2019-06-06 10:27:58</created>
		<closed>2019-09-07 11:03:21</closed>
	</bug>
	<bug>
		<id>5615</id>
		<title>API key option of security does not enable next button</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When using an API client with API key option, it is not possible to create such customization because the next button is not enabled in `Specify security`.  ![image](https://user-images.githubusercontent.com/46345469/58966514-b7daa980-87b2-11e9-85b4-ed4b8adadf3c.png)  ## Steps to reproduce 1. import API client [petstore-test.txt](https://github.com/syndesisio/syndesis/files/3260376/petstore-test.txt) (change the file extension to json, github doesn't allow to upload json files) 2. click on the next button and try to choose API key option   </body>
		<created>2019-06-06 07:18:54</created>
		<closed>2019-06-20 06:57:24</closed>
	</bug>
	<bug>
		<id>5612</id>
		<title>page not loading - edit an integration </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  Editing an integration to add a step: brings you to a page that flickers but doesn't load  ![flickering adding step](https://user-images.githubusercontent.com/674767/58967580-729e8380-8782-11e9-9b42-5d2900d96b89.gif)  load</body>
		<created>2019-06-05 15:10:52</created>
		<closed>2019-06-06 07:40:37</closed>
	</bug>
	<bug>
		<id>5608</id>
		<title>[Conditional flow] flows are still accessible after deleting the step</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The flow dropdown shows flows from the most recently added conditional step, which causes that the user is able to access unusable flows.  ## Steps to reproduce 1. create a simple integration 2. add conditional step and create a few conditions  3. delete the conditional step 4. look at the flows dropdown, there are still the *should be* deleted steps  ## Screenshot ![Peek 2019-06-05 16-10](https://user-images.githubusercontent.com/46345469/58962919-7941f080-87ac-11e9-9d1f-f0e6b0e19361.gif) </body>
		<created>2019-06-05 14:15:37</created>
		<closed>2019-06-08 05:47:47</closed>
	</bug>
	<bug>
		<id>5607</id>
		<title>Unify name of template</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [x] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The template step currently is currently referred to as `template` and `templater`. "Normal user" might not even notice it, but it could be a problem while dealing with localization.  ## Screenshots In one picture you can see that in `Add to integration` it's templater, in `Upload template` it's template.  ![image](https://user-images.githubusercontent.com/46345469/58961124-cf149980-87a8-11e9-9a0a-5282c3817cf5.png) ![image](https://user-images.githubusercontent.com/46345469/58961493-87dad880-87a9-11e9-9aa4-68002e1ff6cd.png)  </body>
		<created>2019-06-05 13:55:16</created>
		<closed>2019-08-19 07:49:14</closed>
	</bug>
	<bug>
		<id>5604</id>
		<title>Advanced filter expression is not saving</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The advanced filter step is not saving the expression, or every time the user clicks on configure of that step, the expression is cleared.  Steps to reproduce: 1. start creating an integration 2. start step can be timer 3. finish step can be log 4. add advanced filter between timer and log 5. write some expression in the textarea and click on done 6. click on the configure button of advanced filter  If this is caused because the user inputs nonsense, it should be handled by error messages. Also I am curious if it's intended behavior to have advanced filter available even though there is no data in the integration I am using to describe the bug.</body>
		<created>2019-06-05 13:23:30</created>
		<closed>2019-09-07 11:04:37</closed>
	</bug>
	<bug>
		<id>5603</id>
		<title>SQL connector cannot access the sampledb tables</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Trying a simple `SELECT * FROM todo` in the SQL step fails with `Table 'TODO' does not exist. Unable to fetch and process metadata`. This is most likely a result of #5591 , though changing the query to `SELECT * FROM sampledb.todo` does not work either.  The table in the database is indeed in the `sampledb` schema:  ``` postgres=# \c sampledb You are now connected to database "sampledb" as user "postgres". sampledb=# \dt                          No relations found. sampledb=# set search_path to sampledb; SET sampledb=# \dt            List of relations   Schema  |   Name   | Type  |  Owner    ----------+----------+-------+----------  sampledb | contact  | table | sampledb  sampledb | todo     | table | sampledb  sampledb | winelist | table | sampledb (3 rows) ```</body>
		<created>2019-06-05 13:14:50</created>
		<closed>2019-07-02 10:15:49</closed>
	</bug>
	<bug>
		<id>5602</id>
		<title>Trouble logging into a redeployed syndesis</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When I have a syndesis instance deployed in minishift, log in to it, then delete the whole project and create a new one, I get a bunch of different errors when trying to log into syndesis. Not sure what exactly fixes it, some combination of ctrl+f5, clearing the site data and opening a new tab.  ## Steps to reproduce 1. create a new project in minishift 2. deploy syndesis into it 3. log into syndesis 4. delete the project 5. create the project again 6. deploy syndesis 7. try logging in again  Please note that I'm NOT clicking on the `Report the issue` button in the following video, I just happen to move my mouse there when hitting ctrl+f5.  ![syndesis-login](https://user-images.githubusercontent.com/9480152/58958400-1dbf3500-87a3-11e9-8f84-39d1b76bf722.gif)  </body>
		<created>2019-06-05 13:06:30</created>
		<closed>2019-07-01 07:17:34</closed>
	</bug>
	<bug>
		<id>5600</id>
		<title>Confusing flow when editing OpenAPI definition of API provider integration</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When trying cancelling view/edit API definition UI asks to upload the OpenAPI specification when cancelling that UI asks for a start connection.  I should return to the screen from which I clicked on view/edit API definition directly without these two additional screens.  ![Peek 2019-06-05 12-50](https://user-images.githubusercontent.com/1306050/58951258-e9db1400-8790-11e9-9f83-34698b063fdf.gif)  </body>
		<created>2019-06-05 10:54:05</created>
		<closed>2019-06-12 17:59:01</closed>
	</bug>
	<bug>
		<id>5599</id>
		<title>Review OData &amp; Email Connectors to tighten up property analysis</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description A number of issues have come to light in how these connectors deal with properties transmitted from the UI: - Use of hidden properties to pass in configured values - Disparities between properties set as optional and expected in verifiers - It was assumed with the angular-ui that empty properties would not appear once delivered server-side. This is no longer the case and connector should tighten up checking for such properties.  see discussions at - #5560  - #5559   </body>
		<created>2019-06-05 10:27:03</created>
		<closed>2019-07-08 08:06:21</closed>
	</bug>
	<bug>
		<id>5593</id>
		<title>In Safari the connector grid page keeps jumping upwards when trying to scroll down</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [*] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description In Safari the connector grid page keeps jumping upwards when trying to scroll down. Works ok in Chrome. </body>
		<created>2019-06-04 18:31:04</created>
		<closed>2019-09-18 12:52:29</closed>
	</bug>
	<bug>
		<id>5583</id>
		<title>Configuring a connection in integration causes white screen</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11420**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When editing an integration and clicking on configure button of some used connection usually displays just white screen to user:  GIF: ![Peek 2019-06-04 14-38](https://user-images.githubusercontent.com/46345469/58879696-84c2e800-86d6-11e9-806e-76154ec8d577.gif)  </body>
		<created>2019-06-04 12:39:44</created>
		<closed>2019-09-07 11:18:06</closed>
	</bug>
	<bug>
		<id>5579</id>
		<title>Data Mapper conditional mapping alert showing behind source table</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  When I create an integration including data mapper and try to click on the `enable/disable conditional mapping expression` with no previously created mappings, there appears an alert with message `Please select a mapping first`. BUT this alert is hiding behind the `source` table.  ![data_mapper_warning](https://user-images.githubusercontent.com/46523434/58870167-f2afe500-86bf-11e9-9243-63bb1f8b6f78.png) </body>
		<created>2019-06-04 10:51:03</created>
		<closed>2019-08-08 08:38:59</closed>
	</bug>
	<bug>
		<id>5578</id>
		<title>User isn't redirected after deleting integration from integration detail</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11421**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description After deleting an integration inside integration detail, the user is not redirected to the integration list and sees an error message.  ![image](https://user-images.githubusercontent.com/46345469/58872080-89ca6c00-86c3-11e9-97af-2c1f7503db62.png)  </body>
		<created>2019-06-04 10:23:48</created>
		<closed>2019-09-07 11:18:18</closed>
	</bug>
	<bug>
		<id>5575</id>
		<title>WebHook doesn't contain route url</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description In ReactUI, the WebHook doesn't contain external url as before. In this case, the users are not able to see (in UI) a route where the webhook is. They have to go to the OpenShift console -&gt; project -&gt; routes.  ![image](https://user-images.githubusercontent.com/16251792/58862348-cb9de700-86b0-11e9-8151-ce25cf5a98ec.png)  </body>
		<created>2019-06-04 08:10:43</created>
		<closed>2019-06-07 16:32:03</closed>
	</bug>
	<bug>
		<id>5573</id>
		<title>Logout not redirecting to login page</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ x ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; The logout does not redirect the user to the login page.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![out](https://user-images.githubusercontent.com/4180208/58859677-ab6b2980-86aa-11e9-83ec-11b0cae63f75.gif)   ## Request and Response Data &lt;!-- Many issues involve both the UI and its backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Click logout 2. the user appears to be logged out, however can still navigate in the UI 3.  4. </body>
		<created>2019-06-04 07:26:36</created>
		<closed>2019-06-11 09:55:31</closed>
	</bug>
	<bug>
		<id>5572</id>
		<title>Unnecessary parameters prevent creating google connections </title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description In google connectors appeared parameters like Authorization URL (2x!) and Token URL that are marked as required and block creating connetions:  ![screenshot_20190604_085236](https://user-images.githubusercontent.com/6814482/58857949-b754ec80-86a6-11e9-8c02-a3aa651e5ad9.png)  Old UI:  ![screenshot_20190604_085421](https://user-images.githubusercontent.com/6814482/58857952-b91eb000-86a6-11e9-92d2-0395bb277839.png)  I'd like to meniton that this is blocking our smoke tests, because we are validating all of our credentials there. </body>
		<created>2019-06-04 06:58:52</created>
		<closed>2019-06-04 12:16:47</closed>
	</bug>
	<bug>
		<id>5566</id>
		<title>Validate button is disabled in API connector</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The `validate` button is disabled no matter what field I change. And the next button is disabled as well, I figured that it probably gets enabled when the connector is validated.   Steps to reproduce: 1. import API client specification ([https://petstore.swagger.io/v2/swagger.json](https://petstore.swagger.io/v2/swagger.json)) 2. go into connections and try to create that connector 3.  ![image](https://user-images.githubusercontent.com/46345469/58807775-05231380-8619-11e9-9e4c-12ca5557c098.png)  </body>
		<created>2019-06-03 14:02:51</created>
		<closed>2019-06-06 08:35:19</closed>
	</bug>
	<bug>
		<id>5565</id>
		<title>Integration Editor does not propagate ids correctly - Missing names of some steps in the Activity log</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description In the activity log, the name of the log step and data mapper is **n/a**. What is worse, the log step also doesn't show any output in the activity log. E.g. I have this integration with steps DB-&gt;LOG-&gt;DATA MAPPER-&gt;LOG-&gt;DB ![image](https://user-images.githubusercontent.com/16251792/58874812-137d3800-86ca-11e9-991e-33e299ca62d4.png) The activity log: ![image](https://user-images.githubusercontent.com/16251792/58874999-a027f600-86ca-11e9-9eac-9a982c834bdb.png)  </body>
		<created>2019-06-03 13:19:24</created>
		<closed>2019-06-04 15:04:27</closed>
	</bug>
	<bug>
		<id>5563</id>
		<title>OData connector details displays a password that hasn't been set</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11422**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  When I create and OData connector (basic, using https://services.odata.org/TripPinRESTierService/ as always, not setting any username, password or server certificate) and then go to connectors details, there is a pretty long password fetched from the backend. When I try to edit the connector, delete the password, save it and re-edit again, the passowrd appears again. (not sure if this can be somehow connected to the validation error reported in [#5559](https://github.com/syndesisio/syndesis/issues/5559), but tried not to validate the service at all and the issue is still present). Can't figure out where this password comes from. </body>
		<created>2019-06-03 12:53:30</created>
		<closed>2019-09-07 11:18:30</closed>
	</bug>
	<bug>
		<id>5560</id>
		<title>unable to create email connection in the new ui</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11423**  ## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; In the new react UI, there are problems with email connectors: When creating a new email connection, if it's a `send email`, then the `Validate` button does not get enabled and is impossible to click, making it impossible to finish connection creation. When creating a `receive email` connection, during the validation an empty red rectangle is drawn, and validation also gets failed.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlisting the acceptance criteria. --&gt; It's possible to both validate and create both types of email connections.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![image](https://user-images.githubusercontent.com/3992240/58799596-0860d400-8606-11e9-9542-6782fad11b09.png) </body>
		<created>2019-06-03 11:45:18</created>
		<closed>2019-09-07 11:18:41</closed>
	</bug>
	<bug>
		<id>5556</id>
		<title>Some integrations might not have `tags`</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Encountered this on the Angular app:  ``` TypeError: "e.tags is undefined"     c main.92dfe73cca4a82a65801.js:32609     list main.92dfe73cca4a82a65801.js:83792     _next polyfills.cd1c6ed959cbc1c630d4.js:1     next polyfills.cd1c6ed959cbc1c630d4.js:1     _next polyfills.cd1c6ed959cbc1c630d4.js:1     next polyfills.cd1c6ed959cbc1c630d4.js:1     _next polyfills.cd1c6ed959cbc1c630d4.js:1     next polyfills.cd1c6ed959cbc1c630d4.js:1     _next polyfills.cd1c6ed959cbc1c630d4.js:1     next polyfills.cd1c6ed959cbc1c630d4.js:1     notifyNext main.92dfe73cca4a82a65801.js:120633     _next main.92dfe73cca4a82a65801.js:121824     next polyfills.cd1c6ed959cbc1c630d4.js:1     _next polyfills.cd1c6ed959cbc1c630d4.js:1     next polyfills.cd1c6ed959cbc1c630d4.js:1     _next main.92dfe73cca4a82a65801.js:130013     next polyfills.cd1c6ed959cbc1c630d4.js:1     u main.92dfe73cca4a82a65801.js:123825     invokeTask polyfills.cd1c6ed959cbc1c630d4.js:1     onInvokeTask main.92dfe73cca4a82a65801.js:21984     invokeTask polyfills.cd1c6ed959cbc1c630d4.js:1     runTask polyfills.cd1c6ed959cbc1c630d4.js:1     invokeTask polyfills.cd1c6ed959cbc1c630d4.js:1     b polyfills.cd1c6ed959cbc1c630d4.js:1     _ polyfills.cd1c6ed959cbc1c630d4.js:1 main.92dfe73cca4a82a65801.js:formatted:141141 ```  I think here we need to check if `integration.tags` is not `null`:  https://github.com/syndesisio/syndesis/blob/8fad0602f5f968861a5ed292f956f53d6e65b296/app/ui-angular/src/app/store/integration/integration.service.ts#L33</body>
		<created>2019-06-03 10:49:02</created>
		<closed>2019-06-12 17:19:21</closed>
	</bug>
	<bug>
		<id>5555</id>
		<title>[Conditional Flow] breaks API provider activity logging</title>
		<body>Once API Provider integrations use conditional flows step the activity logging is not working anymore for that integration. The activity log is completely empty</body>
		<created>2019-06-03 10:33:50</created>
		<closed>2019-06-03 14:28:33</closed>
	</bug>
	<bug>
		<id>5553</id>
		<title>Integration name  is not unique</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Staging 2 is currently in a state where there are 2 integrations with the same name:  `Integration name 'timer_to_log' is not unique`  This is reported as an error by the UI, which is already a positive thing.  But do we have any checks to prevent this, server side? Can we protect against this outcome, or there is no way of doing this and we should think of a clean up job or a job that reports logical errors?   ![Screenshot from 2019-06-03 10-35-12](https://user-images.githubusercontent.com/1520602/58788026-4c92ab00-85eb-11e9-8bc4-5337e8998d22.png) </body>
		<created>2019-06-03 08:43:05</created>
		<closed>2019-09-11 16:33:25</closed>
	</bug>
	<bug>
		<id>5548</id>
		<title>Names of buttons have been changed</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description During connection create last button was "Create" but now it's Next, which might be a bit confusing.   Also on "validation" page was changed from "Next" to "Save".  </body>
		<created>2019-05-31 20:51:58</created>
		<closed>2019-06-03 10:55:37</closed>
	</bug>
	<bug>
		<id>5542</id>
		<title>FHIR - datamapper: mapped an URL string as a record ID </title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11424**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I have an integration: [FHIR_delete-export.zip](https://github.com/syndesisio/syndesis/files/3241609/FHIR_delete-export.zip)  DB periodic SQL -&gt; FHIR create -&gt; **datamapper** -&gt; FHIR delete -&gt; log datamapper should map **id.value** from CREATE action to **id** from DELETE action  But what is mapped is: &lt;code&gt;http://hapi.fhir.org/baseDstu3/Patient/1948754/_history/1&lt;/code&gt;  instead of just 1948754 which causes an exception: &lt;pre&gt;&lt;code&gt; org.apache.camel.RuntimeCamelException: Error invoking resourceById with {stringId=http://hapi.fhir.org/baseDstu3/Patient/1948754/_history/1, resourceAsString=&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;&lt;tns:Patient xmlns:tns="http://hl7.org/fhir"&gt;&lt;name&gt;&lt;tns:given value="Joe"/&gt;&lt;tns:family value="Jackson"/&gt;&lt;/name&gt;&lt;/tns:Patient&gt;, extraParameters={}, type=Patient, version=null, resourceClass=Patient}: LogicalId can not contain '/' (should only be the logical ID portion, not a qualified ID) at org.apache.camel.util.component.ApiMethodHelper.invokeMethod(ApiMethodHelper.java:514) at org.apache.camel.util.component.AbstractApiProducer.doInvokeMethod(AbstractApiProducer.java:120) at org.apache.camel.util.component.AbstractApiProducer$1.run(AbstractApiProducer.java:86) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Caused by: java.lang.IllegalArgumentException: LogicalId can not contain '/' (should only be the logical ID portion, not a qualified ID) at ca.uhn.fhir.rest.client.impl.GenericClient$DeleteInternal.resourceById(GenericClient.java:671) at org.apache.camel.component.fhir.api.FhirDelete.resourceById(FhirDelete.java:71) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.camel.util.component.ApiMethodHelper.invokeMethod(ApiMethodHelper.java:506) ... 9 more &lt;/code&gt;&lt;/pre&gt;   </body>
		<created>2019-05-31 14:24:30</created>
		<closed>2019-09-07 11:20:58</closed>
	</bug>
	<bug>
		<id>5539</id>
		<title>Can't create custom API connector</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ x ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; The custom API connector can't be created.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![out](https://user-images.githubusercontent.com/4180208/58709183-ef63e300-83b9-11e9-9a49-4dbb94a37fad.gif)   </body>
		<created>2019-05-31 13:37:39</created>
		<closed>2019-05-31 15:08:58</closed>
	</bug>
	<bug>
		<id>5535</id>
		<title>React UI is using Red Hat logo for favicon</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Syndesis has a logo we should be using it as favicon.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlisting the acceptance criteria. --&gt; Syndesis logo as favicon.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![Screenshot from 2019-05-31 12-48-08](https://user-images.githubusercontent.com/1306050/58701113-5e354200-83a2-11e9-839a-e751003e7425.png)  </body>
		<created>2019-05-31 10:48:52</created>
		<closed>2019-06-04 12:42:51</closed>
	</bug>
	<bug>
		<id>5534</id>
		<title>Investigate flaky test - io.syndesis.server.runtime.ExtensionsITCase</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  ``` testListExtensionDetails - io.syndesis.server.runtime.ExtensionsITCase  org.awaitility.core.ConditionTimeoutException: Assertion condition defined as a lambda expression in io.syndesis.server.runtime.ExtensionsITCase expected:&lt;[1]&gt; but was:&lt;[0]&gt; within 60 seconds. ```</body>
		<created>2019-05-31 10:07:32</created>
		<closed>2019-05-31 10:19:32</closed>
	</bug>
	<bug>
		<id>5533</id>
		<title>OData filtering causes NPE in log</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description With filtering both filtering &amp; split results turned on and a key predicate specified, the Olingo4Consumer fails with a NP Exception. Seems that the filtering ends up returning null values which are attempted to be indexed (calling null.hashcode()).  This will require a fix in the underlying camel-olingo4 component.  </body>
		<created>2019-05-31 09:55:37</created>
		<closed>2019-07-08 10:46:02</closed>
	</bug>
	<bug>
		<id>5532</id>
		<title>OpenAPI client is displayed without any connections</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The OpenAPI client in settings is displayed on clean installation of Syndesis. Not sure if more API clients get added because all connection types require the info provided by API client during creation.  State on fresh installation of Syndesis: ![image](https://user-images.githubusercontent.com/46345469/58694223-ce3bcc00-8392-11e9-9835-2a277fb6999a.png)  </body>
		<created>2019-05-31 08:57:23</created>
		<closed>2019-06-11 14:14:15</closed>
	</bug>
	<bug>
		<id>5530</id>
		<title>[React-ui] Unable to select Split step</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  ![screenshot_20190531_102043](https://user-images.githubusercontent.com/6814482/58692019-fa088300-838d-11e9-87ea-0818128ad037.png) </body>
		<created>2019-05-31 08:24:44</created>
		<closed>2019-05-31 15:14:58</closed>
	</bug>
	<bug>
		<id>5528</id>
		<title>Wrong schema in the default postgres connection</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The `PostgresDB` connection defined in syndesis by default has the wrong schema set - should be `public` instead of `sampledb` (which is the name of the database, not schema). As far as I can tell, it's not used anywhere in syndesis, since the database steps work with either value - the only problem is that Data Virtualization cannot import the sample db out of the box, because it actually uses the schema. </body>
		<created>2019-05-31 07:48:20</created>
		<closed>2019-07-02 10:35:30</closed>
	</bug>
	<bug>
		<id>5527</id>
		<title>[react-ui] Duplicate connections and integrations created</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When saving/creating Connections and Integrations, the resource in question is created twice:  ![duplicate-connection](https://user-images.githubusercontent.com/9480152/58689680-fbcf4800-8387-11e9-943e-5ec8a3f015b8.gif) ![duplicate-integration](https://user-images.githubusercontent.com/9480152/58689681-fc67de80-8387-11e9-8766-9530cd94f5fd.gif)  </body>
		<created>2019-05-31 07:40:07</created>
		<closed>2019-05-31 17:38:10</closed>
	</bug>
	<bug>
		<id>5526</id>
		<title>Template Step Fails to update the input specification when changed</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description 1. Create a new integration, eg. between odata &amp; log 1. Add a template step between the 2 connections 1. Enter text in the template such as Candidate: {{LastName}} {{FirstName}} 1. Click Done 1. Create a new mapping step between odata &amp; template. Only 'LastName' appears in the target mapping.  </body>
		<created>2019-05-30 16:54:03</created>
		<closed>2019-06-18 12:04:24</closed>
	</bug>
	<bug>
		<id>5521</id>
		<title>API Client not working if multiple http compatible components are found in the camel registry or classpath</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  The rest-swagger connector registers its own component in the camel context but does not enforce the underlying camel component to use it and this could lead to unexpected behaviours when multiple http compatible components are found in the Camel Registry. In case of multiple API Client connection used inside the same integration it could be even worse because each connection could pick up a different http compatible component.  </body>
		<created>2019-05-30 12:26:48</created>
		<closed>2019-07-11 13:35:23</closed>
	</bug>
	<bug>
		<id>5519</id>
		<title>[Conditional Flow] misaligned label when editing name of the flow</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11425**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The `Flow` label jumps down when editing name of the flow. Also the dividers in the same row have different sizes, it would be nice to fix it in react UI.  ![screenshot_20190530_110945](https://user-images.githubusercontent.com/14313995/58622245-78502100-82cb-11e9-907c-ef66e4495b8b.png)   </body>
		<created>2019-05-30 09:16:49</created>
		<closed>2020-06-20 04:00:07</closed>
	</bug>
	<bug>
		<id>5515</id>
		<title>[Conditional Flow] conditional flow step is broken when used inside of API provider</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Using conditional step breaks API provider - there may be more issues but I will leave it as one as this may be a complex problem.  ![out](https://user-images.githubusercontent.com/14313995/58557791-8ba5b280-821f-11e9-8d61-86e516ea9ee4.gif)    When I click on the cancel button at the end of the gif and edit the integration again, there is one more operation in operation count (it probably thinks that the condition == API provider operation), but all the operations are gone:  ![screenshot_20190529_144234](https://user-images.githubusercontent.com/14313995/58558063-23a39c00-8220-11e9-8d0f-0aff417c5305.png)   </body>
		<created>2019-05-29 12:46:43</created>
		<closed>2019-06-26 13:08:00</closed>
	</bug>
	<bug>
		<id>5512</id>
		<title>OData read with query causing RuntimeCamelException</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Running a simple OData read operation with custom query is causing RuntimeCamelException. The input data were:  - service is https://services.odata.org/TripPinRESTierService/  - resource collection is 'People'  - query options are: $filter=LastName eq 'Whyte'&amp;$expand=Trips  Tried that on Odata (read) -&gt; Log integration. This exception can be seen only in integrations logs, there are no items in activity tab of that integration. Tried on latest master (e39cf), 1.6.12 was working as expected.  The whole output of the exception was: ``` Consumer Consumer[olingo4-olingo4-0-0://read] failed polling endpoint: olingo4-olingo4-0-0://read. Will try again at next poll. Caused by: [org.apache.camel.RuntimeCamelException - org.apache.olingo.client.api.communication.ODataClientErrorException: An error has occurred. [HTTP/1.1 500 Internal Server Error]] --  | org.apache.camel.RuntimeCamelException: org.apache.olingo.client.api.communication.ODataClientErrorException: An error has occurred. [HTTP/1.1 500 Internal Server Error]  | at org.apache.camel.util.ObjectHelper.wrapRuntimeCamelException(ObjectHelper.java:1830) ~[camel-core-2.21.0.fuse-740013.jar!/:2.21.0.fuse-740013]  | at org.apache.camel.component.olingo4.Olingo4Consumer.poll(Olingo4Consumer.java:111) ~[camel-olingo4-2.21.0.fuse-740013.jar!/:2.21.0.fuse-740013]  | at org.apache.camel.impl.ScheduledPollConsumer.doRun(ScheduledPollConsumer.java:174) [camel-core-2.21.0.fuse-740013.jar!/:2.21.0.fuse-740013]  | at org.apache.camel.impl.ScheduledPollConsumer.run(ScheduledPollConsumer.java:101) [camel-core-2.21.0.fuse-740013.jar!/:2.21.0.fuse-740013]  | at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_191]  | at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [na:1.8.0_191]  | at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [na:1.8.0_191]  | at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [na:1.8.0_191]  | at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_191]  | at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_191]  | at java.lang.Thread.run(Thread.java:748) [na:1.8.0_191]  | Caused by: org.apache.olingo.client.api.communication.ODataClientErrorException: An error has occurred. [HTTP/1.1 500 Internal Server Error]  | at org.apache.camel.component.olingo4.api.impl.AbstractFutureCallback.checkStatus(AbstractFutureCallback.java:69) ~[camel-olingo4-api-2.21.0.fuse-740013.jar!/:2.21.0.fuse-740013]  | at org.apache.camel.component.olingo4.api.impl.AbstractFutureCallback.completed(AbstractFutureCallback.java:86) ~[camel-olingo4-api-2.21.0.fuse-740013.jar!/:2.21.0.fuse-740013]  | at org.apache.camel.component.olingo4.api.impl.AbstractFutureCallback.completed(AbstractFutureCallback.java:46) ~[camel-olingo4-api-2.21.0.fuse-740013.jar!/:2.21.0.fuse-740013]  | at org.apache.http.concurrent.BasicFuture.completed(BasicFuture.java:123) ~[httpcore-4.4.10.jar!/:4.4.10]  | at org.apache.http.impl.nio.client.DefaultClientExchangeHandlerImpl.responseCompleted(DefaultClientExchangeHandlerImpl.java:181) ~[httpasyncclient-4.1.4.jar!/:4.1.4]  | at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.processResponse(HttpAsyncRequestExecutor.java:439) ~[httpcore-nio-4.4.9.jar!/:4.4.9]  | at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.inputReady(HttpAsyncRequestExecutor.java:329) ~[httpcore-nio-4.4.9.jar!/:4.4.9]  | at org.apache.http.impl.nio.DefaultNHttpClientConnection.consumeInput(DefaultNHttpClientConnection.java:265) ~[httpcore-nio-4.4.9.jar!/:4.4.9]  | at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:81) ~[httpasyncclient-4.1.4.jar!/:4.1.4]  | at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:39) ~[httpasyncclient-4.1.4.jar!/:4.1.4]  | at org.apache.http.impl.nio.reactor.AbstractIODispatch.inputReady(AbstractIODispatch.java:121) ~[httpcore-nio-4.4.9.jar!/:4.4.9]  | at org.apache.http.impl.nio.reactor.BaseIOReactor.readable(BaseIOReactor.java:162) ~[httpcore-nio-4.4.9.jar!/:4.4.9]  | at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvent(AbstractIOReactor.java:337) ~[httpcore-nio-4.4.9.jar!/:4.4.9]  | at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvents(AbstractIOReactor.java:315) ~[httpcore-nio-4.4.9.jar!/:4.4.9]  | at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:276) ~[httpcore-nio-4.4.9.jar!/:4.4.9]  | at org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:104) ~[httpcore-nio-4.4.9.jar!/:4.4.9]  | at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:588) ~[httpcore-nio-4.4.9.jar!/:4.4.9]  | ... 1 common frames omitted ```</body>
		<created>2019-05-29 11:48:05</created>
		<closed>2019-07-15 12:49:17</closed>
	</bug>
	<bug>
		<id>5507</id>
		<title>[React-ui] Unable to publish integration</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description `Unhandled rejection` after setting the name and publishing simple integration  ![screenshot_20190529_085222](https://user-images.githubusercontent.com/6814482/58535909-571a0280-81ef-11e9-9b8f-b9ba68422956.png) </body>
		<created>2019-05-29 06:54:26</created>
		<closed>2019-05-29 09:28:04</closed>
	</bug>
	<bug>
		<id>5506</id>
		<title>[staging] - syndesis server restarts when saving, renaming or deleting an integration</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Maybe it's resource constraints on the backend, but I dunno, I seem to be able to get the backend to restart pretty much on demand.  At first I thought it was just a matter of spamming the save button a bit, but nowadays it seems to just take a save.  Or use the inline-edit control  on the detail page to rename an integration and the backend restarts.  Or deleting an integration also appears to trigger it.    At the moment there's 9 integrations defined on staging, so it doesn't seem like that should be a lot of stuff.  Unfortunately I don't seem to have access to the openshift console any more so I've no backend logs that correlate with any of this. </body>
		<created>2019-05-29 01:16:56</created>
		<closed>2019-06-04 20:16:35</closed>
	</bug>
	<bug>
		<id>5502</id>
		<title>[Angular] [Conditional Flow] done/cancel buttons are not aligned correctly</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description `Cancel` button is slightly higher than `Done` button:  ![screenshot_20190528_165604](https://user-images.githubusercontent.com/14313995/58488448-a7e71800-8169-11e9-9720-f4f0d0514ae7.png)  </body>
		<created>2019-05-28 14:58:28</created>
		<closed>2019-06-13 16:53:09</closed>
	</bug>
	<bug>
		<id>5499</id>
		<title>[react-ui] Unnecessary step page in actions when configuration isn't needed</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11426**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I believe showing this page isn't necessary at all.  ![screenshot_20190528_155719](https://user-images.githubusercontent.com/6814482/58484859-373cfd00-8163-11e9-8613-48fbd6dfa6fe.png) </body>
		<created>2019-05-28 14:11:38</created>
		<closed>2019-09-07 11:21:16</closed>
	</bug>
	<bug>
		<id>5498</id>
		<title>[react-ui] Datamapper step is missing</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description No datamapper step in integration where DM is required:  ![screenshot_20190528_155744](https://user-images.githubusercontent.com/6814482/58484618-b4b43d80-8162-11e9-8994-4d2303687959.png)  </body>
		<created>2019-05-28 14:09:55</created>
		<closed>2019-05-30 08:47:36</closed>
	</bug>
	<bug>
		<id>5493</id>
		<title>SQL connector doesn't return generated IDs when added as start step</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description follow-up to [#4466](https://github.com/syndesisio/syndesis/issues/4466), when performing the INSERT statement as a start step it doesn't return the generated IDs. that means:  - Timer -&gt; SQL (insert) -&gt; Log works just fine, the log shows the generated ID  - periodic SQL (insert) -&gt; Log doesn't return anything</body>
		<created>2019-05-28 12:10:19</created>
		<closed>2019-08-16 09:21:50</closed>
	</bug>
	<bug>
		<id>5492</id>
		<title>[Conditional Flow] add a button to get back to parent conditional flow</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description There is no button to go back to parent conditional flow step when I am finished with implementation of one flow. I have to go to the primary flow and then select conditional flow step every time I want to edit/add new condition. This is very inconvenient. There should be a button which saves the condition implementation and gets you back to the step with conditions - next to the button which returns you to the primary flow:  ![screenshot_20190528_130806](https://user-images.githubusercontent.com/14313995/58473730-a86fb680-8149-11e9-8438-0af6e6a9ca9a.png)  </body>
		<created>2019-05-28 11:09:27</created>
		<closed>2019-06-07 10:56:48</closed>
	</bug>
	<bug>
		<id>5491</id>
		<title>[Conditional Flow] manage new flow starts as a new integration</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description This one is quite a blocker - for some reason new flow starts as an empty integration: ![out](https://user-images.githubusercontent.com/14313995/58470837-d69dc800-8142-11e9-8d36-8970a15238da.gif)  After that I am lost - cancel button does nothing and all I can do is cancel the whole create integration process and start over. </body>
		<created>2019-05-28 10:23:00</created>
		<closed>2019-06-06 15:36:03</closed>
	</bug>
	<bug>
		<id>5490</id>
		<title>API key is not included in query parameter</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When I edit the petstore specification in the UI to use API key as a form of authentication, the api key is not included in the resulting HTTP request.   Causing this error: 2019-05-28 09:17:05.123 WARN 1 --- [/syndesis-timer] o.a.camel.component.timer.TimerConsumer : Error processing exchange. Exchange[i-LfxidPsOAPtPk2BRhF4z]. Caused by: [org.apache.camel.http.common.HttpOperationFailedException - HTTP operation failed invoking http://rest.syndesis.svc:8080/auth/pet with statusCode: 401]  I am not sure if it should be included in the stacktrace but it should be http://rest.syndesis.svc:8080/auth/pet?api_key=****, isn't this related to #5152?  </body>
		<created>2019-05-28 09:30:24</created>
		<closed>2019-08-07 06:43:56</closed>
	</bug>
	<bug>
		<id>5488</id>
		<title>[Conditional Flow] multiple conditional steps share flows</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When I want to use multiple conditional flow steps, they all share flows between each other: ![screenshot_20190528_104350](https://user-images.githubusercontent.com/14313995/58464173-80765800-8135-11e9-9d3b-3b84c8eb4b82.png)  I would expect that when I am inside of a conditional flow step, I can only navigate between its flows and UI does not offer all existing flows which have nothing incommon with the step I am currently editing.   </body>
		<created>2019-05-28 08:46:05</created>
		<closed>2019-06-27 13:04:48</closed>
	</bug>
	<bug>
		<id>5484</id>
		<title>[Conditional Flow] First condition can not be deleted</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description First condition can not be removed - there is no delete icon:  ![screenshot_20190528_102131](https://user-images.githubusercontent.com/14313995/58462635-90d90380-8132-11e9-865d-ff54d3a59121.png)  </body>
		<created>2019-05-28 08:23:58</created>
		<closed>2019-05-29 20:28:55</closed>
	</bug>
	<bug>
		<id>5483</id>
		<title>[Conditional Flow] I have to save the integration before adding the flow step</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description As a user I am forced to save the integration before adding the conditional flow step. This is already not good but what is worse is that if I save the integration previously, then I add another step which changes output data which goes to the conditional flow step I am not forced to save the integration again which means new conditional flow step thinks it gets different input data shape and the integration is broken from that point.  ## Reproducer 1. Create an integration: Webhook -&gt; log Add some json schema as webhook output `{"author":"New Author","title":"Book Title"}`  2. Save the integration 3. change the integration to: webhook -&gt; database (sql insert: select * from contact) -&gt; log 4. add conditional flow step webhook -&gt; database -&gt; split -&gt; conditional flow -&gt; aggregate -&gt; log  note that conditional flow thinks its input data is the json instead of database row  </body>
		<created>2019-05-28 08:20:04</created>
		<closed>2019-06-11 16:31:11</closed>
	</bug>
	<bug>
		<id>5482</id>
		<title>[React-ui] unable to create connections using oauth-flow </title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description This feature isn't implemented yet in react-ui.  Using this issue as placeholder for: https://github.com/syndesisio/syndesis-react/issues/136  </body>
		<created>2019-05-28 07:37:48</created>
		<closed>2019-06-10 13:30:58</closed>
	</bug>
	<bug>
		<id>5481</id>
		<title>[React-ui] selecting list elements only using 'select' button</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11449**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Selecting some list element (ingegration action, integration etc.) is possible currently only using select button unlike before. This feels like step back from UX POV. Especially on larger screens this feels rather odd.   ![screenshot_20190528_092620](https://user-images.githubusercontent.com/6814482/58458975-afd39780-812a-11e9-886f-e50d7201bcc6.png)   </body>
		<created>2019-05-28 07:31:02</created>
		<closed>2019-09-07 11:45:20</closed>
	</bug>
	<bug>
		<id>5480</id>
		<title>API key security option is not parsed into API definition</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description If a user wants to use swagger with API key as security option, the custom API connector doesn't parse API keys to use as an option.  Example: Importing [https://petstore.swagger.io/v2/swagger.json](https://petstore.swagger.io/v2/swagger.json) ![image](https://user-images.githubusercontent.com/46345469/58455281-79454f00-8121-11e9-8a13-f923d813ef5f.png) The API key is imported correctly Changing the definition to use just API keys `sed -i 's/"petstore_auth": ["write:pets", "read:pets"]/"api_key":[]/' petstore.json` Results in  ![image](https://user-images.githubusercontent.com/46345469/58455463-0f797500-8122-11e9-9c03-a5a51c81c063.png) But when comparing the JSONs when the definition is edited in the UI it produces the same output for a path as when changing it manually. i.e  This is what gets imported:  ``` "get": {         "tags": [             "pet"         ],         "summary": "Find pet by ID",         "description": "Returns a single pet",         "operationId": "getPetById",         "produces": [             "application/xml",             "application/json"         ],         "parameters": [             {                 "name": "petId",                 "in": "path",                 "description": "ID of pet to return",                 "required": true,                 "type": "integer",                 "format": "int64"             }         ],         "responses": {             "200": {                 "description": "successful operation",                 "schema": {                     "$ref": "#/definitions/Pet"                 }             },             "400": {                 "description": "Invalid ID supplied"             },             "404": {                 "description": "Pet not found"             }         },         "security": [             {}         ]     } ``` This is after changing it in UI:  ``` "get": {         "tags": [             "pet"         ],         "summary": "Find pet by ID",         "description": "Returns a single pet",         "operationId": "getPetById",         "produces": [             "application/xml",             "application/json"         ],         "parameters": [             {                 "name": "petId",                 "in": "path",                 "description": "ID of pet to return",                 "required": true,                 "type": "integer",                 "format": "int64"             }         ],         "responses": {             "200": {                 "description": "successful operation",                 "schema": {                     "$ref": "#/definitions/Pet"                 }             },             "400": {                 "description": "Invalid ID supplied"             },             "404": {                 "description": "Pet not found"             }         },         "security": [             {                 "api_key": []             }         ]     } ``` And this is what I am importing: ``` "get": {                 "tags": ["pet"],                 "summary": "Find pet by ID",                 "description": "Returns a single pet",                 "operationId": "getPetById",                 "produces": ["application/xml", "application/json"],                 "parameters": [{                     "name": "petId",                     "in": "path",                     "description": "ID of pet to return",                     "required": true,                     "type": "integer",                     "format": "int64"                 }],                 "responses": {                     "200": {                         "description": "successful operation",                         "schema": {                             "$ref": "#/definitions/Pet"                         }                     },                     "400": {                         "description": "Invalid ID supplied"                     },                     "404": {                         "description": "Pet not found"                     }                 },                 "security": [{                     "api_key": []                 }]        } ``` The second JSON and the third are the same (data wise) and when I change the API specification to match the output from the UI, nothing changes. And this issue might be causing the integration pod to fail during start with this log:  [i-asdfadfs-5-69k2f.log](https://github.com/syndesisio/syndesis/files/3225939/i-asdfadfs-5-69k2f.log)   </body>
		<created>2019-05-28 06:39:00</created>
		<closed>2019-06-10 07:13:42</closed>
	</bug>
	<bug>
		<id>5475</id>
		<title>Disable DataVirt UI when Komodo server isn't present</title>
		<body>In certain environments the DataVirt backend may not or cannot be installed. The user interface needs to suppress the dataVirt parts, when the komodo server isn't available to address these situations.</body>
		<created>2019-05-27 14:11:38</created>
		<closed>2019-07-19 12:30:10</closed>
	</bug>
	<bug>
		<id>5474</id>
		<title>[React-ui]  data definition isn't part of  amq connection step</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description QE use amq connection in majority of tests, this blocks migration to react.   See https://github.com/syndesisio/syndesis-react/issues/348 </body>
		<created>2019-05-27 14:11:35</created>
		<closed>2019-05-28 14:58:20</closed>
	</bug>
	<bug>
		<id>5473</id>
		<title>CircleCI build fails on the UI module</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  `apt-get` fails on attempt of interaction as it's missing the `-y` switch.  ```shell #!/bin/bash -eo pipefail apt-get update apt-get install libxss1 patch apt-transport-https echo "deb https://dl.google.com/linux/chrome/deb/ stable main" &gt; /etc/apt/sources.list.d/google-chrome.list curl -sSL https://dl.google.com/linux/linux_signing_key.pub | apt-key add - apt-get update apt-get install -y --no-install-recommends  google-chrome-stable fontconfig fonts-ipafont-gothic fonts-wqy-zenhei fonts-thai-tlwg fonts-kacst fonts-symbola fonts-noto ttf-freefont ./tools/bin/syndesis build --batch-mode --module ui-angular,ui-react --docker | tee build_log.txt  Ign:1 http://deb.debian.org/debian stretch InRelease  Get:2 http://security.debian.org/debian-security stretch/updates InRelease [94.3 kB]  Get:3 http://deb.debian.org/debian stretch-updates InRelease [91.0 kB]  Get:4 http://deb.debian.org/debian stretch Release [118 kB]  Get:5 http://deb.debian.org/debian stretch Release.gpg [2434 B]  Get:6 http://security.debian.org/debian-security stretch/updates/main amd64 Packages [492 kB]  Get:7 http://deb.debian.org/debian stretch-updates/main amd64 Packages [27.2 kB]  Get:8 http://deb.debian.org/debian stretch/main amd64 Packages [7082 kB]  98% [8 Packages store 0 B]98% [8 Packages store 0 B]Fetched 7907 kB in 1s (6794 kB/s)  Reading package lists... 1% Reading package lists... Done   Reading package lists... 1% Reading package lists... Done   Building dependency tree          Reading state information... Done  The following additional packages will be installed:   libx11-6 libx11-data libxau6 libxcb1 libxdmcp6 libxext6 x11-common Suggested packages:   ed diffutils-doc The following NEW packages will be installed:   apt-transport-https libx11-6 libx11-data libxau6 libxcb1 libxdmcp6 libxext6   libxss1 patch x11-common 0 upgraded, 10 newly installed, 0 to remove and 0 not upgraded. Need to get 1819 kB of archives. After this operation, 4653 kB of additional disk space will be used. Do you want to continue? [Y/n] Abort. Exited with code 1 ```</body>
		<created>2019-05-27 14:07:48</created>
		<closed>2019-05-28 06:51:52</closed>
	</bug>
	<bug>
		<id>5472</id>
		<title>CircleCI reports schema validations</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  ``` jobs: 11 schema violations found   jobs: server: extraneous key [filters] is not permitted   jobs: extension: extraneous key [filters] is not permitted   jobs: upgrade: extraneous key [filters] is not permitted   jobs: s2i: extraneous key [filters] is not permitted   jobs: system: -testextraneous key [filters] is not permitted   jobs: ui: extraneous key [filters] is not permitted   jobs: connector: extraneous key [filters] is not permitted   jobs: common: extraneous key [filters] is not permitted   jobs: meta: extraneous key [filters] is not permitted   jobs: integration: extraneous key [filters] is not permitted   jobs: license: -checkextraneous key [filters] is not permitted ```</body>
		<created>2019-05-27 14:02:56</created>
		<closed>2019-06-17 11:26:11</closed>
	</bug>
	<bug>
		<id>5471</id>
		<title>Install script fails for non admin user</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Installing as a non admin user fails with this error:  ```bash oc login -u system:admin tools/bin/syndesis install --setup tools/bin/syndesis install --grant developer oc login -u developer -p whatever tools/bin/syndesis install  ```   ``` ERROR: Cannot create remote resource https://raw.githubusercontent.com/syndesisio/syndesis/master/install/operator/deploy/syndesis-operator.yml  ===============================================================  serviceaccount/syndesis-operator created rolebinding.authorization.openshift.io/syndesis-operator:view created rolebinding.authorization.openshift.io/syndesis-operator:edit created imagestream.image.openshift.io/syndesis-operator created deploymentconfig.apps.openshift.io/syndesis-operator created Error from server (Forbidden): error when creating "https://raw.githubusercontent.com/syndesisio/syndesis/master/install/operator/deploy/syndesis-operator.yml": roles.rbac.authorization.k8s.io "syndesis-operator" is forbidden: attempt to grant extra privileges: [{[get] [serving.knative.dev] [services] [] []} {[list] [serving.knative.dev] [services] [] []} {[watch] [serving.knative.dev] [services] [] []} {[get] [eventing.knative.dev] [channels] [] []} {[list] [eventing.knative.dev] [channels] [] []} {[watch] [eventing.knative.dev] [channels] [] []}] user=&amp;{developer 0a3c3f9d-807c-11e9-aa98-5254003bfc61 [system:authenticated:oauth system:authenticated] map[scopes.authorization.openshift.io:[user:full]]} ownerrules=[{[get] [ user.openshift.io] [users] [~] []} {[list] [ project.openshift.io] [projectrequests] [] []} {[get list] [ authorization.openshift.io] [clusterroles] [] []} {[get list watch] [rbac.authorization.k8s.io] [clusterroles] [] []} {[get list] [storage.k8s.io] [storageclasses] [] []} {[list watch] [ project.openshift.io] [projects] [] []} {[create] [ authorization.openshift.io] [selfsubjectrulesreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews] [] []} {[get] [] [] [] [/healthz /healthz/*]} {[get] [] [] [] [/version /version/* /api /api/* /apis /apis/* /oapi /oapi/* /openapi/v2 /swaggerapi /swaggerapi/* /swagger.json /swagger-2.0.0.pb-v1 /osapi /osapi/ /.well-known /.well-known/* /]} {[create] [ authorization.openshift.io] [selfsubjectrulesreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[impersonate] [ user.openshift.io] [systemusers users] [system:admin] []} {[impersonate] [ user.openshift.io] [groups systemgroups] [system:masters] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews selfsubjectrulesreviews] [] []} {[create] [ build.openshift.io] [builds/docker builds/optimizeddocker] [] []} {[create] [ build.openshift.io] [builds/jenkinspipeline] [] []} {[create] [ build.openshift.io] [builds/source] [] []} {[get] [] [] [] [/api /api/* /apis /apis/* /healthz /openapi /openapi/* /swagger-2.0.0.pb-v1 /swagger.json /swaggerapi /swaggerapi/* /version /version/]} {[delete] [ oauth.openshift.io] [oauthaccesstokens oauthauthorizetokens] [] []} {[get] [] [] [] [/version /version/* /api /api/* /apis /apis/* /oapi /oapi/* /openapi/v2 /swaggerapi /swaggerapi/* /swagger.json /swagger-2.0.0.pb-v1 /osapi /osapi/ /.well-known /.well-known/* /]} {[impersonate] [authentication.k8s.io] [userextras/scopes.authorization.openshift.io] [] []} {[create get] [ build.openshift.io] [buildconfigs/webhooks] [] []} {[create delete deletecollection get list patch update watch] [] [pods pods/attach pods/exec pods/portforward pods/proxy] [] []} {[create delete deletecollection get list patch update watch] [] [configmaps endpoints persistentvolumeclaims replicationcontrollers replicationcontrollers/scale secrets serviceaccounts services services/proxy] [] []} {[get list watch] [] [bindings events limitranges namespaces/status pods/log pods/status replicationcontrollers/status resourcequotas resourcequotas/status] [] []} {[get list watch] [] [namespaces] [] []} {[impersonate] [] [serviceaccounts] [] []} {[create delete deletecollection get list patch update watch] [apps] [daemonsets deployments deployments/rollback deployments/scale replicasets replicasets/scale statefulsets statefulsets/scale] [] []} {[create delete deletecollection get list patch update watch] [autoscaling] [horizontalpodautoscalers] [] []} {[create delete deletecollection get list patch update watch] [batch] [cronjobs jobs] [] []} {[create delete deletecollection get list patch update watch] [extensions] [daemonsets deployments deployments/rollback deployments/scale ingresses networkpolicies replicasets replicasets/scale replicationcontrollers/scale] [] []} {[create delete deletecollection get list patch update watch] [policy] [poddisruptionbudgets] [] []} {[create delete deletecollection get list patch update watch] [networking.k8s.io] [networkpolicies] [] []} {[create] [authorization.k8s.io] [localsubjectaccessreviews] [] []} {[create delete deletecollection get list patch update watch] [rbac.authorization.k8s.io] [rolebindings roles] [] []} {[create delete deletecollection get list patch update watch] [ authorization.openshift.io] [rolebindings roles] [] []} {[create] [ authorization.openshift.io] [localresourceaccessreviews localsubjectaccessreviews subjectrulesreviews] [] []} {[create] [ security.openshift.io] [podsecuritypolicyreviews podsecuritypolicyselfsubjectreviews podsecuritypolicysubjectreviews] [] []} {[get list watch] [ authorization.openshift.io] [rolebindingrestrictions] [] []} {[create delete deletecollection get list patch update watch] [ build.openshift.io] [buildconfigs buildconfigs/webhooks builds] [] []} {[get list watch] [ build.openshift.io] [builds/log] [] []} {[create] [ build.openshift.io] [buildconfigs/instantiate buildconfigs/instantiatebinary builds/clone] [] []} {[update] [ build.openshift.io] [builds/details] [] []} {[admin edit view] [build.openshift.io] [jenkins] [] []} {[create delete deletecollection get list patch update watch] [ apps.openshift.io] [deploymentconfigs deploymentconfigs/scale] [] []} {[create] [ apps.openshift.io] [deploymentconfigrollbacks deploymentconfigs/instantiate deploymentconfigs/rollback] [] []} {[get list watch] [ apps.openshift.io] [deploymentconfigs/log deploymentconfigs/status] [] []} {[create delete deletecollection get list patch update watch] [ image.openshift.io] [imagestreamimages imagestreammappings imagestreams imagestreams/secrets imagestreamtags] [] []} {[get list watch] [ image.openshift.io] [imagestreams/status] [] []} {[get update] [ image.openshift.io] [imagestreams/layers] [] []} {[create] [ image.openshift.io] [imagestreamimports] [] []} {[delete get patch update] [ project.openshift.io] [projects] [] []} {[get list watch] [ quota.openshift.io] [appliedclusterresourcequotas] [] []} {[create delete deletecollection get list patch update watch] [ route.openshift.io] [routes] [] []} {[create] [ route.openshift.io] [routes/custom-host] [] []} {[get list watch] [ route.openshift.io] [routes/status] [] []} {[update] [ route.openshift.io] [routes/status] [] []} {[create delete deletecollection get list patch update watch] [ template.openshift.io] [processedtemplates templateconfigs templateinstances templates] [] []} {[create delete deletecollection get list patch update watch] [extensions networking.k8s.io] [networkpolicies] [] []} {[create delete deletecollection get list patch update watch] [ build.openshift.io] [buildlogs] [] []} {[get list watch] [] [resourcequotausages] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []} {[*] [syndesis.io] [* */finalisers] [] []} {[*] [route.openshift.io] [routes/custom-host] [] []} {[*] [camel.apache.org] [*] [] []} {[*] [monitoring.coreos.com] [alertmanagers prometheuses servicemonitors prometheusrules] [] []} {[*] [integreatly.org] [grafanadashboards] [] []}] ruleResolutionErrors=[] Error from server (NotFound): error when creating "https://raw.githubusercontent.com/syndesisio/syndesis/master/install/operator/deploy/syndesis-operator.yml": roles.rbac.authorization.k8s.io "syndesis-operator" not found ```</body>
		<created>2019-05-27 12:55:36</created>
		<closed>2019-05-27 13:01:04</closed>
	</bug>
	<bug>
		<id>5468</id>
		<title>Daily release builds take a long time</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  I was able to narrow this down to this command taking a lot of CPU: ``` /mnt/hudson_workspace/workspace/syndesis-release-daily/app/ui-react/node/node --max-old-space-size=2048 /mnt/hudson_workspace/workspace/syndesis-release-daily/app/ui-react/node_modules/fork-ts-checker-webpack-plugin/lib/service.js ```  And with @riccardo-forina's help narrowed it down to this issue https://github.com/facebook/create-react-app/issues/6792.</body>
		<created>2019-05-27 09:52:09</created>
		<closed>2019-06-05 19:09:30</closed>
	</bug>
	<bug>
		<id>5458</id>
		<title>Operator tries to update outdated Syndesis resource</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  EDIT: migrated to https://issues.jboss.org/browse/ENTESB-12181  When installing Syndesis via the operator this error is reported. No functionality seems to be lost because of it though.  ``` {"level":"error","ts":1558617960.2453232,"logger":"controller","msg":"Error reconciling","action":"*action.startupAction","phase":"Starting","error":"Operation cannot be fulfilled on syndesises.syndesis.io \"app\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/syndesisio/syndesis/install/operator/vendor/github.com/go-logr/zapr.(*zapLogger).Error\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/github.com/go-logr/zapr/zapr.go:128\ngithub.com/syndesisio/syndesis/install/operator/pkg/controller/syndesis.(*ReconcileSyndesis).Reconcile\n\t/go/src/github.com/syndesisio/syndesis/install/operator/pkg/controller/syndesis/syndesis_controller.go:120\ngithub.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:215\ngithub.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func1\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:158\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.JitterUntil.func1\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:133\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:134\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.Until\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:88"} ``` </body>
		<created>2019-05-23 13:29:14</created>
		<closed>2019-11-05 09:24:56</closed>
	</bug>
	<bug>
		<id>5442</id>
		<title>Unable to deploy syndesis from master</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Using `./tools/bin/syndesis install --project syndesis -y --test-support`:  {"level":"info","ts":1558520033.689927,"logger":"action","msg":"Installing Syndesis resource","type":"install","name":"app"} {"level":"error","ts":1558520033.9660332,"logger":"controller","msg":"Error reconciling","action":"*action.installAction","phase":"Installing","error":"failed to decode json data with gvk(apps.openshift.io/v1, Kind=DeploymentConfig): v1.DeploymentConfig.Spec: v1.DeploymentConfigSpec.Replicas: readUint32: unexpected character: \ufffd, error found in #10 byte of ...|eplicas\":\"0\",\"select|..., bigger context ...|ure\"},\"name\":\"komodo-server\"},\"spec\":{\"replicas\":\"0\",\"selector\":{\"app\":\"syndesis\",\"syndesis.io/app\":|...","stacktrace":"github.com/syndesisio/syndesis/install/operator/vendor/github.com/go-logr/zapr.(*zapLogger).Error\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/github.com/go-logr/zapr/zapr.go:128\ngithub.com/syndesisio/syndesis/install/operator/pkg/controller/syndesis.(*ReconcileSyndesis).Reconcile\n\t/go/src/github.com/syndesisio/syndesis/install/operator/pkg/controller/syndesis/syndesis_controller.go:120\ngithub.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:213\ngithub.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func1\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:158\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.JitterUntil.func1\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:133\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:134\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.Until\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:88"} {"level":"error","ts":1558520033.9661355,"logger":"kubebuilder.controller","msg":"Reconciler error","controller":"syndesis-controller","request":"syndesis/app","error":"failed to decode json data with gvk(apps.openshift.io/v1, Kind=DeploymentConfig): v1.DeploymentConfig.Spec: v1.DeploymentConfigSpec.Replicas: readUint32: unexpected character: \ufffd, error found in #10 byte of ...|eplicas\":\"0\",\"select|..., bigger context ...|ure\"},\"name\":\"komodo-server\"},\"spec\":{\"replicas\":\"0\",\"selector\":{\"app\":\"syndesis\",\"syndesis.io/app\":|...","stacktrace":"github.com/syndesisio/syndesis/install/operator/vendor/github.com/go-logr/zapr.(*zapLogger).Error\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/github.com/go-logr/zapr/zapr.go:128\ngithub.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:215\ngithub.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func1\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:158\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.JitterUntil.func1\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:133\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:134\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.Until\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:88"} </body>
		<created>2019-05-22 10:16:24</created>
		<closed>2019-05-24 08:42:07</closed>
	</bug>
	<bug>
		<id>5436</id>
		<title>Error when installing from sydesis.yml template</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Seems that we no longer can install Syndesis as unprivileged user:  ```     error: roles.rbac.authorization.k8s.io "syndesis-knative-reader" is forbidden: attempt to grant extra privileges: [{[get] [serving.knative.dev] [services] [] []} {[list] [serving.knative.dev] [services] [] []} {[watch] [serving.knative.dev] [services] [] []} {[get] [eventing.knative.dev] [channels] [] []} {[list] [eventing.knative.dev] [channels] [] []} {[watch] [eventing.knative.dev] [channels] [] []}] user=&amp;{developer 39b5fbf2-7bfd-11e9-a53d-52540022a555 [system:authenticated:oauth system:authenticated] map[scopes.authorization.openshift.io:[user:full]]} ownerrules=[{[get] [ user.openshift.io] [users] [~] []} {[list] [ project.openshift.io] [projectrequests] [] []} {[get list] [ authorization.openshift.io] [clusterroles] [] []} {[get list watch] [rbac.authorization.k8s.io] [clusterroles] [] []} {[get list] [storage.k8s.io] [storageclasses] [] []} {[list watch] [ project.openshift.io] [projects] [] []} {[create] [ authorization.openshift.io] [selfsubjectrulesreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews] [] []} {[get] [] [] [] [/healthz /healthz/*]} {[get] [] [] [] [/version /version/* /api /api/* /apis /apis/* /oapi /oapi/* /openapi/v2 /swaggerapi /swaggerapi/* /swagger.json /swagger-2.0.0.pb-v1 /osapi /osapi/ /.well-known /.well-known/* /]} {[create] [ authorization.openshift.io] [selfsubjectrulesreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[impersonate] [ user.openshift.io] [systemusers users] [system:admin] []} {[impersonate] [ user.openshift.io] [groups systemgroups] [system:masters] []} {[*] [syndesis.io] [* */finalisers] [] []} {[*] [route.openshift.io] [routes/custom-host] [] []} {[*] [camel.apache.org] [*] [] []} {[*] [monitoring.coreos.com] [alertmanagers prometheuses servicemonitors prometheusrules] [] []} {[*] [integreatly.org] [grafanadashboards] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews selfsubjectrulesreviews] [] []} {[create] [ build.openshift.io] [builds/docker builds/optimizeddocker] [] []} {[create] [ build.openshift.io] [builds/jenkinspipeline] [] []} {[create] [ build.openshift.io] [builds/source] [] []} {[get] [] [] [] [/api /api/* /apis /apis/* /healthz /openapi /openapi/* /swagger-2.0.0.pb-v1 /swagger.json /swaggerapi /swaggerapi/* /version /version/]} {[delete] [ oauth.openshift.io] [oauthaccesstokens oauthauthorizetokens] [] []} {[get] [] [] [] [/version /version/* /api /api/* /apis /apis/* /oapi /oapi/* /openapi/v2 /swaggerapi /swaggerapi/* /swagger.json /swagger-2.0.0.pb-v1 /osapi /osapi/ /.well-known /.well-known/* /]} {[impersonate] [authentication.k8s.io] [userextras/scopes.authorization.openshift.io] [] []} {[create get] [ build.openshift.io] [buildconfigs/webhooks] [] []} {[create delete deletecollection get list patch update watch] [] [pods pods/attach pods/exec pods/portforward pods/proxy] [] []} {[create delete deletecollection get list patch update watch] [] [configmaps endpoints persistentvolumeclaims replicationcontrollers replicationcontrollers/scale secrets serviceaccounts services services/proxy] [] []} {[get list watch] [] [bindings events limitranges namespaces/status pods/log pods/status replicationcontrollers/status resourcequotas resourcequotas/status] [] []} {[get list watch] [] [namespaces] [] []} {[impersonate] [] [serviceaccounts] [] []} {[create delete deletecollection get list patch update watch] [apps] [daemonsets deployments deployments/rollback deployments/scale replicasets replicasets/scale statefulsets statefulsets/scale] [] []} {[create delete deletecollection get list patch update watch] [autoscaling] [horizontalpodautoscalers] [] []} {[create delete deletecollection get list patch update watch] [batch] [cronjobs jobs] [] []} {[create delete deletecollection get list patch update watch] [extensions] [daemonsets deployments deployments/rollback deployments/scale ingresses networkpolicies replicasets replicasets/scale replicationcontrollers/scale] [] []} {[create delete deletecollection get list patch update watch] [policy] [poddisruptionbudgets] [] []} {[create delete deletecollection get list patch update watch] [networking.k8s.io] [networkpolicies] [] []} {[create] [authorization.k8s.io] [localsubjectaccessreviews] [] []} {[create delete deletecollection get list patch update watch] [rbac.authorization.k8s.io] [rolebindings roles] [] []} {[create delete deletecollection get list patch update watch] [ authorization.openshift.io] [rolebindings roles] [] []} {[create] [ authorization.openshift.io] [localresourceaccessreviews localsubjectaccessreviews subjectrulesreviews] [] []} {[create] [ security.openshift.io] [podsecuritypolicyreviews podsecuritypolicyselfsubjectreviews podsecuritypolicysubjectreviews] [] []} {[get list watch] [ authorization.openshift.io] [rolebindingrestrictions] [] []} {[create delete deletecollection get list patch update watch] [ build.openshift.io] [buildconfigs buildconfigs/webhooks builds] [] []} {[get list watch] [ build.openshift.io] [builds/log] [] []} {[create] [ build.openshift.io] [buildconfigs/instantiate buildconfigs/instantiatebinary builds/clone] [] []} {[update] [ build.openshift.io] [builds/details] [] []} {[admin edit view] [build.openshift.io] [jenkins] [] []} {[create delete deletecollection get list patch update watch] [ apps.openshift.io] [deploymentconfigs deploymentconfigs/scale] [] []} {[create] [ apps.openshift.io] [deploymentconfigrollbacks deploymentconfigs/instantiate deploymentconfigs/rollback] [] []} {[get list watch] [ apps.openshift.io] [deploymentconfigs/log deploymentconfigs/status] [] []} {[create delete deletecollection get list patch update watch] [ image.openshift.io] [imagestreamimages imagestreammappings imagestreams imagestreams/secrets imagestreamtags] [] []} {[get list watch] [ image.openshift.io] [imagestreams/status] [] []} {[get update] [ image.openshift.io] [imagestreams/layers] [] []} {[create] [ image.openshift.io] [imagestreamimports] [] []} {[delete get patch update] [ project.openshift.io] [projects] [] []} {[get list watch] [ quota.openshift.io] [appliedclusterresourcequotas] [] []} {[create delete deletecollection get list patch update watch] [ route.openshift.io] [routes] [] []} {[create] [ route.openshift.io] [routes/custom-host] [] []} {[get list watch] [ route.openshift.io] [routes/status] [] []} {[update] [ route.openshift.io] [routes/status] [] []} {[create delete deletecollection get list patch update watch] [ template.openshift.io] [processedtemplates templateconfigs templateinstances templates] [] []} {[create delete deletecollection get list patch update watch] [extensions networking.k8s.io] [networkpolicies] [] []} {[create delete deletecollection get list patch update watch] [ build.openshift.io] [buildlogs] [] []} {[get list watch] [] [resourcequotausages] [] []} {[create] [ authorization.openshift.io] [resourceaccessreviews subjectaccessreviews] [] []}] ruleResolutionErrors=[]     error: roles.rbac.authorization.k8s.io "syndesis-knative-reader" not found ```  </body>
		<created>2019-05-21 19:57:03</created>
		<closed>2019-05-27 21:28:38</closed>
	</bug>
	<bug>
		<id>5425</id>
		<title>Datamapper - source/target values hidden under expandable "noname" item</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11427**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The elements in the Source mapping area (only this case) are hidden under an expandable element without any name. The "noname" element should not be there - it's confusing.  Other complication is the element doesn't have an id attribute value which makes automated testing difficult. All other named elements have their id values.  I suggest removing this element and make the underlying list visible by default. ![datamapperNoId](https://user-images.githubusercontent.com/8707251/58029182-5e208100-7b1c-11e9-9dac-c317eb54074e.png)  </body>
		<created>2019-05-20 14:35:35</created>
		<closed>2019-09-07 11:24:42</closed>
	</bug>
	<bug>
		<id>5424</id>
		<title>[camel-k] Syndesis integration deployment with Camel-k error </title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  I can't use the camel-k runtime in syndesis as integration runtime.  This error seems to be the root cause: https://github.com/apache/camel-k/issues/466  The camel-k operator is attached:  [log.txt](https://github.com/syndesisio/syndesis/files/3198155/log.txt)  ## Steps to reproduce  * install syndesis with camel-k runtime: ```./syndesis minishift --install --project syndesis --camel-k``` * ```oc get configmap syndesis-server-config -o yaml | sed 's/controllers:/controllers:\n      integration: camel-k/' | oc apply -f -``` * ```oc delete pod -l syndesis.io/component=syndesis-server``` * create sample integration - timer -&gt; DB * observe the error in camel-k operator pod</body>
		<created>2019-05-20 14:16:45</created>
		<closed>2019-06-11 13:46:41</closed>
	</bug>
	<bug>
		<id>5422</id>
		<title>Allow to customize return value when exposing integration as Knative service</title>
		<body>Currently last value of the intgration is implicitly sent back to the user</body>
		<created>2019-05-20 13:42:18</created>
		<closed>2019-09-02 13:51:11</closed>
	</bug>
	<bug>
		<id>5420</id>
		<title>Duplicate extensions can be achieved when importing integrations</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Relates to #5163  Multiple extensions of the same extensionId shouldn't be present in Syndesis at the same time, but the importing process ignores this restriction and the user usually ends up with duplicates of the same extension, which can be only resolved by deleting *both* integrations and related extension (you have to delete both integrations to be able to delete the duplicate extension).  Steps to reproduce: 1. import set body extension 2. import integration using set body extension   What is also interesting is if you remove both extensions and then import the integration you end up with having two integrations in Syndesis.  Another way to achieve this is by having two *different* integrations (importing the same integration twice only overwrites the original integration) which also causes this behavior.   </body>
		<created>2019-05-20 11:27:35</created>
		<closed>2019-06-20 07:44:00</closed>
	</bug>
	<bug>
		<id>5410</id>
		<title>Ghost steps appear</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ x] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description 12. Ghosts steps when not finishing the connection configuration and adding an additional step/mapper.  </body>
		<created>2019-05-17 14:45:13</created>
		<closed>2019-08-28 16:51:52</closed>
	</bug>
	<bug>
		<id>5396</id>
		<title>Illegal access of connector property on a connection without it</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  The Knative connection doesn't embed `connector` within it so accessing `connection.connector.someprop` will result in an error in the UI.  Not exactly sure how to fix it other than to skip over the knative connector.  On a clean database this looks like:  ![Peek 2019-05-17 12-50](https://user-images.githubusercontent.com/1306050/57923359-5f467980-78a2-11e9-9516-058e57629b65.gif)  cc @gashcrumb @nicolaferraro  </body>
		<created>2019-05-17 10:50:43</created>
		<closed>2019-07-03 14:10:38</closed>
	</bug>
	<bug>
		<id>5392</id>
		<title>NPE if no OAuth scopes defined in OpenAPI specification</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When `securityDefinitions` contains an OAuth security definition without any `scopes` property a `NullPointerException` occurs. </body>
		<created>2019-05-17 06:21:02</created>
		<closed>2019-05-17 10:07:15</closed>
	</bug>
	<bug>
		<id>5391</id>
		<title>Swagger dataShape's kind enum is different from the one used in the app</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request [x] Tech debt &lt;/code&gt;&lt;/pre&gt;  ## Description  This is the `stepKind` definition from the Swagger file: ```json "DataShape": {       "type": "object",       "properties": {         ...cut..         "kind": {           "type": "string",           "enum": [             "ANY",             "JAVA",             "JSON_SCHEMA",             "JSON_INSTANCE",             "XML_SCHEMA",             "XML_SCHEMA_INSPECTED",             "XML_INSTANCE",             "NONE"           ]         }   ...cut... ```  In the React codebase, it gets properly translated to this: ```ts export interface DataShape {     ...     kind?: "ANY" | "JAVA" | "JSON_SCHEMA" | "JSON_INSTANCE" | "XML_SCHEMA" | "XML_SCHEMA_INSPECTED" | "XML_INSTANCE" | "NONE"; } ```  Unfortunately tho, the Angular app [uses this enum](https://github.com/syndesisio/syndesis/blob/08fbc208cc369c3b8dded0b452e8356640ac66fe/app/ui/src/app/platform/types/platform.models.ts#L155-L164) which has the values as lower case strings: ```ts export enum DataShapeKinds {   ANY = 'any',   JAVA = 'java',   JSON_SCHEMA = 'json-schema',   JSON_INSTANCE = 'json-instance',   XML_SCHEMA = 'xml-schema',   XML_SCHEMA_INSPECTED = 'xml-schema-inspected',   XML_INSTANCE = 'xml-instance',   NONE = 'none' } ```  This same interface has been ported over to the React codebase together with a number of helper functions we use to work with the models.  The problem is that since the React codebase uses the models as defined by the swagger file, we have type mismatch issues like this one: ![image](https://user-images.githubusercontent.com/966316/57906612-dc5df880-787a-11e9-821c-e7f594863944.png)  For the moment we have bypassed the problem converting both sides to lower case strings when doing the comparison, and shutting down the type check in the assignments, but this isn't really maintainable.   Normally I'd simply update the enum to be in sync with the swagger definition (or get rid of the enum completely, since hardcoded strings as values of a union type field are type checked), but I'm wary of doing so without guidance. The app has been using the lower case version so far, and things just work, so maybe the lower case version is the right one?  What do you suggest doing here @zregvart @igarashitm? Can we update the enum to be in sync with the definition from the swagger? Or should we do the opposite, so update the swagger to be in sync with what the UI has been using in the last year?  CC @gashcrumb  </body>
		<created>2019-05-17 06:16:02</created>
		<closed>2019-09-11 16:33:26</closed>
	</bug>
	<bug>
		<id>5386</id>
		<title>OData read entity returns null when mapped</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I tried to create simple integration OData (read) -&gt; Data Mapper -&gt; OData(update). When published, it fails every time with error mentioned below. ``` io.atlasmap.api.AtlasException: Errors: [Unexpected exception is thrown while reading source field: null: docId='-Lf-gxkgsYfw_FUEYeOu', path='/ID'], [Unexpected exception is thrown while reading source field: null: docId='-Lf-gxkgsYfw_FUEYeOu', path='/ID'], [Unexpected exception is thrown while reading source field: null: docId='-Lf-gxkgsYfw_FUEYeOu', path='/ID'], [Unexpected exception is thrown while reading source field: null: docId='-Lf-gxkgsYfw_FUEYeOu', path='/ID'], [Unexpected exception is thrown while reading source field: null: docId='-Lf-gxkgsYfw_FUEYeOu', path='/ID'], [Unexpected exception is thrown while reading source field: null: docId='-Lf-gxkgsYfw_FUEYeOu', path='/Name'], [Unexpected exception is thrown while reading source field: null: docId='-Lf-gxkgsYfw_FUEYeOu', path='/ID'], [Unexpected exception is thrown while reading source field: null: docId='-Lf-gxkgsYfw_FUEYeOu', path='/ID'], [Unexpected exception is thrown while reading source field: null: docId='-Lf-gxkgsYfw_FUEYeOu', path='/Name'], [Unexpected exception is thrown while reading source field: null: docId='-Lf-gxkgsYfw_FUEYeOu', path='/Name'],  at org.apache.camel.component.atlasmap.AtlasEndpoint.onExchange(AtlasEndpoint.java:266) at org.apache.camel.impl.ProcessorEndpoint$1.process(ProcessorEndpoint.java:71) at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.util.AsyncProcessorHelper.process(AsyncProcessorHelper.java:109) at org.apache.camel.processor.Pipeline.process(Pipeline.java:80) at org.apache.camel.util.component.ApiConsumerHelper.processResult(ApiConsumerHelper.java:140) at org.apache.camel.util.component.ApiConsumerHelper.getResultsProcessed(ApiConsumerHelper.java:127) at org.apache.camel.component.olingo4.Olingo4Consumer.poll(Olingo4Consumer.java:106) at org.apache.camel.impl.ScheduledPollConsumer.doRun(ScheduledPollConsumer.java:174) at org.apache.camel.impl.ScheduledPollConsumer.run(ScheduledPollConsumer.java:101) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) ``` </body>
		<created>2019-05-16 12:59:27</created>
		<closed>2019-07-08 10:47:49</closed>
	</bug>
	<bug>
		<id>5383</id>
		<title>api-generator strips out securty requirements from OpenAPI document</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  In order to minimise the OpenAPI document stored in JSONDB api-generator removes attributes from the OpenAPI document that are not used at runtime. We recently started using operation's security requirement attribute, so it should not be removed.</body>
		<created>2019-05-16 11:12:06</created>
		<closed>2019-05-17 06:23:39</closed>
	</bug>
	<bug>
		<id>5373</id>
		<title>Remove host and base URL configuration from the custom API clients</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  I think we should remove host and base URL configuration from the custom API clients.  ![Screenshot_2019-05-15 Syndesis](https://user-images.githubusercontent.com/1306050/57783786-0acebd00-772f-11e9-9da4-0570257d1b79.png)  That configuration is repeated when connection is created:  ![Screenshot_2019-05-15 Syndesis(1)](https://user-images.githubusercontent.com/1306050/57783889-3e114c00-772f-11e9-864f-38d7b317757b.png)  Also, settings on the connection have lower precedence over settings on the connector (which might be a bug), and to, for example, change the hostname one needs to perform the change on the Custom API settings page and not on the connection.  Any objections @gaughan @syndesisio/uxd?</body>
		<created>2019-05-15 14:36:08</created>
		<closed>2019-05-23 12:51:41</closed>
	</bug>
	<bug>
		<id>5366</id>
		<title>Syndesis allows to create more integrations than cap</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Standard installation with maxIntegrations=1, if I try to create two integrations quickly one after the other, they both run.  If I stop them and try to start both, syndesis allows me to start only one. That caused me troubles, because there's no hint in the UI that tells me I've reached the limit, they just don't start together. And since I had 2 integrations running at the beginning, I cannot figure out that I've reached some cap.. </body>
		<created>2019-05-15 08:32:49</created>
		<closed>2019-08-22 06:00:37</closed>
	</bug>
	<bug>
		<id>5365</id>
		<title>Atlasmap infinite request loop</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Setting a mapping using the embedded Atlasmap starts an infinite loop of ajax requests that if left unattended can cause the server to reboot.  ## Demo  ![infinite-loop](https://user-images.githubusercontent.com/966316/57758366-d2f85300-76f7-11e9-9152-8025cb8ac1da.gif)  I cut this short but it goes on forever. Yesterday it even crashed the server. This is on staging.  CC @igarashitm  </body>
		<created>2019-05-15 07:59:01</created>
		<closed>2019-05-28 13:48:43</closed>
	</bug>
	<bug>
		<id>5364</id>
		<title>[Migration] Migration probably shouldn't call migration script for current schema</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When doing the upgrade from `1.6.9` to `latest`, I am on `28` schema from 1.6.9, however the migration script for schema `28` is called during the upgrade:  ``` 07:38:23.766 Current database schema version: 28 07:38:23.799 Migrating to schema: 28 Migration to schema 28 ... This migration will auto add split steps to integrations with implicit split configured Migrating integration ':i-LeuOQBxh0156frqpBxYz' - adding explicit split step Number of integrations migrated: 1 Migrated to schema 28 completed ``` </body>
		<created>2019-05-15 07:48:50</created>
		<closed>2019-05-28 06:45:43</closed>
	</bug>
	<bug>
		<id>5340</id>
		<title>[SQS] DeleteIfFiltered doesn't delete the message from SQS</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I have an integration `SQS poll -&gt; Basic filter (message doesn't contain "ignore") -&gt; Log`  In SQS poll I use following setting:  ``` [ ] Obtain messages and then delete from the queue [X] Obtain messages and delete the message if the it does make it through a Camel filter. ```  The message doesn't get to log as it shouldn't, however the message is not deleted from the SQS queue and therefore it is trying again and again:  ``` 2019-05-13 13:27:31.435 DEBUG 1 --- [           main] .r.s.IntegrationRuntimeAutoConfiguration : Routes:  &lt;?xml version="1.0" encoding="UTF-8" standalone="yes"?&gt; &lt;routes xmlns="http://camel.apache.org/schema/spring"&gt;     &lt;route customId="true" id="-LelMWs6wMkyi_bavNDB"&gt;         &lt;from customId="true" id="-LelMX9JwMkyi_bavNDB" uri="aws-sqs-0-0"/&gt;         &lt;setHeader headerName="Syndesis.FLOW_ID" id="setHeader1"&gt;             &lt;constant&gt;-LelMWs6wMkyi_bavNDB&lt;/constant&gt;         &lt;/setHeader&gt;         &lt;setHeader headerName="Syndesis.STEP_ID" id="setHeader2"&gt;             &lt;constant&gt;-LelMX9JwMkyi_bavNDB&lt;/constant&gt;         &lt;/setHeader&gt;         &lt;process id="process1"/&gt;         &lt;pipeline customId="true" id="step:-LelM_hQwMkyi_bavNDC"&gt;             &lt;setHeader headerName="Syndesis.STEP_ID" id="setHeader3"&gt;                 &lt;constant&gt;-LelM_hQwMkyi_bavNDC&lt;/constant&gt;             &lt;/setHeader&gt;             &lt;filter id="filter1"&gt;                 &lt;expressionDefinition&gt;io.syndesis.integration.runtime.util.JsonSimplePredicate@7d88fa9c&lt;/expressionDefinition&gt;                 &lt;process id="process2"/&gt;                 &lt;pipeline customId="true" id="step:-LelMZj2wMkyi_bavNDB"&gt;                     &lt;setHeader headerName="Syndesis.STEP_ID" id="setHeader4"&gt;                         &lt;constant&gt;-LelMZj2wMkyi_bavNDB&lt;/constant&gt;                     &lt;/setHeader&gt;                     &lt;log id="log1" loggingLevel="INFO" marker="-LelMZj2wMkyi_bavNDB" message="Body: [${bean:bodyLogger}] "/&gt;                     &lt;process id="process3"/&gt;                 &lt;/pipeline&gt;             &lt;/filter&gt;         &lt;/pipeline&gt;     &lt;/route&gt; &lt;/routes&gt; 2019-05-13 13:27:31.436 DEBUG 1 --- [           main] o.a.camel.spring.boot.RoutesCollector    : CamelContextConfiguration found. Invoking afterApplicationStart: io.syndesis.integration.runtime.sb.jmx.IntegrationMetadataAutoConfiguration$1@51df223b 2019-05-13 13:27:31.436 DEBUG 1 --- [           main] o.a.camel.spring.boot.RoutesCollector    : CamelContextConfiguration found. Invoking afterApplicationStart: io.syndesis.integration.runtime.sb.logging.IntegrationLoggingAutoConfiguration$1@4204541c 2019-05-13 13:27:31.547  INFO 1 --- [           main] b.c.e.u.UndertowEmbeddedServletContainer : Undertow started on port(s) 8080 (http) 2019-05-13 13:27:31.563  INFO 1 --- [           main] io.syndesis.example.Application          : Started Application in 26.762 seconds (JVM running for 30.478) {"exchange":"i-LelNBPHUIKKnMwoGt2Kz","status":"begin"} {"exchange":"i-LelNBPHUIKKnMwoGt2Kz","step":"-LelM_hQwMkyi_bavNDC","id":"i-LelNBR7UIKKnMwoGt2Mz","duration":82448998} {"exchange":"i-LelNBPHUIKKnMwoGt2Kz","status":"done","failed":false} {"exchange":"i-LelNKkLUIKKnMwoGt2Nz","status":"begin"} {"exchange":"i-LelNKkLUIKKnMwoGt2Nz","step":"-LelM_hQwMkyi_bavNDC","id":"i-LelNKkOUIKKnMwoGt2Pz","duration":10648920} {"exchange":"i-LelNKkLUIKKnMwoGt2Nz","status":"done","failed":false} {"exchange":"i-LelNS6fUIKKnMwoGt2Qz","status":"begin"} {"exchange":"i-LelNS6fUIKKnMwoGt2Qz","step":"-LelM_hQwMkyi_bavNDC","id":"i-LelNS6gUIKKnMwoGt2Sz","duration":812571} {"exchange":"i-LelNS6fUIKKnMwoGt2Qz","status":"done","failed":false} {"exchange":"i-LelNcNyUIKKnMwoGt2Tz","status":"begin"} {"exchange":"i-LelNcNyUIKKnMwoGt2Tz","step":"-LelM_hQwMkyi_bavNDC","id":"i-LelNcNzUIKKnMwoGt2Vz","duration":632425} {"exchange":"i-LelNcNyUIKKnMwoGt2Tz","status":"done","failed":false} {"exchange":"i-LelNjkAUIKKnMwoGt2Wz","status":"begin"} {"exchange":"i-LelNjkAUIKKnMwoGt2Wz","step":"-LelM_hQwMkyi_bavNDC","id":"i-LelNjkGUIKKnMwoGt2Yz","duration":11456538} {"exchange":"i-LelNjkAUIKKnMwoGt2Wz","status":"done","failed":false} {"exchange":"i-LelNs20UIKKnMwoGt2Zz","status":"begin"} {"exchange":"i-LelNs20UIKKnMwoGt2Zz","step":"-LelM_hQwMkyi_bavNDC","id":"i-LelNs21UIKKnMwoGt2az","duration":596714} {"exchange":"i-LelNs20UIKKnMwoGt2Zz","status":"done","failed":false} {"exchange":"i-LelNzkKUIKKnMwoGt2bz","status":"begin"} {"exchange":"i-LelNzkKUIKKnMwoGt2bz","step":"-LelM_hQwMkyi_bavNDC","id":"i-LelNzkLUIKKnMwoGt2dz","duration":593876} {"exchange":"i-LelNzkKUIKKnMwoGt2bz","status":"done","failed":false}  ``` </body>
		<created>2019-05-13 13:33:54</created>
		<closed>2019-05-13 14:17:28</closed>
	</bug>
	<bug>
		<id>5338</id>
		<title>FHIR integration: Transaction-&gt;Read: resource Id not mapped by datamapper</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description An integration: **FHIR transaction** -&gt; **Datamapper (id-&gt;id)** -&gt; **FHIR read**  throws an exception: &lt;pre&gt;&lt;code&gt; org.apache.camel.RuntimeCamelException: Error invoking resourceById with {stringId=null, resources=[org.hl7.fhir.dstu3.model.Organization@3ad11c48, org.hl7.fhir.dstu3.model.Patient@2b9a89d7], extraParameters={}, version=null, resourceClass=Patient}: The ID can not be blank at org.apache.camel.util.component.ApiMethodHelper.invokeMethod(ApiMethodHelper.java:514) at org.apache.camel.util.component.AbstractApiProducer.doInvokeMethod(AbstractApiProducer.java:120) at org.apache.camel.util.component.AbstractApiProducer$1.run(AbstractApiProducer.java:86) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Caused by: java.lang.NullPointerException: The ID can not be blank at org.apache.commons.lang3.Validate.notBlank(Validate.java:451) at ca.uhn.fhir.rest.client.impl.GenericClient$ReadInternal.withId(GenericClient.java:1599) at org.apache.camel.component.fhir.api.FhirRead.readWithOptionalVersion(FhirRead.java:135) at org.apache.camel.component.fhir.api.FhirRead.resourceById(FhirRead.java:68) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.camel.util.component.ApiMethodHelper.invokeMethod(ApiMethodHelper.java:506) ... 9 more &lt;/code&gt;&lt;/pre&gt;  The read action doesn't get a resource id from the datamapper step. The exported integration: [FHIR_transaction-export.zip](https://github.com/syndesisio/syndesis/files/3166458/FHIR_transaction-export.1.zip)   </body>
		<created>2019-05-10 12:32:57</created>
		<closed>2019-05-16 11:27:31</closed>
	</bug>
	<bug>
		<id>5332</id>
		<title>Changes to OpenAPI not reflected in API Provider</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description After editing an OpenAPI definition in an APi Provider integration (such as deleting an operation or adding a new one), the list of available operation remains unchaged.  ## Steps to reproduce 1. create an API Provider Integration from an existing swagger json 2. click View/Edit OpenAPI definition 3. delete one of the operations 4. click save 5. the list of operations still contains the deleted operation  </body>
		<created>2019-05-09 12:31:42</created>
		<closed>2019-06-25 07:39:03</closed>
	</bug>
	<bug>
		<id>5323</id>
		<title>Documentation for Actions in a Google Sheet connection are truncated and cannot be read fully. </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ x] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem Documentation for Actions in a Google Sheet connection are truncated and cannot be read fully.   ## Expected behavior There is plenty of space on the screen to move the text into multiple lines rather than truncating the longer single line.   ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; &lt;img width="1438" alt="screenshot" src="https://user-images.githubusercontent.com/1889892/57368570-b7d39380-718b-11e9-8309-97570dfdf832.png"&gt;   ## Tasks involved / Steps to Reproduce 1. Create a new Google Sheets connection 2. Create a new Integration with the Google Sheets connection at the start.  3. Review the screen that requests you to choose an Action  </body>
		<created>2019-05-08 10:21:32</created>
		<closed>2019-08-22 06:00:38</closed>
	</bug>
	<bug>
		<id>5321</id>
		<title>Clean up integration data when integration gets deleted</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [x] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  When an integration is deleted we should remove all related data from the database. At the moment the database still holds integration related data (e.g. integration definition, integration-deployments, integration-activity, open-api specs, integration-bulletin-board).   We should clean up those entries when the integration is deleted. </body>
		<created>2019-05-08 09:37:59</created>
		<closed>2019-08-08 11:39:02</closed>
	</bug>
	<bug>
		<id>5312</id>
		<title>Create integration - disable Save and Publish buttons until an integration name set</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11428**  ## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Save and Publish buttons are enabled even if the integration name hasn't been set yet. If they are clicked, the integration setting is lost because the buttons are set disabled forever then. The only way how to reset them is going back to Integrations page and set the all new integration settings again.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlisting the acceptance criteria. --&gt; Keep Save and Publish buttons disabled while the integration name is not set.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![save1](https://user-images.githubusercontent.com/8707251/57298979-ce1e1880-70d3-11e9-954c-9849e13a87d3.png) ![save2](https://user-images.githubusercontent.com/8707251/57298990-d24a3600-70d3-11e9-8dfb-fc91c9c6be85.png) </body>
		<created>2019-05-07 12:25:52</created>
		<closed>2019-09-07 11:24:51</closed>
	</bug>
	<bug>
		<id>5311</id>
		<title>Unable to find adapter for google calendar</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Trying to add any google calendar step results in the following message:  ![image](https://user-images.githubusercontent.com/9480152/57293542-51843d80-70c5-11e9-890c-60ac259ce724.png) </body>
		<created>2019-05-07 10:42:07</created>
		<closed>2019-05-21 14:22:52</closed>
	</bug>
	<bug>
		<id>5310</id>
		<title>Flows mismatched when editing OpenAPI definition of API provider itegration</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  If I create an OpenAPI definition without specifying `operationId` a `operationId` will be generated as `operation-#` (say `operation-0`). If I edit the OpenAPI definition to remove an operation and add another operation without specifying the `operationId` the new operation will use the same `operationId` (the same `operation-0`).  The result of this is that the flow designed for the first, now removed, operation will be assigned to the flow of the newly added operation.  I think it would make sense to generate unique `operationId`s as the numbered ones can lead to clashes like this.</body>
		<created>2019-05-07 09:47:29</created>
		<closed>2019-05-29 11:57:58</closed>
	</bug>
	<bug>
		<id>5304</id>
		<title>[SQS] Unable to poll from FIFO - messageGroupIdStrategy must be set for FIFO queues</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When starting the integration with polling from fifo queue:  ``` org.apache.camel.RuntimeCamelException: org.apache.camel.FailedToCreateRouteException: Failed to create route -LeBF_2JOIoZGDczXxt7: Route(-LeBF_2JOIoZGDczXxt7)[[From[aws-sqs-0-0]] -&gt; [SetHeade... because of Failed to resolve endpoint: aws-sqs-0-0 due to: Failed to resolve endpoint: aws-sqs://syndesis-in.fifo?accessKey=RAW(AKIAIEEBY2PHYAUTXZNQ)&amp;delay=500&amp;deleteAfterRead=true&amp;deleteIfFiltered=true&amp;maxMessagesPerPoll=10&amp;region=US_WEST_1&amp;secretKey=RAW(z4R0A/AUbA4nujVRKEMCiQXbumP9H5sR2Wvz8AIt) due to: messageGroupIdStrategy must be set for FIFO queues. at org.apache.camel.util.ObjectHelper.wrapRuntimeCamelException(ObjectHelper.java:1830) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.spring.SpringCamelContext.start(SpringCamelContext.java:136) ~[camel-spring-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.spring.SpringCamelContext.onApplicationEvent(SpringCamelContext.java:174) ~[camel-spring-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:393) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:347) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:883) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.finishRefresh(EmbeddedWebApplicationContext.java:144) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at io.syndesis.example.Application.main(Application.java:13) [classes!/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_191] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_191] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_191] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_191] at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.Launcher.launch(Launcher.java:87) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.Launcher.launch(Launcher.java:50) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.PropertiesLauncher.main(PropertiesLauncher.java:595) [project-0.1-SNAPSHOT.jar:na] Caused by: org.apache.camel.FailedToCreateRouteException: Failed to create route -LeBF_2JOIoZGDczXxt7: Route(-LeBF_2JOIoZGDczXxt7)[[From[aws-sqs-0-0]] -&gt; [SetHeade... because of Failed to resolve endpoint: aws-sqs-0-0 due to: Failed to resolve endpoint: aws-sqs://syndesis-in.fifo?accessKey=RAW(AKIAIEEBY2PHYAUTXZNQ)&amp;delay=500&amp;deleteAfterRead=true&amp;deleteIfFiltered=true&amp;maxMessagesPerPoll=10&amp;region=US_WEST_1&amp;secretKey=RAW(z4R0A/AUbA4nujVRKEMCiQXbumP9H5sR2Wvz8AIt) due to: messageGroupIdStrategy must be set for FIFO queues. at org.apache.camel.model.RouteDefinition.addRoutes(RouteDefinition.java:209) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.impl.DefaultCamelContext.startRoute(DefaultCamelContext.java:1143) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.impl.DefaultCamelContext.startRouteDefinitions(DefaultCamelContext.java:3729) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.impl.DefaultCamelContext.doStartCamel(DefaultCamelContext.java:3443) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.impl.DefaultCamelContext.access$000(DefaultCamelContext.java:209) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.impl.DefaultCamelContext$2.call(DefaultCamelContext.java:3251) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.impl.DefaultCamelContext$2.call(DefaultCamelContext.java:3247) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.impl.DefaultCamelContext.doWithDefinedClassLoader(DefaultCamelContext.java:3270) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.impl.DefaultCamelContext.doStart(DefaultCamelContext.java:3247) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.impl.DefaultCamelContext.start(DefaultCamelContext.java:3163) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.spring.SpringCamelContext.start(SpringCamelContext.java:133) ~[camel-spring-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] ... 24 common frames omitted Caused by: org.apache.camel.ResolveEndpointFailedException: Failed to resolve endpoint: aws-sqs-0-0 due to: Failed to resolve endpoint: aws-sqs://syndesis-in.fifo?accessKey=RAW(AKIAIEEBY2PHYAUTXZNQ)&amp;delay=500&amp;deleteAfterRead=true&amp;deleteIfFiltered=true&amp;maxMessagesPerPoll=10&amp;region=US_WEST_1&amp;secretKey=RAW(z4R0A/AUbA4nujVRKEMCiQXbumP9H5sR2Wvz8AIt) due to: messageGroupIdStrategy must be set for FIFO queues. at org.apache.camel.impl.DefaultCamelContext.getEndpoint(DefaultCamelContext.java:758) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.util.CamelContextHelper.getMandatoryEndpoint(CamelContextHelper.java:80) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.model.RouteDefinition.resolveEndpoint(RouteDefinition.java:219) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.impl.DefaultRouteContext.resolveEndpoint(DefaultRouteContext.java:115) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.impl.DefaultRouteContext.resolveEndpoint(DefaultRouteContext.java:121) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.model.FromDefinition.resolveEndpoint(FromDefinition.java:69) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.impl.DefaultRouteContext.getEndpoint(DefaultRouteContext.java:97) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.model.RouteDefinition.addRoutes(RouteDefinition.java:1283) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.model.RouteDefinition.addRoutes(RouteDefinition.java:204) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] ... 35 common frames omitted Caused by: org.apache.camel.ResolveEndpointFailedException: Failed to resolve endpoint: aws-sqs://syndesis-in.fifo?accessKey=RAW(AKIAIEEBY2PHYAUTXZNQ)&amp;delay=500&amp;deleteAfterRead=true&amp;deleteIfFiltered=true&amp;maxMessagesPerPoll=10&amp;region=US_WEST_1&amp;secretKey=RAW(z4R0A/AUbA4nujVRKEMCiQXbumP9H5sR2Wvz8AIt) due to: messageGroupIdStrategy must be set for FIFO queues. at org.apache.camel.impl.DefaultCamelContext.getEndpoint(DefaultCamelContext.java:758) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at io.syndesis.integration.component.proxy.ComponentProxyComponent.createDelegateEndpoint(ComponentProxyComponent.java:346) ~[integration-component-proxy-1.7-SNAPSHOT.jar!/:1.7-SNAPSHOT] at io.syndesis.integration.component.proxy.ComponentProxyComponent.createEndpoint(ComponentProxyComponent.java:133) ~[integration-component-proxy-1.7-SNAPSHOT.jar!/:1.7-SNAPSHOT] at org.apache.camel.impl.DefaultComponent.createEndpoint(DefaultComponent.java:130) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.impl.DefaultCamelContext.getEndpoint(DefaultCamelContext.java:743) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] ... 43 common frames omitted Caused by: java.lang.IllegalArgumentException: messageGroupIdStrategy must be set for FIFO queues. at org.apache.camel.component.aws.sqs.SqsComponent.createEndpoint(SqsComponent.java:91) ~[camel-aws-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.impl.DefaultComponent.createEndpoint(DefaultComponent.java:130) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.impl.DefaultCamelContext.getEndpoint(DefaultCamelContext.java:711) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] ... 47 common frames omitted ```  @oscerd we will need to backport https://issues.apache.org/jira/browse/CAMEL-13230</body>
		<created>2019-05-06 08:53:40</created>
		<closed>2019-05-14 06:43:01</closed>
	</bug>
	<bug>
		<id>5302</id>
		<title>[SQS] Issues with SQSMessage - Datamapper, Batch messages</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description There are two issues present with `SQSMessage` class: - (1) Mapping the received message to something is not possible - (2) Sending batch message fails with String cannot be cast to io.syndesis.connector.aws.sqs.SQSMessage  `(1)`  I have `SQS -&gt; AMQ` integration, where I specified AMQ input datashape as `JSON_INSTANCE` `{"body":"msg"}` and I used datamapper to map between `/message` from SQS and `/body` from AMQ, however it fails at runtime with:  ``` 2019-05-03 12:01:54.167 ERROR 1 --- [s://syndesis-in] o.a.camel.processor.DefaultErrorHandler  : Failed delivery for (MessageId: i-LdxZbTi97Gb-KX27JKtz on ExchangeId: i-LdxZbPa97Gb-KX27JKsz). Exhausted after delivery attempt: 1 caught: io.atlasmap.api.AtlasException: Errors: [Field 'message' not found on object 'Hello from SQS!': docId='-LdxZ69RtCbBnSknBdJu', path='/message'],  Message History --------------------------------------------------------------------------------------------------------------------------------------- RouteId              ProcessorId          Processor                                                                        Elapsed (ms) [-LdxZ5gjtCbBnSknBd] [-LdxZ5gjtCbBnSknBd] [aws-sqs://syndesis-in?accessKey=RAW(AKIAIEEBY2PHYAUTXZNQ)&amp;delay=500&amp;deleteAfte] [      2260] [-LdxZ5gjtCbBnSknBd] [setHeader1        ] [setHeader[Syndesis.FLOW_ID]                                                   ] [        25] [-LdxZ5gjtCbBnSknBd] [setHeader2        ] [setHeader[Syndesis.STEP_ID]                                                   ] [         0] [-LdxZ5gjtCbBnSknBd] [process1          ] [Processor@0x1d3bf5e2                                                          ] [         1] [-LdxZ5gjtCbBnSknBd] [step:-LdxZESTtCbBn] [pipeline                                                                      ] [         0] [-LdxZ5gjtCbBnSknBd] [setHeader3        ] [setHeader[Syndesis.STEP_ID]                                                   ] [         0] [-LdxZ5gjtCbBnSknBd] [to1               ] [atlas:mapping-flow-0-step-1.json?encoding=UTF-8&amp;sourceMapName=Syndesis.CAPTURE] [      2107] Stacktrace --------------------------------------------------------------------------------------------------------------------------------------- io.atlasmap.api.AtlasException: Errors: [Field 'message' not found on object 'Hello from SQS!': docId='-LdxZ69RtCbBnSknBdJu', path='/message'],  at org.apache.camel.component.atlasmap.AtlasEndpoint.onExchange(AtlasEndpoint.java:266) ~[camel-atlasmap-1.39.6.jar!/:na] at org.apache.camel.impl.ProcessorEndpoint$1.process(ProcessorEndpoint.java:71) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) [integration-runtime-1.7-SNAPSHOT.jar!/:1.7-SNAPSHOT] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.component.aws.sqs.SqsConsumer.processBatch(SqsConsumer.java:206) [camel-aws-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.component.aws.sqs.SqsConsumer.poll(SqsConsumer.java:111) [camel-aws-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.impl.ScheduledPollConsumer.doRun(ScheduledPollConsumer.java:174) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.impl.ScheduledPollConsumer.run(ScheduledPollConsumer.java:101) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_191] at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [na:1.8.0_191] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [na:1.8.0_191] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [na:1.8.0_191] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_191] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_191] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_191] ```  `(2)` - **solved**  I have `HTTP -&gt; SQS (send batch message)` and it fails with:  ``` {"exchange":"i-LdxgIDrFTCvHuVV7-KVz","status":"begin"} 2019-05-03 12:35:26.954 ERROR 1 --- [r://integration] o.a.camel.processor.DefaultErrorHandler  : Failed delivery for (MessageId: i-LdxgINhFTCvHuVV7-KYz on ExchangeId: i-LdxgINcFTCvHuVV7-KXz). Exhausted after delivery attempt: 1 caught: java.lang.ClassCastException: java.lang.String cannot be cast to io.syndesis.connector.aws.sqs.SQSMessage Message History --------------------------------------------------------------------------------------------------------------------------------------- RouteId              ProcessorId          Processor                                                                        Elapsed (ms) [-Ldxae_ZtCbBnSknBd] [-Ldxae_ZtCbBnSknBd] [timer://integration?period=300000                                             ] [       658] [-Ldxae_ZtCbBnSknBd] [setHeader2        ] [setHeader[Syndesis.STEP_ID]                                                   ] [         0] [-Ldxae_ZtCbBnSknBd] [process1          ] [Processor@0x2789b038                                                          ] [         1] [-Ldxae_ZtCbBnSknBd] [step:-LdxarcDtCbBn] [pipeline                                                                      ] [         0] [-Ldxae_ZtCbBnSknBd] [setHeader3        ] [setHeader[Syndesis.STEP_ID]                                                   ] [         0] [-Ldxae_ZtCbBnSknBd] [to2               ] [aws-sqs-0-2                                                                   ] [        16] Stacktrace --------------------------------------------------------------------------------------------------------------------------------------- java.lang.ClassCastException: java.lang.String cannot be cast to io.syndesis.connector.aws.sqs.SQSMessage at io.syndesis.connector.aws.sqs.AWSSQSBatchMessagesCustomizer.beforeProducer(AWSSQSBatchMessagesCustomizer.java:47) ~[connector-aws-sqs-1.7-SNAPSHOT.jar!/:1.7-SNAPSHOT] at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at io.syndesis.integration.component.proxy.ComponentProxyProducer.process(ComponentProxyProducer.java:44) ~[integration-component-proxy-1.7-SNAPSHOT.jar!/:1.7-SNAPSHOT] at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) ~[camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) [integration-runtime-1.7-SNAPSHOT.jar!/:1.7-SNAPSHOT] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.MulticastProcessor.doProcessSequential(MulticastProcessor.java:715) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.MulticastProcessor.doProcessSequential(MulticastProcessor.java:638) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.MulticastProcessor.process(MulticastProcessor.java:248) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.Splitter.process(Splitter.java:122) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79) [camel-core-2.21.0.fuse-740007.jar!/:2.21.0.fuse-740007] at java.util.TimerThread.mainLoop(Timer.java:555) [na:1.8.0_191] at java.util.TimerThread.run(Timer.java:505) [na:1.8.0_191]  ```  `HTTP (same endpoint) -&gt; SQS single message` works OK </body>
		<created>2019-05-03 12:06:03</created>
		<closed>2019-05-09 13:11:11</closed>
	</bug>
	<bug>
		<id>5298</id>
		<title>Artifact for integration-bom-camel-k not released</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Looking at a released tag, that artifact is still present with a snapshot version: https://github.com/syndesisio/syndesis/blob/6654c7a703338f4c2ee2a102e65d32af9c674999/app/integration/bom-camel-k/pom.xml#L23  It happens because it is not a descendant of the root project (and it should not be).  But this in turns mean that it's not published in the maven repo when we do the release.   cc: @heiko-braun, @lburgazzoli, @valdar  Seems a CI / Prod issue. Affects 7.3.</body>
		<created>2019-05-02 13:01:51</created>
		<closed>2019-05-04 09:34:24</closed>
	</bug>
	<bug>
		<id>5297</id>
		<title>[camel-k] [activity-tracking] Failure occurred while processing controller for pod</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  When running in camel-k mode on a system when istio is configured, I see the following errors in the syndesis-server logs:  ``` 2019-05-02 12:12:26.238  INFO [-,,,] 1 --- [oller Scheduler] i.s.s.c.i.BaseIntegrationController      : Checking integrations for their status. 2019-05-02 12:12:27.333  INFO [-,,,] 1 --- [ning]: pollPods] i.s.s.l.j.c.ActivityTrackingController   : Recovered state: {} 2019-05-02 12:12:27.338  INFO [-,,,] 1 --- [fd6776896-vsmfv] i.s.s.l.j.c.ActivityTrackingController   : Getting controller for pod: i-sensor-to-damage-00001-deployment-5fd6776896-vsmfv 2019-05-02 12:12:27.343 INFO [-,,,] 1 --- [timestamps=true] i.s.s.l.j.controller.KubernetesSupport : Failure occurred while processing controller for pod: i-sensor-to-damage-00001-deployment-5fd6776896-vsmfv, http status: 400, details: {"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"a container name must be specified for pod i-sensor-to-damage-00001-deployment-5fd6776896-vsmfv, choose one of: [user-container queue-proxy]","reason":"BadRequest","code":400} ```</body>
		<created>2019-05-02 12:56:11</created>
		<closed>2019-11-12 16:18:56</closed>
	</bug>
	<bug>
		<id>5296</id>
		<title>[camel-k] [prometheus] IllegalStateException: Duplicate key 53455</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  When running in camel-k mode and scaling the integration with replicas &gt; 1, then the following error apperas in the syndesis-server log:  ``` java.lang.IllegalStateException: Duplicate key 53455     at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133) ~[na:1.8.0_151]     at java.util.HashMap.merge(HashMap.java:1254) ~[na:1.8.0_151]     at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320) ~[na:1.8.0_151]     at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ~[na:1.8.0_151]     at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1380) ~[na:1.8.0_151]     at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ~[na:1.8.0_151]     at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ~[na:1.8.0_151]     at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ~[na:1.8.0_151]     at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[na:1.8.0_151]     at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ~[na:1.8.0_151]     at io.syndesis.server.metrics.prometheus.QueryResult.lambda$getValueMap$5(QueryResult.java:61) ~[server-metrics-prometheus-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT]     at java.util.Optional.map(Optional.java:215) ~[na:1.8.0_151]     at io.syndesis.server.metrics.prometheus.QueryResult.getValueMap(QueryResult.java:60) ~[server-metrics-prometheus-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT]     at io.syndesis.server.metrics.prometheus.PrometheusMetricsProviderImpl.getTopIntegrations(PrometheusMetricsProviderImpl.java:255) ~[server-metrics-prometheus-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT]     at io.syndesis.server.metrics.prometheus.PrometheusMetricsProviderImpl.getTotalIntegrationMetricsSummary(PrometheusMetricsProviderImpl.java:212) ~[server-metrics-prometheus-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT]     at io.syndesis.server.endpoint.v1.handler.metrics.IntegrationMetricsHandler.get(IntegrationMetricsHandler.java:65) ~[server-endpoint-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT]     at sun.reflect.GeneratedMethodAccessor417.invoke(Unknown Source) ~[na:na]     at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151]     at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151]     at org.jboss.resteasy.core.MethodInjectorImpl.invoke(MethodInjectorImpl.java:140) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]     at org.jboss.resteasy.core.ResourceMethodInvoker.internalInvokeOnTarget(ResourceMethodInvoker.java:509) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]     at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTargetAfterFilter(ResourceMethodInvoker.java:399) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]     at org.jboss.resteasy.core.ResourceMethodInvoker.lambda$invokeOnTarget$0(ResourceMethodInvoker.java:363) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]     at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:358) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]     at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTarget(ResourceMethodInvoker.java:365) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]     at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:337) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]     at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:310) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]     at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:443) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]     at org.jboss.resteasy.core.SynchronousDispatcher.lambda$invoke$4(SynchronousDispatcher.java:233) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]     at org.jboss.resteasy.core.SynchronousDispatcher.lambda$preprocess$0(SynchronousDispatcher.java:139) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]     at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:358) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]     at org.jboss.resteasy.core.SynchronousDispatcher.preprocess(SynchronousDispatcher.java:142) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]     at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:219) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]     at org.jboss.resteasy.plugins.server.servlet.ServletContainerDispatcher.service(ServletContainerDispatcher.java:227) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]     at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:56) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]     at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:51) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final]     at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) ~[javax.servlet-api-3.1.0.jar!/:3.1.0]     at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) ~[spring-boot-1.5.17.RELEASE.jar!/:1.5.17.RELEASE]     at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.20.RELEASE.jar!/:4.3.20.RELEASE]     at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:111) ~[spring-boot-actuator-1.5.17.RELEASE.jar!/:1.5.17.RELEASE]     at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.20.RELEASE.jar!/:4.3.20.RELEASE]     at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.security.web.authentication.preauth.AbstractPreAuthenticatedProcessingFilter.doFilter(AbstractPreAuthenticatedProcessingFilter.java:121) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.security.web.csrf.CsrfFilter.doFilterInternal(CsrfFilter.java:100) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.20.RELEASE.jar!/:4.3.20.RELEASE]     at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96) ~[spring-web-4.3.20.RELEASE.jar!/:4.3.20.RELEASE]     at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.20.RELEASE.jar!/:4.3.20.RELEASE]     at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:66) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.20.RELEASE.jar!/:4.3.20.RELEASE]     at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.20.RELEASE.jar!/:4.3.20.RELEASE]     at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]     at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) ~[spring-web-4.3.20.RELEASE.jar!/:4.3.20.RELEASE]     at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) ~[spring-web-4.3.20.RELEASE.jar!/:4.3.20.RELEASE]     at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-4.3.20.RELEASE.jar!/:4.3.20.RELEASE]     at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.20.RELEASE.jar!/:4.3.20.RELEASE]     at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109) ~[spring-web-4.3.20.RELEASE.jar!/:4.3.20.RELEASE]     at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.20.RELEASE.jar!/:4.3.20.RELEASE]     at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) ~[spring-web-4.3.20.RELEASE.jar!/:4.3.20.RELEASE]     at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.20.RELEASE.jar!/:4.3.20.RELEASE]     at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at org.springframework.cloud.sleuth.instrument.web.TraceFilter.doFilter(TraceFilter.java:186) ~[spring-cloud-sleuth-core-1.2.6.RELEASE.jar!/:1.2.6.RELEASE]     at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.micrometer.spring.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:106) ~[micrometer-spring-legacy-1.1.2.jar!/:1.1.2]     at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.20.RELEASE.jar!/:4.3.20.RELEASE]     at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) ~[spring-web-4.3.20.RELEASE.jar!/:4.3.20.RELEASE]     at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.20.RELEASE.jar!/:4.3.20.RELEASE]     at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:103) ~[spring-boot-actuator-1.5.17.RELEASE.jar!/:1.5.17.RELEASE]     at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.20.RELEASE.jar!/:4.3.20.RELEASE]     at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:65) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:132) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) ~[undertow-core-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) ~[undertow-core-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) ~[undertow-core-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.server.Connectors.executeRootHandler(Connectors.java:336) ~[undertow-core-1.4.26.Final.jar!/:1.4.26.Final]     at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) ~[undertow-core-1.4.26.Final.jar!/:1.4.26.Final]     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_151]     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_151]     at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_151] ``` @KurtStam @dhirajsb any clue ?</body>
		<created>2019-05-02 12:50:35</created>
		<closed>2019-09-18 13:52:27</closed>
	</bug>
	<bug>
		<id>5290</id>
		<title>Integrations do not start because ClassNotFoundException: io.opentracing.NoopTracer</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Any integration startup `on master` fails with:  ``` 2019-04-29 09:02:14.212 ERROR 1 --- [           main] o.s.boot.SpringApplication               : Application startup failed org.springframework.context.ApplicationContextException: Unable to start embedded container; nested exception is java.lang.RuntimeException: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'tracingFilter' defined in class path resource [io/opentracing/contrib/spring/web/autoconfig/ServerTracingAutoConfiguration.class]: Unsatisfied dependency expressed through method 'tracingFilter' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'noopTracer' defined in class path resource [io/opentracing/contrib/spring/web/autoconfig/TracerAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.opentracing.Tracer]: Factory method 'noopTracer' threw exception; nested exception is java.lang.NoClassDefFoundError: io/opentracing/NoopTracer at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.onRefresh(EmbeddedWebApplicationContext.java:137) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:537) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at io.syndesis.example.Application.main(Application.java:13) [classes!/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_191] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_191] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_191] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_191] at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.Launcher.launch(Launcher.java:87) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.Launcher.launch(Launcher.java:50) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.PropertiesLauncher.main(PropertiesLauncher.java:595) [project-0.1-SNAPSHOT.jar:na] Caused by: java.lang.RuntimeException: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'tracingFilter' defined in class path resource [io/opentracing/contrib/spring/web/autoconfig/ServerTracingAutoConfiguration.class]: Unsatisfied dependency expressed through method 'tracingFilter' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'noopTracer' defined in class path resource [io/opentracing/contrib/spring/web/autoconfig/TracerAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.opentracing.Tracer]: Factory method 'noopTracer' threw exception; nested exception is java.lang.NoClassDefFoundError: io/opentracing/NoopTracer at io.undertow.servlet.core.DeploymentManagerImpl.deploy(DeploymentManagerImpl.java:241) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at org.springframework.boot.context.embedded.undertow.UndertowEmbeddedServletContainerFactory.createDeploymentManager(UndertowEmbeddedServletContainerFactory.java:416) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.context.embedded.undertow.UndertowEmbeddedServletContainerFactory.getEmbeddedServletContainer(UndertowEmbeddedServletContainerFactory.java:238) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.createEmbeddedServletContainer(EmbeddedWebApplicationContext.java:164) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.onRefresh(EmbeddedWebApplicationContext.java:134) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] ... 16 common frames omitted Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'tracingFilter' defined in class path resource [io/opentracing/contrib/spring/web/autoconfig/ServerTracingAutoConfiguration.class]: Unsatisfied dependency expressed through method 'tracingFilter' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'noopTracer' defined in class path resource [io/opentracing/contrib/spring/web/autoconfig/TracerAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.opentracing.Tracer]: Factory method 'noopTracer' threw exception; nested exception is java.lang.NoClassDefFoundError: io/opentracing/NoopTracer at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:749) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:467) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1178) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1072) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:511) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:481) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:312) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:308) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.boot.web.servlet.ServletContextInitializerBeans.getOrderedBeansOfType(ServletContextInitializerBeans.java:234) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.web.servlet.ServletContextInitializerBeans.getOrderedBeansOfType(ServletContextInitializerBeans.java:215) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.web.servlet.ServletContextInitializerBeans.addServletContextInitializerBeans(ServletContextInitializerBeans.java:91) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.web.servlet.ServletContextInitializerBeans.&lt;init&gt;(ServletContextInitializerBeans.java:79) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.getServletContextInitializerBeans(EmbeddedWebApplicationContext.java:241) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.selfInitialize(EmbeddedWebApplicationContext.java:228) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.access$000(EmbeddedWebApplicationContext.java:89) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext$1.onStartup(EmbeddedWebApplicationContext.java:213) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.context.embedded.undertow.UndertowEmbeddedServletContainerFactory$Initializer.onStartup(UndertowEmbeddedServletContainerFactory.java:734) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at io.undertow.servlet.core.DeploymentManagerImpl$1.call(DeploymentManagerImpl.java:192) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.core.DeploymentManagerImpl$1.call(DeploymentManagerImpl.java:174) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:42) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.core.DeploymentManagerImpl.deploy(DeploymentManagerImpl.java:239) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] ... 20 common frames omitted Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'noopTracer' defined in class path resource [io/opentracing/contrib/spring/web/autoconfig/TracerAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.opentracing.Tracer]: Factory method 'noopTracer' threw exception; nested exception is java.lang.NoClassDefFoundError: io/opentracing/NoopTracer at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:599) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1178) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1072) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:511) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:481) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:312) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:308) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1136) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1064) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:835) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:741) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] ... 43 common frames omitted Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.opentracing.Tracer]: Factory method 'noopTracer' threw exception; nested exception is java.lang.NoClassDefFoundError: io/opentracing/NoopTracer at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:189) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] ... 56 common frames omitted Caused by: java.lang.NoClassDefFoundError: io/opentracing/NoopTracer at io.opentracing.contrib.spring.web.autoconfig.TracerAutoConfiguration.noopTracer(TracerAutoConfiguration.java:23) ~[opentracing-spring-web-autoconfigure-0.0.4.jar!/:na] at io.opentracing.contrib.spring.web.autoconfig.TracerAutoConfiguration$$EnhancerBySpringCGLIB$$b2fc646f.CGLIB$noopTracer$0(&lt;generated&gt;) ~[opentracing-spring-web-autoconfigure-0.0.4.jar!/:na] at io.opentracing.contrib.spring.web.autoconfig.TracerAutoConfiguration$$EnhancerBySpringCGLIB$$b2fc646f$$FastClassBySpringCGLIB$$4593bd2f.invoke(&lt;generated&gt;) ~[opentracing-spring-web-autoconfigure-0.0.4.jar!/:na] at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228) ~[spring-core-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.opentracing.contrib.spring.web.autoconfig.TracerAutoConfiguration$$EnhancerBySpringCGLIB$$b2fc646f.noopTracer(&lt;generated&gt;) ~[opentracing-spring-web-autoconfigure-0.0.4.jar!/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_191] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_191] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_191] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_191] at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] ... 57 common frames omitted Caused by: java.lang.ClassNotFoundException: io.opentracing.NoopTracer at java.net.URLClassLoader.findClass(URLClassLoader.java:382) ~[na:1.8.0_191] at java.lang.ClassLoader.loadClass(ClassLoader.java:424) ~[na:1.8.0_191] at org.springframework.boot.loader.LaunchedURLClassLoader.loadClass(LaunchedURLClassLoader.java:94) ~[project-0.1-SNAPSHOT.jar:na] at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ~[na:1.8.0_191] ... 68 common frames omitted ``` </body>
		<created>2019-04-29 09:04:39</created>
		<closed>2019-05-02 07:16:57</closed>
	</bug>
	<bug>
		<id>5282</id>
		<title>[SQS] ARN as queue name results in No enum constant com.amazonaws.regions.Regions.us-west-1</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The ARN of my queue is `arn:aws:sqs:us-west-1:928544467084:in` and  when I use it as the queue name, the integration startup fails with:  ``` 2019-04-26 12:22:40.788  INFO 1 --- [           main] i.s.i.c.proxy.ComponentProxyComponent    : Connector resolved: aws-sqs-0-0 -&gt; aws-sqs://arn:aws:sqs:us-west-1:928544467084:in?accessKey=RAW(&lt;key here&gt;)&amp;delay=500&amp;deleteAfterRead=true&amp;deleteIfFiltered=true&amp;maxMessagesPerPoll=1&amp;region=US_WEST_1&amp;secretKey=xxxxxx 2019-04-26 12:22:40.942  INFO 1 --- [           main] i.s.i.c.proxy.ComponentProxyComponent    : Connector resolved: aws-sqs-0-1 -&gt; aws-sqs://arn:aws:sqs:us-west-1:928544467084:out?accessKey=RAW(&lt;key here&gt;)&amp;delaySeconds=0&amp;messageDeduplicationIdStrategy=useExchangeId&amp;messageGroupIdStrategy=useConstant&amp;region=US_WEST_1&amp;secretKey=xxxxxx 2019-04-26 12:22:40.991  INFO 1 --- [           main] o.a.c.impl.DefaultStreamCachingStrategy  : StreamCaching in use with spool directory: /tmp/camel/camel-tmp-ddc47350-ff7a-42d9-aaa8-6468cd8fd438 and rules: [Spool &gt; 128K body size] 2019-04-26 12:22:41.035  INFO 1 --- [           main] o.a.camel.spring.SpringCamelContext      : Apache Camel 2.21.0.fuse-740005 (CamelContext: sqs) is shutting down 2019-04-26 12:22:41.058 DEBUG 1 --- [           main] i.s.i.c.proxy.ComponentProxyComponent    : Stopping connector: aws-sqs-0-1 2019-04-26 12:22:41.058 DEBUG 1 --- [           main] i.s.i.c.proxy.ComponentProxyComponent    : Stopping connector: aws-sqs-0-0 2019-04-26 12:22:41.073  INFO 1 --- [           main] o.a.camel.spring.SpringCamelContext      : Apache Camel 2.21.0.fuse-740005 (CamelContext: sqs) uptime 0.607 seconds 2019-04-26 12:22:41.076  INFO 1 --- [           main] o.a.camel.spring.SpringCamelContext      : Apache Camel 2.21.0.fuse-740005 (CamelContext: sqs) is shutdown in 0.041 seconds 2019-04-26 12:22:41.090  INFO 1 --- [           main] utoConfigurationReportLoggingInitializer :  Error starting ApplicationContext. To display the auto-configuration report re-run your application with 'debug' enabled. 2019-04-26 12:22:41.120 ERROR 1 --- [           main] o.s.boot.SpringApplication               : Application startup failed org.apache.camel.RuntimeCamelException: org.apache.camel.FailedToCreateRouteException: Failed to create route -LdOZtsXN9q6Eay-U8rp: Route(-LdOZtsXN9q6Eay-U8rp)[[From[aws-sqs-0-0]] -&gt; [SetHeade... because of No enum constant com.amazonaws.regions.Regions.us-west-1 at org.apache.camel.util.ObjectHelper.wrapRuntimeCamelException(ObjectHelper.java:1830) ~[camel-core-2.21.0.fuse-740005.jar!/:2.21.0.fuse-740005] at org.apache.camel.spring.SpringCamelContext.start(SpringCamelContext.java:136) ~[camel-spring-2.21.0.fuse-740005.jar!/:2.21.0.fuse-740005] at org.apache.camel.spring.SpringCamelContext.onApplicationEvent(SpringCamelContext.java:174) ~[camel-spring-2.21.0.fuse-740005.jar!/:2.21.0.fuse-740005] at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:393) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:347) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:883) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.finishRefresh(EmbeddedWebApplicationContext.java:144) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at io.syndesis.example.Application.main(Application.java:13) [classes!/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_191] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_191] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_191] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_191] at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.Launcher.launch(Launcher.java:87) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.Launcher.launch(Launcher.java:50) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.PropertiesLauncher.main(PropertiesLauncher.java:595) [project-0.1-SNAPSHOT.jar:na] Caused by: org.apache.camel.FailedToCreateRouteException: Failed to create route -LdOZtsXN9q6Eay-U8rp: Route(-LdOZtsXN9q6Eay-U8rp)[[From[aws-sqs-0-0]] -&gt; [SetHeade... because of No enum constant com.amazonaws.regions.Regions.us-west-1 at org.apache.camel.impl.RouteService.warmUp(RouteService.java:147) ~[camel-core-2.21.0.fuse-740005.jar!/:2.21.0.fuse-740005] at org.apache.camel.impl.DefaultCamelContext.doWarmUpRoutes(DefaultCamelContext.java:3947) ~[camel-core-2.21.0.fuse-740005.jar!/:2.21.0.fuse-740005] at org.apache.camel.impl.DefaultCamelContext.safelyStartRouteServices(DefaultCamelContext.java:3854) ~[camel-core-2.21.0.fuse-740005.jar!/:2.21.0.fuse-740005] at org.apache.camel.impl.DefaultCamelContext.doStartOrResumeRoutes(DefaultCamelContext.java:3640) ~[camel-core-2.21.0.fuse-740005.jar!/:2.21.0.fuse-740005] at org.apache.camel.impl.DefaultCamelContext.doStartCamel(DefaultCamelContext.java:3492) ~[camel-core-2.21.0.fuse-740005.jar!/:2.21.0.fuse-740005] at org.apache.camel.impl.DefaultCamelContext.access$000(DefaultCamelContext.java:209) ~[camel-core-2.21.0.fuse-740005.jar!/:2.21.0.fuse-740005] at org.apache.camel.impl.DefaultCamelContext$2.call(DefaultCamelContext.java:3251) ~[camel-core-2.21.0.fuse-740005.jar!/:2.21.0.fuse-740005] at org.apache.camel.impl.DefaultCamelContext$2.call(DefaultCamelContext.java:3247) ~[camel-core-2.21.0.fuse-740005.jar!/:2.21.0.fuse-740005] at org.apache.camel.impl.DefaultCamelContext.doWithDefinedClassLoader(DefaultCamelContext.java:3270) ~[camel-core-2.21.0.fuse-740005.jar!/:2.21.0.fuse-740005] at org.apache.camel.impl.DefaultCamelContext.doStart(DefaultCamelContext.java:3247) ~[camel-core-2.21.0.fuse-740005.jar!/:2.21.0.fuse-740005] at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.21.0.fuse-740005.jar!/:2.21.0.fuse-740005] at org.apache.camel.impl.DefaultCamelContext.start(DefaultCamelContext.java:3163) ~[camel-core-2.21.0.fuse-740005.jar!/:2.21.0.fuse-740005] at org.apache.camel.spring.SpringCamelContext.start(SpringCamelContext.java:133) ~[camel-spring-2.21.0.fuse-740005.jar!/:2.21.0.fuse-740005] ... 24 common frames omitted Caused by: java.lang.IllegalArgumentException: No enum constant com.amazonaws.regions.Regions.us-west-1 at java.lang.Enum.valueOf(Enum.java:238) ~[na:1.8.0_191] at com.amazonaws.regions.Regions.valueOf(Regions.java:26) ~[aws-java-sdk-core-1.11.269.jar!/:na] at org.apache.camel.component.aws.sqs.SqsEndpoint.createClient(SqsEndpoint.java:314) ~[camel-aws-2.21.0.fuse-740005.jar!/:2.21.0.fuse-740005] at org.apache.camel.component.aws.sqs.SqsEndpoint.getClient(SqsEndpoint.java:274) ~[camel-aws-2.21.0.fuse-740005.jar!/:2.21.0.fuse-740005] at org.apache.camel.component.aws.sqs.SqsEndpoint.doStart(SqsEndpoint.java:117) ~[camel-aws-2.21.0.fuse-740005.jar!/:2.21.0.fuse-740005] at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.21.0.fuse-740005.jar!/:2.21.0.fuse-740005] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.21.0.fuse-740005.jar!/:2.21.0.fuse-740005] at io.syndesis.integration.component.proxy.ComponentProxyEndpoint.doStart(ComponentProxyEndpoint.java:152) ~[integration-component-proxy-1.7-SNAPSHOT.jar!/:1.7-SNAPSHOT] at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.21.0.fuse-740005.jar!/:2.21.0.fuse-740005] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.21.0.fuse-740005.jar!/:2.21.0.fuse-740005] at org.apache.camel.impl.RouteService.doWarmUp(RouteService.java:157) ~[camel-core-2.21.0.fuse-740005.jar!/:2.21.0.fuse-740005] at org.apache.camel.impl.RouteService.warmUp(RouteService.java:145) ~[camel-core-2.21.0.fuse-740005.jar!/:2.21.0.fuse-740005] ... 36 common frames omitted  ```  It works when I manually change the region in the ARN from `us-west-1` to `US_WEST_1` </body>
		<created>2019-04-26 12:45:09</created>
		<closed>2019-04-29 18:29:37</closed>
	</bug>
	<bug>
		<id>5268</id>
		<title>[Master][HTTP] No bean could be found in the registry for: syndesisHeaderStrategy</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Any integration with HTTP endpoint fails with:   ``` org.apache.camel.RuntimeCamelException: org.apache.camel.FailedToCreateRouteException: Failed to create route -Ld7x2rredgAbVyxhcJc at: &gt;&gt;&gt; To[http4-0-0] &lt;&lt;&lt; in route: Route(-Ld7x2rredgAbVyxhcJc)[[From[timer:integration?period=3... because of Failed to resolve endpoint: http4-0-0 due to: Failed to resolve endpoint: http4://http-svc:8080/?headerFilterStrategy=syndesisHeaderStrategy&amp;httpClient.redirectsEnabled=true&amp;httpMethod=GET due to: No bean could be found in the registry for: syndesisHeaderStrategy of type: org.apache.camel.spi.HeaderFilterStrategy at org.apache.camel.util.ObjectHelper.wrapRuntimeCamelException(ObjectHelper.java:1830) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.spring.SpringCamelContext.start(SpringCamelContext.java:136) ~[camel-spring-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.spring.SpringCamelContext.onApplicationEvent(SpringCamelContext.java:174) ~[camel-spring-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:393) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:347) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:883) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.finishRefresh(EmbeddedWebApplicationContext.java:144) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at io.syndesis.example.Application.main(Application.java:13) [classes!/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_191] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_191] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_191] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_191] at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.Launcher.launch(Launcher.java:87) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.Launcher.launch(Launcher.java:50) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.PropertiesLauncher.main(PropertiesLauncher.java:595) [project-0.1-SNAPSHOT.jar:na] Caused by: org.apache.camel.FailedToCreateRouteException: Failed to create route -Ld7x2rredgAbVyxhcJc at: &gt;&gt;&gt; To[http4-0-0] &lt;&lt;&lt; in route: Route(-Ld7x2rredgAbVyxhcJc)[[From[timer:integration?period=3... because of Failed to resolve endpoint: http4-0-0 due to: Failed to resolve endpoint: http4://http-svc:8080/?headerFilterStrategy=syndesisHeaderStrategy&amp;httpClient.redirectsEnabled=true&amp;httpMethod=GET due to: No bean could be found in the registry for: syndesisHeaderStrategy of type: org.apache.camel.spi.HeaderFilterStrategy at org.apache.camel.model.RouteDefinition.addRoutes(RouteDefinition.java:1303) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.model.RouteDefinition.addRoutes(RouteDefinition.java:204) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.impl.DefaultCamelContext.startRoute(DefaultCamelContext.java:1143) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.impl.DefaultCamelContext.startRouteDefinitions(DefaultCamelContext.java:3729) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.impl.DefaultCamelContext.doStartCamel(DefaultCamelContext.java:3443) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.impl.DefaultCamelContext.access$000(DefaultCamelContext.java:209) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.impl.DefaultCamelContext$2.call(DefaultCamelContext.java:3251) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.impl.DefaultCamelContext$2.call(DefaultCamelContext.java:3247) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.impl.DefaultCamelContext.doWithDefinedClassLoader(DefaultCamelContext.java:3270) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.impl.DefaultCamelContext.doStart(DefaultCamelContext.java:3247) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.impl.DefaultCamelContext.start(DefaultCamelContext.java:3163) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.spring.SpringCamelContext.start(SpringCamelContext.java:133) ~[camel-spring-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] ... 24 common frames omitted Caused by: org.apache.camel.ResolveEndpointFailedException: Failed to resolve endpoint: http4-0-0 due to: Failed to resolve endpoint: http4://http-svc:8080/?headerFilterStrategy=syndesisHeaderStrategy&amp;httpClient.redirectsEnabled=true&amp;httpMethod=GET due to: No bean could be found in the registry for: syndesisHeaderStrategy of type: org.apache.camel.spi.HeaderFilterStrategy at org.apache.camel.impl.DefaultCamelContext.getEndpoint(DefaultCamelContext.java:758) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.util.CamelContextHelper.getMandatoryEndpoint(CamelContextHelper.java:80) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.model.RouteDefinition.resolveEndpoint(RouteDefinition.java:219) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.impl.DefaultRouteContext.resolveEndpoint(DefaultRouteContext.java:115) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.impl.DefaultRouteContext.resolveEndpoint(DefaultRouteContext.java:121) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.model.SendDefinition.resolveEndpoint(SendDefinition.java:62) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.model.SendDefinition.createProcessor(SendDefinition.java:56) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.model.ProcessorDefinition.makeProcessorImpl(ProcessorDefinition.java:562) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.model.ProcessorDefinition.makeProcessor(ProcessorDefinition.java:523) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.model.ProcessorDefinition.addRoutes(ProcessorDefinition.java:239) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.model.RouteDefinition.addRoutes(RouteDefinition.java:1300) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] ... 36 common frames omitted Caused by: org.apache.camel.ResolveEndpointFailedException: Failed to resolve endpoint: http4://http-svc:8080/?headerFilterStrategy=syndesisHeaderStrategy&amp;httpClient.redirectsEnabled=true&amp;httpMethod=GET due to: No bean could be found in the registry for: syndesisHeaderStrategy of type: org.apache.camel.spi.HeaderFilterStrategy at org.apache.camel.impl.DefaultCamelContext.getEndpoint(DefaultCamelContext.java:758) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at io.syndesis.connector.http.HttpConnectorFactories$Http4$1.createDelegateEndpoint(HttpConnectorFactories.java:68) ~[connector-http-1.7-SNAPSHOT.jar!/:1.7-SNAPSHOT] at io.syndesis.integration.component.proxy.ComponentProxyComponent.createEndpoint(ComponentProxyComponent.java:133) ~[integration-component-proxy-1.7-SNAPSHOT.jar!/:1.7-SNAPSHOT] at org.apache.camel.impl.DefaultComponent.createEndpoint(DefaultComponent.java:130) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.impl.DefaultCamelContext.getEndpoint(DefaultCamelContext.java:743) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] ... 46 common frames omitted Caused by: org.apache.camel.NoSuchBeanException: No bean could be found in the registry for: syndesisHeaderStrategy of type: org.apache.camel.spi.HeaderFilterStrategy at org.apache.camel.util.CamelContextHelper.mandatoryLookupAndConvert(CamelContextHelper.java:201) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.util.EndpointHelper.resolveReferenceParameter(EndpointHelper.java:324) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.util.EndpointHelper.resolveReferenceParameter(EndpointHelper.java:306) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.impl.DefaultComponent.resolveAndRemoveReferenceParameter(DefaultComponent.java:429) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.impl.DefaultComponent.resolveAndRemoveReferenceParameter(DefaultComponent.java:408) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.component.http4.HttpComponent.createEndpoint(HttpComponent.java:234) ~[camel-http4-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.impl.DefaultComponent.createEndpoint(DefaultComponent.java:130) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.impl.DefaultCamelContext.getEndpoint(DefaultCamelContext.java:711) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] ... 50 common frames omitted ```</body>
		<created>2019-04-23 06:52:58</created>
		<closed>2019-05-02 07:16:22</closed>
	</bug>
	<bug>
		<id>5256</id>
		<title>Extension maven plugin fails on Maven 3.6</title>
		<body>## This is a...   - [ ] Feature request  - [ ] Regression (a behavior that used to work and stopped working in a new release)  - [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt;  - [ ] Documentation issue or request  ## Description  This is the error on Maven 3.6.1:  ``` [ERROR] Failed to execute goal io.syndesis.extension:extension-maven-plugin:1.6.12:repackage-extension (default) on project syndesis-http-error-handling-extension: Execution default of goal io.syndesis.extension:extension-maven-plugin:1.6.12:repackage-extension failed: Unable to invoke onlyOne([Ljava.lang.Class;@5ea9373e) on object org.jboss.shrinkwrap.resolver.spi.loader.ServiceRegistry with parameters [Ljava.lang.Object;@3e595da3: InvocationTargetException: Could not create new service instance: org/eclipse/aether/internal/impl/DefaultDependencyCollector: org.eclipse.aether.internal.impl.DefaultDependencyCollector -&gt; [Help 1] ```</body>
		<created>2019-04-18 13:20:04</created>
		<closed>2019-08-22 06:00:39</closed>
	</bug>
	<bug>
		<id>5255</id>
		<title>Icon of a step extension not visible</title>
		<body>## This is a...   - [ ] Feature request  - [ ] Regression (a behavior that used to work and stopped working in a new release)  - [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt;  - [ ] Documentation issue or request  ## Description  Icon placed in `src/main/resources/META-INF/syndesis/icon.[svg|png]` is bundled but not presented in the UI. The `icon` property points to `extension:icon.[svg|png]` which is directly rendered for `src` attribute of an `&lt;img&gt;`.</body>
		<created>2019-04-18 11:26:53</created>
		<closed>2019-06-06 07:40:37</closed>
	</bug>
	<bug>
		<id>5253</id>
		<title>[camel-k] metrics : IllegalStateException thrown by prometheus provider</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  I sometime experience the following error while running an integration using camel-k and then scale it to replicas &gt; 1:  ```  java.lang.IllegalStateException: Duplicate key 19365  at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133) ~[na:1.8.0_151]  at java.util.HashMap.merge(HashMap.java:1254) ~[na:1.8.0_151]  at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320) ~[na:1.8.0_151]  at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ~[na:1.8.0_151]  at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1380) ~[na:1.8.0_151]  at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ~[na:1.8.0_151]  at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ~[na:1.8.0_151]  at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ~[na:1.8.0_151]  at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[na:1.8.0_151]  at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ~[na:1.8.0_151]  at io.syndesis.server.metrics.prometheus.QueryResult.lambda$getValueMap$5(QueryResult.java:61) ~[server-metrics-prometheus-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT]  at java.util.Optional.map(Optional.java:215) ~[na:1.8.0_151]  at io.syndesis.server.metrics.prometheus.QueryResult.getValueMap(QueryResult.java:60) ~[server-metrics-prometheus-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT]  at io.syndesis.server.metrics.prometheus.PrometheusMetricsProviderImpl.getTopIntegrations(PrometheusMetricsProviderImpl.java:255) ~[server-metrics-prometheus-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT]  at io.syndesis.server.metrics.prometheus.PrometheusMetricsProviderImpl.getTotalIntegrationMetricsSummary(PrometheusMetricsProviderImpl.java:212) ~[server-metrics-prometheus-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT]  at io.syndesis.server.endpoint.v1.handler.metrics.IntegrationMetricsHandler.get(IntegrationMetricsHandler.java:65) ~[server-endpoint-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT]  at sun.reflect.GeneratedMethodAccessor632.invoke(Unknown Source) ~[na:na]  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151]  at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151] ```  </body>
		<created>2019-04-18 10:53:14</created>
		<closed>2019-05-27 12:45:41</closed>
	</bug>
	<bug>
		<id>5250</id>
		<title>Migrate old style API connectors</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When importing an integration with a API connector, the connector and and the OpenAPI specification get imported into Syndesis, but building the integration using this connector fails when assembling.  Also if this is meant to happen, something should indicate inside Syndesis that the integration is in invalid state because the integration status also changes from **starting** to **building** even though there is no build pod present. Which makes the user just what is taking so long.  Sample integration: [https://drive.google.com/open?id=1l9A5lS8l1EdsyyVSaj7bej0BFlOw1Rk-](https://drive.google.com/open?id=1l9A5lS8l1EdsyyVSaj7bej0BFlOw1Rk-)  Stacktrace: ``` java.lang.UnsupportedOperationException: Old style of connectors from camel-connector are not supported anymore, please be sure that integration json satisfy connector.getComponentScheme().isPresent() || descriptor.getComponentScheme().isPresent() at io.syndesis.integration.project.generator.ProjectGenerator.generateApplicationProperties(ProjectGenerator.java:174) ~[integration-project-generator-1.7-SNAPSHOT.jar!/:1.7-SNAPSHOT] at io.syndesis.server.controller.integration.online.PublishHandler.createDeploymentData(PublishHandler.java:136) ~[server-controller-1.7-SNAPSHOT.jar!/:1.7-SNAPSHOT] at io.syndesis.server.controller.integration.online.PublishHandler.execute(PublishHandler.java:99) ~[server-controller-1.7-SNAPSHOT.jar!/:1.7-SNAPSHOT] at io.syndesis.server.controller.StateChangeHandler.execute(StateChangeHandler.java:33) [server-controller-1.7-SNAPSHOT.jar!/:1.7-SNAPSHOT] at io.syndesis.server.controller.integration.BaseIntegrationController.lambda$callStateChangeHandler$10(BaseIntegrationController.java:220) [server-controller-1.7-SNAPSHOT.jar!/:1.7-SNAPSHOT] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_151] at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_151] ```</body>
		<created>2019-04-18 07:52:30</created>
		<closed>2019-06-06 08:21:27</closed>
	</bug>
	<bug>
		<id>5244</id>
		<title>Integrations don't start on master</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description After publishing an integration, the integration builds successfully but the deploy pod finishes in a few seconds and the integration pod gets created but errors out after just booting up.  Attaching log from the integration pod: ``` Starting the Java application using /opt/run-java/run-java.sh ... exec java -javaagent:/opt/jolokia/jolokia.jar=config=/opt/jolokia/etc/jolokia.properties -javaagent:/opt/prometheus/jmx_prometheus_javaagent.jar=9779:/tmp/src/prometheus-config.yml -XX:+UseParallelGC -XX:GCTimeRatio=4 -XX:AdaptiveSizePolicyWeight=90 -XX:MinHeapFreeRatio=20 -XX:MaxHeapFreeRatio=40 -XX:+ExitOnOutOfMemoryError -cp . -jar /deployments/project-0.1-SNAPSHOT.jar OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N I&gt; No access restrictor found, access to any MBean is allowed Jolokia: Agent started with URL https://172.17.0.11:8778/jolokia/        _______.                 _               _     /       |                 | |             (_)    |   (----`_   _  ____    _ | |  ____   ___  _   ___     \   \   | | | ||  _ \  / || | / _  ) /___)| | /___) .----)   |  | |_| || | | |( (_| |( (/ / |___ || ||___ | |_______/    \__  ||_| |_| \____| \____)(___/ |_|(___/ ============ (____/ =================================== :: Integration ::  :: v 2019-04-17 07:00:02.440  INFO 1 --- [           main] io.syndesis.example.Application          : Starting Application on i-test-4-9prwh with PID 1 (/deployments/project-0.1-SNAPSHOT.jar started by jboss in /deployments) 2019-04-17 07:00:02.455 DEBUG 1 --- [           main] io.syndesis.example.Application          : Running with Spring Boot v1.5.16.RELEASE, Spring v4.3.19.RELEASE 2019-04-17 07:00:02.456  INFO 1 --- [           main] io.syndesis.example.Application          : No active profile set, falling back to default profiles: default 2019-04-17 07:00:02.667  INFO 1 --- [           main] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@3ec300f1: startup date [Wed Apr 17 07:00:02 UTC 2019]; root of context hierarchy 2019-04-17 07:00:03.453  WARN 1 --- [           main] ationConfigEmbeddedWebApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanDefinitionStoreException: Failed to process import candidates for configuration class [io.syndesis.example.Application]; nested exception is java.lang.IllegalStateException: Unable to read meta-data for class  io.syndesis.integration.runtime.sb.jmx.IntegrationMetadataAutoConfiguration 2019-04-17 07:00:03.613 ERROR 1 --- [           main] o.s.boot.SpringApplication               : Application startup failed org.springframework.beans.factory.BeanDefinitionStoreException: Failed to process import candidates for configuration class [io.syndesis.example.Application]; nested exception is java.lang.IllegalStateException: Unable to read meta-data for class  io.syndesis.integration.runtime.sb.jmx.IntegrationMetadataAutoConfiguration at org.springframework.context.annotation.ConfigurationClassParser.processDeferredImportSelectors(ConfigurationClassParser.java:561) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.annotation.ConfigurationClassParser.parse(ConfigurationClassParser.java:187) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:308) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:228) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:272) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:92) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:687) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:525) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at io.syndesis.example.Application.main(Application.java:13) [classes!/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_191] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_191] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_191] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_191] at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.Launcher.launch(Launcher.java:87) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.Launcher.launch(Launcher.java:50) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.PropertiesLauncher.main(PropertiesLauncher.java:595) [project-0.1-SNAPSHOT.jar:na] Caused by: java.lang.IllegalStateException: Unable to read meta-data for class  io.syndesis.integration.runtime.sb.jmx.IntegrationMetadataAutoConfiguration at org.springframework.boot.autoconfigure.AutoConfigurationSorter$AutoConfigurationClass.getAnnotationMetadata(AutoConfigurationSorter.java:217) ~[spring-boot-autoconfigure-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.autoconfigure.AutoConfigurationSorter$AutoConfigurationClass.getAnnotationValue(AutoConfigurationSorter.java:198) ~[spring-boot-autoconfigure-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.autoconfigure.AutoConfigurationSorter$AutoConfigurationClass.readBefore(AutoConfigurationSorter.java:186) ~[spring-boot-autoconfigure-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.autoconfigure.AutoConfigurationSorter$AutoConfigurationClass.&lt;init&gt;(AutoConfigurationSorter.java:158) ~[spring-boot-autoconfigure-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.autoconfigure.AutoConfigurationSorter$AutoConfigurationClasses.&lt;init&gt;(AutoConfigurationSorter.java:115) ~[spring-boot-autoconfigure-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.autoconfigure.AutoConfigurationSorter.getInPriorityOrder(AutoConfigurationSorter.java:57) ~[spring-boot-autoconfigure-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.autoconfigure.AutoConfigurationImportSelector.sort(AutoConfigurationImportSelector.java:241) ~[spring-boot-autoconfigure-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.autoconfigure.AutoConfigurationImportSelector.selectImports(AutoConfigurationImportSelector.java:98) ~[spring-boot-autoconfigure-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.context.annotation.ConfigurationClassParser.processDeferredImportSelectors(ConfigurationClassParser.java:552) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] ... 22 common frames omitted Caused by: java.io.FileNotFoundException: class path resource [ io/syndesis/integration/runtime/sb/jmx/IntegrationMetadataAutoConfiguration.class] cannot be opened because it does not exist at org.springframework.core.io.ClassPathResource.getInputStream(ClassPathResource.java:172) ~[spring-core-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.core.type.classreading.SimpleMetadataReader.&lt;init&gt;(SimpleMetadataReader.java:50) ~[spring-core-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.core.type.classreading.SimpleMetadataReaderFactory.getMetadataReader(SimpleMetadataReaderFactory.java:102) ~[spring-core-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.boot.type.classreading.ConcurrentReferenceCachingMetadataReaderFactory.createMetadataReader(ConcurrentReferenceCachingMetadataReaderFactory.java:89) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.type.classreading.ConcurrentReferenceCachingMetadataReaderFactory.getMetadataReader(ConcurrentReferenceCachingMetadataReaderFactory.java:76) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.core.type.classreading.SimpleMetadataReaderFactory.getMetadataReader(SimpleMetadataReaderFactory.java:80) ~[spring-core-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.boot.autoconfigure.AutoConfigurationSorter$AutoConfigurationClass.getAnnotationMetadata(AutoConfigurationSorter.java:213) ~[spring-boot-autoconfigure-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] ... 30 common frames omitted  ``` </body>
		<created>2019-04-17 07:04:59</created>
		<closed>2019-04-17 12:14:49</closed>
	</bug>
	<bug>
		<id>5241</id>
		<title>Passing String as key predicate to OData connection</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Trying to create simple integration OData (Read) -&gt; Data Mapper -&gt; OData (Update). In the Data Mapper, tried to set a string as keyPredicate, and when I ran it, I got error  ``` org.apache.camel.RuntimeCamelException: Error invoking patch with {endpointHttpHeaders={}, keyPredicate=russellwhyte, responseHandler=org.apache.camel.component.olingo4.Olingo4Producer$1@1bfbd9df, data={"LastName":"Whyte","UserName":"russellwhyte","FirstName":"Russell","MiddleName":"Heyyy"}, filterAlreadySeen=false, resourcePath=People(russellwhyte), edm=org.apache.olingo.commons.core.edm.EdmProviderImpl@4a59d5cc}: parseUri (People(russellwhyte),null): Unknown key property russellwhyte ``` It seems it is trying to reach People(russellwhyte) instead of People('russellwhyte'), and so ends with Error.</body>
		<created>2019-04-16 20:25:24</created>
		<closed>2019-07-22 12:04:41</closed>
	</bug>
	<bug>
		<id>5234</id>
		<title>Box - OutputDataShape java.io.OutputStream not needed as it can't be mapped to anything</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [X] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description `Download file` action specifies the datashape as `java.io.OutputStream` and that is not needed, as it can't be mapped to anything.   ![dm](https://user-images.githubusercontent.com/7081216/56188693-75081b00-6026-11e9-95d9-9d40afa2d1e7.png)  It would be better if the connector was returning some custom structure (if it is possible) with properties like `fileName` `content` `size` `...` that could be mapped to something </body>
		<created>2019-04-16 07:04:55</created>
		<closed>2019-06-24 12:46:40</closed>
	</bug>
	<bug>
		<id>5233</id>
		<title>Box - no property for fileName in upload action</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11433**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The only property for box upload action is `parentFolderId` and when I try to use box connector in `SQL -&gt; Box` integration, it fails with `Missing properties for upload, need one or more from [fileName, size, created, listener, modified]`   ``` {"exchange":"i-LcZtWP4KguUebqgO_N7z","step":"-LcZtDcRXiVo7s6EHBN3","id":"i-LcZtWWMKguUebqgO_N9z","duration":1201657626} 2019-04-16 06:47:01.656 ERROR 1 --- [r://integration] o.a.camel.processor.DefaultErrorHandler  : Failed delivery for (MessageId: i-LcZtWo8KguUebqgO_NAz on ExchangeId: i-LcZtWP4KguUebqgO_N7z). Exhausted after delivery attempt: 1 caught: org.apache.camel.RuntimeCamelException: Missing properties for upload, need one or more from [fileName, size, created, listener, modified] Message History --------------------------------------------------------------------------------------------------------------------------------------- RouteId              ProcessorId          Processor                                                                        Elapsed (ms) [-LcZsyC-XiVo7s6EHB] [-LcZsyC-XiVo7s6EHB] [timer://integration?period=60000                                              ] [      1677] [-LcZsyC-XiVo7s6EHB] [setHeader1        ] [setHeader[Syndesis.FLOW_ID]                                                   ] [         4] [-LcZsyC-XiVo7s6EHB] [to1               ] [sql-0-0                                                                       ] [       430] [-LcZsyC-XiVo7s6EHB] [setHeader2        ] [setHeader[Syndesis.STEP_ID]                                                   ] [         0] [-LcZsyC-XiVo7s6EHB] [process1          ] [Processor@0x7f4d33c3                                                          ] [        13] [-LcZsyC-XiVo7s6EHB] [step:-LcZtDcRXiVo7] [pipeline                                                                      ] [      1204] [-LcZsyC-XiVo7s6EHB] [setHeader3        ] [setHeader[Syndesis.STEP_ID]                                                   ] [         0] [-LcZsyC-XiVo7s6EHB] [process2          ] [Processor@0x78662cd5                                                          ] [         3] [-LcZsyC-XiVo7s6EHB] [to2               ] [atlas:mapping-flow-0-step-1.json?encoding=UTF-8&amp;sourceMapName=Syndesis.CAPTURE] [      1178] [-LcZsyC-XiVo7s6EHB] [process3          ] [Processor@0x2507613b                                                          ] [         0] [-LcZsyC-XiVo7s6EHB] [process4          ] [Processor@0x7f4d33c3                                                          ] [         0] [-LcZsyC-XiVo7s6EHB] [step:-LcZt-nsXiVo7] [pipeline                                                                      ] [         0] [-LcZsyC-XiVo7s6EHB] [setHeader4        ] [setHeader[Syndesis.STEP_ID]                                                   ] [         0] [-LcZsyC-XiVo7s6EHB] [to3               ] [box-0-2                                                                       ] [         3] Stacktrace --------------------------------------------------------------------------------------------------------------------------------------- org.apache.camel.RuntimeCamelException: Missing properties for upload, need one or more from [fileName, size, created, listener, modified] at org.apache.camel.util.component.AbstractApiProducer.findMethod(AbstractApiProducer.java:149) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.util.component.AbstractApiProducer.process(AbstractApiProducer.java:69) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at io.syndesis.integration.component.proxy.ComponentProxyProducer.process(ComponentProxyProducer.java:44) ~[integration-component-proxy-1.7.1-20190415.jar!/:1.7.1-20190415] at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) [integration-runtime-1.7.1-20190415.jar!/:1.7.1-20190415] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197) [camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79) [camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at java.util.TimerThread.mainLoop(Timer.java:555) [na:1.8.0_191] at java.util.TimerThread.run(Timer.java:505) [na:1.8.0_191] {"exchange":"i-LcZtWP4KguUebqgO_N7z","step":"-LcZt-nsXiVo7s6EHBN2","id":"i-LcZtWoAKguUebqgO_NBz","duration":12795180,"failure":"org.apache.camel.RuntimeCamelException: Missing properties for upload, need one or more from [fileName, size, created, listener, modified]\n\tat org.apache.camel.util.component.AbstractApiProducer.findMethod(AbstractApiProducer.java:149)\n\tat org.apache.camel.util.component.AbstractApiProducer.process(AbstractApiProducer.java:69)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:138)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:101)\n\tat io.syndesis.integration.component.proxy.ComponentProxyProducer.process(ComponentProxyProducer.java:44)\n\tat org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148)\n\tat org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110)\n\tat org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548)\n\tat org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:138)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:101)\n\tat org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110)\n\tat io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79)\n\tat org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110)\n\tat org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548)\n\tat org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:138)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:101)\n\tat org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201)\n\tat org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197)\n\tat org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79)\n\tat java.util.TimerThread.mainLoop(Timer.java:555)\n\tat java.util.TimerThread.run(Timer.java:505)\n"} {"exchange":"i-LcZtWP4KguUebqgO_N7z","status":"done","failed":true} 2019-04-16 06:47:01.658  WARN 1 --- [r://integration] o.a.camel.component.timer.TimerConsumer  : Error processing exchange. Exchange[i-LcZtWP4KguUebqgO_N7z]. Caused by: [org.apache.camel.RuntimeCamelException - Missing properties for upload, need one or more from [fileName, size, created, listener, modified]] org.apache.camel.RuntimeCamelException: Missing properties for upload, need one or more from [fileName, size, created, listener, modified] at org.apache.camel.util.component.AbstractApiProducer.findMethod(AbstractApiProducer.java:149) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.util.component.AbstractApiProducer.process(AbstractApiProducer.java:69) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at io.syndesis.integration.component.proxy.ComponentProxyProducer.process(ComponentProxyProducer.java:44) ~[integration-component-proxy-1.7.1-20190415.jar!/:1.7.1-20190415] at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) ~[integration-runtime-1.7.1-20190415.jar!/:1.7.1-20190415] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) ~[camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197) [camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79) [camel-core-2.21.0.fuse-740001.jar!/:2.21.0.fuse-740001] at java.util.TimerThread.mainLoop(Timer.java:555) [na:1.8.0_191] at java.util.TimerThread.run(Timer.java:505) [na:1.8.0_191] ``` </body>
		<created>2019-04-16 06:50:53</created>
		<closed>2019-09-07 11:28:17</closed>
	</bug>
	<bug>
		<id>5232</id>
		<title>Meta doesn't start on master</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description ``` org.springframework.beans.factory.BeanDefinitionStoreException: Failed to process import candidates for configuration class [io.syndesis.connector.meta.Application]; nested exception is java.lang.IllegalStateException: Unable to read meta-data for class io.syndesis.integration.runtime.sb.SyndesisHttpConfiguration at org.springframework.context.annotation.ConfigurationClassParser.processDeferredImportSelectors(ConfigurationClassParser.java:561) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.annotation.ConfigurationClassParser.parse(ConfigurationClassParser.java:187) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:308) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:228) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:272) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:92) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:687) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:525) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at io.syndesis.connector.meta.Application.main(Application.java:47) [classes!/:1.7-SNAPSHOT] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_151] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_151] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151] at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48) [meta-1.7-SNAPSHOT.jar:1.7-SNAPSHOT] at org.springframework.boot.loader.Launcher.launch(Launcher.java:87) [meta-1.7-SNAPSHOT.jar:1.7-SNAPSHOT] at org.springframework.boot.loader.Launcher.launch(Launcher.java:50) [meta-1.7-SNAPSHOT.jar:1.7-SNAPSHOT] at org.springframework.boot.loader.PropertiesLauncher.main(PropertiesLauncher.java:595) [meta-1.7-SNAPSHOT.jar:1.7-SNAPSHOT] Caused by: java.lang.IllegalStateException: Unable to read meta-data for class io.syndesis.integration.runtime.sb.SyndesisHttpConfiguration at org.springframework.boot.autoconfigure.AutoConfigurationSorter$AutoConfigurationClass.getAnnotationMetadata(AutoConfigurationSorter.java:217) ~[spring-boot-autoconfigure-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.autoconfigure.AutoConfigurationSorter$AutoConfigurationClass.getAnnotationValue(AutoConfigurationSorter.java:198) ~[spring-boot-autoconfigure-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.autoconfigure.AutoConfigurationSorter$AutoConfigurationClass.readBefore(AutoConfigurationSorter.java:186) ~[spring-boot-autoconfigure-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.autoconfigure.AutoConfigurationSorter$AutoConfigurationClass.&lt;init&gt;(AutoConfigurationSorter.java:158) ~[spring-boot-autoconfigure-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.autoconfigure.AutoConfigurationSorter$AutoConfigurationClasses.&lt;init&gt;(AutoConfigurationSorter.java:115) ~[spring-boot-autoconfigure-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.autoconfigure.AutoConfigurationSorter.getInPriorityOrder(AutoConfigurationSorter.java:57) ~[spring-boot-autoconfigure-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.autoconfigure.AutoConfigurationImportSelector.sort(AutoConfigurationImportSelector.java:241) ~[spring-boot-autoconfigure-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.autoconfigure.AutoConfigurationImportSelector.selectImports(AutoConfigurationImportSelector.java:98) ~[spring-boot-autoconfigure-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.context.annotation.ConfigurationClassParser.processDeferredImportSelectors(ConfigurationClassParser.java:552) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] ... 22 common frames omitted Caused by: java.io.FileNotFoundException: class path resource [io/syndesis/integration/runtime/sb/SyndesisHttpConfiguration.class] cannot be opened because it does not exist at org.springframework.core.io.ClassPathResource.getInputStream(ClassPathResource.java:172) ~[spring-core-4.3.18.RELEASE.jar!/:4.3.18.RELEASE] at org.springframework.core.type.classreading.SimpleMetadataReader.&lt;init&gt;(SimpleMetadataReader.java:50) ~[spring-core-4.3.18.RELEASE.jar!/:4.3.18.RELEASE] at org.springframework.core.type.classreading.SimpleMetadataReaderFactory.getMetadataReader(SimpleMetadataReaderFactory.java:102) ~[spring-core-4.3.18.RELEASE.jar!/:4.3.18.RELEASE] at org.springframework.boot.type.classreading.ConcurrentReferenceCachingMetadataReaderFactory.createMetadataReader(ConcurrentReferenceCachingMetadataReaderFactory.java:89) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.type.classreading.ConcurrentReferenceCachingMetadataReaderFactory.getMetadataReader(ConcurrentReferenceCachingMetadataReaderFactory.java:76) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.core.type.classreading.SimpleMetadataReaderFactory.getMetadataReader(SimpleMetadataReaderFactory.java:80) ~[spring-core-4.3.18.RELEASE.jar!/:4.3.18.RELEASE] at org.springframework.boot.autoconfigure.AutoConfigurationSorter$AutoConfigurationClass.getAnnotationMetadata(AutoConfigurationSorter.java:213) ~[spring-boot-autoconfigure-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] ... 30 common frames omitted ``` </body>
		<created>2019-04-16 06:01:10</created>
		<closed>2019-04-17 08:41:28</closed>
	</bug>
	<bug>
		<id>5225</id>
		<title>OAuth proxy image stream tag mismatch between community and prod version</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11429**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The template generator defines tags for both prod and community templates, but for the community the expected tag for oauth proxy is `v4.0.0`:  https://github.com/syndesisio/syndesis/blob/cda907377a9c6181770f895ec7d5d720117e0854/install/generator/syndesis-template.go#L112-L117  whereas for prod image the expected tag is `v1.1.0:  https://github.com/syndesisio/syndesis/blob/cda907377a9c6181770f895ec7d5d720117e0854/install/generator/syndesis-template.go#L142-L147  Probably not a big deal but it would be good to have it unified  # Related  - https://issues.jboss.org/browse/ENTESB-10377</body>
		<created>2019-04-15 12:54:49</created>
		<closed>2019-09-07 11:24:58</closed>
	</bug>
	<bug>
		<id>5215</id>
		<title>[conditional-flows] UI data shape handling of CBR step</title>
		<body>- A CBR step can be inserted at any point in an existing flow. When added the step adopts the output data shape of the previous step and this is the fixed starting shape of all conditional flows added (= first step in conditional flow provides this shape as fixed output shape). - By default the CBR step has no output shape defined so the conditional flows can produce any output and the primary flow is not able to access the shapes created within the conditional flow. - Changes to the input/output data shapes of the CBR step must be propagated to all sub-flows </body>
		<created>2019-04-15 07:50:39</created>
		<closed>2019-07-17 08:15:24</closed>
	</bug>
	<bug>
		<id>5194</id>
		<title>Provisioning error on openshift online</title>
		<body>When we try to use the **template based install** (read no operators) on openshift online, it fails.  The installation command: ``` Running system command: oc new-app --template=fuse-ignite/fuse-ignite-1.6 -p ROUTE_HOSTNAME=&lt;URL&gt; -p OPENSHIFT_MASTER=https://api.online-stg.openshift.com -p OPENSHIFT_CONSOLE_URL=https://console.online-stg.openshift.com/console -p OPENSHIFT_PROJECT=fuseproj11926 -p OPENSHIFT_OAUTH_CLIENT_SECRET=$(oc sa get-token syndesis-oauth-client -n fuseproj11926) -p MAX_INTEGRATIONS_PER_USER=5 -p SAR_PROJECT=fuseproj11926 -n fuseproj11926 ```  The error: ```     error: roles.rbac.authorization.k8s.io "camel-k" is forbidden: attempt to grant extra privileges: [{[get] [camel.apache.org] [*] [] []} {[list] [camel.apache.org] [*] [] []} {[create] [camel.apache.org] [*] [] []} {[update] [camel.apache.org] [*] [] []} {[delete] [camel.apache.org] [*] [] []} {[deletecollection] [camel.apache.org] [*] [] []} {[watch] [camel.apache.org] [*] [] []}] user=&amp;{system:serviceaccount:openshift-infra:online-registration d9c18dbd-8dd1-11e7-ac2a-022d8035b649 [system:serviceaccounts system:serviceaccounts:openshift-infra system:authenticated] map[]} ownerrules=[{[create delete deletecollection get list patch update watch] [] [pods pods/attach pods/exec pods/portforward pods/proxy] [] []} {[create delete deletecollection get list patch update watch] [] [configmaps endpoints persistentvolumeclaims replicationcontrollers replicationcontrollers/scale secrets serviceaccounts services services/proxy] [] []} {[get list watch] [] [bindings events limitranges namespaces/status pods/log pods/status replicationcontrollers/status resourcequotas resourcequotas/status] [] []} {[get list watch] [] [namespaces] [] []} {[impersonate] [] [serviceaccounts] [] []} {[create delete deletecollection get list patch update watch] [apps] [deployments deployments/rollback deployments/scale replicasets replicasets/scale statefulsets] [] []} {[get list watch] [apps] [daemonsets] [] []} {[create delete deletecollection get list patch update watch] [autoscaling] [horizontalpodautoscalers] [] []} {[create delete deletecollection get list patch update watch] [batch] [cronjobs jobs] [] []} {[create delete deletecollection get list patch update watch] [extensions] [deployments deployments/rollback deployments/scale ingresses replicasets replicasets/scale replicationcontrollers/scale] [] []} {[get list watch] [extensions] [daemonsets] [] []} {[create delete deletecollection get list patch update watch] [policy] [poddisruptionbudgets] [] []} {[create] [authorization.k8s.io] [localsubjectaccessreviews] [] []} {[create delete deletecollection get list patch update watch] [rbac.authorization.k8s.io] [rolebindings roles] [] []} {[create] [apps] [daemonsets] [] []} {[delete] [apps] [daemonsets] [] []} {[deletecollection] [apps] [daemonsets] [] []} {[patch] [apps] [daemonsets] [] []} {[update] [apps] [daemonsets] [] []} {[create] [extensions] [daemonsets] [] []} {[delete] [extensions] [daemonsets] [] []} {[deletecollection] [extensions] [daemonsets] [] []} {[patch] [extensions] [daemonsets] [] []} {[update] [extensions] [daemonsets] [] []} {[create] [apps] [statefulsets/scale] [] []} {[delete] [apps] [statefulsets/scale] [] []} {[deletecollection] [apps] [statefulsets/scale] [] []} {[get] [apps] [statefulsets/scale] [] []} {[list] [apps] [statefulsets/scale] [] []} {[patch] [apps] [statefulsets/scale] [] []} {[update] [apps] [statefulsets/scale] [] []} {[watch] [apps] [statefulsets/scale] [] []} {[create] [extensions] [networkpolicies] [] []} {[delete] [extensions] [networkpolicies] [] []} {[deletecollection] [extensions] [networkpolicies] [] []} {[get] [extensions] [networkpolicies] [] []} {[list] [extensions] [networkpolicies] [] []} {[patch] [extensions] [networkpolicies] [] []} {[update] [extensions] [networkpolicies] [] []} {[watch] [extensions] [networkpolicies] [] []} {[create] [networking.k8s.io] [networkpolicies] [] []} {[delete] [networking.k8s.io] [networkpolicies] [] []} {[deletecollection] [networking.k8s.io] [networkpolicies] [] []} {[get] [networking.k8s.io] [networkpolicies] [] []} {[list] [networking.k8s.io] [networkpolicies] [] []} {[patch] [networking.k8s.io] [networkpolicies] [] []} {[update] [networking.k8s.io] [networkpolicies] [] []} {[watch] [networking.k8s.io] [networkpolicies] [] []} {[get list watch] [] [bindings events limitranges namespaces namespaces/status pods/log pods/status replicationcontrollers/status resourcequotas resourcequotas/status] [] []} {[create delete deletecollection get list patch update watch] [batch] [cronjobs jobs scheduledjobs] [] []} {[create delete deletecollection get list patch update watch] [extensions] [deployments deployments/rollback deployments/scale horizontalpodautoscalers jobs networkpolicies replicasets replicasets/scale replicationcontrollers/scale] [] []} {[create delete deletecollection get list patch update watch] [apps] [deployments deployments/scale deployments/status statefulsets] [] []} {[create delete deletecollection get list patch update watch] [authorization.openshift.io ] [rolebindings roles] [] []} {[create] [authorization.openshift.io ] [localresourceaccessreviews localsubjectaccessreviews subjectrulesreviews] [] []} {[create] [security.openshift.io ] [podsecuritypolicyreviews podsecuritypolicyselfsubjectreviews podsecuritypolicysubjectreviews] [] []} {[get list watch] [authorization.openshift.io ] [policies policybindings rolebindingrestrictions] [] []} {[create delete deletecollection get list patch update watch] [build.openshift.io ] [buildconfigs buildconfigs/webhooks builds] [] []} {[get list watch] [build.openshift.io ] [builds/log] [] []} {[create] [build.openshift.io ] [buildconfigs/instantiate buildconfigs/instantiatebinary builds/clone] [] []} {[update] [build.openshift.io ] [builds/details] [] []} {[admin edit view] [build.openshift.io] [jenkins] [] []} {[create delete deletecollection get list patch update watch] [apps.openshift.io ] [deploymentconfigs deploymentconfigs/scale generatedeploymentconfigs] [] []} {[create] [apps.openshift.io ] [deploymentconfigrollbacks deploymentconfigs/instantiate deploymentconfigs/rollback] [] []} {[get list watch] [apps.openshift.io ] [deploymentconfigs/log deploymentconfigs/status] [] []} {[create delete deletecollection get list patch update watch] [image.openshift.io ] [imagestreamimages imagestreammappings imagestreams imagestreams/secrets imagestreamtags] [] []} {[get list watch] [image.openshift.io ] [imagestreams/status] [] []} {[get update] [image.openshift.io ] [imagestreams/layers] [] []} {[create] [image.openshift.io ] [imagestreamimports] [] []} {[delete get patch update] [project.openshift.io ] [projects] [] []} {[get list watch] [quota.openshift.io ] [appliedclusterresourcequotas] [] []} {[create delete deletecollection get list patch update watch] [route.openshift.io ] [routes] [] []} {[create] [route.openshift.io ] [routes/custom-host] [] []} {[get list watch] [route.openshift.io ] [routes/status] [] []} {[update] [route.openshift.io ] [routes/status] [] []} {[create delete deletecollection get list patch update watch] [template.openshift.io ] [processedtemplates templateconfigs templateinstances templates] [] []} {[create delete deletecollection get list patch update watch] [build.openshift.io ] [buildlogs] [] []} {[get list watch] [] [resourcequotausages] [] []} {[create] [authorization.openshift.io ] [resourceaccessreviews subjectaccessreviews] [] []} {[create] [rbac.authorization.k8s.io] [rolebindings] [] []} {[delete] [rbac.authorization.k8s.io] [rolebindings] [] []} {[deletecollection] [rbac.authorization.k8s.io] [rolebindings] [] []} {[get] [rbac.authorization.k8s.io] [rolebindings] [] []} {[list] [rbac.authorization.k8s.io] [rolebindings] [] []} {[patch] [rbac.authorization.k8s.io] [rolebindings] [] []} {[update] [rbac.authorization.k8s.io] [rolebindings] [] []} {[watch] [rbac.authorization.k8s.io] [rolebindings] [] []} {[create] [rbac.authorization.k8s.io] [roles] [] []} {[delete] [rbac.authorization.k8s.io] [roles] [] []} {[deletecollection] [rbac.authorization.k8s.io] [roles] [] []} {[get] [rbac.authorization.k8s.io] [roles] [] []} {[list] [rbac.authorization.k8s.io] [roles] [] []} {[patch] [rbac.authorization.k8s.io] [roles] [] []} {[update] [rbac.authorization.k8s.io] [roles] [] []} {[watch] [rbac.authorization.k8s.io] [roles] [] []} {[create] [apps] [deployments/rollback] [] []} {[delete] [apps] [deployments/rollback] [] []} {[deletecollection] [apps] [deployments/rollback] [] []} {[get] [apps] [deployments/rollback] [] []} {[list] [apps] [deployments/rollback] [] []} {[patch] [apps] [deployments/rollback] [] []} {[update] [apps] [deployments/rollback] [] []} {[watch] [apps] [deployments/rollback] [] []} {[create] [apps] [replicasets] [] []} {[delete] [apps] [replicasets] [] []} {[deletecollection] [apps] [replicasets] [] []} {[get] [apps] [replicasets] [] []} {[list] [apps] [replicasets] [] []} {[patch] [apps] [replicasets] [] []} {[update] [apps] [replicasets] [] []} {[watch] [apps] [replicasets] [] []} {[create] [apps] [replicasets/scale] [] []} {[delete] [apps] [replicasets/scale] [] []} {[deletecollection] [apps] [replicasets/scale] [] []} {[get] [apps] [replicasets/scale] [] []} {[list] [apps] [replicasets/scale] [] []} {[patch] [apps] [replicasets/scale] [] []} {[update] [apps] [replicasets/scale] [] []} {[watch] [apps] [replicasets/scale] [] []} {[create] [apps] [replicationcontrollers/scale] [] []} {[delete] [apps] [replicationcontrollers/scale] [] []} {[deletecollection] [apps] [replicationcontrollers/scale] [] []} {[get] [apps] [replicationcontrollers/scale] [] []} {[list] [apps] [replicationcontrollers/scale] [] []} {[patch] [apps] [replicationcontrollers/scale] [] []} {[update] [apps] [replicationcontrollers/scale] [] []} {[watch] [apps] [replicationcontrollers/scale] [] []} {[get] [apps] [daemonsets] [] []} {[list] [apps] [daemonsets] [] []} {[watch] [apps] [daemonsets] [] []} {[get] [user.openshift.io ] [users] [~] []} {[list] [project.openshift.io ] [projectrequests] [] []} {[get list] [authorization.openshift.io ] [clusterroles] [] []} {[get list] [storage.k8s.io] [storageclasses] [] []} {[list watch] [project.openshift.io ] [projects] [] []} {[create] [authorization.openshift.io ] [selfsubjectrulesreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews] [] []} {[get] [rbac.authorization.k8s.io] [clusterroles] [] []} {[list] [rbac.authorization.k8s.io] [clusterroles] [] []} {[watch] [rbac.authorization.k8s.io] [clusterroles] [] []} {[get list watch] [] [bindings componentstatuses configmaps endpoints events limitranges namespaces namespaces/status nodes nodes/status persistentvolumeclaims persistentvolumeclaims/status persistentvolumes persistentvolumes/status pods pods/binding pods/eviction pods/log pods/status podtemplates replicationcontrollers replicationcontrollers/scale replicationcontrollers/status resourcequotas resourcequotas/status securitycontextconstraints serviceaccounts services services/status] [] []} {[get list watch] [apps] [deployments deployments/scale deployments/status statefulsets statefulsets/status] [] []} {[get list watch] [autoscaling] [horizontalpodautoscalers horizontalpodautoscalers/status] [] []} {[get list watch] [batch] [cronjobs cronjobs/status jobs jobs/status scheduledjobs scheduledjobs/status] [] []} {[get list watch] [extensions] [daemonsets daemonsets/status deployments deployments/scale deployments/status horizontalpodautoscalers horizontalpodautoscalers/status ingresses ingresses/status jobs jobs/status networkpolicies podsecuritypolicies replicasets replicasets/scale replicasets/status replicationcontrollers replicationcontrollers/scale storageclasses thirdpartyresources] [] []} {[get list watch] [policy] [poddisruptionbudgets poddisruptionbudgets/status] [] []} {[get list watch] [rbac.authorization.k8s.io] [clusterrolebindings clusterroles rolebindings roles] [] []} {[get list watch] [settings.k8s.io] [podpresets] [] []} {[get list watch] [storage.k8s.io] [storageclasses] [] []} {[get list watch] [certificates.k8s.io] [certificatesigningrequests certificatesigningrequests/approval certificatesigningrequests/status] [] []} {[get list watch] [authorization.openshift.io ] [clusterpolicies clusterpolicybindings clusterrolebindings clusterroles policies policybindings rolebindingrestrictions rolebindings roles] [] []} {[get list watch] [build.openshift.io ] [buildconfigs buildconfigs/webhooks builds builds/details builds/log] [] []} {[get list watch] [apps.openshift.io ] [deploymentconfigs deploymentconfigs/log deploymentconfigs/scale deploymentconfigs/status] [] []} {[get list watch] [image.openshift.io ] [images imagesignatures imagestreamimages imagestreams imagestreams/status imagestreamtags] [] []} {[get] [image.openshift.io ] [imagestreams/layers] [] []} {[get list watch] [oauth.openshift.io ] [oauthclientauthorizations] [] []} {[get list watch] [project.openshift.io ] [projectrequests projects] [] []} {[get list watch] [quota.openshift.io ] [appliedclusterresourcequotas clusterresourcequotas clusterresourcequotas/status] [] []} {[get list watch] [route.openshift.io ] [routes routes/status] [] []} {[get list watch] [network.openshift.io ] [clusternetworks egressnetworkpolicies hostsubnets netnamespaces] [] []} {[get list watch] [security.openshift.io ] [securitycontextconstraints] [] []} {[get list watch] [template.openshift.io ] [processedtemplates templateconfigs templateinstances templates] [] []} {[get list watch] [user.openshift.io ] [groups identities useridentitymappings users] [] []} {[create] [authorization.openshift.io ] [localresourceaccessreviews localsubjectaccessreviews resourceaccessreviews selfsubjectrulesreviews subjectaccessreviews subjectrulesreviews] [] []} {[create] [authorization.k8s.io] [localsubjectaccessreviews selfsubjectaccessreviews subjectaccessreviews] [] []} {[create] [authentication.k8s.io] [tokenreviews] [] []} {[create] [security.openshift.io ] [podsecuritypolicyreviews podsecuritypolicyselfsubjectreviews podsecuritypolicysubjectreviews] [] []} {[get] [] [nodes/metrics nodes/spec] [] []} {[create get] [] [nodes/stats] [] []} {[get] [] [] [] [*]} {[get list watch] [build.openshift.io ] [buildlogs] [] []} {[get list watch] [] [resourcequotausages] [] []} {[get] [apps] [controllerrevisions] [] []} {[list] [apps] [controllerrevisions] [] []} {[watch] [apps] [controllerrevisions] [] []} {[get] [apiextensions.k8s.io] [customresourcedefinitions] [] []} {[list] [apiextensions.k8s.io] [customresourcedefinitions] [] []} {[watch] [apiextensions.k8s.io] [customresourcedefinitions] [] []} {[get] [apiextensions.k8s.io] [customresourcedefinitions/status] [] []} {[list] [apiextensions.k8s.io] [customresourcedefinitions/status] [] []} {[watch] [apiextensions.k8s.io] [customresourcedefinitions/status] [] []} {[get] [apiregistration.k8s.io] [apiservices] [] []} {[list] [apiregistration.k8s.io] [apiservices] [] []} {[watch] [apiregistration.k8s.io] [apiservices] [] []} {[get] [apiregistration.k8s.io] [apiservices/status] [] []} {[list] [apiregistration.k8s.io] [apiservices/status] [] []} {[watch] [apiregistration.k8s.io] [apiservices/status] [] []} {[get] [networking.k8s.io] [networkpolicies] [] []} {[list] [networking.k8s.io] [networkpolicies] [] []} {[watch] [networking.k8s.io] [networkpolicies] [] []} {[get] [] [brokertemplateinstances] [] []} {[list] [] [brokertemplateinstances] [] []} {[watch] [] [brokertemplateinstances] [] []} {[get] [] [templateinstances/status] [] []} {[list] [] [templateinstances/status] [] []} {[watch] [] [templateinstances/status] [] []} {[get] [template.openshift.io] [brokertemplateinstances] [] []} {[list] [template.openshift.io] [brokertemplateinstances] [] []} {[watch] [template.openshift.io] [brokertemplateinstances] [] []} {[get] [template.openshift.io] [templateinstances/status] [] []} {[list] [template.openshift.io] [templateinstances/status] [] []} {[watch] [template.openshift.io] [templateinstances/status] [] []} {[get] [apps] [daemonsets] [] []} {[list] [apps] [daemonsets] [] []} {[watch] [apps] [daemonsets] [] []} {[get] [apps] [daemonsets/status] [] []} {[list] [apps] [daemonsets/status] [] []} {[watch] [apps] [daemonsets/status] [] []} {[get] [apps] [replicasets] [] []} {[list] [apps] [replicasets] [] []} {[watch] [apps] [replicasets] [] []} {[get] [apps] [replicasets/scale] [] []} {[list] [apps] [replicasets/scale] [] []} {[watch] [apps] [replicasets/scale] [] []} {[get] [apps] [replicasets/status] [] []} {[list] [apps] [replicasets/status] [] []} {[watch] [apps] [replicasets/status] [] []} {[get] [apps] [statefulsets/scale] [] []} {[list] [apps] [statefulsets/scale] [] []} {[watch] [apps] [statefulsets/scale] [] []} {[create] [authorization.k8s.io] [selfsubjectrulesreviews] [] []} {[get] [admissionregistration.k8s.io] [mutatingwebhookconfigurations] [] []} {[list] [admissionregistration.k8s.io] [mutatingwebhookconfigurations] [] []} {[watch] [admissionregistration.k8s.io] [mutatingwebhookconfigurations] [] []} {[get] [admissionregistration.k8s.io] [validatingwebhookconfigurations] [] []} {[list] [admissionregistration.k8s.io] [validatingwebhookconfigurations] [] []} {[watch] [admissionregistration.k8s.io] [validatingwebhookconfigurations] [] []} {[get] [events.k8s.io] [events] [] []} {[list] [events.k8s.io] [events] [] []} {[watch] [events.k8s.io] [events] [] []} {[get] [policy] [podsecuritypolicies] [] []} {[list] [policy] [podsecuritypolicies] [] []} {[watch] [policy] [podsecuritypolicies] [] []} {[get] [storage.k8s.io] [volumeattachments] [] []} {[list] [storage.k8s.io] [volumeattachments] [] []} {[watch] [storage.k8s.io] [volumeattachments] [] []} {[get] [security.openshift.io] [rangeallocations] [] []} {[list] [security.openshift.io] [rangeallocations] [] []} {[watch] [security.openshift.io] [rangeallocations] [] []} {[get] [scheduling.k8s.io] [priorityclasses] [] []} {[list] [scheduling.k8s.io] [priorityclasses] [] []} {[watch] [scheduling.k8s.io] [priorityclasses] [] []} {[get list watch] [] [configmaps endpoints persistentvolumeclaims pods replicationcontrollers replicationcontrollers/scale serviceaccounts services] [] []} {[get list watch] [] [bindings events limitranges namespaces/status pods/log pods/status replicationcontrollers/status resourcequotas resourcequotas/status] [] []} {[get list watch] [] [namespaces] [] []} {[get list watch] [apps] [daemonsets deployments deployments/scale replicasets replicasets/scale statefulsets] [] []} {[get list watch] [autoscaling] [horizontalpodautoscalers] [] []} {[get list watch] [batch] [cronjobs jobs] [] []} {[get list watch] [extensions] [daemonsets deployments deployments/scale ingresses replicasets replicasets/scale replicationcontrollers/scale] [] []} {[get list watch] [policy] [poddisruptionbudgets] [] []} {[get] [extensions] [networkpolicies] [] []} {[list] [extensions] [networkpolicies] [] []} {[watch] [extensions] [networkpolicies] [] []} {[get list watch] [] [configmaps endpoints persistentvolumeclaims pods replicationcontrollers serviceaccounts services] [] []} {[get list watch] [] [bindings events limitranges namespaces namespaces/status pods/log pods/status replicationcontrollers/status resourcequotas resourcequotas/status] [] []} {[get list watch] [batch] [cronjobs jobs scheduledjobs] [] []} {[get list watch] [extensions] [deployments deployments/scale horizontalpodautoscalers jobs replicasets replicasets/scale] [] []} {[get list watch] [extensions] [daemonsets] [] []} {[get list watch] [apps] [deployments deployments/scale statefulsets] [] []} {[get list watch] [build.openshift.io ] [buildconfigs buildconfigs/webhooks builds] [] []} {[get list watch] [build.openshift.io ] [builds/log] [] []} {[view] [build.openshift.io] [jenkins] [] []} {[get list watch] [apps.openshift.io ] [deploymentconfigs deploymentconfigs/scale] [] []} {[get list watch] [apps.openshift.io ] [deploymentconfigs/log deploymentconfigs/status] [] []} {[get list watch] [image.openshift.io ] [imagestreamimages imagestreammappings imagestreams imagestreamtags] [] []} {[get list watch] [image.openshift.io ] [imagestreams/status] [] []} {[get] [project.openshift.io ] [projects] [] []} {[get list watch] [quota.openshift.io ] [appliedclusterresourcequotas] [] []} {[get list watch] [route.openshift.io ] [routes] [] []} {[get list watch] [route.openshift.io ] [routes/status] [] []} {[get] [] [] [] [/healthz /healthz/*]} {[get] [] [] [] [/.well-known /.well-known/* /api /api/* /apis /apis/* /oapi /oapi/* /osapi /osapi/ /swagger.json /swaggerapi /swaggerapi/* /version /version/*]} {[get] [] [] [] [/]} {[get] [] [] [] [/swagger-2.0.0.pb-v1]} {[get] [] [] [] [/openapi/v2]} {[create delete get list update watch] [ user.openshift.io] [identities useridentitymappings users] [] []} {[create delete get list update watch] [ quota.openshift.io] [clusterresourcequotas] [] []} {[delete get list patch watch] [] [namespaces] [] []} {[delete deletecollection get list watch] [ oauth.openshift.io] [oauthaccesstokens oauthclientauthorizations] [] []} {[impersonate] [ user.openshift.io] [groups users] [] []} {[create delete get list patch update watch] [] [resourcequotas] [] []} {[create] [ project.openshift.io] [projectrequests] [] []} {[patch update] [ authorization.openshift.io] [rolebindingrestrictions] [] []} {[create] [authorization.openshift.io ] [selfsubjectrulesreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews] [] []} {[create] [project.openshift.io ] [projectrequests] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectrulesreviews] [] []} {[create] [build.openshift.io ] [builds/jenkinspipeline] [] []} {[create] [build.openshift.io ] [builds/source] [] []} {[get] [] [] [] [/.well-known /.well-known/* /api /api/* /apis /apis/* /oapi /oapi/* /osapi /osapi/ /swagger.json /swaggerapi /swaggerapi/* /version /version/*]} {[get] [] [] [] [/]} {[get] [] [] [] [/swagger-2.0.0.pb-v1]} {[get] [] [] [] [/openapi/v2]} {[get] [] [] [] [/healthz]} {[get] [] [] [] [/openapi]} {[get] [] [] [] [/openapi/*]} {[get] [] [] [] [/.well-known /.well-known/* /api /api/* /apis /apis/* /oapi /oapi/* /osapi /osapi/ /swagger.json /swaggerapi /swaggerapi/* /version /version/*]} {[get] [] [] [] [/]} {[get] [] [] [] [/swagger-2.0.0.pb-v1]} {[get] [] [] [] [/openapi/v2]} {[get] [] [] [] [/healthz]} {[get] [] [] [] [/openapi]} {[get] [] [] [] [/openapi/*]} {[delete] [oauth.openshift.io ] [oauthaccesstokens oauthauthorizetokens] [] []} {[get] [] [] [] [/version /version/* /api /api/* /apis /apis/* /oapi /oapi/* /openapi/v2 /swaggerapi /swaggerapi/* /swagger.json /swagger-2.0.0.pb-v1 /osapi /osapi/ /.well-known /.well-known/* /]} {[impersonate] [authentication.k8s.io] [userextras/scopes.authorization.openshift.io] [] []} {[create get] [build.openshift.io ] [buildconfigs/webhooks] [] []}] ruleResolutionErrors=[]     **error: roles.rbac.authorization.k8s.io "camel-k" not found** ```</body>
		<created>2019-04-12 07:03:44</created>
		<closed>2019-04-16 05:36:25</closed>
	</bug>
	<bug>
		<id>5192</id>
		<title>[1.6.10][master] Integration doesn't start</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Create any integration on master or 1.6.10 and it fails with:  ``` Starting the Java application using /opt/run-java/run-java.sh ... exec java -javaagent:/opt/jolokia/jolokia.jar=config=/opt/jolokia/etc/jolokia.properties -javaagent:/opt/prometheus/jmx_prometheus_javaagent.jar=9779:/tmp/src/prometheus-config.yml -XX:+UseParallelGC -XX:GCTimeRatio=4 -XX:AdaptiveSizePolicyWeight=90 -XX:MinHeapFreeRatio=20 -XX:MaxHeapFreeRatio=40 -XX:+ExitOnOutOfMemoryError -cp . -jar /deployments/project-0.1-SNAPSHOT.jar OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N I&gt; No access restrictor found, access to any MBean is allowed Jolokia: Agent started with URL https://172.17.0.10:8778/jolokia/       _______.                 _               _     /       |                 | |             (_)    |   (----`_   _  ____    _ | |  ____   ___  _   ___     \   \   | | | ||  _ \  / || | / _  ) /___)| | /___) .----)   |  | |_| || | | |( (_| |( (/ / |___ || ||___ | |_______/    \__  ||_| |_| \____| \____)(___/ |_|(___/ ============ (____/ =================================== :: Integration ::  :: v 2019-04-12 06:28:46.716  INFO 1 --- [           main] io.syndesis.example.Application          : Starting Application on i-zzz-1-7fnxq with PID 1 (/deployments/project-0.1-SNAPSHOT.jar started by jboss in /deployments) 2019-04-12 06:28:46.721 DEBUG 1 --- [           main] io.syndesis.example.Application          : Running with Spring Boot v1.5.17.RELEASE, Spring v4.3.20.RELEASE 2019-04-12 06:28:46.722  INFO 1 --- [           main] io.syndesis.example.Application          : No active profile set, falling back to default profiles: default 2019-04-12 06:28:46.847  INFO 1 --- [           main] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@123f1134: startup date [Fri Apr 12 06:28:46 UTC 2019]; root of context hierarchy 2019-04-12 06:28:49.626  INFO 1 --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.apache.camel.spring.boot.CamelAutoConfiguration' of type [org.apache.camel.spring.boot.CamelAutoConfiguration$$EnhancerBySpringCGLIB$$493367aa] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2019-04-12 06:28:50.190  INFO 1 --- [           main] org.xnio                                 : XNIO version 3.3.8.Final 2019-04-12 06:28:50.219  INFO 1 --- [           main] org.xnio.nio                             : XNIO NIO Implementation Version 3.3.8.Final 2019-04-12 06:28:50.305  WARN 1 --- [           main] io.undertow.websockets.jsr               : UT026009: XNIO worker was not set on WebSocketDeploymentInfo, the default worker will be used 2019-04-12 06:28:50.305  WARN 1 --- [           main] io.undertow.websockets.jsr               : UT026010: Buffer pool was not set on WebSocketDeploymentInfo, the default pool will be used 2019-04-12 06:28:50.346  INFO 1 --- [           main] io.undertow.servlet                      : Initializing Spring embedded WebApplicationContext 2019-04-12 06:28:50.347  INFO 1 --- [           main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 3501 ms 2019-04-12 06:28:50.627  INFO 1 --- [           main] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/] 2019-04-12 06:28:50.634  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'metricsFilter' to: [/*] 2019-04-12 06:28:50.635  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*] 2019-04-12 06:28:50.635  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*] 2019-04-12 06:28:50.635  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*] 2019-04-12 06:28:50.635  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*] 2019-04-12 06:28:50.635  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'webRequestLoggingFilter' to: [/*] 2019-04-12 06:28:50.635  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'applicationContextIdFilter' to: [/*] 2019-04-12 06:28:51.304  INFO 1 --- [           main] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@123f1134: startup date [Fri Apr 12 06:28:46 UTC 2019]; root of context hierarchy 2019-04-12 06:28:51.451  INFO 1 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) 2019-04-12 06:28:51.458  INFO 1 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity&lt;java.util.Map&lt;java.lang.String, java.lang.Object&gt;&gt; org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest) 2019-04-12 06:28:51.535  INFO 1 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler] 2019-04-12 06:28:51.536  INFO 1 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler] 2019-04-12 06:28:51.618  INFO 1 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler] 2019-04-12 06:28:52.080  INFO 1 --- [           main] o.a.c.s.boot.CamelAutoConfiguration      : Using custom InterceptStrategy with id: integrationLoggingInterceptStrategy and implementation: io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy@556d0826 2019-04-12 06:28:52.239  INFO 1 --- [           main] o.a.c.i.converter.DefaultTypeConverter   : Type converters loaded (core: 194, classpath: 1) 2019-04-12 06:28:53.634  INFO 1 --- [           main] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/health || /health.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,java.security.Principal) 2019-04-12 06:28:53.889  INFO 1 --- [           main] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup 2019-04-12 06:28:53.931  INFO 1 --- [           main] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 0 2019-04-12 06:28:54.012 DEBUG 1 --- [           main] o.a.camel.spring.boot.RoutesCollector    : Post-processing CamelContext bean: zzz 2019-04-12 06:28:54.014 DEBUG 1 --- [           main] o.a.camel.spring.boot.RoutesCollector    : CamelContextConfiguration found. Invoking beforeApplicationStart: io.syndesis.integration.runtime.sb.IntegrationRuntimeAutoConfiguration$1@7ca20101 2019-04-12 06:28:54.014  INFO 1 --- [           main] .r.s.IntegrationRuntimeAutoConfiguration : Autowired IntegrationStepHandlers found: 0 2019-04-12 06:28:54.043  INFO 1 --- [           main] .r.s.IntegrationRuntimeAutoConfiguration : ServiceLoader loaded IntegrationStepHandlers: 12 2019-04-12 06:28:54.046  INFO 1 --- [           main] i.s.i.runtime.IntegrationRouteBuilder    : Loading integration from: classpath:syndesis/integration/integration.json 2019-04-12 06:28:54.100  INFO 1 --- [           main] utoConfigurationReportLoggingInitializer :  Error starting ApplicationContext. To display the auto-configuration report re-run your application with 'debug' enabled. 2019-04-12 06:28:54.107 ERROR 1 --- [           main] o.s.b.d.LoggingFailureAnalysisReporter   :  *************************** APPLICATION FAILED TO START *************************** Description: An attempt was made to call the method com.fasterxml.jackson.databind.ObjectMapper.setDefaultPropertyInclusion(Lcom/fasterxml/jackson/annotation/JsonInclude$Value;)Lcom/fasterxml/jackson/databind/ObjectMapper; but it does not exist. Its class, com.fasterxml.jackson.databind.ObjectMapper, is available from the following locations:     jar:file:/deployments/project-0.1-SNAPSHOT.jar!/BOOT-INF/lib/jackson-databind-2.8.11.2.jar!/com/fasterxml/jackson/databind/ObjectMapper.class It was loaded from the following location:     jar:file:/deployments/project-0.1-SNAPSHOT.jar!/BOOT-INF/lib/jackson-databind-2.8.11.2.jar!/ Action: Correct the classpath of your application so that it contains a single, compatible version of com.fasterxml.jackson.databind.ObjectMapper 2019-04-12 06:28:54.111  INFO 1 --- [           main] ationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@123f1134: startup date [Fri Apr 12 06:28:46 UTC 2019]; root of context hierarchy 2019-04-12 06:28:54.115  INFO 1 --- [           main] o.s.c.support.DefaultLifecycleProcessor  : Stopping beans in phase 2147483647 2019-04-12 06:28:54.116  INFO 1 --- [           main] o.a.camel.spring.SpringCamelContext      : Apache Camel 2.21.0.fuse-730054 (CamelContext: zzz) is shutting down 2019-04-12 06:28:54.176  INFO 1 --- [           main] o.a.camel.spring.SpringCamelContext      : Apache Camel 2.21.0.fuse-730054 (CamelContext: zzz) uptime  2019-04-12 06:28:54.177  INFO 1 --- [           main] o.a.camel.spring.SpringCamelContext      : Apache Camel 2.21.0.fuse-730054 (CamelContext: zzz) is shutdown in 0.060 seconds 2019-04-12 06:28:54.178  INFO 1 --- [           main] o.s.c.support.DefaultLifecycleProcessor  : Stopping beans in phase 0 2019-04-12 06:28:54.180  INFO 1 --- [           main] o.s.j.e.a.AnnotationMBeanExporter        : Unregistering JMX-exposed beans on shutdown ``` </body>
		<created>2019-04-12 06:36:28</created>
		<closed>2019-04-15 06:54:30</closed>
	</bug>
	<bug>
		<id>5189</id>
		<title>[camel-k] SyndesisHeaderStrategy not loaded into the registry</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Some connectors requires an HeaderStrategy named syndesisHeaderStrategy to be present in the registry and it was done using spring boot before but that does not work any more in camel-k so we need to implement a similar strategy in camel-k otherwhise integration using such connector won't even start  We missed to replicate what https://github.com/syndesisio/syndesis/blob/master/app/connector/support/processor/src/main/java/io/syndesis/connector/support/processor/SyndesisHttpConfiguration.java does so we could hit `No bean could be found in the registry for: syndesisHeaderStrategy of type: org.apache.camel.spi.HeaderFilterStrategy` in case we use i.e. the http component. </body>
		<created>2019-04-11 15:26:50</created>
		<closed>2019-04-12 14:51:20</closed>
	</bug>
	<bug>
		<id>5184</id>
		<title>[camel-k] AtlasMap's multi document vs InputStream</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  I've been working on an application that requires to map the same document multiple time in the integration flow and I run into an issue because the document that I wanted to map was stored in the exchnage's message body as InputStream and the stream was consumed by a previous step.  This happens because we do copy the message a map stored as exchange property but as the body is an InputStream the first processor that consumes it, will break all the subsequent mapping.  NOTE: with camel-k backend </body>
		<created>2019-04-11 09:04:03</created>
		<closed>2019-04-12 14:05:01</closed>
	</bug>
	<bug>
		<id>5174</id>
		<title>Unable to start integration from box connector</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description There are currently no actions to start the integration in box connector and 2 actions to finish (upload, download).  This should be "From" I assume: https://github.com/syndesisio/syndesis/blob/28cb62a0c74be5c58792d8aca83a2a194fdfb22a/app/connector/box/src/main/resources/META-INF/syndesis/connector/box.json#L87-L88 </body>
		<created>2019-04-10 08:43:08</created>
		<closed>2019-04-10 09:13:38</closed>
	</bug>
	<bug>
		<id>5173</id>
		<title>Not able to get JSON out of JSON template</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Created API Provider with simple Slack integration. Posts a message to Slack user and returns the Slack message in the API response as JSON.   Mapped the Slack message to JSON template to convert the message string to JSON. Tried to map that JSON to API response body and it returns the message string and not the message string in JSON format.   Ping me if you need more details.  </body>
		<created>2019-04-10 00:46:16</created>
		<closed>2019-07-16 10:09:19</closed>
	</bug>
	<bug>
		<id>5167</id>
		<title>syndesis-server: gc under pressure when UI requests integration details</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  When UI shows an integration summary, it [fetches](https://github.com/syndesisio/syndesis/blob/master/app/server/endpoint/src/main/java/io/syndesis/server/endpoint/v1/handler/integration/IntegrationOverviewHelper.java#L89-L90) all the `IntegrationDeployment` for the given integration and because each deployment contains a snapshot of the integration for the revision, such operation is quite memory intensive and: - can put the GC under pressure so in some case this result in a long phase so that the liveness proves reports the the application not more healthy thus openshift restarts it - can trigger OOM  This problem is exacerbate using camle-k as back-end as deployment are quick and people may end-up amending  integrations more often.  </body>
		<created>2019-04-09 09:47:46</created>
		<closed>2019-08-08 06:31:55</closed>
	</bug>
	<bug>
		<id>5166</id>
		<title>[Rollback] syndesis-db-metrics causes db rollback to fail</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11430**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When the rollback is trying to drop db (to be restored from the backup right after), it fails because `database "syndesis" is being accessed by other users`. That seems to be the `syndesis-db-metrics` pod that is co-located with the DB, as when I removed it, it didn't fail afterwards  ``` ...  --- * Rolling back 'Migrate database' deploymentconfig.apps.openshift.io/syndesis-server scaled deploymentconfig.apps.openshift.io/syndesis-meta scaled Waiting for syndesis-server to be scaled to 0 NAME                          READY     STATUS        RESTARTS   AGE httpendpoints-1-x4l2q         1/1       Running       0          9m i-upgrade-1-build             0/1       Completed     0          7m i-upgrade-2-nkgsj             1/1       Running       0          5m syndesis-db-3-z8xjd           2/2       Running       0          1m syndesis-meta-3-ml5kd         1/1       Terminating   0          1m syndesis-oauthproxy-1-fvvzx   1/1       Running       0          1m syndesis-prometheus-1-mk8mt   1/1       Running       0          1m syndesis-server-3-4sx2w       1/1       Terminating   0          1m syndesis-ui-3-pmmtb           1/1       Running       0          1m todo-1-b4jg2                  1/1       Running       0          11m todo-1-build                  0/1       Completed     0          13m Sleeping 10s ... syndesis-meta-3-ml5kd   0/1       Terminating   0         1m syndesis-meta-3-ml5kd   0/1       Terminating   0         1m syndesis-meta-3-ml5kd   0/1       Terminating   0         1m syndesis-meta-3-ml5kd   0/1       Terminating   0         1m syndesis-server-3-4sx2w   0/1       Terminating   0         1m syndesis-server-3-4sx2w   0/1       Terminating   0         1m syndesis-server-3-4sx2w   0/1       Terminating   0         1m Waiting for syndesis-meta to be scaled to 0 Defaulting container name to postgresql. Use 'oc describe pod/syndesis-db-3-z8xjd -n syndesis' to see all of the containers in this pod. Unable to use a TTY - input is not a terminal or the right kind of file pg_restore: connecting to database for restore pg_restore: creating SCHEMA "public" pg_restore: creating COMMENT "SCHEMA public" pg_restore: creating EXTENSION "plpgsql" pg_restore: creating COMMENT "EXTENSION plpgsql" pg_restore: creating TABLE "public.config" pg_restore: creating TABLE "public.filestore" pg_restore: creating TABLE "public.jsondb" pg_restore: processing data for table "public.config" pg_restore: processing data for table "public.filestore" pg_restore: processing data for table "public.jsondb" pg_restore: creating CONSTRAINT "public.config_pkey" pg_restore: creating CONSTRAINT "public.filestore_pkey" pg_restore: creating CONSTRAINT "public.jsondb_pkey" pg_restore: creating INDEX "public.jsondb_idx" pg_restore: creating ACL "SCHEMA public" dropdb: database removal failed: ERROR:  database "syndesis" is being accessed by other users DETAIL:  There is 1 other session using the database. command terminated with exit code 1 ====&gt; Rollback Error !!  ... ``` </body>
		<created>2019-04-09 08:12:07</created>
		<closed>2019-09-07 11:25:05</closed>
	</bug>
	<bug>
		<id>5155</id>
		<title>Modal stays when integration no longer exists</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11431**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description This happens due to the delay between user calling delete on integration and the integration no longer existing in the UI. The delay is sometimes too long and it seems that nothing is happening so the user decides to press delete again; the modal shows up and in that time the integration can be already deleted.  The part of this behavior I'd call bug is that the modal stays up and the cancel and the X button don't close the window, so you have to refresh the page. When you click on any of those button you get these errors in the console ![image](https://user-images.githubusercontent.com/46345469/55710017-f1c54480-59e9-11e9-8ba4-95157a532743.png)   </body>
		<created>2019-04-08 08:35:35</created>
		<closed>2019-09-07 11:25:14</closed>
	</bug>
	<bug>
		<id>5154</id>
		<title>Links in masthead help menu don't work </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  I'm using the staging site and noticed the links in the masthead help menu (clicking on the "?" icon) don't work and go to 404 pages.   These following links don't work: - Sample Integration Tutorials  - User Guide  - Connections Guide   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlisting the acceptance criteria. --&gt;  All links should go to proper web pages.   ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  &lt;img width="583" alt="Screen Shot 2019-04-05 at 3 13 55 PM" src="https://user-images.githubusercontent.com/24943812/55651103-8bf07700-57b5-11e9-9ae8-fe4f7ffb9a6a.png"&gt;   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2019-04-05 19:17:54</created>
		<closed>2019-04-08 14:08:21</closed>
	</bug>
	<bug>
		<id>5153</id>
		<title>Extra scrollbar appears when hovering on the IVP expansion bar  </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  When creating an integration, an extra scrollbar appears when hovering on the IVP expansion bar. This behavior happens when using the staging site.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlisting the acceptance criteria. --&gt;  No extra scrollbar when hovering on the expansion bar.   ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![wOeiD8II38](https://user-images.githubusercontent.com/24943812/55650722-82b2da80-57b4-11e9-9b64-c15b21040720.gif)   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create Integration 2. Hover on the Integration IVP expansion bar  </body>
		<created>2019-04-05 19:11:26</created>
		<closed>2019-04-17 10:13:47</closed>
	</bug>
	<bug>
		<id>5152</id>
		<title>API provider ignoring query parameters</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Query parameters on API provider operations are always `null`. The query parameter is passed to the unified data shape but the value is not set correctly at runtime. Instead the parameter value is always `null`.  You can reproduce this with a simple GET operation that uses a query parameter and log the body right after entering the operation flow. </body>
		<created>2019-04-05 12:45:24</created>
		<closed>2019-08-19 08:21:16</closed>
	</bug>
	<bug>
		<id>5147</id>
		<title>Syndesis server fails to deploy on master</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  In server log during deployment:  ``` org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'connectorHandler' defined in URL [jar:file:/deployments/runtime.jar!/BOOT-INF/lib/server-endpoint-1.7-SNAPSHOT.jar!/io/syndesis/server/endpoint/v1/handler/connection/ConnectorHandler.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'externalVerifierService': Invocation of init method failed; nested exception is java.lang.NullPointerException at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:749) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:189) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1198) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1100) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:511) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:481) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:312) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:308) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:543) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at io.syndesis.server.runtime.Application.main(Application.java:68) [classes!/:1.7-SNAPSHOT] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_151] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_151] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151] at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48) [runtime.jar:1.7-SNAPSHOT] at org.springframework.boot.loader.Launcher.launch(Launcher.java:87) [runtime.jar:1.7-SNAPSHOT] at org.springframework.boot.loader.Launcher.launch(Launcher.java:50) [runtime.jar:1.7-SNAPSHOT] at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:51) [runtime.jar:1.7-SNAPSHOT] Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'externalVerifierService': Invocation of init method failed; nested exception is java.lang.NullPointerException at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:137) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:407) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1623) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:481) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:312) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:308) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1136) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1064) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:835) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:741) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] ... 27 common frames omitted Caused by: java.lang.NullPointerException: null at java.util.concurrent.CopyOnWriteArrayList.addAllAbsent(CopyOnWriteArrayList.java:764) ~[na:1.8.0_151] at java.util.concurrent.CopyOnWriteArraySet.addAll(CopyOnWriteArraySet.java:293) ~[na:1.8.0_151] at org.jboss.resteasy.spi.ResteasyProviderFactory.&lt;init&gt;(ResteasyProviderFactory.java:318) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.client.jaxrs.internal.LocalResteasyProviderFactory.&lt;init&gt;(LocalResteasyProviderFactory.java:26) ~[resteasy-client-3.6.1.Final.jar!/:3.6.1.Final] at io.syndesis.server.verifier.ExternalVerifierService.init(ExternalVerifierService.java:73) ~[server-verifier-1.7-SNAPSHOT.jar!/:1.7-SNAPSHOT] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_151] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_151] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151] at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(InitDestroyAnnotationBeanPostProcessor.java:366) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleMetadata.invokeInitMethods(InitDestroyAnnotationBeanPostProcessor.java:311) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:134) ~[spring-beans-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] ... 40 common frames omitted ```  @zregvart :thinking: </body>
		<created>2019-04-05 09:05:07</created>
		<closed>2019-04-10 10:35:57</closed>
	</bug>
	<bug>
		<id>5140</id>
		<title>Maven POM generation doesn't take into account dependency's version</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  When generating the Maven POM for the S2I build we're not including the specified version of a dependency, say one that has been added as a dependency to the extension descriptor.  This prevents adding a dependency not present in one of the imported BOMs and fails the integration build  This seems to be on purpose, relying on the fact that any dependency we use currently is present in one of the BOMs we import. Perhaps as a way of prohibiting version clashes.  Not sure what would be the best way of dealing with these, seems that we need to take into account all dependencies imported from the BOM and for any dependency not present in the BOM specify its version when generating the POM for the integration build.</body>
		<created>2019-04-04 09:34:09</created>
		<closed>2019-07-15 17:09:18</closed>
	</bug>
	<bug>
		<id>5110</id>
		<title>[1.6.4][regression]google-sheets: Can not deserialize instance of java.util.LinkedHashMap when split involved</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I have simple integration DB -&gt; Split -&gt; DataMapper -&gt; Google-sheets:update (collums). The expected behavior is that I get couple of records from DB and overwrite values in spreadsheet.  I'm getting following exception on update action:  ``` 019-04-02 09:51:43.588 ERROR 1 --- [r://integration] o.a.camel.processor.DefaultErrorHandler  : Failed delivery for (MessageId: i-LbSSXrA4FH1JgLE80W6z on ExchangeId: i-LbSSXlb4FH1JgLE80W3z). Exhausted after delivery attempt: 1 caught: com.fasterxml.jackson.databind.JsonMappingException: Can not deserialize instance of java.util.LinkedHashMap out of START_ARRAY token  at [Source: [{"spreadsheetId":"1SXR0Ui5KwS7D_aIKngxGfVeKMMCz3Rb4oeMdY5t4u0I","#1":"Matej","#2":"Foo","#3":"Red Hat","#4":"db"}]; line: 1, column: 1] Message History --------------------------------------------------------------------------------------------------------------------------------------- RouteId              ProcessorId          Processor                                                                        Elapsed (ms) [-LbSSDoXn5sHKoSiPQ] [-LbSSDoXn5sHKoSiPQ] [timer://integration?period=60000000                                           ] [       621] [-LbSSDoXn5sHKoSiPQ] [setHeader2        ] [setHeader[Syndesis.STEP_ID]                                                   ] [         1] [-LbSSDoXn5sHKoSiPQ] [process1          ] [Processor@0x7fc5849e                                                          ] [         0] [-LbSSDoXn5sHKoSiPQ] [step:-LbSSJSmn5sHK] [pipeline                                                                      ] [       357] [-LbSSDoXn5sHKoSiPQ] [setHeader3        ] [setHeader[Syndesis.STEP_ID]                                                   ] [         0] [-LbSSDoXn5sHKoSiPQ] [process2          ] [Processor@0x99b1a4b                                                           ] [         1] [-LbSSDoXn5sHKoSiPQ] [to2               ] [atlas:mapping-flow-0-step-2.json?encoding=UTF-8&amp;sourceMapName=Syndesis.CAPTURE] [       353] [-LbSSDoXn5sHKoSiPQ] [process3          ] [Processor@0x76a5bf37                                                          ] [         0] [-LbSSDoXn5sHKoSiPQ] [process4          ] [Processor@0x7fc5849e                                                          ] [         0] [-LbSSDoXn5sHKoSiPQ] [step:-LbSSI4Hn5sHK] [pipeline                                                                      ] [         0] [-LbSSDoXn5sHKoSiPQ] [setHeader4        ] [setHeader[Syndesis.STEP_ID]                                                   ] [         0] [-LbSSDoXn5sHKoSiPQ] [to3               ] [google-sheets-0-3                                                             ] [        16] Stacktrace --------------------------------------------------------------------------------------------------------------------------------------- com.fasterxml.jackson.databind.JsonMappingException: Can not deserialize instance of java.util.LinkedHashMap out of START_ARRAY token  at [Source: [{"spreadsheetId":"1SXR0Ui5KwS7D_aIKngxGfVeKMMCz3Rb4oeMdY5t4u0I","#1":"Matej","#2":"Foo","#3":"Red Hat","#4":"db"}]; line: 1, column: 1] at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:270) ~[jackson-databind-2.8.11.2.jar!/:2.8.11.2] at com.fasterxml.jackson.databind.DeserializationContext.reportMappingException(DeserializationContext.java:1247) ~[jackson-databind-2.8.11.2.jar!/:2.8.11.2] at com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1122) ~[jackson-databind-2.8.11.2.jar!/:2.8.11.2] at com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1075) ~[jackson-databind-2.8.11.2.jar!/:2.8.11.2] at com.fasterxml.jackson.databind.deser.std.StdDeserializer._deserializeFromEmpty(StdDeserializer.java:892) ~[jackson-databind-2.8.11.2.jar!/:2.8.11.2] at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:358) ~[jackson-databind-2.8.11.2.jar!/:2.8.11.2] at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:27) ~[jackson-databind-2.8.11.2.jar!/:2.8.11.2] at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:1626) ~[jackson-databind-2.8.11.2.jar!/:2.8.11.2] at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1220) ~[jackson-databind-2.8.11.2.jar!/:2.8.11.2] at io.syndesis.connector.sheets.GoogleSheetsUpdateValuesCustomizer.beforeProducer(GoogleSheetsUpdateValuesCustomizer.java:97) ~[connector-google-sheets-1.6.4.jar!/:1.6.4] at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at io.syndesis.integration.component.proxy.ComponentProxyProducer.process(ComponentProxyProducer.java:44) ~[integration-component-proxy-1.6.4.jar!/:1.6.4] at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) ~[camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) [integration-runtime-1.6.4.jar!/:1.6.4] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.MulticastProcessor.doProcessSequential(MulticastProcessor.java:715) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.MulticastProcessor.doProcessSequential(MulticastProcessor.java:638) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.MulticastProcessor.process(MulticastProcessor.java:248) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.Splitter.process(Splitter.java:122) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at java.util.TimerThread.mainLoop(Timer.java:555) [na:1.8.0_191] at java.util.TimerThread.run(Timer.java:505) [na:1.8.0_191] ```  This is not working in 1.6.4 and CR1, but it worked with 1.6.2</body>
		<created>2019-04-02 11:52:54</created>
		<closed>2019-04-04 14:46:07</closed>
	</bug>
	<bug>
		<id>5108</id>
		<title>OData connector url validation with trailing slash</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description If you put a URL to OData service that has a trailing slash, the connector will not validate it correctly, because it adds "/$metadata" (to check if it is an OData service), which results in some.url/odata//$metadata </body>
		<created>2019-04-02 11:28:27</created>
		<closed>2019-07-01 12:54:49</closed>
	</bug>
	<bug>
		<id>5107</id>
		<title>Malformed integration can be published</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11450**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I am able to publish an integration which is malformed and will have errors in log and won't work. Small warning icon about data type mismatch is present but it is not enough to stop me from deploying the integration.   We should not allow malformed integration to be published.  ## Reproducer   ![screenshot_20190402_124915](https://user-images.githubusercontent.com/14313995/55397143-d23f9f00-5545-11e9-9fda-6a2eb66fbc02.png) ![screenshot_20190402_124856](https://user-images.githubusercontent.com/14313995/55397144-d23f9f00-5545-11e9-9111-1dd3f03b9424.png) ![screenshot_20190402_124938](https://user-images.githubusercontent.com/14313995/55397142-d23f9f00-5545-11e9-935e-a73bb3ace110.png) ![screenshot_20190402_124948](https://user-images.githubusercontent.com/14313995/55397141-d23f9f00-5545-11e9-80a1-b6c8dcf4e916.png)   </body>
		<created>2019-04-02 10:52:13</created>
		<closed>2019-09-07 11:45:29</closed>
	</bug>
	<bug>
		<id>5104</id>
		<title>Exported API Connectors reference icon by db id</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Exported API Connectors reference icon by db id but target system may not contains it, example:  ```json "connectorGroupId": "swagger-connector-template", "description": "A damage service api used to work with damage events.", "icon": "db:i-LbI5KTzgrJnaWjUyQ_7z", "id": "i-LbI3csggrJnaWjUyQ_5z", "name": "Damage Service", ```  </body>
		<created>2019-04-02 09:55:35</created>
		<closed>2019-07-10 16:43:27</closed>
	</bug>
	<bug>
		<id>5102</id>
		<title>Failure to download spring-social-salesforce dependency</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Seems that the build is failing with:  ``` [INFO] --- dependency-scope-maven-plugin:0.8:check (default) @ server-endpoint --- [INFO] Downloading from central: https://repo.maven.apache.org/maven2/com/github/mikegirard/spring-social-salesforce/1.3.0/spring-social-salesforce-1.3.0.pom [INFO] Downloading from jboss-ea: https://repository.jboss.org/nexus/content/groups/ea/com/github/mikegirard/spring-social-salesforce/1.3.0/spring-social-salesforce-1.3.0.pom [INFO] Downloading from redhat-ga: https://maven.repository.redhat.com/ga/com/github/mikegirard/spring-social-salesforce/1.3.0/spring-social-salesforce-1.3.0.pom  ...  [ERROR] Failed to execute goal com.hubspot.maven.plugins:dependency-scope-maven-plugin:0.8:check (default) on project server-endpoint: Error resolving descriptor for artifact com.github.mikegirard:spring-social-salesforce:1.3.0: Failed to read artifact descriptor for com.github.mikegirard:spring-social-salesforce:jar:1.3.0: Could not transfer artifact com.github.mikegirard:spring-social-salesforce:pom:1.3.0 from/to redhat-ga (https://maven.repository.redhat.com/ga/): Failed to transfer file: https://maven.repository.redhat.com/ga/com/github/mikegirard/spring-social-salesforce/1.3.0/spring-social-salesforce-1.3.0.pom. Return code is: 500, ReasonPhrase: Internal Server Error. -&gt; [Help 1] ```  Perhaps the best option would be to try to eliminate that dependency and not depend on it being downloaded from jitpack.  Or would be to try to determine why it's not downloaded in this use case.</body>
		<created>2019-04-02 07:00:26</created>
		<closed>2019-10-08 21:20:47</closed>
	</bug>
	<bug>
		<id>5100</id>
		<title>"n/a" when uptime of integration is less than 1 minute</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11432**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When uptime of the integration is less than 1 minute, the UI shows n/a. That can be confusing for the users and they can think that integration is not running. ![image](https://user-images.githubusercontent.com/16251792/55345006-34999080-54af-11e9-84c0-425b55288fd8.png)  </body>
		<created>2019-04-01 16:56:02</created>
		<closed>2019-09-07 11:25:19</closed>
	</bug>
	<bug>
		<id>5097</id>
		<title>Imported extension fails when building integration</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description relates to #4981  If you import an exported integration which used extension then that extension is imported as well, but for some reason the imported integration can't be built if you use the imported extension.  I tried to build the same integration with importing everything manually (not from the integration zip) and the integration builds and works.  Attaching log from the build phase  ``` Using docker.io/syndesis/syndesis-s2i@sha256:e35869ed9172c40493993684585dfcafdb289a1950be1cf683c91869389e3b96 as the s2i builder image Preparing to build temp.builder.openshift.io/syndesis/i-todo-test-1:b003d79d Copying sources from "/tmp/build/inputs" to "/tmp/upload/src" Clean build will be performed Running "assemble" in "temp.builder.openshift.io/syndesis/i-todo-test-1:b003d79d" tar: scripts: time stamp 2019-04-01 07:23:10 is 0.072104575 s in the future tar: src/pom.xml: time stamp 2019-04-01 07:23:10 is 0.071196303 s in the future tar: src/src/main/java/io/syndesis/example/Application.java: time stamp 2019-04-01 07:23:10 is 0.07098253 s in the future tar: src/src/main/java/io/syndesis/example: time stamp 2019-04-01 07:23:10 is 0.070946878 s in the future tar: src/src/main/java/io/syndesis: time stamp 2019-04-01 07:23:10 is 0.07091485 s in the future tar: src/src/main/java/io: time stamp 2019-04-01 07:23:10 is 0.070892865 s in the future tar: src/src/main/java: time stamp 2019-04-01 07:23:10 is 0.070872002 s in the future tar: src/src/main/resources/application.properties: time stamp 2019-04-01 07:23:10 is 0.070798193 s in the future tar: src/src/main/resources/loader.properties: time stamp 2019-04-01 07:23:10 is 0.070739909 s in the future tar: src/src/main/resources/syndesis/integration/integration.json: time stamp 2019-04-01 07:23:10 is 0.070615818 s in the future tar: src/src/main/resources/syndesis/integration: time stamp 2019-04-01 07:23:10 is 0.070577298 s in the future tar: src/src/main/resources/syndesis: time stamp 2019-04-01 07:23:10 is 0.070548766 s in the future tar: src/src/main/resources: time stamp 2019-04-01 07:23:10 is 0.070521214 s in the future tar: src/src/main: time stamp 2019-04-01 07:23:10 is 0.070492891 s in the future tar: src/src: time stamp 2019-04-01 07:23:10 is 0.070469384 s in the future tar: src: time stamp 2019-04-01 07:23:10 is 0.070445621 s in the future ================================================================== Starting S2I Java Build ..... S2I source build for Maven detected Using MAVEN_OPTS '-XX:+UseG1GC -XX:+UseStringDeduplication -Xmx310m' Found pom.xml ... Running 'mvn -Dmaven.repo.local=/tmp/artifacts/m2 package -DskipTests -Dmaven.javadoc.skip=true -Dmaven.site.skip=true -Dmaven.source.skip=true -Djacoco.skip=true -Dcheckstyle.skip=true -Dfindbugs.skip=true -Dpmd.skip=true -Dfabric8.skip=true -e -B ' Apache Maven 3.5.4 (1edded0938998edf8bf061f1ceb3cfdeccf443fe; 2018-06-17T18:33:14Z) Maven home: /opt/maven Java version: 1.8.0_191, vendor: Oracle Corporation, runtime: /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.191.b12-1.el7_6.x86_64/jre Default locale: en_US, platform encoding: ANSI_X3.4-1968 OS name: "linux", version: "3.10.0-957.5.1.el7.x86_64", arch: "amd64", family: "unix" [INFO] Error stacktraces are turned on. [INFO] Scanning for projects... [INFO] Downloading from 01_maven_central: https://repo1.maven.org/maven2/org/apache/camel/camel-spring-boot-dependencies/2.21.0.fuse-730054/camel-spring-boot-dependencies-2.21.0.fuse-730054.pom  [ERROR] [ERROR] Some problems were encountered while processing the POMs: [ERROR] Non-resolvable import POM: Could not find artifact org.apache.camel:camel-spring-boot-dependencies:pom:2.21.0.fuse-730054 in 01_maven_central (https://repo1.maven.org/maven2 ) @ line 52, column 19 @ [ERROR] The build could not read 1 project -&gt; [Help 1] org.apache.maven.project.ProjectBuildingException: Some problems were encountered while processing the POMs: [ERROR] Non-resolvable import POM: Could not find artifact org.apache.camel:camel-spring-boot-dependencies:pom:2.21.0.fuse-730054 in 01_maven_central (https://repo1.maven.org/maven2 ) @ line 52, column 19 at org.apache.maven.project.DefaultProjectBuilder.build (DefaultProjectBuilder.java:383) at org.apache.maven.graph.DefaultGraphBuilder.collectProjects (DefaultGraphBuilder.java:414) at org.apache.maven.graph.DefaultGraphBuilder.getProjectsForMavenReactor (DefaultGraphBuilder.java:405) at org.apache.maven.graph.DefaultGraphBuilder.build (DefaultGraphBuilder.java:82) at org.apache.maven.DefaultMaven.buildGraph (DefaultMaven.java:507) at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:219) at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192) at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105) at org.apache.maven.cli.MavenCli.execute (MavenCli.java:954) at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:288) at org.apache.maven.cli.MavenCli.main (MavenCli.java:192) at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke (Method.java:498) at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289) at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229) at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:415) at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:356) [ERROR] [ERROR]   The project io.syndesis.integrations:project:0.1-SNAPSHOT (/tmp/src/pom.xml) has 1 error [ERROR]     Non-resolvable import POM: Could not find artifact org.apache.camel:camel-spring-boot-dependencies:pom:2.21.0.fuse-730054 in 01_maven_central (https://repo1.maven.org/maven2 ) @ line 52, column 19 -&gt; [Help 2] org.apache.maven.model.resolution.UnresolvableModelException: Could not find artifact org.apache.camel:camel-spring-boot-dependencies:pom:2.21.0.fuse-730054 in 01_maven_central (https://repo1.maven.org/maven2 ) at org.apache.maven.project.ProjectModelResolver.resolveModel (ProjectModelResolver.java:197) at org.apache.maven.model.building.DefaultModelBuilder.importDependencyManagement (DefaultModelBuilder.java:1247) at org.apache.maven.model.building.DefaultModelBuilder.build (DefaultModelBuilder.java:458) at org.apache.maven.model.building.DefaultModelBuilder.build (DefaultModelBuilder.java:424) at org.apache.maven.project.DefaultProjectBuilder.build (DefaultProjectBuilder.java:583) at org.apache.maven.project.DefaultProjectBuilder.build (DefaultProjectBuilder.java:373) at org.apache.maven.graph.DefaultGraphBuilder.collectProjects (DefaultGraphBuilder.java:414) at org.apache.maven.graph.DefaultGraphBuilder.getProjectsForMavenReactor (DefaultGraphBuilder.java:405) at org.apache.maven.graph.DefaultGraphBuilder.build (DefaultGraphBuilder.java:82) at org.apache.maven.DefaultMaven.buildGraph (DefaultMaven.java:507) at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:219) at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192) at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105) at org.apache.maven.cli.MavenCli.execute (MavenCli.java:954) at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:288) at org.apache.maven.cli.MavenCli.main (MavenCli.java:192) at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke (Method.java:498) at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289) at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229) at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:415) at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:356) Caused by: org.eclipse.aether.resolution.ArtifactResolutionException: Could not find artifact org.apache.camel:camel-spring-boot-dependencies:pom:2.21.0.fuse-730054 in 01_maven_central (https://repo1.maven.org/maven2 ) at org.eclipse.aether.internal.impl.DefaultArtifactResolver.resolve (DefaultArtifactResolver.java:422) at org.eclipse.aether.internal.impl.DefaultArtifactResolver.resolveArtifacts (DefaultArtifactResolver.java:224) at org.eclipse.aether.internal.impl.DefaultArtifactResolver.resolveArtifact (DefaultArtifactResolver.java:201) at org.eclipse.aether.internal.impl.DefaultRepositorySystem.resolveArtifact (DefaultRepositorySystem.java:260) at org.apache.maven.project.ProjectModelResolver.resolveModel (ProjectModelResolver.java:193) at org.apache.maven.model.building.DefaultModelBuilder.importDependencyManagement (DefaultModelBuilder.java:1247) at org.apache.maven.model.building.DefaultModelBuilder.build (DefaultModelBuilder.java:458) at org.apache.maven.model.building.DefaultModelBuilder.build (DefaultModelBuilder.java:424) at org.apache.maven.project.DefaultProjectBuilder.build (DefaultProjectBuilder.java:583) at org.apache.maven.project.DefaultProjectBuilder.build (DefaultProjectBuilder.java:373) at org.apache.maven.graph.DefaultGraphBuilder.collectProjects (DefaultGraphBuilder.java:414) at org.apache.maven.graph.DefaultGraphBuilder.getProjectsForMavenReactor (DefaultGraphBuilder.java:405) at org.apache.maven.graph.DefaultGraphBuilder.build (DefaultGraphBuilder.java:82) at org.apache.maven.DefaultMaven.buildGraph (DefaultMaven.java:507) at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:219) at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192) at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105) at org.apache.maven.cli.MavenCli.execute (MavenCli.java:954) at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:288) at org.apache.maven.cli.MavenCli.main (MavenCli.java:192) at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke (Method.java:498) at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289) at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229) at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:415) at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:356) Caused by: org.eclipse.aether.transfer.ArtifactNotFoundException: Could not find artifact org.apache.camel:camel-spring-boot-dependencies:pom:2.21.0.fuse-730054 in 01_maven_central (https://repo1.maven.org/maven2 ) at org.eclipse.aether.connector.basic.ArtifactTransportListener.transferFailed (ArtifactTransportListener.java:48) at org.eclipse.aether.connector.basic.BasicRepositoryConnector$TaskRunner.run (BasicRepositoryConnector.java:365) at org.eclipse.aether.util.concurrency.RunnableErrorForwarder$1.run (RunnableErrorForwarder.java:75) at org.eclipse.aether.connector.basic.BasicRepositoryConnector$DirectExecutor.execute (BasicRepositoryConnector.java:583) at org.eclipse.aether.connector.basic.BasicRepositoryConnector.get (BasicRepositoryConnector.java:259) at org.eclipse.aether.internal.impl.DefaultArtifactResolver.performDownloads (DefaultArtifactResolver.java:498) at org.eclipse.aether.internal.impl.DefaultArtifactResolver.resolve (DefaultArtifactResolver.java:399) at org.eclipse.aether.internal.impl.DefaultArtifactResolver.resolveArtifacts (DefaultArtifactResolver.java:224) at org.eclipse.aether.internal.impl.DefaultArtifactResolver.resolveArtifact (DefaultArtifactResolver.java:201) at org.eclipse.aether.internal.impl.DefaultRepositorySystem.resolveArtifact (DefaultRepositorySystem.java:260) at org.apache.maven.project.ProjectModelResolver.resolveModel (ProjectModelResolver.java:193) at org.apache.maven.model.building.DefaultModelBuilder.importDependencyManagement (DefaultModelBuilder.java:1247) at org.apache.maven.model.building.DefaultModelBuilder.build (DefaultModelBuilder.java:458) at org.apache.maven.model.building.DefaultModelBuilder.build (DefaultModelBuilder.java:424) at org.apache.maven.project.DefaultProjectBuilder.build (DefaultProjectBuilder.java:583) at org.apache.maven.project.DefaultProjectBuilder.build (DefaultProjectBuilder.java:373) at org.apache.maven.graph.DefaultGraphBuilder.collectProjects (DefaultGraphBuilder.java:414) at org.apache.maven.graph.DefaultGraphBuilder.getProjectsForMavenReactor (DefaultGraphBuilder.java:405) at org.apache.maven.graph.DefaultGraphBuilder.build (DefaultGraphBuilder.java:82) at org.apache.maven.DefaultMaven.buildGraph (DefaultMaven.java:507) at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:219) at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192) at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105) at org.apache.maven.cli.MavenCli.execute (MavenCli.java:954) at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:288) at org.apache.maven.cli.MavenCli.main (MavenCli.java:192) at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke (Method.java:498) at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289) at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229) at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:415) at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:356) [ERROR] [ERROR] Re-run Maven using the -X switch to enable full debug logging. [ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles: [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException  [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/UnresolvableModelException  Aborting due to error code 1 for Maven build error: build error: non-zero (13) exit code from docker.io/syndesis/syndesis-s2i@sha256:e35869ed9172c40493993684585dfcafdb289a1950be1cf683c91869389e3b96 ``` And also the exported integration [todo-test-export.zip](https://github.com/syndesisio/syndesis/files/2989090/todo-test-export.zip) </body>
		<created>2019-04-01 07:35:03</created>
		<closed>2019-04-24 15:20:15</closed>
	</bug>
	<bug>
		<id>5096</id>
		<title>Returning an empty collection from API Provider causes an error</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When the return value of an API Provider operation is an empty colleciton, a 500 error is returned instead, along with the following stack trace: ``` io.atlasmap.api.AtlasException: Errors: [It's not yet supported to have a collection field as a part of multiple source fields in a same mapping: docId='-LbMg_X2En_TXeIobD32', path='/&lt;&gt;/completed'],  at org.apache.camel.component.atlasmap.AtlasEndpoint.onExchange(AtlasEndpoint.java:266) at org.apache.camel.impl.ProcessorEndpoint$1.process(ProcessorEndpoint.java:71) at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.component.direct.DirectBlockingProducer.process(DirectBlockingProducer.java:53) at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:97) at org.apache.camel.http.common.CamelServlet.doService(CamelServlet.java:214) at org.apache.camel.http.common.CamelServlet.service(CamelServlet.java:80) at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:111) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:103) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:64) at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:132) at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292) at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) at io.undertow.server.Connectors.executeRootHandler(Connectors.java:336) at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) ```  </body>
		<created>2019-04-01 07:13:19</created>
		<closed>2019-07-02 09:51:14</closed>
	</bug>
	<bug>
		<id>5093</id>
		<title>Split step not able to handle input stream bodies</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Some connectors provide input stream as message body (e.g. Http connector). Split step is not able to handle the input stream. Split step should read input stream content and try to perform split on the String content (e.g. Json array). </body>
		<created>2019-03-31 20:09:52</created>
		<closed>2019-04-17 11:53:36</closed>
	</bug>
	<bug>
		<id>5078</id>
		<title>CI/CD tag is set for all integrations</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description This issue exists in the last CR1 (1.6.2.fuse-730001-redhat-00001). In the master, it works. When I add a tag in the CI/CD dialog, the tag is added to all integration. I am not able to uncheck it, only delete it from all integration. The issue looks similar (not same) as #4683 . However, all fixes from that issue look back-ported in 1.6.x .  ----------------------------------- **CR1:** ``` curl .../timer-to-log-1/tags --request PUT -d '["tag100"]' ``` The _timer-to-log-1_ contains it ``` curl .../timer-to-log-1/tags --request GET {"tag100":{"name":"tag100","releaseTag":"i-Lb2oX1en02206AHqYm6z","lastTaggedAt":1553768521898}} ``` The _timer-to-log-2_ contains it too (but it shouldn't) however inconsistent with null ``` curl ... /timer-to-log-2/tags --request GET {"tag100":null} ``` ----------------------------------- On the **master,** it works correctly: ``` curl .../timer-to-log-1/tags --request PUT -d '["tag100"]' ``` The _timer-to-log-1_ contains it ``` curl .../timer-to-log-1/tags --request GET {"tag100":{"name":"tag100","releaseTag":"i-Lb2oX1en02206AHqYm6z","lastTaggedAt":1553768521898}} ``` The _timer-to-log-2_ doesn't contains it  ``` curl ... /timer-to-log-2/tags --request GET {} ```  On the video below, on the right site is master, on the left site is 1.6.2.fuse-730001-redhat-00001. ![output](https://user-images.githubusercontent.com/16251792/55150606-c53d3d00-514c-11e9-97bd-4ec9637abe70.gif)  Lets say, that the user have three integrations (timer1, timer2, timer3) in the _environment1_. So in case, when the user want to export some integrations (e.g. _timer1_, _timer2_) according to the particular tag, the all integrations are exported (_timer3_ too). As a workaround, the user can delete the unnecessary integrations after import .zip file in the _environment2_. However, when they have integration with the same name on both environment (_timer3_ is in the _environment2_ before import Ing zip file, _timer1_ and _timer2_ not), and they want to export only _timer1_ and _timer2_, _timer3_ will be exported too (because a tag is set accross all integrations) and after import zip file original _timer3_ in the _environment2_ will be replace by imported _timer3_. Because of that, I marked this issue as Blocker.</body>
		<created>2019-03-28 11:59:47</created>
		<closed>2019-04-15 11:05:22</closed>
	</bug>
	<bug>
		<id>5076</id>
		<title>warns about parameters changed on a connection</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When I create an integration on staging I always see the banner that warns about parameters changed on a connection  ![image](https://user-images.githubusercontent.com/1868933/55149176-fbc58880-5149-11e9-9938-1b27252fcff9.png)  </body>
		<created>2019-03-28 10:10:25</created>
		<closed>2019-07-10 16:43:28</closed>
	</bug>
	<bug>
		<id>5060</id>
		<title>OData enum output is wrong</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Using OData connector to read and then create/update, it needs Data Mapper in between. I tried to map enum today and it fails with error: `[Failed to convert field value 'Male' into type 'NUMBER': docId='-LatezusaSAYPd8-rHUM', path='/&lt;0&gt;/Gender'], [Unexpected exception is thrown while populating target field: null: docId='-Latf3VcaSAYPd8-rHUM', path='/Gender'], ` it seems that the odata is using number to represent the enum, but it is passing the string representation instead of the actual number, is that right?  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create new integration: OData read -&gt; Data Mapper -&gt; OData update (try to use https://services.odata.org/TripPinRESTierService/ as sample service) 2. map enum value (Data Mapper shows the type of the value as NUMBER) 3. run the integration </body>
		<created>2019-03-26 13:46:46</created>
		<closed>2019-07-29 10:06:46</closed>
	</bug>
	<bug>
		<id>5047</id>
		<title>Exception when using arrays of integers as response of API provider integration</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  `java.lang.IllegalArgumentException: Only references to schemas are supported` is thrown when using operations defined like:  ```json     {       "get" : {         "produces" : [ "application/json" ],         "responses" : {           "200" : {             "description" : "The list of machine ID's",             "schema" : {               "type" : "array",               "items" : {                 "type" : "integer"               }             }           }         }       }     } ```</body>
		<created>2019-03-25 16:46:01</created>
		<closed>2019-04-03 12:00:57</closed>
	</bug>
	<bug>
		<id>5036</id>
		<title>Update migration scripts</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [X] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Currently, the update mechanism allows executing scripts which are stored in a directory named as the target version. However, this approach doesn't work on both, upstream and product because they are using different version schemes.  Since this mechanism is fragile, it should be removed, and update migrations scripts are supposed to be idempotent and the sense they can detect whether they have been already run, and if so, do nothing if running a second time. The directory `migration/resources/any` is reserved for this.  See also #4413 for the original discussion.</body>
		<created>2019-03-22 15:24:54</created>
		<closed>2019-07-03 16:15:53</closed>
	</bug>
	<bug>
		<id>5029</id>
		<title>Twitter search action can't have multiple keywords</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The keywords tooltip (and keyword on its own being plural) hints at keywords taking a comma separated list of keywords, but if you specify keywords like that, the Twitter connection does not produce any outputs.  I have created a simple integration which searches twitter for keyword test, and then modified it to be looking for a list of keywords like this:  ![image](https://user-images.githubusercontent.com/46345469/54823075-034ae480-4ca7-11e9-875b-d04b655a7da0.png) The first version produced output every 5 seconds but the second version does not produce any output as you can see here:  ![image](https://user-images.githubusercontent.com/46345469/54823128-28d7ee00-4ca7-11e9-8985-97af8474b15b.png)  </body>
		<created>2019-03-22 12:32:54</created>
		<closed>2019-06-25 06:17:56</closed>
	</bug>
	<bug>
		<id>5026</id>
		<title>Data Mapper Transformation is unexpectedly duplicated</title>
		<body>Backport atlasmap/atlasmap#834 fix once it's released, it's gonna be atlasmap-1.39.6. </body>
		<created>2019-03-21 21:58:29</created>
		<closed>2019-04-04 06:13:05</closed>
	</bug>
	<bug>
		<id>5022</id>
		<title>Unable to use fetches a record from Salesforce by external id</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  I created a simple integration that does:      db -&gt; split -&gt; datamapper -&gt; salesforce -&gt; log  with the aim of retrieving an object from Salesforce using a contact from the contact table (sampledb) but the integration fails for a number of reasons:  - atlasmap is not able to istantiate the object that the salesforce connector expects (SalesforceIdentifier) - salesforce connector does not check for the message body for being of the expected type and tries to convert it to the expected type as it were a string  </body>
		<created>2019-03-21 14:34:33</created>
		<closed>2019-03-21 18:01:05</closed>
	</bug>
	<bug>
		<id>5019</id>
		<title>Error in data mapper when editing an API Provider flow which changed due to API definition change</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11434**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description In an API Provider integration, after changing the return type of an operation that's already implemented, trying to update the data mapping causes the following error: ``` Data Mapper UI Initialization Error: Could not load document 'i-LaUfMv856-V-nkQhsB7z': undefined undefined  ``` ![image](https://user-images.githubusercontent.com/9480152/54748810-ffe62900-4bd2-11e9-9779-ac2f9bd549fe.png)  ## Steps to reproduce: 1. create an API Provider integration with a flow that requires a data mapping 1. edit the operation so that the data mapping would not be valid (e.g. change the return type) 1. save the API definition 1. open the appropriate flow, notice a warning badge on the result 1. open the data mapper to change the mapping, the above error is shown  </body>
		<created>2019-03-21 11:18:09</created>
		<closed>2019-09-07 11:28:43</closed>
	</bug>
	<bug>
		<id>5018</id>
		<title>No indication a flow needs to be updated when editing API definition</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11451**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description After editing an operation that's already implemented in an API Provider integration, there's no indication on the Operation List page that the flow needs to be updated.  ## Steps to reproduce 1. create an API Provider integration with a flow that requires a data mapping 2. edit the operation so that the data mapping would not be valid (e.g. change the return type) 3. save the API definition 4. no indication that the mapping is no longer valid </body>
		<created>2019-03-21 11:11:25</created>
		<closed>2019-09-07 11:45:36</closed>
	</bug>
	<bug>
		<id>5000</id>
		<title>Documentation links lead to 404 page</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description All the documentation links at least in release 1.6.2 lead to 404 page. I feel like on master the same thing happened but can't switch versions right now.  </body>
		<created>2019-03-20 14:40:00</created>
		<closed>2019-05-10 12:06:23</closed>
	</bug>
	<bug>
		<id>4997</id>
		<title>Google-sheets: Max results is ignored</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description User is still getting amount of rows defined in range so max results option is not taken into account. </body>
		<created>2019-03-20 13:49:21</created>
		<closed>2019-07-10 15:43:27</closed>
	</bug>
	<bug>
		<id>4995</id>
		<title>Publishing imported integration fails if integration once existed in Syndesis</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Exported integrations can be imported into Syndesis, but they can't be published. On fresh deployment of Syndesis the integration can be imported and works fine. I am attaching log from the server pod, I imported the integration and tried to publish it, it worked for the first time, but after deleting the integration, it is not possible to publish the integration.  I'd say that the error might be caused or have something to do with this error message: ``` 2019-03-20 12:58:43.420 ERROR [-,4dd2d40e3221f18c,4dd2d40e3221f18c,false] 1 --- [  XNIO-3 task-6] i.s.s.e.v.h.i.IntegrationHandler         : Error deleting integration deployment todo-test: Failure executing: PATCH at: https://kubernetes.default.svc/api/v1/namespaces/syndesis/replicationcontrollers/i-todo-test-2 . Message: Forbidden!Configured service account doesn't have access. Service account may have been revoked. replicationcontrollers "i-todo-test-2" is forbidden: cannot set blockOwnerDeletion if an ownerReference refers to a resource you can't set finalizers on: no RBAC policy matched, &lt;nil&gt;. ``` [syndesis-server-1-krf47.log](https://github.com/syndesisio/syndesis/files/2988290/syndesis-server-1-krf47.log)  </body>
		<created>2019-03-20 13:14:31</created>
		<closed>2019-05-20 13:47:54</closed>
	</bug>
	<bug>
		<id>4994</id>
		<title>[GoogleSheets] data mapper not able to handle split results</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When split option on the GoogleSheets connector is enabled the data mapper is not able to process the messages.  This is because the GoogleSheets connection defines a data shape of type json object but provides a Java list of json beans (with one single bean in it).  That used to work but is now causing errors while mapping with data mapper. The connector should provide a json object string instead of a single element list in that case when split is option is enabled.   Sample exception stack trace: ``` io.atlasmap.api.AtlasException: Errors: [Unexpected exception is thrown while reading source field: null: docId='-LaQ3UP2ZcoAB-YQIrI3', path='/A'], [Unexpected exception is thrown while reading source field: null: docId='-LaQ3UP2ZcoAB-YQIrI3', path='/A'], [Unexpected exception is thrown while reading source field: null: docId='-LaQ3UP2ZcoAB-YQIrI3', path='/B'], [Unexpected exception is thrown while reading source field: null: docId='-LaQ3UP2ZcoAB-YQIrI3', path='/A'], [Unexpected exception is thrown while reading source field: null: docId='-LaQ3UP2ZcoAB-YQIrI3', path='/B'], [Unexpected exception is thrown while reading source field: null: docId='-LaQ3UP2ZcoAB-YQIrI3', path='/C'],  at org.apache.camel.component.atlasmap.AtlasEndpoint.onExchange(AtlasEndpoint.java:266) at org.apache.camel.impl.ProcessorEndpoint$1.process(ProcessorEndpoint.java:71) at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.component.google.sheets.stream.GoogleSheetsStreamConsumer.processBatch(GoogleSheetsStreamConsumer.java:129) at org.apache.camel.component.google.sheets.stream.GoogleSheetsStreamConsumer.poll(GoogleSheetsStreamConsumer.java:111) at org.apache.camel.impl.ScheduledPollConsumer.doRun(ScheduledPollConsumer.java:174) at org.apache.camel.impl.ScheduledPollConsumer.run(ScheduledPollConsumer.java:101) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) ```</body>
		<created>2019-03-20 13:03:34</created>
		<closed>2019-04-04 14:52:05</closed>
	</bug>
	<bug>
		<id>4981</id>
		<title>Imported integration with extension does not import the extension</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I created a simple integration  Timer -&gt; OpenAPI connector -&gt; Script Extension -&gt; Log Exported it, manually deleted all connections, OpenAPI specifications and extensions. The OpenAPI connector gets imported while importing the integration, but the integration gets imported with empty step instead of the Script extension, although the .jar file is present in the exported file ZIP. </body>
		<created>2019-03-20 07:58:53</created>
		<closed>2019-04-03 06:54:48</closed>
	</bug>
	<bug>
		<id>4978</id>
		<title>[Apicurito operator] - CRD cannot be deleted</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ X ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  An operator works fine but after tests when I am doing cleanup there is a problem with CRD. The CRD cannot be deleted. Command:  `oc delete crd apicuritos.apicur.io` This command never ends and CRD is in state "object is being deleted"  btw. other resources (Role, RoleBinding, ... ) have not this problem.  #4871 </body>
		<created>2019-03-19 15:56:34</created>
		<closed>2019-03-26 15:28:19</closed>
	</bug>
	<bug>
		<id>4977</id>
		<title>Deleting all operations from an API Provider integration breaks Apicurito</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When editing an existing API Provider integration's specification and deleting all defined operations, clicking the Save button in Apicurito does nothing. After that, it's impossible to navigate away from Apicurito, either by clicking Save, Cancel button or the Back link.  This is related to #4976 , inlcuding the error message in the console, but in this case, it's not possible to deploy the resulting integration. </body>
		<created>2019-03-19 15:48:13</created>
		<closed>2019-06-04 13:48:42</closed>
	</bug>
	<bug>
		<id>4969</id>
		<title>Can't add any step/connection to the integration after trying to add the Aggregate step</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Steps to reproduce 1. start creating a new integration 2. select start and finish connections 3. add Split step between them 4. if you try to select the Aggregate step, it fails and any other step/connection can't be selected  Only refreshing the browser tab brings back the possibility of selecting the steps but the Aggregate step still can't be clicked otherwise it causes the same problem again.   ![syndesis](https://user-images.githubusercontent.com/8707251/54598635-38ea9600-4a39-11e9-8ca4-51a73aa7dd19.gif) </body>
		<created>2019-03-19 10:25:38</created>
		<closed>2019-04-02 11:40:24</closed>
	</bug>
	<bug>
		<id>4961</id>
		<title>Parsing oc version doesn't work for 4.X version of oc</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description seems that oc changed the version output:  ``` oc version Client Version: version.Info{Major:"4", Minor:"0+", GitVersion:"v4.0.22", GitCommit:"219bbe2f0c", GitTreeState:"", BuildDate:"2019-03-10T22:23:11Z", GoVersion:"", Compiler:"", Platform:""} Server Version: version.Info{Major:"1", Minor:"12+", GitVersion:"v1.12.4+0f8e04e", GitCommit:"0f8e04e", GitTreeState:"clean", BuildDate:"2019-03-04T15:33:19Z", GoVersion:"go1.10.8", Compiler:"gc", Platform:"linux/amd64"} ```  This command then fails: https://github.com/syndesisio/syndesis/blob/d2c05e8e797dfa87d3ac6a5c2f8e3c46b0bfe665/tools/bin/commands/util/openshift_funcs#L9</body>
		<created>2019-03-19 08:10:28</created>
		<closed>2019-05-28 19:08:50</closed>
	</bug>
	<bug>
		<id>4960</id>
		<title>datamapper editor does not appear</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  After updating to latest master UI, I'm experiencing the following issue when doing an integration from Telegram to Telegram:  ![telegram2telegram](https://user-images.githubusercontent.com/1868933/54582828-7687f880-4a12-11e9-8e0d-459544985b1b.gif)  This does not happen when doing other integrations such as DB to DB.  The same behaviour can be observed on staging.  I do not know if this applies to 1.6 too.  </body>
		<created>2019-03-19 05:50:10</created>
		<closed>2019-03-26 12:12:19</closed>
	</bug>
	<bug>
		<id>4945</id>
		<title>[camel-k] Update Operator to link service accounts if a given secret 'camel-k-pull-secret' exists</title>
		<body> See https://github.com/syndesisio/syndesis/issues/4900 for a description. The same mechanics need to applied by the camel -k operator the be able to pull from a terms based registry.  For camel-k, as far as I know, the `builder` SA needs to be linked to the pull secret as well. (See https://github.com/syndesisio/syndesis/issues/4900#issuecomment-473936723) </body>
		<created>2019-03-18 15:33:50</created>
		<closed>2019-04-03 13:15:16</closed>
	</bug>
	<bug>
		<id>4943</id>
		<title>Cannot create log connection step</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When trying to add Log connection (Log -&gt; Simple Logger action) as finish step, the connection just keeps loading and nothing happens. the chrome console displays  `ERROR TypeError: Cannot read property 'find' of undefined     at /12.93e47d2f00a932911647.js:1     at Array.forEach (&lt;anonymous&gt;)     at n.reconcileAllDataShapes (/12.93e47d2f00a932911647.js:1)     at o (/12.93e47d2f00a932911647.js:1)     at n.handleEvent (/12.93e47d2f00a932911647.js:1)     at /12.93e47d2f00a932911647.js:1     at e.t.object.o [as _next] (main.f99b4e125a82f5836537.js:1)     at e.__tryOrUnsub (polyfills.cd1c6ed959cbc1c630d4.js:1)     at e.next (polyfills.cd1c6ed959cbc1c630d4.js:1)     at e._next (polyfills.cd1c6ed959cbc1c630d4.js:1)`  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![simple_logger](https://user-images.githubusercontent.com/46523434/54539224-0340a100-4996-11e9-9c44-dcc2aed301c1.png)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. select periodic sql invocation as start step 2. select Log connection as finish step with simple logger action </body>
		<created>2019-03-18 14:56:59</created>
		<closed>2019-03-18 15:00:55</closed>
	</bug>
	<bug>
		<id>4937</id>
		<title>Dict points to wrong version in 1.6.x</title>
		<body>https://github.com/syndesisio/syndesis/blob/1.6.x/app/ui/src/assets/dictionary/en-GB.json#L332 refers to 7.2, but it should use 7.3 instead</body>
		<created>2019-03-18 14:12:00</created>
		<closed>2019-03-18 14:49:38</closed>
	</bug>
	<bug>
		<id>4935</id>
		<title>Two "Log" cards appear when the user has to choose a step</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  For 7.3, the user now sees two Log cards but has no way to know which card to click. Something must change for 7.3.  See related issue:  https://github.com/syndesisio/syndesis/issues/4425</body>
		<created>2019-03-18 13:57:20</created>
		<closed>2019-03-26 11:37:34</closed>
	</bug>
	<bug>
		<id>4934</id>
		<title>Remove the Tech Preview banner from the API Provider card </title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  The "Technology Preview" banner still appears on the API Provider card after a user clicks "Create Integration". This banner needs to be removed for 7.3.   </body>
		<created>2019-03-18 13:54:49</created>
		<closed>2019-03-18 15:25:11</closed>
	</bug>
	<bug>
		<id>4933</id>
		<title>Add AMQ connection causes error in UI</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description ![Bildschirmfoto 2019-03-18 um 14 31 56](https://user-images.githubusercontent.com/195264/54533580-d2a73a00-498a-11e9-9a3b-80360f6a09c9.png)  Steps to reproduce: Add AMQ connection as finish connection  Most likely related to https://github.com/syndesisio/syndesis/issues/4914 when step action has no tags defined. AMQ connector provides no tags and is just an example. </body>
		<created>2019-03-18 13:36:49</created>
		<closed>2019-03-19 07:23:14</closed>
	</bug>
	<bug>
		<id>4926</id>
		<title>Lib alignment errors in Camel K mode</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Standard mode imports the spring-boot bom, that among other things aligns versions of some libraries such as Jackson.  Camel versions should be aligned, but if we mix them with syndesis runtime jar, we get `jackson-annotation` 2.9 and other related libraries in version `2.8` (camel version).  The result is:  ```  Exception in thread "main" java.lang.NoSuchFieldError: _valueInstantiator --  | at com.fasterxml.jackson.datatype.jdk8.OptionalDeserializer.withResolved(OptionalDeserializer.java:38)  | at com.fasterxml.jackson.datatype.jdk8.OptionalDeserializer.withResolved(OptionalDeserializer.java:10)  | at com.fasterxml.jackson.databind.deser.std.ReferenceTypeDeserializer.createContextual(ReferenceTypeDeserializer.java:74)  | at com.fasterxml.jackson.databind.DeserializationContext.handlePrimaryContextualization(DeserializationContext.java:650)  | at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.resolve(BeanDeserializerBase.java:490)  | at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:293)  | at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244)  | at com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142)  | at com.fasterxml.jackson.databind.DeserializationContext.findContextualValueDeserializer(DeserializationContext.java:443)  | at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.createContextual(CollectionDeserializer.java:206)  | at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.createContextual(CollectionDeserializer.java:26)  | at com.fasterxml.jackson.databind.DeserializationContext.handlePrimaryContextualization(DeserializationContext.java:650)  | at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.resolve(BeanDeserializerBase.java:490)  | at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:293)  | at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244)  | at com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142)  | at com.fasterxml.jackson.databind.DeserializationContext.findRootValueDeserializer(DeserializationContext.java:476)  | at com.fasterxml.jackson.databind.ObjectReader._prefetchRootDeserializer(ObjectReader.java:1902)  | at com.fasterxml.jackson.databind.ObjectReader.forType(ObjectReader.java:676)  | at com.fasterxml.jackson.databind.ObjectReader.forType(ObjectReader.java:696)  | at io.syndesis.integration.runtime.IntegrationRouteBuilder.loadIntegration(IntegrationRouteBuilder.java:91)  | at io.syndesis.integration.runtime.IntegrationRouteBuilder.configure(IntegrationRouteBuilder.java:102)  | at org.apache.camel.builder.RouteBuilder.checkInitialized(RouteBuilder.java:462)  | at org.apache.camel.builder.RouteBuilder.configureRoutes(RouteBuilder.java:402)  | at org.apache.camel.builder.RouteBuilder.addRoutesToCamelContext(RouteBuilder.java:383)  | at org.apache.camel.impl.DefaultCamelContext$1.call(DefaultCamelContext.java:1027)  | at org.apache.camel.impl.DefaultCamelContext$1.call(DefaultCamelContext.java:1024)  | at org.apache.camel.impl.DefaultCamelContext.doWithDefinedClassLoader(DefaultCamelContext.java:3270)  | at org.apache.camel.impl.DefaultCamelContext.addRoutes(DefaultCamelContext.java:1024)  | at org.apache.camel.k.listener.RoutesConfigurer.load(RoutesConfigurer.java:73)  | at org.apache.camel.k.listener.RoutesConfigurer.accept(RoutesConfigurer.java:45)  | at org.apache.camel.k.listener.AbstractPhaseListener.accept(AbstractPhaseListener.java:31)  | at org.apache.camel.k.jvm.ApplicationRuntime$MainListenerAdapter.lambda$configure$2(ApplicationRuntime.java:156)  | at java.lang.Iterable.forEach(Iterable.java:75)  | at org.apache.camel.k.jvm.ApplicationRuntime$MainListenerAdapter.configure(ApplicationRuntime.java:156)  | at org.apache.camel.main.MainSupport.postProcessCamelContext(MainSupport.java:618)  | at org.apache.camel.main.MainSupport.postProcessContext(MainSupport.java:550)  | at org.apache.camel.k.jvm.ApplicationRuntime$Main.doStart(ApplicationRuntime.java:126)  | at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61)  | at org.apache.camel.main.MainSupport.run(MainSupport.java:170)  | at org.apache.camel.k.jvm.ApplicationRuntime.run(ApplicationRuntime.java:72)  | at org.apache.camel.k.jvm.Application.main(Application.java:52)   ```  To reproduce: create an integration from telegram to telegram with datamapper in the middle. cc: @lburgazzoli  </body>
		<created>2019-03-18 11:13:00</created>
		<closed>2019-03-20 06:26:12</closed>
	</bug>
	<bug>
		<id>4924</id>
		<title>Cancel button cancels the whole integration when adding a middle step</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description @gashcrumb on latest master I can see the exact issue as described in #4610, the cancel button exits the integration editor where I would expect to cancel only the add step page. When I want to cancel adding a middle step, I need to first select some step and then hit the cancel button </body>
		<created>2019-03-18 08:26:00</created>
		<closed>2019-06-14 06:44:18</closed>
	</bug>
	<bug>
		<id>4914</id>
		<title>Invoking metadata endpoints for non dynamic actions</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  In API provider integrations I noticed that we invoke `/api/v1/connections/api-provider/actions/io.syndesis:api-provider-start` and `/api/v1/connections/api-provider/actions/io.syndesis:api-provider-end` endpoints -- the action metadata. For actions that are not tagged with `dynamic`. The generated integration already contains the shapes based on the OpenAPI specification and invoking the action metadata endpoint for them will yield `any` data shape as that's what the connector descriptor defines.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlisting the acceptance criteria. --&gt; Invoking action metadata endpoint only for actions tagged with `dynamic`.  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create API provider integration based on the [TODO OpenAPI](https://todo-syndesis-staging.b6ff.rh-idev.openshiftapps.com/swagger.json) 2. While implementing one of the flows notice the invocations of `/api/v1/connections/api-provider/actions/io.syndesis:api-provider-start` and `/api/v1/connections/api-provider/actions/io.syndesis:api-provider-end` endpoints </body>
		<created>2019-03-15 13:23:53</created>
		<closed>2019-08-09 07:00:19</closed>
	</bug>
	<bug>
		<id>4912</id>
		<title>Test failure in OData connector</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Seems that we have a test failure, it's blocking the 1.6.1 release:  ``` 12:49:47 [ERROR] testReadMetaDataRetrievalWithSplit(io.syndesis.connector.odata.meta.ODataMetaDataRetrievalTest)  Time elapsed: 0.042 s  &lt;&lt;&lt; ERROR! 12:49:47 java.lang.IllegalArgumentException: Class com.fasterxml.jackson.module.jsonSchema.types.ArraySchema not subtype of [simple type, class com.fasterxml.jackson.module.jsonSchema.types.ObjectSchema] 12:49:47 at io.syndesis.connector.odata.meta.ODataMetaDataRetrievalTest.checkShape(ODataMetaDataRetrievalTest.java:68) 12:49:47 at io.syndesis.connector.odata.meta.ODataMetaDataRetrievalTest.testReadMetaDataRetrievalWithSplit(ODataMetaDataRetrievalTest.java:176) ``` </body>
		<created>2019-03-15 12:36:16</created>
		<closed>2019-03-15 12:56:25</closed>
	</bug>
	<bug>
		<id>4911</id>
		<title>Filters/Sorts have dropdowns with only one option</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Filters/Sorts have dropdowns with only one option, so it probably doesn't make sense to have the dropdowns, wdyt?  In the integration for example: - in "Choose a step" page - in for example SQL connector, where I can filter the actions I can use  ![U91n](https://user-images.githubusercontent.com/7081216/54430752-d3d72d80-4724-11e9-97db-257da24a3970.png) </body>
		<created>2019-03-15 12:19:12</created>
		<closed>2019-06-20 13:43:31</closed>
	</bug>
	<bug>
		<id>4910</id>
		<title>API Connector does not save any change with warnings</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Upload an OpenAPI file, click to edit it. Make some "good" changes and one with some warning. E.g. create one operation with a response but do not fill description -&gt; warning shows. Click on Save button. The current step is previous (Upload OpenAPI Document ) with an error similar to: ![warnn](https://user-images.githubusercontent.com/22192892/54428621-53adc980-471e-11e9-8f33-cb7cb205268a.png)  Now you cannot click on the Next button.  Problem is when I make a lot of changes but one has a warning, not an error in apicurito I will lose all changes. </body>
		<created>2019-03-15 12:08:17</created>
		<closed>2019-07-17 10:54:53</closed>
	</bug>
	<bug>
		<id>4908</id>
		<title>Clicking a split step defined in the integration causes flickers</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Clicking a split step already defined in the integration causes flickers as it probably tries to open the configuration, but obviously it doesn't have any.  ![out](https://user-images.githubusercontent.com/7081216/54430184-097b1700-4723-11e9-8f5f-626b750fd071.gif)  the same happens with aggregate </body>
		<created>2019-03-15 12:06:54</created>
		<closed>2019-06-13 13:33:42</closed>
	</bug>
	<bug>
		<id>4907</id>
		<title>User is prompted twice when exiting integration editor during editing api provider connector</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I wanted to create a new integration but I missclicked the `API Provider` start connector, I didn't specify anything and wanted to go back, so I clicked `Cancel` and I got this prompt:  ``` Do you really want to cancel?  You have not finished creating an API definition. If you cancel now you will lose data you already entered. Do you still want to cancel? ```  I hit yes and I get:  ``` Unsaved Changes Are you sure you want to exit editing the integration? ```  I would expect only one prompt, especially when I didn't enter anything into the API provider  </body>
		<created>2019-03-15 11:57:23</created>
		<closed>2019-03-18 13:33:47</closed>
	</bug>
	<bug>
		<id>4905</id>
		<title>Datamapper before/after Aggregate - both sides of the mapping are equal (can't map anything)</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description **Example 1:** DB -&gt; Split -&gt; Datamapper -&gt; Aggregate -&gt; Google sheets **Datamapper offers mapping from DB to DB** ![Screenshot from 2019-03-15 11-00-08](https://user-images.githubusercontent.com/8707251/54424078-6ae6ba00-4712-11e9-93c5-545e2758b944.png)  **Example 2:** DB -&gt; Split -&gt; Aggregate -&gt; Datamapper-&gt; Google sheets **Datamapper offers mapping from Google sheets to Google sheets** ![Screenshot from 2019-03-15 11-00-22](https://user-images.githubusercontent.com/8707251/54424051-5c000780-4712-11e9-80b0-a27db35f0723.png)  </body>
		<created>2019-03-15 10:08:21</created>
		<closed>2019-04-02 13:21:39</closed>
	</bug>
	<bug>
		<id>4889</id>
		<title>OData connector cant delete/update entity</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When I do a read from OData service (as start step) and then delete, the delete suggests that I should put datamapper in between, but then there's no way to map it (read operation sends it's datashape, but there's nothing in the delete step).   ![delete_op](https://user-images.githubusercontent.com/46523434/54344931-40c5c700-4642-11e9-9911-10d2ad8cbaf2.png) when not using a datamapper, the path is created so that the whole body that read produces is taken by the delete operation as Key predicate, which results into wrong resourcePath.  For update, I can map it, but it takes the Key Predicate without single quatation marks (using Airports(KLAX) instead of Airports('KLAX')), which produces error as well. </body>
		<created>2019-03-14 09:21:14</created>
		<closed>2019-04-02 11:50:58</closed>
	</bug>
	<bug>
		<id>4885</id>
		<title>Cannot build s2i module</title>
		<body>Trying to rebuild and fabric8 deploy the s2i module fails using the command: &gt; syndesis build -c -f -i -m s2i --maven-mirror http://peregrine:8081/repository/maven-public  PS. Despite mvn observing the maven-mirror option, it seems the fabric8 container does not. As a sidenote, is there a mechanism for that to happen?  ``` phantomjinx ~$ syndesis build -c -f -i -m s2i --maven-mirror http://peregrine:8081/repository/maven-public Modules: s2i ============================================================================== ./mvnw -N --batch-mode install -Pflash ### Installing parent pom.xml [INFO] Scanning for projects... [INFO]  [INFO] ------------------------------------------------------------------------ [INFO] Building Syndesis 1.7-SNAPSHOT [INFO] ------------------------------------------------------------------------ [INFO]  [INFO] --- git-commit-id-plugin:2.2.5:revision (default) @ syndesis-parent --- [INFO]  [INFO] --- maven-assembly-plugin:3.1.0:single (create-tool-jar) @ syndesis-parent --- [INFO] Reading assembly descriptor: tools.xml [INFO] Building jar: /home/phantomjinx/programming/java/syndesis/app/target/syndesis-parent-1.7-SNAPSHOT-tools.jar [INFO]  [INFO] --- dependency-scope-maven-plugin:0.8:check (default) @ syndesis-parent --- [INFO] Skipping plugin execution [INFO]  [INFO] &gt;&gt;&gt; spotbugs-maven-plugin:3.1.6:check (default) &gt; :spotbugs @ syndesis-parent &gt;&gt;&gt; [INFO]  [INFO] --- spotbugs-maven-plugin:3.1.6:spotbugs (spotbugs) @ syndesis-parent --- [INFO]  [INFO] &lt;&lt;&lt; spotbugs-maven-plugin:3.1.6:check (default) &lt; :spotbugs @ syndesis-parent &lt;&lt;&lt; [INFO]  [INFO]  [INFO] --- spotbugs-maven-plugin:3.1.6:check (default) @ syndesis-parent --- [INFO]  [INFO] --- maven-install-plugin:2.5.2:install (default-install) @ syndesis-parent --- [INFO] Installing /home/phantomjinx/programming/java/syndesis/app/pom.xml to /home/phantomjinx/.m2/repository/io/syndesis/syndesis-parent/1.7-SNAPSHOT/syndesis-parent-1.7-SNAPSHOT.pom [INFO] Installing /home/phantomjinx/programming/java/syndesis/app/target/syndesis-parent-1.7-SNAPSHOT-tools.jar to /home/phantomjinx/.m2/repository/io/syndesis/syndesis-parent/1.7-SNAPSHOT/syndesis-parent-1.7-SNAPSHOT-tools.jar [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 5.224 s [INFO] Finished at: 2019-03-13T17:52:43Z [INFO] Final Memory: 26M/86M [INFO] ------------------------------------------------------------------------ ============================================================================== ./mvnw -Pflash -Pimage -Dfabric8.mode=openshift -DmavenMirror=http://peregrine:8081/repository/maven-public clean install -f s2i ### Processing module s2i ============================================================================== [INFO] Scanning for projects... [INFO]  [INFO] ------------------------------------------------------------------------ [INFO] Building S2I 1.7-SNAPSHOT [INFO] ------------------------------------------------------------------------ [INFO]  [INFO] --- maven-clean-plugin:3.1.0:clean (default-clean) @ s2i --- [INFO] Deleting /home/phantomjinx/programming/java/syndesis/app/s2i/target [INFO]  [INFO] --- maven-resources-plugin:3.1.0:copy-resources (copy-resources) @ s2i --- [INFO] Using 'UTF-8' encoding to copy filtered resources. [INFO] Copying 2 resources [INFO] Copying 1 resource [INFO]  [INFO] --- git-commit-id-plugin:2.2.5:revision (default) @ s2i --- [INFO]  [INFO] --- maven-dependency-plugin:3.0.2:copy (copy) @ s2i --- [INFO] Configured Artifact: io.syndesis.server:server-builder-image-generator:1.7-SNAPSHOT:jar [INFO] Copying server-builder-image-generator-1.7-SNAPSHOT.jar to /home/phantomjinx/programming/java/syndesis/app/s2i/target/rest-builder-image-generator.jar [INFO]  [INFO] --- exec-maven-plugin:1.6.0:exec (copy-local-repo) @ s2i --- + project_dir=/home/phantomjinx/programming/java/syndesis/app/s2i + version=1.7-SNAPSHOT + target_dir=/home/phantomjinx/programming/java/syndesis/app/s2i/target/generated-sources/docker + local_repo= + '[' -z '' ']' + local_repo=/home/phantomjinx/.m2/repository/ + mkdir -p /home/phantomjinx/programming/java/syndesis/app/s2i/target/generated-sources/docker/m2 + cd /home/phantomjinx/.m2/repository/ + find ./io/syndesis + grep -v -- '-sources\.' + grep -F -- /1.7-SNAPSHOT/ + grep -v -- '-tests\.' + xargs tar -c + tar -vx -C /home/phantomjinx/programming/java/syndesis/app/s2i/target/generated-sources/docker/m2 ./io/syndesis/s2i/s2i/1.7-SNAPSHOT/_remote.repositories ./io/syndesis/s2i/s2i/1.7-SNAPSHOT/s2i-1.7-SNAPSHOT.pom ./io/syndesis/s2i/s2i/1.7-SNAPSHOT/maven-metadata-local.xml ./io/syndesis/syndesis-documentation-tools/1.7-SNAPSHOT/_remote.repositories ./io/syndesis/syndesis-documentation-tools/1.7-SNAPSHOT/maven-metadata-local.xml &lt;snip&gt; ./io/syndesis/syndesis-docs/1.7-SNAPSHOT/syndesis-docs-1.7-SNAPSHOT.pom ./io/syndesis/syndesis-docs/1.7-SNAPSHOT/_remote.repositories ./io/syndesis/syndesis-docs/1.7-SNAPSHOT/maven-metadata-local.xml + '[' -z '' ']' + echo 'This installation won'\''t use a camel snapshot version' This installation won't use a camel snapshot version + cp /home/phantomjinx/programming/java/syndesis/app/s2i/src/main/docker/Dockerfile /home/phantomjinx/programming/java/syndesis/app/s2i/target/generated-sources/docker [INFO]  [INFO] --- exec-maven-plugin:1.6.0:exec (rest-builder-image-generator) @ s2i ---    .   ____          _            __ _ _  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \ ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )   '  |____| .__|_| |_|_| |_\__, | / / / /  =========|_|==============|___/=/_/_/_/  :: Spring Boot ::       (v1.5.16.RELEASE)  2019-03-13 17:52:48.052  INFO 7389 --- [           main] i.s.s.b.image.generator.Application      : Starting Application v1.7-SNAPSHOT on peregrine.birds-of-prey.phantomjinx.org.uk with PID 7389 (/home/phantomjinx/programming/java/syndesis/app/s2i/target/rest-builder-image-generator.jar started by phantomjinx in /home/phantomjinx/programming/java/syndesis/app/s2i) 2019-03-13 17:52:48.056  INFO 7389 --- [           main] i.s.s.b.image.generator.Application      : No active profile set, falling back to default profiles: default 2019-03-13 17:52:48.121  INFO 7389 --- [           main] s.c.a.AnnotationConfigApplicationContext : Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@506c589e: startup date [Wed Mar 13 17:52:48 GMT 2019]; root of context hierarchy 2019-03-13 17:52:48.848  INFO 7389 --- [           main] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup To: /home/phantomjinx/programming/java/syndesis/app/s2i/target/generated-sources/docker/m2/project 2019-03-13 17:52:49.698  INFO 7389 --- [           main] i.s.s.b.image.generator.Application      : Started Application in 1.948 seconds (JVM running for 2.403) 2019-03-13 17:52:49.699  INFO 7389 --- [       Thread-2] s.c.a.AnnotationConfigApplicationContext : Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@506c589e: startup date [Wed Mar 13 17:52:48 GMT 2019]; root of context hierarchy 2019-03-13 17:52:49.700  INFO 7389 --- [       Thread-2] o.s.j.e.a.AnnotationMBeanExporter        : Unregistering JMX-exposed beans on shutdown [INFO]  [INFO] --- fabric8-maven-plugin:3.5.38:build (exec) @ s2i --- [INFO] F8: Using OpenShift build with strategy Docker [INFO] F8: Generators: [INFO] F8:  - spring-boot [INFO] F8:  - wildfly-swarm [INFO] F8:  - karaf [INFO] F8:  - vertx [INFO] F8:  - java-exec [INFO] F8:  - webapp [INFO] Building tar: /home/phantomjinx/programming/java/syndesis/app/s2i/target/docker/syndesis/syndesis-s2i/latest/tmp/docker-build.tar [INFO] F8: [syndesis/syndesis-s2i:latest]: Created docker source tar /home/phantomjinx/programming/java/syndesis/app/s2i/target/docker/syndesis/syndesis-s2i/latest/tmp/docker-build.tar                                             [INFO] F8: Updating BuildServiceConfig syndesis-s2i-s2i for Docker strategy [INFO] F8: Adding to ImageStream syndesis-s2i [INFO] F8: Enrichers: [INFO] F8: - fmp-name [INFO] F8: - fmp-controller [INFO] F8: - fmp-service [INFO] F8: - fmp-image [INFO] F8: - fmp-portname [INFO] F8: - fmp-ianaservice [INFO] F8: - fmp-project [INFO] F8: - fmp-dependency [INFO] F8: - fmp-pod-annotations [INFO] F8: - fmp-git [INFO] F8: - fmp-debug [INFO] F8: - fmp-merge [INFO] F8: - fmp-remove-build-annotations [INFO] F8: - fmp-volume-permission [INFO] F8: - f8-cd [INFO] F8: - f8-cd-doc-link [INFO] F8: - f8-cd-grafana-link [INFO] F8: - f8-icon [INFO] F8: - f8-expose [INFO] F8: - fmp-openshift-route [INFO] F8: - spring-boot-health-check [INFO] F8: - wildfly-swarm-health-check [INFO] F8: - karaf-health-check [INFO] F8: - vertx-health-check [INFO] F8: - docker-health-check [INFO] F8: - f8-prometheus [INFO] F8: - f8-maven-scm [INFO] F8: - f8-maven-issue-mgmt [INFO] F8: - f8-watch [INFO] F8: - fmp-revision-history [INFO] F8: - fmp-docker-registry-secret [INFO] F8: Starting Build syndesis-s2i-s2i [INFO] F8: Waiting for build syndesis-s2i-s2i-2 to complete... [INFO] F8: Step 1/11 : FROM fabric8/s2i-java:3.0-java8 [INFO] F8:  ---&gt; f36e68604d42 [INFO] F8: Step 2/11 : ENV AB_JOLOKIA_HTTPS "true" [INFO] F8: BuildWatch: Received event MODIFIED , build status: BuildStatus(cancelled=null, completionTimestamp=null, config=ObjectReference(apiVersion=null, fieldPath=null, kind=BuildConfig, name=syndesis-s2i-s2i, namespace=syndesis, resourceVersion=null, uid=null, additionalProperties={}), duration=null, logSnippet=null, message=null, output=BuildStatusOutput(to=null, additionalProperties={}), outputDockerImageReference=172.30.1.1:5000/syndesis/syndesis-s2i:latest, phase=Running, reason=null, stages=[], startTimestamp=2019-03-13T17:52:53Z, additionalProperties={})                                                                                                                  [INFO] F8: Build syndesis-s2i-s2i-2 status: Running [INFO] Current reconnect backoff is 1000 milliseconds (T0) [INFO] F8:  ---&gt; Using cache [INFO] F8:  ---&gt; dc26bc28bb68 [INFO] F8: Step 3/11 : COPY m2 /tmp/artifacts/m2/ [INFO] F8: BuildWatch: Received event MODIFIED , build status: BuildStatus(cancelled=null, completionTimestamp=null, config=ObjectReference(apiVersion=null, fieldPath=null, kind=BuildConfig, name=syndesis-s2i-s2i, namespace=syndesis, resourceVersion=null, uid=null, additionalProperties={}), duration=null, logSnippet=null, message=null, output=BuildStatusOutput(to=null, additionalProperties={}), outputDockerImageReference=172.30.1.1:5000/syndesis/syndesis-s2i:latest, phase=Running, reason=null, stages=[], startTimestamp=2019-03-13T17:52:53Z, additionalProperties={})                                                                                                                  [INFO] Current reconnect backoff is 2000 milliseconds (T1) [INFO] F8: BuildWatch: Received event MODIFIED , build status: BuildStatus(cancelled=null, completionTimestamp=null, config=ObjectReference(apiVersion=null, fieldPath=null, kind=BuildConfig, name=syndesis-s2i-s2i, namespace=syndesis, resourceVersion=null, uid=null, additionalProperties={}), duration=null, logSnippet=null, message=null, output=BuildStatusOutput(to=null, additionalProperties={}), outputDockerImageReference=172.30.1.1:5000/syndesis/syndesis-s2i:latest, phase=Running, reason=null, stages=[], startTimestamp=2019-03-13T17:52:53Z, additionalProperties={})                                                                                                                  [INFO] Current reconnect backoff is 4000 milliseconds (T2) [INFO] F8:  ---&gt; 7f769d8bac88 [INFO] F8: Removing intermediate container ae2b2c38fe86 [INFO] F8: Step 4/11 : COPY settings.xml /tmp/settings.xml [INFO] F8:  ---&gt; 24cfd0c6d208 [INFO] F8: Removing intermediate container 76867bc66e40 [INFO] F8: Step 5/11 : USER 0 [INFO] F8:  ---&gt; Running in e400901c05fe [INFO] F8:  ---&gt; b8b453ddf799 [INFO] F8: Removing intermediate container e400901c05fe [INFO] F8: Step 6/11 : RUN cd /tmp/artifacts/m2/project  &amp;&amp; mvn --batch-mode -s /tmp/settings.xml -Dmaven.repo.local=/tmp/artifacts/m2 package -DskipTests -e -Dfabric8.skip=true  &amp;&amp; rm -rf /tmp/artifacts/m2/project  &amp;&amp; chgrp -R 0 /tmp/artifacts/m2  &amp;&amp; chmod -R g=u /tmp/artifacts/m2                                                             [INFO] F8:  ---&gt; Running in 312f160d3320 [INFO] F8: [INFO] Error stacktraces are turned on. [INFO] F8: [INFO] Scanning for projects... [INFO] F8: [INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/springframework/boot/spring-boot-dependencies/1.5.16.RELEASE/spring-boot-dependencies-1.5.16.RELEASE.pom                                        [INFO] F8: [INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/springframework/boot/spring-boot-dependencies/1.5.16.RELEASE/spring-boot-dependencies-1.5.16.RELEASE.pom (110 kB at 167 kB/s)                    [INFO] F8: [INFO] Downloading from redhat-ga: https://maven.repository.redhat.com/ga/com/fasterxml/jackson/jackson-bom/2.8.11.20180608/jackson-bom-2.8.11.20180608.pom                                                               [INFO] F8: BuildWatch: Received event MODIFIED , build status: BuildStatus(cancelled=null, completionTimestamp=null, config=ObjectReference(apiVersion=null, fieldPath=null, kind=BuildConfig, name=syndesis-s2i-s2i, namespace=syndesis, resourceVersion=null, uid=null, additionalProperties={}), duration=null, logSnippet=null, message=null, output=BuildStatusOutput(to=null, additionalProperties={}), outputDockerImageReference=172.30.1.1:5000/syndesis/syndesis-s2i:latest, phase=Running, reason=null, stages=[], startTimestamp=2019-03-13T17:52:53Z, additionalProperties={})                                                                                                                  [INFO] Current reconnect backoff is 8000 milliseconds (T3) [INFO] F8: [INFO] Downloading from jboss-ea: https://repository.jboss.org/nexus/content/groups/ea/com/fasterxml/jackson/jackson-bom/2.8.11.20180608/jackson-bom-2.8.11.20180608.pom                                                  [INFO] F8: [INFO] Downloading from central: https://repo.maven.apache.org/maven2/com/fasterxml/jackson/jackson-bom/2.8.11.20180608/jackson-bom-2.8.11.20180608.pom                                                                   [INFO] F8: [INFO] Downloaded from central: https://repo.maven.apache.org/maven2/com/fasterxml/jackson/jackson-bom/2.8.11.20180608/jackson-bom-2.8.11.20180608.pom (11 kB at 80 kB/s)                                                 [INFO] F8: [INFO] Downloading from redhat-ga: https://maven.repository.redhat.com/ga/com/fasterxml/jackson/jackson-parent/2.8/jackson-parent-2.8.pom                                                                                 [INFO] F8: [INFO] Downloading from jboss-ea: https://repository.jboss.org/nexus/content/groups/ea/com/fasterxml/jackson/jackson-parent/2.8/jackson-parent-2.8.pom                                                                    [INFO] F8: [INFO] Downloading from central: https://repo.maven.apache.org/maven2/com/fasterxml/jackson/jackson-parent/2.8/jackson-parent-2.8.pom                                                                                     [INFO] F8: [INFO] Downloaded from central: https://repo.maven.apache.org/maven2/com/fasterxml/jackson/jackson-parent/2.8/jackson-parent-2.8.pom (8.0 kB at 95 kB/s)                                                                  [INFO] F8: [INFO] Downloading from redhat-ga: https://maven.repository.redhat.com/ga/com/fasterxml/oss-parent/27/oss-parent-27.pom                                                                                                   [INFO] F8: [INFO] Downloading from jboss-ea: https://repository.jboss.org/nexus/content/groups/ea/com/fasterxml/oss-parent/27/oss-parent-27.pom                                                                                      [INFO] F8: [INFO] Downloading from central: https://repo.maven.apache.org/maven2/com/fasterxml/oss-parent/27/oss-parent-27.pom                                                                                                       [INFO] F8: [INFO] Downloaded from central: https://repo.maven.apache.org/maven2/com/fasterxml/oss-parent/27/oss-parent-27.pom (20 kB at 180 kB/s)                                                                                    [INFO] F8: [INFO] Downloading from redhat-ga: https://maven.repository.redhat.com/ga/org/apache/logging/log4j/log4j-bom/2.7/log4j-bom-2.7.pom                                                                                        [INFO] F8: [INFO] Downloading from jboss-ea: https://repository.jboss.org/nexus/content/groups/ea/org/apache/logging/log4j/log4j-bom/2.7/log4j-bom-2.7.pom                                                                           [INFO] F8: [INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/apache/logging/log4j/log4j-bom/2.7/log4j-bom-2.7.pom                                                                                            [INFO] F8: [INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/logging/log4j/log4j-bom/2.7/log4j-bom-2.7.pom (5.4 kB at 62 kB/s)                                                                         [INFO] F8: [INFO] Downloading from redhat-ga: https://maven.repository.redhat.com/ga/org/apache/apache/9/apache-9.pom                                                                                                                [INFO] F8: [INFO] Downloading from jboss-ea: https://repository.jboss.org/nexus/content/groups/ea/org/apache/apache/9/apache-9.pom                                                                                                   [INFO] F8: [INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/apache/apache/9/apache-9.pom [INFO] F8: [INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/apache/9/apache-9.pom (15 kB at 117 kB/s)                                                                                                 [INFO] F8: [INFO] Downloading from redhat-ga: https://maven.repository.redhat.com/ga/org/springframework/spring-framework-bom/4.3.19.RELEASE/spring-framework-bom-4.3.19.RELEASE.pom                                                 [INFO] F8: [INFO] Downloading from jboss-ea: https://repository.jboss.org/nexus/content/groups/ea/org/springframework/spring-framework-bom/4.3.19.RELEASE/spring-framework-bom-4.3.19.RELEASE.pom                                    [INFO] F8: [INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/springframework/spring-framework-bom/4.3.19.RELEASE/spring-framework-bom-4.3.19.RELEASE.pom                                                     [INFO] F8: [INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/springframework/spring-framework-bom/4.3.19.RELEASE/spring-framework-bom-4.3.19.RELEASE.pom (5.1 kB at 58 kB/s)                                  [INFO] F8: [INFO] Downloading from redhat-ga: https://maven.repository.redhat.com/ga/org/springframework/data/spring-data-releasetrain/Ingalls-SR15/spring-data-releasetrain-Ingalls-SR15.pom                                        [INFO] F8: [INFO] Downloading from jboss-ea: https://repository.jboss.org/nexus/content/groups/ea/org/springframework/data/spring-data-releasetrain/Ingalls-SR15/spring-data-releasetrain-Ingalls-SR15.pom                           [INFO] F8: [INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/springframework/data/spring-data-releasetrain/Ingalls-SR15/spring-data-releasetrain-Ingalls-SR15.pom                                            [INFO] F8: [INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/springframework/data/spring-data-releasetrain/Ingalls-SR15/spring-data-releasetrain-Ingalls-SR15.pom (4.6 kB at 54 kB/s)                         [INFO] F8: [INFO] Downloading from redhat-ga: https://maven.repository.redhat.com/ga/org/springframework/data/build/spring-data-build/1.9.15.RELEASE/spring-data-build-1.9.15.RELEASE.pom                                            [INFO] F8: [INFO] Downloading from jboss-ea: https://repository.jboss.org/nexus/content/groups/ea/org/springframework/data/build/spring-data-build/1.9.15.RELEASE/spring-data-build-1.9.15.RELEASE.pom                               [INFO] F8: [INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/springframework/data/build/spring-data-build/1.9.15.RELEASE/spring-data-build-1.9.15.RELEASE.pom                                                [INFO] F8: [INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/springframework/data/build/spring-data-build/1.9.15.RELEASE/spring-data-build-1.9.15.RELEASE.pom (6.6 kB at 68 kB/s)                             [INFO] F8: [INFO] Downloading from redhat-ga: https://maven.repository.redhat.com/ga/org/springframework/integration/spring-integration-bom/4.3.17.RELEASE/spring-integration-bom-4.3.17.RELEASE.pom                                 [INFO] F8: [INFO] Downloading from jboss-ea: https://repository.jboss.org/nexus/content/groups/ea/org/springframework/integration/spring-integration-bom/4.3.17.RELEASE/spring-integration-bom-4.3.17.RELEASE.pom                    [INFO] F8: BuildWatch: Received event MODIFIED , build status: BuildStatus(cancelled=null, completionTimestamp=null, config=ObjectReference(apiVersion=null, fieldPath=null, kind=BuildConfig, name=syndesis-s2i-s2i, namespace=syndesis, resourceVersion=null, uid=null, additionalProperties={}), duration=null, logSnippet=null, message=null, output=BuildStatusOutput(to=null, additionalProperties={}), outputDockerImageReference=172.30.1.1:5000/syndesis/syndesis-s2i:latest, phase=Running, reason=null, stages=[], startTimestamp=2019-03-13T17:52:53Z, additionalProperties={})                                                                                                                  [INFO] Current reconnect backoff is 16000 milliseconds (T4) [INFO] F8: [INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/springframework/integration/spring-integration-bom/4.3.17.RELEASE/spring-integration-bom-4.3.17.RELEASE.pom                                     [INFO] F8: [INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/springframework/integration/spring-integration-bom/4.3.17.RELEASE/spring-integration-bom-4.3.17.RELEASE.pom (8.5 kB at 52 kB/s)                  [INFO] F8: [INFO] Downloading from redhat-ga: https://maven.repository.redhat.com/ga/org/springframework/security/spring-security-bom/4.2.8.RELEASE/spring-security-bom-4.2.8.RELEASE.pom                                            [INFO] F8: [INFO] Downloading from jboss-ea: https://repository.jboss.org/nexus/content/groups/ea/org/springframework/security/spring-security-bom/4.2.8.RELEASE/spring-security-bom-4.2.8.RELEASE.pom                               [INFO] F8: [INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/springframework/security/spring-security-bom/4.2.8.RELEASE/spring-security-bom-4.2.8.RELEASE.pom                                                [INFO] F8: [INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/springframework/security/spring-security-bom/4.2.8.RELEASE/spring-security-bom-4.2.8.RELEASE.pom (4.3 kB at 48 kB/s)                             [INFO] F8: [INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/apache/camel/camel-spring-boot-dependencies/2.21.0.fuse-730054/camel-spring-boot-dependencies-2.21.0.fuse-730054.pom                            [INFO] F8: [INFO] Downloading from redhat-ga: https://maven.repository.redhat.com/ga/org/apache/camel/camel-spring-boot-dependencies/2.21.0.fuse-730054/camel-spring-boot-dependencies-2.21.0.fuse-730054.pom                        [INFO] F8: [INFO] Downloading from jboss-ea: https://repository.jboss.org/nexus/content/groups/ea/org/apache/camel/camel-spring-boot-dependencies/2.21.0.fuse-730054/camel-spring-boot-dependencies-2.21.0.fuse-730054.pom           [INFO] F8: [INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/springframework/boot/spring-boot-dependencies/1.5.13.RELEASE/spring-boot-dependencies-1.5.13.RELEASE.pom                                        [INFO] F8: [INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/springframework/boot/spring-boot-dependencies/1.5.13.RELEASE/spring-boot-dependencies-1.5.13.RELEASE.pom (110 kB at 274 kB/s)                    [INFO] F8: [INFO] Downloading from jboss-ea: https://repository.jboss.org/nexus/content/groups/ea/com/fasterxml/jackson/jackson-bom/2.8.11.20180405/jackson-bom-2.8.11.20180405.pom                                                  [INFO] F8: [INFO] Downloading from redhat-ga: https://maven.repository.redhat.com/ga/com/fasterxml/jackson/jackson-bom/2.8.11.20180405/jackson-bom-2.8.11.20180405.pom                                                               [INFO] F8: [INFO] Downloading from central: https://repo.maven.apache.org/maven2/com/fasterxml/jackson/jackson-bom/2.8.11.20180405/jackson-bom-2.8.11.20180405.pom                                                                   [INFO] F8: [INFO] Downloaded from central: https://repo.maven.apache.org/maven2/com/fasterxml/jackson/jackson-bom/2.8.11.20180405/jackson-bom-2.8.11.20180405.pom (11 kB at 106 kB/s)                                                [INFO] F8: [INFO] Downloading from jboss-ea: https://repository.jboss.org/nexus/content/groups/ea/org/springframework/spring-framework-bom/4.3.17.RELEASE/spring-framework-bom-4.3.17.RELEASE.pom                                    [INFO] F8: [INFO] Downloading from redhat-ga: https://maven.repository.redhat.com/ga/org/springframework/spring-framework-bom/4.3.17.RELEASE/spring-framework-bom-4.3.17.RELEASE.pom                                                 [INFO] F8: [INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/springframework/spring-framework-bom/4.3.17.RELEASE/spring-framework-bom-4.3.17.RELEASE.pom                                                     [INFO] F8: [INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/springframework/spring-framework-bom/4.3.17.RELEASE/spring-framework-bom-4.3.17.RELEASE.pom (5.1 kB at 67 kB/s)                                  [INFO] F8: [INFO] Downloading from jboss-ea: https://repository.jboss.org/nexus/content/groups/ea/org/springframework/data/spring-data-releasetrain/Ingalls-SR12/spring-data-releasetrain-Ingalls-SR12.pom                           [INFO] F8: [INFO] Downloading from redhat-ga: https://maven.repository.redhat.com/ga/org/springframework/data/spring-data-releasetrain/Ingalls-SR12/spring-data-releasetrain-Ingalls-SR12.pom                                        [INFO] F8: [INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/springframework/data/spring-data-releasetrain/Ingalls-SR12/spring-data-releasetrain-Ingalls-SR12.pom                                            [INFO] F8: [INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/springframework/data/spring-data-releasetrain/Ingalls-SR12/spring-data-releasetrain-Ingalls-SR12.pom (4.6 kB at 56 kB/s)                         [INFO] F8: [INFO] Downloading from jboss-ea: https://repository.jboss.org/nexus/content/groups/ea/org/springframework/data/build/spring-data-build/1.9.12.RELEASE/spring-data-build-1.9.12.RELEASE.pom                               [INFO] F8: [INFO] Downloading from redhat-ga: https://maven.repository.redhat.com/ga/org/springframework/data/build/spring-data-build/1.9.12.RELEASE/spring-data-build-1.9.12.RELEASE.pom                                            [INFO] F8: [INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/springframework/data/build/spring-data-build/1.9.12.RELEASE/spring-data-build-1.9.12.RELEASE.pom                                                [INFO] F8: [INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/springframework/data/build/spring-data-build/1.9.12.RELEASE/spring-data-build-1.9.12.RELEASE.pom (6.6 kB at 81 kB/s)                             [INFO] F8: [INFO] Downloading from jboss-ea: https://repository.jboss.org/nexus/content/groups/ea/org/springframework/integration/spring-integration-bom/4.3.16.RELEASE/spring-integration-bom-4.3.16.RELEASE.pom                    [INFO] F8: [INFO] Downloading from redhat-ga: https://maven.repository.redhat.com/ga/org/springframework/integration/spring-integration-bom/4.3.16.RELEASE/spring-integration-bom-4.3.16.RELEASE.pom                                 [INFO] F8: [INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/springframework/integration/spring-integration-bom/4.3.16.RELEASE/spring-integration-bom-4.3.16.RELEASE.pom                                     [INFO] F8: [INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/springframework/integration/spring-integration-bom/4.3.16.RELEASE/spring-integration-bom-4.3.16.RELEASE.pom (8.5 kB at 100 kB/s)                 [INFO] F8: [INFO] Downloading from jboss-ea: https://repository.jboss.org/nexus/content/groups/ea/org/springframework/security/spring-security-bom/4.2.6.RELEASE/spring-security-bom-4.2.6.RELEASE.pom                               [INFO] F8: [INFO] Downloading from redhat-ga: https://maven.repository.redhat.com/ga/org/springframework/security/spring-security-bom/4.2.6.RELEASE/spring-security-bom-4.2.6.RELEASE.pom                                            [INFO] F8: [INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/springframework/security/spring-security-bom/4.2.6.RELEASE/spring-security-bom-4.2.6.RELEASE.pom                                                [INFO] F8: [INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/springframework/security/spring-security-bom/4.2.6.RELEASE/spring-security-bom-4.2.6.RELEASE.pom (4.3 kB at 55 kB/s)                             [INFO] F8: [ERROR] [ERROR] Some problems were encountered while processing the POMs: [INFO] F8: [ERROR] Non-resolvable import POM: Could not transfer artifact org.apache.camel:camel-spring-boot-dependencies:pom:2.21.0.fuse-730054 from/to redhat-ga (https://maven.repository.redhat.com/ga/): maven.repository.redhat.com @ line 38, column 19                                                                                         [INFO] F8: BuildWatch: Received event MODIFIED , build status: BuildStatus(cancelled=null, completionTimestamp=2019-03-13T17:53:25Z, config=ObjectReference(apiVersion=null, fieldPath=null, kind=BuildConfig, name=syndesis-s2i-s2i, namespace=syndesis, resourceVersion=null, uid=null, additionalProperties={}), duration=32000000000, logSnippet=[INFO] Downloading from redhat-ga: https://maven.repositor...ity-bom/4.2.6.RELEASE/spring-security-bom-4.2.6.RELEASE.pom                                                                                                              [INFO] Downloading from central: https://repo.maven.apache...ity-bom/4.2.6.RELEASE/spring-security-bom-4.2.6.RELEASE.pom                                                                                                             [INFO] Downloaded from central: https://repo.maven.apache....E/spring-security-bom-4.2.6.RELEASE.pom (4.3 kB at 55 kB/s)                                                                                                             [ERROR] [ERROR] Some problems were encountered while processing the POMs:                                          [ERROR] Non-resolvable import POM: Could not transfer arti....com/ga/): maven.repository.redhat.com @ line 38, column 19, message=Docker build strategy has failed., output=BuildStatusOutput(to=null, additionalProperties={}), outputDockerImageReference=172.30.1.1:5000/syndesis/syndesis-s2i:latest, phase=Failed, reason=DockerBuildFailed, stages=[StageInfo(durationMilliseconds=19134, name=Build, startTime=2019-03-13T17:53:05Z, steps=[StepInfo(durationMilliseconds=19134, name=DockerBuild, startTime=2019-03-13T17:53:05Z, additionalProperties={})], additionalProperties={})], startTimestamp=2019-03-13T17:52:53Z, additionalProperties={})                                                [INFO] F8: Build syndesis-s2i-s2i-2 status: Failed [INFO] Current reconnect backoff is 32000 milliseconds (T5) [ERROR] Exception in reconnect java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@5c2cccf9 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@192e4918[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 10]     at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution (ThreadPoolExecutor.java:2063)     at java.util.concurrent.ThreadPoolExecutor.reject (ThreadPoolExecutor.java:830)     at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute (ScheduledThreadPoolExecutor.java:326)     at java.util.concurrent.ScheduledThreadPoolExecutor.schedule (ScheduledThreadPoolExecutor.java:533)     at java.util.concurrent.Executors$DelegatedScheduledExecutorService.schedule (Executors.java:729)     at io.fabric8.kubernetes.client.dsl.internal.WatchHTTPManager$3.run (WatchHTTPManager.java:207)     at java.util.concurrent.Executors$RunnableAdapter.call (Executors.java:511)     at java.util.concurrent.FutureTask.run (FutureTask.java:266)     at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201 (ScheduledThreadPoolExecutor.java:180)     at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run (ScheduledThreadPoolExecutor.java:293)     at java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1149)     at java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:624)     at java.lang.Thread.run (Thread.java:748) [ERROR] F8: Failed to execute the build [Unable to build the image using the OpenShift build service] [INFO] ------------------------------------------------------------------------ [INFO] BUILD FAILURE [INFO] ------------------------------------------------------------------------ [INFO] Total time: 55.147 s [INFO] Finished at: 2019-03-13T17:53:39Z [INFO] Final Memory: 45M/148M [INFO] ------------------------------------------------------------------------ [ERROR] Failed to execute goal io.fabric8:fabric8-maven-plugin:3.5.38:build (exec) on project s2i: Failed to execute the build: Unable to build the image using the OpenShift build service: OpenShift Build syndesis-s2i-s2i-2: Failed: DockerBuildFailed -&gt; [Help 1] [ERROR]  [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch. [ERROR] Re-run Maven using the -X switch to enable full debug logging. [ERROR]  [ERROR] For more information about the errors and possible solutions, please read the following articles: [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException ERROR: Last command exited with 1 ```</body>
		<created>2019-03-13 18:03:51</created>
		<closed>2019-04-01 14:18:12</closed>
	</bug>
	<bug>
		<id>4879</id>
		<title>Aggregate datashape </title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I want to create this integration:   ``` sql select split   filter (I want only some elements from the collection) aggregate (I want to continue with the collection) datamapper (I want to concatenate all last names from the collection into one message) activemq queue ```  When I use following flow:  ``` 1. start SQL 2. end AMQ 3. split 4. aggregate ```  The split has the `none -&gt; sql result` datashape (correct), but the aggregate has `amq-in(json instance in my case) -&gt; sql result`.  In this case, the aggregate should have the same datashapes as the `sql select` as I only filtered out some elements.  This results in two datamappers required by the ui:  ![6Gnn](https://user-images.githubusercontent.com/7081216/54288195-5508b600-45a7-11e9-82ee-8685e8604d06.png)  </body>
		<created>2019-03-13 14:48:30</created>
		<closed>2019-03-20 15:06:33</closed>
	</bug>
	<bug>
		<id>4878</id>
		<title>Inconsistent descriptions for SQL connector</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When selecting SQL connector action, it states:  ``` Periodically invoke SQL to obtain, store, update, or delete data. ```  When I click on it, it brings me to the query configuration where the description is:  ``` Enter a SQL statement that starts with SELECT. ```  This doesn't match the previous screen.  Also the validator states more methods when entering some invalid query:  ``` Your statement is invalid and should start with INSERT, UPDATE, SELECT or DELETE. ```  </body>
		<created>2019-03-13 14:20:16</created>
		<closed>2019-06-24 06:55:25</closed>
	</bug>
	<bug>
		<id>4874</id>
		<title>[Datamapper] Transformation's delimiter not saved</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11435**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Integration sql -&gt; datamapper -&gt; amq  ``` 1. open datamapper 2. map from one field to another 3. add source transformation 4. select concatenate 5. insert delimiter , 6. click done 7. reopen datamapper to check the delimiter 8. comma isn't there 9. (bonus) there are now 2 concatenate transformations with empty delimiters, writing into one mirrors the input in the second ```  ## Workaround Press `&lt;Tab&gt;` key after step 5, so that the focus gets out from input field. Then delimiter is properly saved.</body>
		<created>2019-03-13 13:26:38</created>
		<closed>2019-09-07 11:28:58</closed>
	</bug>
	<bug>
		<id>4871</id>
		<title>Apicurito operator is not working</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Operator from: [https://github.com/Apicurio/apicurito/tree/master/operator](https://github.com/Apicurio/apicurito/tree/master/operator)  After all the steps I have this in operator pod logs:  ` 2019/03/13 13:12:51 uninstall: Failed deletion of "apicurito-9jau31jxxt0pw0rw5ap8ijd2l": deploymentconfigs.apps.openshift.io "apicurito-ui" is forbidden: User "system:serviceaccount:tmp-operator:default" cannot delete deploymentconfigs.apps.openshift.io in the namespace "tmp-operator": no RBAC policy matched  2019/03/13 13:12:51 uninstall: Failed deletion of "apicurito-9jau31jxxt0pw0rw5ap8ijd2l": imagestreams.image.openshift.io "apicurito-ui" is forbidden: User "system:serviceaccount:tmp-operator:default" cannot delete imagestreams.image.openshift.io in the namespace "tmp-operator": no RBAC policy matched    #### 2019/03/13 13:12:51 uninstall: Failed deletion of "apicurito-9jau31jxxt0pw0rw5ap8ijd2l": routes.route.openshift.io "apicurito" is forbidden: User "system:serviceaccount:tmp-operator:default" cannot delete routes.route.openshift.io in the namespace "tmp-operator": no RBAC policy matched time="2019-03-13T13:12:51Z" level=error msg="failed to reconcile release for apiVersion=apicur.io/v1alpha1 kind=Apicurito name=tmp-operator/apicurito: install error: release apicurito-9jau31jxxt0pw0rw5ap8ijd2l failed: deploymentconfigs.apps.openshift.io is forbidden: User \"system:serviceaccount:tmp-operator:default\" cannot create deploymentconfigs.apps.openshift.io in the namespace \"tmp-operator\": no RBAC policy matched" `  </body>
		<created>2019-03-13 13:18:27</created>
		<closed>2019-03-15 13:41:41</closed>
	</bug>
	<bug>
		<id>4868</id>
		<title>[Datamapper] Delimiter is aligned to the right</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description First time using transformation in the datamapper I used "," as delimiter and I was wondering why it didn't pick up the comma, then I noticed it was aligned to the right and I didn't expect that :-)  ![bM4u](https://user-images.githubusercontent.com/7081216/54279541-9d1edd00-4595-11e9-8f78-418958bab984.png)  </body>
		<created>2019-03-13 12:41:33</created>
		<closed>2019-06-19 23:43:31</closed>
	</bug>
	<bug>
		<id>4867</id>
		<title>Starting an integration fails occasionally with SIGSEGV due to missing prometheus config</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When publishing an integration, it sometimes fails to start after successful build with the following error: ``` Starting the Java application using /opt/run-java/run-java.sh ... exec java -javaagent:/opt/jolokia/jolokia.jar=config=/opt/jolokia/etc/jolokia.properties -javaagent:/opt/prometheus/jmx_prometheus_javaagent.jar=9779:/tmp/src/prometheus-config.yml -XX:+UseParallelGC -XX:GCTimeRatio=4 -XX:AdaptiveSizePolicyWeight=90 -XX:MinHeapFreeRatio=20 -XX:MaxHeapFreeRatio=40 -XX:+ExitOnOutOfMemoryError -cp . -jar /deployments/project-0.1-SNAPSHOT.jar OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N Exception in thread "main" java.lang.reflect.InvocationTargetException at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at sun.instrument.InstrumentationImpl.loadClassAndStartAgent(InstrumentationImpl.java:386) at sun.instrument.InstrumentationImpl.loadClassAndCallPremain(InstrumentationImpl.java:401) Caused by: java.io.FileNotFoundException: /tmp/src/prometheus-config.yml (No such file or directory) at java.io.FileInputStream.open0(Native Method) at java.io.FileInputStream.open(FileInputStream.java:195) at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:138) at java.io.FileReader.&lt;init&gt;(FileReader.java:72) at io.prometheus.jmx.shaded.io.prometheus.jmx.JmxCollector.&lt;init&gt;(JmxCollector.java:74) at io.prometheus.jmx.shaded.io.prometheus.jmx.JavaAgent.premain(JavaAgent.java:47) ... 6 more FATAL ERROR in native method: processing of -javaagent failed # # A fatal error has been detected by the Java Runtime Environment: # #  SIGSEGV (0xb) at pc=0x00007fbb5b0e4a47, pid=1, tid=0x00007fbb5bed5700 # # JRE version: OpenJDK Runtime Environment (8.0_191-b12) (build 1.8.0_191-b12) # Java VM: OpenJDK 64-Bit Server VM (25.191-b12 mixed mode linux-amd64 compressed oops) # Problematic frame: # C  [libc.so.6+0x37a47]  abort+0x297 # # Core dump written. Default location: /deployments/core or core.1 # # An error report file with more information is saved as: # /deployments/hs_err_pid1.log # # If you would like to submit a bug report, please visit: #   http://bugreport.java.com/bugreport/crash.jsp  # [error occurred during error reporting , id 0xb] ```  </body>
		<created>2019-03-13 12:03:05</created>
		<closed>2019-04-03 12:00:30</closed>
	</bug>
	<bug>
		<id>4866</id>
		<title>Aggregate step does not update its data shape </title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The aggregate step does not update its datashape when subsequent steps change, split steps handles changes correctly.  ![image](https://user-images.githubusercontent.com/46345469/54270424-af8e1c00-457f-11e9-8465-534b2e4624b8.png) It can be fixed by removing the aggregate step and adding it again.  ## Steps to reproduce - Start: db "select * from todo" - End: db add_lead - add split and aggregate steps between start and end - add template after aggregate (template used by example, use whatever comes in handy) - aggregate step still says it outputs SQL or SQL procedure parameters - delete and place aggregate again - aggregate outputs json-schema for template</body>
		<created>2019-03-13 11:57:57</created>
		<closed>2019-03-20 14:59:09</closed>
	</bug>
	<bug>
		<id>4865</id>
		<title>Publish button disabled when editing deployed API Provider integration</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When editing an already deployed API Provider integration, the Publish button is disabled (it's greyed out and shows the in-progress spinner). This only happens with API provider integration, not with regular integration.   ## Steps to reproduce 1. create an API Provider integration, implement at least one operation 2. publish the integration, wait until it's running 3. edit the integration, the publish button is disabled  ![int-running](https://user-images.githubusercontent.com/9480152/54271651-3d6b0680-4582-11e9-9208-d1f32e1d9cc7.png) ![cannot-publish](https://user-images.githubusercontent.com/9480152/54271654-3f34ca00-4582-11e9-95e9-25a4318a31e7.png) </body>
		<created>2019-03-13 10:22:26</created>
		<closed>2019-03-20 10:48:07</closed>
	</bug>
	<bug>
		<id>4864</id>
		<title>Inconsistent Maven repositories configuration</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  It seems that we're inconsistently configuring Maven repositories, this leads to hard to debug issues (artefacts not found, builds fail). From what QE reports is that it fails integration S2I builds.  What we do know is that we should not be using `origin-repository.jboss.org`.  This could also be a `prio/p0`, marking it as `prio/p1` for now.  cc @asmigala</body>
		<created>2019-03-13 10:06:12</created>
		<closed>2019-05-24 08:44:57</closed>
	</bug>
	<bug>
		<id>4863</id>
		<title>Templating step not working in Camel K mode</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  `mustache` component not found. It is not added in Camel K mode when used.</body>
		<created>2019-03-13 09:26:08</created>
		<closed>2019-03-18 15:29:00</closed>
	</bug>
	<bug>
		<id>4857</id>
		<title>OCP 4: Can't login: 500 Internal Error</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem Part of #4614. When you try to log into Syndesis via OCP 4: you get a 500 Internal Error screen.  ## Expected behavior Syndesis UI  ## Screenshot  ![500_Internal_Error](https://user-images.githubusercontent.com/103255/54227242-e1e33f00-44d5-11e9-8b66-3f1b99e64719.jpg)  ## Oauth Proxy Log:  [syndesis-oauthproxy-1-f7xrk-syndesis-oauthproxy.log](https://github.com/syndesisio/syndesis/files/2958308/syndesis-oauthproxy-1-f7xrk-syndesis-oauthproxy.log)  </body>
		<created>2019-03-12 18:50:02</created>
		<closed>2019-03-18 15:29:00</closed>
	</bug>
	<bug>
		<id>4854</id>
		<title>OCP 4: syndesis-server exception: Caused by: java.net.UnknownHostException: openshift.default.svc: Name or service not known</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description On openshift 4, I see this error in the sydnesis-server logs: `Caused by: java.net.UnknownHostException: openshift.default.svc: Name or service not known`  Using a terminal against the server pod: ``` sh-4.2$ ping openshift.default.svc ping: openshift.default.svc: Name or service not known sh-4.2$ ping kubernetes.default.svc PING kubernetes.default.svc.cluster.local (172.30.0.1) 56(84) bytes of data. From ip-10-131-0-1.ec2.internal (10.131.0.1) icmp_seq=1 Destination Host Unreachable From ip-10-131-0-1.ec2.internal (10.131.0.1) icmp_seq=2 Destination Host Unreachable From ip-10-131-0-1.ec2.internal (10.131.0.1) icmp_seq=3 Destination Host Unreachable``` ```</body>
		<created>2019-03-12 16:34:35</created>
		<closed>2019-03-20 13:32:19</closed>
	</bug>
	<bug>
		<id>4848</id>
		<title>New exception with OData's read operation</title>
		<body>I got new exception with OData's read operation: `o.a.c.component.olingo4.Olingo4Consumer  : Consumer Consumer[olingo4-olingo4-0-0://read] failed polling endpoint: olingo4-olingo4-0-0://read. Will try again at next poll. Caused by: [org.apache.camel.RuntimeCamelException - org.apache.olingo.client.api.communication.ODataClientErrorException: Path segment not supported: City) [HTTP/1.1 501 Not Implemented]] org.apache.camel.RuntimeCamelException: org.apache.olingo.client.api.communication.ODataClientErrorException: Path segment not supported: City) [HTTP/1.1 501 Not Implemented]`  Not sure if this is caused by the exception reported in this GH issue or not, either way the read operation is not working properly for me (I am able to get the whole collection and single entity, but not individual property of entity).  ### Steps to reproduce:  1. Create integration with OData connector as start step  2. Choose read action  3. Choose "Airports" as Resource collection  4. Enter `('KLAX')/Location` in the Entity Key Predicate  It would be useful if the connector logged to pod what Request URL it's trying to send.  _Originally posted by @jsafarik in https://github.com/syndesisio/syndesis/issues/4791#issuecomment-471488857_</body>
		<created>2019-03-12 12:56:09</created>
		<closed>2019-03-27 10:21:23</closed>
	</bug>
	<bug>
		<id>4846</id>
		<title>AtlasMap is unable to find mapping</title>
		<body>This is because we do sanitize the resource name like: https://github.com/syndesisio/syndesis/blob/1.6.x/app/server/controller/src/main/java/io/syndesis/server/controller/integration/camelk/CamelKPublishHandler.java#L344  </body>
		<created>2019-03-12 12:16:48</created>
		<closed>2019-04-04 10:49:22</closed>
	</bug>
	<bug>
		<id>4840</id>
		<title>AtlasMap mapping definition not bound to the mapping step</title>
		<body>While testing camel-k and atlasmap I've noticed that clicking to the done button after having defined the mapping seems to do noting but after a while the mapping editor is closed.   When the integration is the deployed, the mapping step lacks mapping definition.  ![image](https://user-images.githubusercontent.com/1868933/54177656-4cbf5680-4493-11e9-8442-53e8afdfd59d.png) </body>
		<created>2019-03-12 02:09:49</created>
		<closed>2019-04-04 08:49:49</closed>
	</bug>
	<bug>
		<id>4836</id>
		<title>Fix kubeclient version</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  `kubernetes-client 3.1.12.fuse-730020` used in branch 1.6.x and master is not pinned and will disappear shortly. We should use `kubernetes-client 3.1.12.fuse-730022` which is pinned. </body>
		<created>2019-03-11 22:09:57</created>
		<closed>2019-03-18 15:29:00</closed>
	</bug>
	<bug>
		<id>4835</id>
		<title>[camel k] inconsistent libs for webhook and api provider</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Both webhook and api provider are based on the Camel servlet component which expects that the runtime will provide a server. This is true for spring-boot based integrations where we add spring-boot-web by default, but Camel K integrations are no more spring-boot based.</body>
		<created>2019-03-11 21:54:40</created>
		<closed>2019-05-24 08:57:57</closed>
	</bug>
	<bug>
		<id>4834</id>
		<title>[camel k] cannot find atlas component</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Get this when running a integration with mapping.  ``` i-l-idqznfgqs09i-ddlgz-6cccbb6c46-swqqb i-l-idqznfgqs09i-ddlgz Caused by: org.apache.camel.ResolveEndpointFailedException: Failed to resolve endpoint: atlas://mapping-flow-0-step-1.json?encoding=UTF-8&amp;sourceMapName=Syndesis.CAPTURED_OUT_MESSAGES_MAP due to: No component found with scheme: atlas i-l-idqznfgqs09i-ddlgz-6cccbb6c46-swqqb i-l-idqznfgqs09i-ddlgz  at org.apache.camel.impl.DefaultCamelContext.getEndpoint(DefaultCamelContext.java:759) i-l-idqznfgqs09i-ddlgz-6cccbb6c46-swqqb i-l-idqznfgqs09i-ddlgz  at org.apache.camel.util.CamelContextHelper.getMandatoryEndpoint(CamelContextHelper.java:80) i-l-idqznfgqs09i-ddlgz-6cccbb6c46-swqqb i-l-idqznfgqs09i-ddlgz  at org.apache.camel.model.RouteDefinition.resolveEndpoint(RouteDefinition.java:227) i-l-idqznfgqs09i-ddlgz-6cccbb6c46-swqqb i-l-idqznfgqs09i-ddlgz  at org.apache.camel.impl.DefaultRouteContext.resolveEndpoint(DefaultRouteContext.java:116) i-l-idqznfgqs09i-ddlgz-6cccbb6c46-swqqb i-l-idqznfgqs09i-ddlgz  at org.apache.camel.impl.DefaultRouteContext.resolveEndpoint(DefaultRouteContext.java:122) i-l-idqznfgqs09i-ddlgz-6cccbb6c46-swqqb i-l-idqznfgqs09i-ddlgz  at org.apache.camel.model.SendDefinition.resolveEndpoint(SendDefinition.java:62) i-l-idqznfgqs09i-ddlgz-6cccbb6c46-swqqb i-l-idqznfgqs09i-ddlgz  at org.apache.camel.model.SendDefinition.createProcessor(SendDefinition.java:56) i-l-idqznfgqs09i-ddlgz-6cccbb6c46-swqqb i-l-idqznfgqs09i-ddlgz  at org.apache.camel.model.ProcessorDefinition.createProcessor(ProcessorDefinition.java:518) i-l-idqznfgqs09i-ddlgz-6cccbb6c46-swqqb i-l-idqznfgqs09i-ddlgz  at org.apache.camel.model.ProcessorDefinition.createOutputsProcessorImpl(ProcessorDefinition.java:481) i-l-idqznfgqs09i-ddlgz-6cccbb6c46-swqqb i-l-idqznfgqs09i-ddlgz  at org.apache.camel.model.ProcessorDefinition.createOutputsProcessor(ProcessorDefinition.java:448) i-l-idqznfgqs09i-ddlgz-6cccbb6c46-swqqb i-l-idqznfgqs09i-ddlgz  at org.apache.camel.model.ProcessorDefinition.createOutputsProcessor(ProcessorDefinition.java:186) i-l-idqznfgqs09i-ddlgz-6cccbb6c46-swqqb i-l-idqznfgqs09i-ddlgz  at org.apache.camel.model.ProcessorDefinition.createChildProcessor(ProcessorDefinition.java:205) i-l-idqznfgqs09i-ddlgz-6cccbb6c46-swqqb i-l-idqznfgqs09i-ddlgz  at org.apache.camel.model.PipelineDefinition.createProcessor(PipelineDefinition.java:51) i-l-idqznfgqs09i-ddlgz-6cccbb6c46-swqqb i-l-idqznfgqs09i-ddlgz  at org.apache.camel.model.ProcessorDefinition.makeProcessorImpl(ProcessorDefinition.java:569) i-l-idqznfgqs09i-ddlgz-6cccbb6c46-swqqb i-l-idqznfgqs09i-ddlgz  at org.apache.camel.model.ProcessorDefinition.makeProcessor(ProcessorDefinition.java:530) i-l-idqznfgqs09i-ddlgz-6cccbb6c46-swqqb i-l-idqznfgqs09i-ddlgz  at org.apache.camel.model.ProcessorDefinition.addRoutes(ProcessorDefinition.java:240) i-l-idqznfgqs09i-ddlgz-6cccbb6c46-swqqb i-l-idqznfgqs09i-ddlgz  at org.apache.camel.model.RouteDefinition.addRoutes(RouteDefinition.java:1349) i-l-idqznfgqs09i-ddlgz-6cccbb6c46-swqqb i-l-idqznfgqs09i-ddlgz  ... 15 more ```</body>
		<created>2019-03-11 21:50:24</created>
		<closed>2019-03-13 09:31:08</closed>
	</bug>
	<bug>
		<id>4827</id>
		<title>ExtensionsITCase::testListExtensionDetails is flaky</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  We can either extend the timeout or we can try to address the underlying issue of asynchronous update to the `usage` property.</body>
		<created>2019-03-11 14:54:30</created>
		<closed>2019-06-19 12:49:24</closed>
	</bug>
	<bug>
		<id>4825</id>
		<title>IntegrationDeploymentITCase is flaky</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  The 1.6.0 release failed two times in a row with `IntegrationDeploymentITCase`, the third time the test passed. We need to see if we can improve the robustness of that test.</body>
		<created>2019-03-11 13:59:28</created>
		<closed>2019-11-23 12:08:09</closed>
	</bug>
	<bug>
		<id>4821</id>
		<title>upgrade camel-k runtime to version 0.3.1</title>
		<body></body>
		<created>2019-03-10 19:21:28</created>
		<closed>2019-03-15 22:51:43</closed>
	</bug>
	<bug>
		<id>4819</id>
		<title>Metrics not available for integrations deployed using camel-k</title>
		<body></body>
		<created>2019-03-10 19:07:37</created>
		<closed>2019-03-15 22:51:43</closed>
	</bug>
	<bug>
		<id>4811</id>
		<title>Integration flow doesn't continue after DB DELETE and INSERT </title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11436**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Let's have an integration: DB Insert -&gt; whatever or DB Delete -&gt; whatever  Each integration run performs only Insert and Delete and doesn't continue to the following defined steps.  Note: DB Select doesn't interrupt an integration run even if the result is nothing. </body>
		<created>2019-03-08 17:10:26</created>
		<closed>2019-09-07 11:29:08</closed>
	</bug>
	<bug>
		<id>4807</id>
		<title>Cannot initialize component proxy if the component is not in catalog</title>
		<body>Trying to use a `knative` connector but the runtime component proxy refuses it because it's not on the internal catalog.  ``` Exception in thread "main" org.apache.camel.RuntimeCamelException: java.lang.IllegalArgumentException: Failed to find component definition for scheme 'knative'. Missing component definition in classpath 'org/apache/camel/catalog/components/knative.json'         at org.apache.camel.util.ObjectHelper.wrapRuntimeCamelException(ObjectHelper.java:1830)         at org.apache.camel.k.adapter.Exceptions.wrapRuntimeCamelException(Exceptions.java:27)         at org.apache.camel.k.listener.RoutesConfigurer.load(RoutesConfigurer.java:75)         at org.apache.camel.k.listener.RoutesConfigurer.accept(RoutesConfigurer.java:45)         at org.apache.camel.k.listener.AbstractPhaseListener.accept(AbstractPhaseListener.java:31)         at org.apache.camel.k.jvm.ApplicationRuntime$MainListenerAdapter.lambda$configure$2(ApplicationRuntime.java:156)         at java.lang.Iterable.forEach(Iterable.java:75)         at org.apache.camel.k.jvm.ApplicationRuntime$MainListenerAdapter.configure(ApplicationRuntime.java:156)         at org.apache.camel.main.MainSupport.postProcessCamelContext(MainSupport.java:618)         at org.apache.camel.main.MainSupport.postProcessContext(MainSupport.java:550)         at org.apache.camel.k.jvm.ApplicationRuntime$Main.doStart(ApplicationRuntime.java:126)         at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61)         at org.apache.camel.main.MainSupport.run(MainSupport.java:170)         at org.apache.camel.k.jvm.ApplicationRuntime.run(ApplicationRuntime.java:72)         at org.apache.camel.k.jvm.Application.main(Application.java:52) Caused by: java.lang.IllegalArgumentException: Failed to find component definition for scheme 'knative'. Missing component definition in classpath 'org/apache/camel/catalog/components/knative.json'         at io.syndesis.integration.component.proxy.ComponentDefinition.lambda$forScheme$0(ComponentDefinition.java:123)         at java.util.Optional.orElseThrow(Optional.java:290)         at io.syndesis.integration.component.proxy.ComponentDefinition.forScheme(ComponentDefinition.java:123)         at io.syndesis.integration.component.proxy.ComponentProxyComponent.&lt;init&gt;(ComponentProxyComponent.java:75)         at io.syndesis.connector.knative.KnativeComponentProxyFactory$1.&lt;init&gt;(KnativeComponentProxyFactory.java:18)         at io.syndesis.connector.knative.KnativeComponentProxyFactory.newInstance(KnativeComponentProxyFactory.java:18)         at io.syndesis.integration.runtime.handlers.ConnectorStepHandler.resolveComponent(ConnectorStepHandler.java:158)         at io.syndesis.integration.runtime.handlers.ConnectorStepHandler.handle(ConnectorStepHandler.java:80)         at io.syndesis.integration.runtime.IntegrationRouteBuilder.configureFlow(IntegrationRouteBuilder.java:174)         at io.syndesis.integration.runtime.IntegrationRouteBuilder.configure(IntegrationRouteBuilder.java:104)         at org.apache.camel.builder.RouteBuilder.checkInitialized(RouteBuilder.java:462)         at org.apache.camel.builder.RouteBuilder.configureRoutes(RouteBuilder.java:402)         at org.apache.camel.builder.RouteBuilder.addRoutesToCamelContext(RouteBuilder.java:383)         at org.apache.camel.impl.DefaultCamelContext$1.call(DefaultCamelContext.java:1027)         at org.apache.camel.impl.DefaultCamelContext$1.call(DefaultCamelContext.java:1024)         at org.apache.camel.impl.DefaultCamelContext.doWithDefinedClassLoader(DefaultCamelContext.java:3270)         at org.apache.camel.impl.DefaultCamelContext.addRoutes(DefaultCamelContext.java:1024)         at org.apache.camel.k.listener.RoutesConfigurer.load(RoutesConfigurer.java:73)         ... 12 more ```</body>
		<created>2019-03-08 13:45:17</created>
		<closed>2019-06-15 20:09:33</closed>
	</bug>
	<bug>
		<id>4806</id>
		<title>Integration name on openshift should not be a random uid when using camel k</title>
		<body>E.g. of name: `i-l-stdmntog-o3o1y9mhz`, while the integration is named in a totally different way..</body>
		<created>2019-03-08 13:33:09</created>
		<closed>2019-03-15 22:51:43</closed>
	</bug>
	<bug>
		<id>4800</id>
		<title>Change connection via Public API throws EntityNotFoundException: null</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When I want to change properties of default PostgresSQL via Public API  ``` curl --request POST ... /public/connections/PostgresDB/properties -d '{ "user": "myuser", "password": "mypassword" }' ``` the result is ``` {"errorCode":404,"userMsg":"Please check your request data","developerMsg":"Entity Not Found Exception null"} ``` but the properties were changed in that connection. ![image](https://user-images.githubusercontent.com/16251792/54019524-ae2daf80-418b-11e9-84bd-0c51d7626839.png) In the server shows error: ``` 2019-03-08 09:08:57.176 ERROR [-,ecc49071e5ec47e6,ecc49071e5ec47e6,false] 1 --- [  XNIO-3 task-6] .s.e.v.h.e.EntityNotFoundExceptionMapper : Entity Not Found Exception null javax.persistence.EntityNotFoundException: null at io.syndesis.server.endpoint.v1.handler.connection.ConnectionHandler.get(ConnectionHandler.java:133) ~[server-endpoint-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at io.syndesis.server.endpoint.v1.handler.external.PublicApiHandler.configureConnection(PublicApiHandler.java:447) ~[server-endpoint-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_151] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_151] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151] at org.jboss.resteasy.core.MethodInjectorImpl.invoke(MethodInjectorImpl.java:140) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.internalInvokeOnTarget(ResourceMethodInvoker.java:509) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTargetAfterFilter(ResourceMethodInvoker.java:399) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.lambda$invokeOnTarget$0(ResourceMethodInvoker.java:363) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:358) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTarget(ResourceMethodInvoker.java:365) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:337) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:310) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:443) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.lambda$invoke$4(SynchronousDispatcher.java:233) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.lambda$preprocess$0(SynchronousDispatcher.java:139) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:358) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.preprocess(SynchronousDispatcher.java:142) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:219) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.ServletContainerDispatcher.service(ServletContainerDispatcher.java:227) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:56) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:51) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) ~[javax.servlet-api-3.1.0.jar!/:3.1.0] at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] ```  ![output](https://user-images.githubusercontent.com/16251792/54019329-3f505680-418b-11e9-8f05-ce2941d7e830.gif) </body>
		<created>2019-03-08 09:19:47</created>
		<closed>2019-03-13 09:39:49</closed>
	</bug>
	<bug>
		<id>4799</id>
		<title>Cannot use registry.redhat.io</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  </body>
		<created>2019-03-08 08:17:13</created>
		<closed>2019-04-02 07:10:44</closed>
	</bug>
	<bug>
		<id>4792</id>
		<title>Publish operation hangs when some connection step details are opened</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  - Open an integration - select a connection to display its details - While on that opened details page hit the publish button   The publish operation hangs and nothing happens. This only happens when you hit that publish button while a connection step details page is opened.  ![out](https://user-images.githubusercontent.com/195264/53967008-b090fa80-40f4-11e9-9c6e-b07d25c14b8e.gif) </body>
		<created>2019-03-07 14:13:09</created>
		<closed>2019-06-10 13:09:10</closed>
	</bug>
	<bug>
		<id>4791</id>
		<title>OData connector causing error when creating integration</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When I create OData connector (with https://services.odata.org/TripPinRESTierService/ sample service) and try to create integration I get "javax.ws.rs.NotSupportedException: RESTEASY003200: Could not find message body reader for type: org.jboss.resteasy.util.Types$1@2b0b08a5 of content type: */*" in server pod log. When I continue and create integration (odata -&gt; split -&gt; log), wait for it to start and then try to edit it (the integration), I am not able to update or ~~remove~~ (with --full-reset install of syndesis, I am able to remove the step) the OData connector from the integration.  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create OData connector (https://services.odata.org/TripPinRESTierService/ sample service) 2. Create integration odata -&gt; split -&gt; log 3. Check server pod log 4. Try to edit integration and ~~delete~~/update odata connector </body>
		<created>2019-03-07 13:26:15</created>
		<closed>2019-03-20 11:23:19</closed>
	</bug>
	<bug>
		<id>4790</id>
		<title>Validation of the updated tag name</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When I rename the tag via Public API with a wrong parameter which contains special characters, e.g. ``` curl -X PUT ... /public/environments/tag2 -d '{"tag3"}' ``` instead of a correct ``` curl -X PUT ... /public/environments/tag2 -d 'tag3'  ```  the name is saved anyway.  ![image](https://user-images.githubusercontent.com/16251792/53959309-9bf83680-40e3-11e9-95fc-1dec8110587d.png)  However, it contains special characters so after that, I am not able to delete the tag. When I click on a remove button, in the server shows exception: ``` 2019-03-07 13:12:18.717 ERROR [-,,,] 1 --- [  XNIO-3 task-6] io.undertow.request                      : UT005023: Exception handling request to /api/v1/public/environments/%257B%2522tag3%2522%257D org.springframework.security.web.firewall.RequestRejectedException: The request was rejected because the URL contained a potentially malicious String "%25" at org.springframework.security.web.firewall.StrictHttpFirewall.rejectedBlacklistedUrls(StrictHttpFirewall.java:265) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.firewall.StrictHttpFirewall.getFirewalledRequest(StrictHttpFirewall.java:245) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:193) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.cloud.sleuth.instrument.web.TraceFilter.doFilter(TraceFilter.java:186) ~[spring-cloud-sleuth-core-1.2.6.RELEASE.jar!/:1.2.6.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] ... ``` ![output](https://user-images.githubusercontent.com/16251792/53959321-a286ae00-40e3-11e9-8660-e1d5606be029.gif)  I am able to do it via CI/CD dialog too ![output](https://user-images.githubusercontent.com/16251792/53959674-994a1100-40e4-11e9-8898-a81febd1213f.gif)   </body>
		<created>2019-03-07 13:24:54</created>
		<closed>2019-03-13 15:46:37</closed>
	</bug>
	<bug>
		<id>4789</id>
		<title>Stop integration via Public API doesn't work</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I have a running integration. When I call ``` curl -k -L -H -v -X PUT "Content-Type: application/json" -H "SYNDESIS-XSRF-TOKEN: awesome" -H 'Authorization: Bearer &lt;TOKEN&gt;' https://public-syndesis.my-minishift.syndesis.io/api/v1/public/integrations/timer-to-log/deployments/stop  ``` It returns  ``` {"errorCode":403,"userMsg":"Given request is not acceptable","developerMsg":"Integration timer-to-log is not published"} ```  On the other hand, when the integration is Unpublished, it returns `204 No Content`. In my POV, it should return the error to notify a user that the integration is not published.   ![output](https://user-images.githubusercontent.com/16251792/53956354-af070880-40db-11e9-8c4f-4086e13b5cc0.gif) </body>
		<created>2019-03-07 12:21:46</created>
		<closed>2019-03-15 10:00:38</closed>
	</bug>
	<bug>
		<id>4788</id>
		<title>service-now: processing connection step in integration editor takes too long </title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11437**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Processing connection step (i.e Add record, confirm after select import-set) in integration editor takes too long when service-now is involved. Confirmation connection after for example selecting import-set may take longer than 15s.  ![screenshot_20190307_114648](https://user-images.githubusercontent.com/6814482/53951818-9a247800-40cf-11e9-97b7-dfa1d290db6f.png)   </body>
		<created>2019-03-07 10:52:15</created>
		<closed>2019-09-07 11:29:16</closed>
	</bug>
	<bug>
		<id>4785</id>
		<title>[Upgrade] Operator throws errors in log related to upgrade pvc</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11438**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When starting the upgrade, the operator prints these into the logs:  ``` {"level":"info","ts":1551940655.3237867,"logger":"action","msg":"Starting upgrade of Syndesis resource","type":"check-updates","name":"app","currentVersion":"1.5.9","targetVersion":"1.6.1-20190307","type":"checkUpdate"} {"level":"info","ts":1551940655.3299284,"logger":"controller","msg":"Reconciling Syndesis","Request.Namespace":"syndesis","Request.Name":"app"} {"level":"info","ts":1551940655.3300223,"logger":"controller","msg":"Running action","action":"*action.upgradeAction"} {"level":"info","ts":1551940665.156088,"logger":"action","msg":"Upgrading syndesis resource ","type":"upgrade","name":"app","currentVersion":"1.5.9","targetVersion":"1.6.1-20190307"} {"level":"error","ts":1551940665.1691592,"logger":"controller","msg":"Error reconciling","action":"*action.upgradeAction","phase":"Upgrading","error":"object is being deleted: persistentvolumeclaims \"syndesis-upgrade\" already exists","stacktrace":"github.com/syndesisio/syndesis/install/operator/vendor/github.com/go-logr/zapr.(*zapLogger).Error\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/github.com/go-logr/zapr/zapr.go:128\ngithub.com/syndesisio/syndesis/install/operator/pkg/controller/syndesis.(*ReconcileSyndesis).Reconcile\n\t/go/src/github.com/syndesisio/syndesis/install/operator/pkg/controller/syndesis/syndesis_controller.go:119\ngithub.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:213\ngithub.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func1\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:158\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.JitterUntil.func1\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:133\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:134\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.Until\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:88"} {"level":"error","ts":1551940665.1692502,"logger":"kubebuilder.controller","msg":"Reconciler error","controller":"syndesis-controller","request":"syndesis/app","error":"object is being deleted: persistentvolumeclaims \"syndesis-upgrade\" already exists","stacktrace":"github.com/syndesisio/syndesis/install/operator/vendor/github.com/go-logr/zapr.(*zapLogger).Error\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/github.com/go-logr/zapr/zapr.go:128\ngithub.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:215\ngithub.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func1\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:158\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.JitterUntil.func1\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:133\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:134\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.Until\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:88"} ```  They seems to be harmless, but they don't look good :grin:  </body>
		<created>2019-03-07 06:39:37</created>
		<closed>2019-09-07 11:29:21</closed>
	</bug>
	<bug>
		<id>4781</id>
		<title>[Upgrade] CR phase stays "Upgrading" after the upgrade is done</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When doing upgrade, after the upgrade is done, the CR phase stays "Upgrading":  ``` Name:         example Namespace:    syndesis Labels:       &lt;none&gt; Annotations:  syndesis.io/applicationUrl=https://syndesis.my-minishift.syndesis.io API Version:  syndesis.io/v1alpha1 Kind:         Syndesis Metadata:   Creation Timestamp:  2019-03-06T15:51:28Z   Generation:          1   Resource Version:    8730   Self Link:           /apis/syndesis.io/v1alpha1/namespaces/syndesis/syndesises/example   UID:                 b47f242e-4027-11e9-b065-08002701baf0 Spec:   Components:     Db:       Database:                syndesis       Image Stream Namespace:  openshift       Resources:         Limits:           Memory:         255Mi         Volume Capacity:  1Gi       User:               syndesis     Grafana:       Resources:     Meta:       Resources:         Limits:           Memory:         512Mi         Volume Capacity:  1Gi     Prometheus:       Resources:         Limits:           Memory:         512Mi         Volume Capacity:  1Gi     Server:       Features:       Resources:         Limits:           Memory:  800Mi     Upgrade:       Resources:         Volume Capacity:   1Gi   Demo Data:               false   Deploy Integrations:     true   Image Stream Namespace:  syndesis   Integration:     Limit:                 5     State Check Interval:  60   Registry:                docker.io   Route Hostname:          syndesis.my-minishift.syndesis.io   Test Support:            true Status:   Description:     Upgrading from 1.5.9 to 1.6.1-20190306   Phase:           Upgrading   Target Version:  1.6.1-20190306   Version:         1.5.9 Events:            &lt;none&gt; ```  ``` syndesis-db-2-wgkm7               2/2       Running     0          6m syndesis-meta-2-zcfxn             1/1       Running     0          6m syndesis-oauthproxy-1-dcc74       1/1       Running     0          6m syndesis-operator-2-mzsfn         1/1       Running     0          9m syndesis-prometheus-1-tbgl8       1/1       Running     0          6m syndesis-server-2-r4fdm           1/1       Running     0          6m syndesis-ui-2-q7fsn               1/1       Running     0          6m syndesis-upgrade-1.6.1-20190306   0/1       Completed   0          8m todo-1-build                      0/1       Completed   0          21m todo-2-build                      1/1       Running     0          11s  ```  This for example causes, that when the CR is deleted, operator does not pick up this and does not undeploy syndesis</body>
		<created>2019-03-06 16:15:23</created>
		<closed>2019-03-18 18:12:13</closed>
	</bug>
	<bug>
		<id>4777</id>
		<title>Data mapping to and from template step is not possible </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ x ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  There is this demo of the template step: https://www.youtube.com/watch?v=Pfysm8W8sco&amp;t=0s  Following the steps (just used DB search instead of twitter search), the mapping step ignores the specified template step - is only possible to map to the last step of the integration.  ## Expected behavior The user should be able to map to the template step  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![out](https://user-images.githubusercontent.com/4180208/53887856-6a1f9b00-4023-11e9-9b9a-3579aae582ea.gif)  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Start creating new integration - e.g. DB -&gt; gmail 2. Specify template step in between -&gt; use mustache as the template type 3. Try to create mapping in front of the template step 4. The mapping is not possible </body>
		<created>2019-03-06 14:24:25</created>
		<closed>2019-03-08 08:36:43</closed>
	</bug>
	<bug>
		<id>4771</id>
		<title>Data Mapper UI partially hidden when in API Provider integration</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When editing a data mapping in an API Provder integration, the Data Mapper UI is partially hidden by the API Provider toolbar.  ![screenshot_2019-03-06_11-30-26](https://user-images.githubusercontent.com/9480152/53874937-c96db300-4003-11e9-81c8-54f4ce7f1a5f.png)  This breaks most of our automated tests, since they expect the buttons in the toolbar to be visible and clickable. </body>
		<created>2019-03-06 10:35:06</created>
		<closed>2019-03-20 10:54:03</closed>
	</bug>
	<bug>
		<id>4766</id>
		<title>Tooltip for filter toolbar is partially hidden</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Tooltip for the dropdown on the filter toolbar is partially hidden behind another page element. See screenshots below. This happens on both Create a Connection step 1 and the integration list page.   Possibly relates to https://github.com/syndesisio/syndesis/issues/4385  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlisting the acceptance criteria. --&gt; The tooltip should be fully visible when hover.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; &lt;img width="455" alt="screen shot 2019-03-05 at 2 57 25 pm" src="https://user-images.githubusercontent.com/24943812/53834535-4859e180-3f59-11e9-8cb8-f024b536ab53.png"&gt;  &lt;img width="960" alt="screen shot 2019-03-05 at 3 17 14 pm" src="https://user-images.githubusercontent.com/24943812/53834758-df269e00-3f59-11e9-89d9-56ea22627092.png"&gt;   ## Request and Response Data &lt;!-- Many issues involve both the UI and its backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4.  cc: @mcoker @seanforyou23 </body>
		<created>2019-03-05 20:22:02</created>
		<closed>2019-06-10 21:38:31</closed>
	</bug>
	<bug>
		<id>4762</id>
		<title>FuseOnlineDatabaseInstanceDown alert is not activated when Syndesis-db is down</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  I have those alerts (https://github.com/syndesisio/syndesis/issues/4151 , https://github.com/syndesisio/syndesis/issues/4499): ![image](https://user-images.githubusercontent.com/16251792/53820191-8fe96900-3f6b-11e9-9060-89928be2f6cc.png)  I scale syndesis-db to 0 due to simulate database down state for alerting. After some time, when the server cannot connect to db, the latency of RestAPI is higher(10s) ![image](https://user-images.githubusercontent.com/16251792/53820296-c8894280-3f6b-11e9-9d9c-69f6c7f7f941.png) Because of that, The FuseOnlineRestApiHighEndpointLatency and FuseOnlineRestApiHighEndpointErrorRate alerts are in the pending state ![image](https://user-images.githubusercontent.com/16251792/53820390-f66e8700-3f6b-11e9-8233-f5531c052dd5.png) and after some times, they are fired ![image](https://user-images.githubusercontent.com/16251792/53820464-1aca6380-3f6c-11e9-9355-99ae92776bd1.png)  However, the [FuseOnlineDatabaseInstanceDown]( https://github.com/jamesnetherton/syndesis/blob/ec10dc4ec4ceb5bf90dd84e07fc7fd6c3ab9ddfe/doc/managing_environments/topics/alerting_sop.adoc#fuseonlinedatabaseinstancedown) alert is still inactive. In my POV, when syndesis-db pod is scaled down to 0, this alert should fired too.   </body>
		<created>2019-03-05 16:31:34</created>
		<closed>2019-03-11 15:51:09</closed>
	</bug>
	<bug>
		<id>4758</id>
		<title>OData connector with https url needs client certificate </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When setting up OData connector with TripPin sample service (https://services.odata.org/TripPinRESTierService/) and trying to validate it, there's message saying "An https / ssl OData connection requires an ssl client certificate.". Why does it need that? Simple HTTPS connector is able to validate this url and use it properly.  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create OData connector 2. As Service Root URL add https://services.odata.org/TripPinRESTierService/ 3. Try to Validate </body>
		<created>2019-03-05 15:29:12</created>
		<closed>2019-03-18 11:12:57</closed>
	</bug>
	<bug>
		<id>4756</id>
		<title>Connection checkbox default values not being honoured</title>
		<body>When configuring an integration's connection, default values for checkboxes are being passed to the UI's form model but the latter is ignoring them, eg.  ![odata-connector-default-values](https://user-images.githubusercontent.com/1634180/53811543-8fdc6f80-3f51-11e9-9774-b8da83fcb32e.png) _Checkboxes have default values of 'true'_  The reason this occurs is located in [form-factory-provider.service.ts](https://github.com/syndesisio/syndesis/blob/master/app/ui/src/app/core/providers/form-factory-provider.service.ts). - [createFormModel()](https://github.com/syndesisio/syndesis/blob/master/app/ui/src/app/core/providers/form-factory-provider.service.ts#L26) is called; - For each [key](https://github.com/syndesisio/syndesis/blob/master/app/ui/src/app/core/providers/form-factory-provider.service.ts#L37) in the properties received from the server, a create..() method is determined - for boolean/checkboxes -&gt; createCheckbox(); - In most cases, _value_ is passed to create methods as _undefined_. However, for checkboxes, this is converted into a [boolean](https://github.com/syndesisio/syndesis/blob/master/app/ui/src/app/core/providers/form-factory-provider.service.ts#L69) &lt;- **_(problem!)_**; - In [createCheckbox()](https://github.com/syndesisio/syndesis/blob/master/app/ui/src/app/core/providers/form-factory-provider.service.ts#L313), _value_ is evaluated and either _it_, _field.value_ or _field.defaultValue_ should be used. However, _value_ is always chosen due to it having already been [assigned](https://github.com/syndesisio/syndesis/blob/master/app/ui/src/app/core/providers/form-factory-provider.service.ts#L69). </body>
		<created>2019-03-05 14:29:36</created>
		<closed>2019-03-11 15:29:38</closed>
	</bug>
	<bug>
		<id>4755</id>
		<title>Tags are duplicated in the CI/CD dialog after import</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description After the fix of the https://github.com/syndesisio/syndesis/issues/4735 , the tags are duplicated in another syndesis where the integrations are imported.   Let's say I have syndesis1 with integration: Integration **a** with tags: _x,y,ENV2_ Integration **b** with tags: _x,y,ENV2_ I export this integration with ``` curl ... https://public-syndesis.my-minishift.syndesis.io/api/v1/public/integrations/ENV2/export.zip -O ``` After that I import this export.zip into another syndesis instance (syndesis2): ``` curl ... https://public-syndesis.my-minishift.syndesis.io/api/v1/public/integrations -F data=@export.zip -F environment=ENV2 ```  So after that, I see all tags duplicated: ![image](https://user-images.githubusercontent.com/16251792/53807829-ea290080-3f50-11e9-8450-2cbd9d1d6f65.png)  Before the fix for: https://github.com/syndesisio/syndesis/issues/4735 in the dialog was only ENV2. ![image](https://user-images.githubusercontent.com/16251792/53807902-1fcde980-3f51-11e9-8053-7bb4f8264fa0.png)  -----  The same situation is when I want to add integration2 to use the tag which already exists. It is created the duplicated of the tag. ![output](https://user-images.githubusercontent.com/16251792/53809157-6113c880-3f54-11e9-8435-6469c95e2f9c.gif) ``` /api/v1/public/environments ``` returns ["ENV1","ENV1"]  If I have 10 integration and in every integration, I check the same tag, I will have 10 same tags.</body>
		<created>2019-03-05 13:47:51</created>
		<closed>2019-03-07 12:51:29</closed>
	</bug>
	<bug>
		<id>4753</id>
		<title>Monitoring - Syndesis DB Grafana dashboard should be resilient to pod restarts</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  The syndesis-db Grafana dashboard is not very resilient to restarts of the syndesis-db pod. Some of the 'singlestat' metrics at the top of the dashboard fail because it cannot handle multiple time series being returned. Hence they appear like:  ![dashboard-error](https://user-images.githubusercontent.com/4721408/53805623-99aaa680-3f42-11e9-85fa-7b6e7c6d4ed0.png)  Other rows such as 'Active Connections' start to report on multiple time series, thus it's not obvious to the user what's being graphed. See below example, there are multiple series for the syndesis database. One for the old dead pod and another for the new one. Which is confusing.  ![dashboard-error-1](https://user-images.githubusercontent.com/4721408/53805717-d9718e00-3f42-11e9-9cdb-ef49c3a9dfb7.png) </body>
		<created>2019-03-05 12:49:30</created>
		<closed>2019-03-11 15:20:17</closed>
	</bug>
	<bug>
		<id>4752</id>
		<title>Filter in split/aggregate not working</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Adding a basic filter step in a split/aggregate leads to weird behavior where the aggregate is not working as expected.  Expected behavior is to only aggregate those elements that matched the filter.  Example Integration: [FilterInSplit-export.zip](https://github.com/syndesisio/syndesis/files/2930406/FilterInSplit-export.zip)  ![filter-in-split](https://user-images.githubusercontent.com/195264/53798570-cb1e7480-3f38-11e9-8186-469cdd2ed03d.png)  Activity Log:  ![filter-in-split-activity](https://user-images.githubusercontent.com/195264/53798580-d376af80-3f38-11e9-9728-042c115ac420.png)  </body>
		<created>2019-03-05 10:22:34</created>
		<closed>2019-04-24 13:44:33</closed>
	</bug>
	<bug>
		<id>4751</id>
		<title>Build - Fails at camel-k step</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When I try to build the project with `./syndesis --setup` the process fails at `camel-k` step:  ``` 11:10 $ git show HEAD --oneline  ec8add976 (HEAD -&gt; master) Merge pull request #4745 from dhirajsb/cicd-services ```  Error:  ``` [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 29:57 min [INFO] Finished at: 2019-03-05T10:03:44+01:00 [INFO] Final Memory: 565M/1702M [INFO] ------------------------------------------------------------------------ ============================================================================== Building syndesis-operator ============================================================================== Sending build context to Docker daemon 43.64 MB Step 1/8 : FROM golang:1.11.0  ---&gt; fb7a47d8605b Step 2/8 : RUN go get -u github.com/golang/dep/cmd/dep  ---&gt; Using cache  ---&gt; 27379cdb1ad2 Step 3/8 : WORKDIR /go/src/github.com/syndesisio/syndesis/install/operator  ---&gt; Using cache  ---&gt; e5b9d6d2c373 Step 4/8 : COPY Gopkg.toml .  ---&gt; Using cache  ---&gt; 66e21f540dcf Step 5/8 : COPY Gopkg.lock .  ---&gt; Using cache  ---&gt; 0a6ee40789b3 Step 6/8 : RUN dep ensure -vendor-only -v  ---&gt; Using cache  ---&gt; 464a248974d3 Step 7/8 : COPY . .  ---&gt; 0ee00dff1e98 Removing intermediate container db4b9a9f8a35 Step 8/8 : RUN CGO_ENABLED=0 go build -o /syndesis-operator ./cmd/syndesis-operator  ---&gt; Running in 62f146d1c154  ---&gt; cb304f7380d7 Removing intermediate container 62f146d1c154 Successfully built cb304f7380d7 /data/repo/github/work/syndesis/syndesis/app ============================================================================== Building camel-k ============================================================================== /data/repo/github/work/syndesis/syndesis/tools/bin/commands/build: line 188: GOPATH: unbound variable ERROR: Last command exited with 1  ``` </body>
		<created>2019-03-05 10:11:40</created>
		<closed>2019-03-11 09:27:58</closed>
	</bug>
	<bug>
		<id>4749</id>
		<title>When trying to cancel the integration creation process - the popup window seems to be broken</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ x ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Try to cancel the integration setup process - popup window does not provide any info, seems like the text is missing, only question marks are displayed. Tried with the newest master on Firefox.   ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![cancel_integration](https://user-images.githubusercontent.com/4180208/53789879-d5834300-3f25-11e9-9dea-f4db123be7a3.png)   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Start the "Create integration" process  2. When half way through (start step is defined) press cancel 3. See the popup window with question marks </body>
		<created>2019-03-05 08:07:12</created>
		<closed>2019-03-05 09:22:07</closed>
	</bug>
	<bug>
		<id>4747</id>
		<title>bug: Public API does not return any state details for un-deployed integrations</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  The public API for integration state MUST return the current integration state in addition to any available state details. </body>
		<created>2019-03-05 07:45:14</created>
		<closed>2019-03-06 11:27:56</closed>
	</bug>
	<bug>
		<id>4741</id>
		<title>[collection-support] Fix data type mismatch overlay icon</title>
		<body>Steps that require some data mapping are provided with a warning sign as overlay icon. When using split/aggregate steps the data type mismatch icon is displayed multiple times on aggregate and subsequent step. It should only appear on aggregate step.  ![bildschirmfoto 2019-03-04 um 20 21 28](https://user-images.githubusercontent.com/195264/53757263-886a8700-3ebb-11e9-9aef-063e44d56c5a.png)  Also when mapper has beed added the overlay icon on the aggregate step disappears but the one on the subsequent step is still displayed and never goes away.  ![bildschirmfoto 2019-03-04 um 20 21 52](https://user-images.githubusercontent.com/195264/53757304-a1733800-3ebb-11e9-9529-81f43a568599.png)   [TodoApiProvider-export.zip](https://github.com/syndesisio/syndesis/files/2931311/TodoApiProvider-export.zip)  </body>
		<created>2019-03-04 19:26:47</created>
		<closed>2019-03-07 13:15:53</closed>
	</bug>
	<bug>
		<id>4738</id>
		<title>OpenAPI connector no route to host</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When using the [todo json OpenAPI specification](https://github.com/syndesisio/syndesis-qe/blob/6dc4eac614ef48368a6a743cecaf3bcf0da2359f/ui-tests/src/test/resources/swagger/connectors/todo.json) with hostname: http://todo-syndesis.my-minishift.syndesis.io/ always results in NoRouteToHost Exception, I've tried reconfiguring the hostname multiple times but nothing seems to be working. In the log included, it seems that there is always : at the end of the URL   ``` 2019-03-04 15:40:33.054 DEBUG 1 --- [           main] o.a.camel.spring.boot.RoutesCollector    : CamelContextConfiguration found. Invoking afterApplicationStart: io.syndesis.integration.runtime.sb.jmx.IntegrationMetadataAutoConfiguration$1@6cbcf243 2019-03-04 15:40:33.055 DEBUG 1 --- [           main] o.a.camel.spring.boot.RoutesCollector    : CamelContextConfiguration found. Invoking afterApplicationStart: io.syndesis.integration.runtime.sb.logging.IntegrationLoggingAutoConfiguration$1@339bf286 2019-03-04 15:40:33.130  INFO 1 --- [           main] b.c.e.u.UndertowEmbeddedServletContainer : Undertow started on port(s) 8080 (http) 2019-03-04 15:40:33.135  INFO 1 --- [           main] io.syndesis.example.Application          : Started Application in 8.646 seconds (JVM running for 9.617) 2019-03-04 15:40:35.948  INFO 1 --- [/syndesis-timer] o.apache.http.impl.execchain.RetryExec   : I/O exception (java.net.NoRouteToHostException) caught when processing request to {}-&gt;http://todo-syndesis.my-minishift.syndesis.io:80:  No route to host (Host unreachable) 2019-03-04 15:40:35.949  INFO 1 --- [/syndesis-timer] o.apache.http.impl.execchain.RetryExec   : Retrying request to {}-&gt;http://todo-syndesis.my-minishift.syndesis.io:80  2019-03-04 15:40:38.958  INFO 1 --- [/syndesis-timer] o.apache.http.impl.execchain.RetryExec   : I/O exception (java.net.NoRouteToHostException) caught when processing request to {}-&gt;http://todo-syndesis.my-minishift.syndesis.io:80:  No route to host (Host unreachable) 2019-03-04 15:40:38.958  INFO 1 --- [/syndesis-timer] o.apache.http.impl.execchain.RetryExec   : Retrying request to {}-&gt;http://todo-syndesis.my-minishift.syndesis.io:80  2019-03-04 15:40:41.962  INFO 1 --- [/syndesis-timer] o.apache.http.impl.execchain.RetryExec   : I/O exception (java.net.NoRouteToHostException) caught when processing request to {}-&gt;http://todo-syndesis.my-minishift.syndesis.io:80:  No route to host (Host unreachable) 2019-03-04 15:40:41.962  INFO 1 --- [/syndesis-timer] o.apache.http.impl.execchain.RetryExec   : Retrying request to {}-&gt;http://todo-syndesis.my-minishift.syndesis.io:80  2019-03-04 15:40:44.975 ERROR 1 --- [/syndesis-timer] o.a.camel.processor.DefaultErrorHandler  : Failed delivery for (MessageId: i-L_8MGmN-iESMJwF8mCgz on ExchangeId: i-L_8MGm1-iESMJwF8mCfz). Exhausted after delivery attempt: 1 caught: java.net.NoRouteToHostException: No route to host (Host unreachable) Message History --------------------------------------------------------------------------------------------------------------------------------------- RouteId              ProcessorId          Processor                                                                        Elapsed (ms) [-L_8M-dKasdV8AaodB] [-L_8M-dKasdV8AaodB] [timer://syndesis-timer?period=60000                                           ] [     12194] [-L_8M-dKasdV8AaodB] [setHeader1        ] [setHeader[Syndesis.FLOW_ID]                                                   ] [         7] [-L_8M-dKasdV8AaodB] [setHeader2        ] [setHeader[Syndesis.STEP_ID]                                                   ] [         0] [-L_8M-dKasdV8AaodB] [process1          ] [Processor@0x6396414a                                                          ] [         0] [-L_8M-dKasdV8AaodB] [step:-L_8M1Y5asdV8] [pipeline                                                                      ] [         0] [-L_8M-dKasdV8AaodB] [setHeader3        ] [setHeader[Syndesis.STEP_ID]                                                   ] [         0] [-L_8M-dKasdV8AaodB] [to1               ] [swagger-operation-0-1?operationId=operation-0                                 ] [     12174] Stacktrace --------------------------------------------------------------------------------------------------------------------------------------- java.net.NoRouteToHostException: No route to host (Host unreachable) at java.net.PlainSocketImpl.socketConnect(Native Method) ~[na:1.8.0_191] at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[na:1.8.0_191] at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[na:1.8.0_191] at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[na:1.8.0_191] at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[na:1.8.0_191] at java.net.Socket.connect(Socket.java:589) ~[na:1.8.0_191] at org.apache.http.conn.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:75) ~[httpclient-4.5.6.jar!/:4.5.6] at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142) ~[httpclient-4.5.6.jar!/:4.5.6] at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:373) ~[httpclient-4.5.6.jar!/:4.5.6] at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:394) ~[httpclient-4.5.6.jar!/:4.5.6] at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237) ~[httpclient-4.5.6.jar!/:4.5.6] at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185) ~[httpclient-4.5.6.jar!/:4.5.6] at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89) ~[httpclient-4.5.6.jar!/:4.5.6] at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110) ~[httpclient-4.5.6.jar!/:4.5.6] at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185) ~[httpclient-4.5.6.jar!/:4.5.6] at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83) ~[httpclient-4.5.6.jar!/:4.5.6] at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56) ~[httpclient-4.5.6.jar!/:4.5.6] at org.apache.camel.component.http4.HttpProducer.executeMethod(HttpProducer.java:335) ~[camel-http4-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.component.http4.HttpProducer.process(HttpProducer.java:194) ~[camel-http4-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.component.rest.RestProducer.process(RestProducer.java:86) ~[camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.component.connector.ConnectorProducer.process(ConnectorProducer.java:45) ~[camel-connector-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) ~[camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) [integration-runtime-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79) [camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at java.util.TimerThread.mainLoop(Timer.java:555) [na:1.8.0_191] at java.util.TimerThread.run(Timer.java:505) [na:1.8.0_191] ```   </body>
		<created>2019-03-04 15:50:21</created>
		<closed>2019-05-28 06:55:59</closed>
	</bug>
	<bug>
		<id>4736</id>
		<title>Integration pod still being deployed after deleting it in UI</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description This has happened to me a few times before, but usually it sorted itself out after a while or after deleting other integrations. But now I am not able to make it work (apart from redeploying syndesis again)  From the server logs I discovered there's integration called i-simple-test still trying to be deployed although I have deleted it in the UI.  I am attaching server log (it's going to be quite a lot to go through but I am not sure, what caused it really just can tell you that i-simple-test is misbehaving): [syndesis-server-1-5qvhk(1).log](https://github.com/syndesisio/syndesis/files/2926975/syndesis-server-1-5qvhk.1.log)  </body>
		<created>2019-03-04 15:29:29</created>
		<closed>2019-06-19 18:30:10</closed>
	</bug>
	<bug>
		<id>4735</id>
		<title>Cannot delete environment tag in UI when it is imported via PublicAPI</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When I created some environment tag (ENV1) in CI/CD dialog, i am able to delete it.  However, when I import some integrations through PublicAPI and I specify another environment tag (ENV2),  ` curl ... https://public-syndesis.my-minishift.syndesis.io/api/v1/public/integrations -F data=@export.zip -F environment=ENV2 ` I am not able to delete it (ENV2) via UI dialog even though the imported integrations are already deleted. I am able to delete it only via PublicAPI ` curl ... -X DELETE https://public-syndesis.my-minishift.syndesis.io/api/v1/public/environments/ENV2  ` ![output](https://user-images.githubusercontent.com/16251792/53741896-ade59980-3e97-11e9-906c-487fa3b820fc.gif)  </body>
		<created>2019-03-04 15:10:39</created>
		<closed>2019-03-05 13:49:33</closed>
	</bug>
	<bug>
		<id>4734</id>
		<title>Cron timer can't resolve endpoint quartz2</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When creating a simple integration using the cron integration action of timer, leaving the default configuration results in this error: ``` org.apache.camel.RuntimeCamelException: org.apache.camel.FailedToCreateRouteException: Failed to create route -L_7vQwYcso8HIomNGxM: Route(-L_7vQwYcso8HIomNGxM)[[From[quartz2-0-0]] -&gt; [SetHeade... because of Failed to resolve endpoint: quartz2-0-0 due to: Failed to resolve endpoint: quartz2://syndesis-quartz?cron=0+0%2F1+*+*+*+%3F due to: No component found with scheme: quartz2 at org.apache.camel.util.ObjectHelper.wrapRuntimeCamelException(ObjectHelper.java:1830) ~[camel-core-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.spring.SpringCamelContext.start(SpringCamelContext.java:136) ~[camel-spring-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.apache.camel.spring.SpringCamelContext.onApplicationEvent(SpringCamelContext.java:174) ~[camel-spring-2.21.0.fuse-730054.jar!/:2.21.0.fuse-730054] at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:393) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:347) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:883) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.finishRefresh(EmbeddedWebApplicationContext.java:144) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at io.syndesis.example.Application.main(Application.java:13) [classes!/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_191] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_191] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_191] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_191] at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.Launcher.launch(Launcher.java:87) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.Launcher.launch(Launcher.java:50) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.PropertiesLauncher.main(PropertiesLauncher.java:595) [project-0.1-SNAPSHOT.jar:na] ```  </body>
		<created>2019-03-04 14:09:50</created>
		<closed>2019-03-06 11:36:33</closed>
	</bug>
	<bug>
		<id>4731</id>
		<title>Unable to delete integration</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  I created an integration named `webhook-to-todo` and when I tried to delete it I got an error:  `must match \"^[A-Za-z_][A-Za-z0-9_]*$\"`  ```http DELETE /api/v1/integrations/i-L_7TlnQe8rqSJX5wKkKz HTTP/1.1 Host: syndesis.192.168.42.75.nip.io Connection: keep-alive Accept: application/json, text/plain, */* Origin: https://syndesis.192.168.42.75.nip.io SYNDESIS-XSRF-TOKEN: awesome User-Agent: Mozilla/5.0 (X11; Fedora; Fedora; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36 Referer: https://syndesis.192.168.42.75.nip.io/integrations Accept-Encoding: gzip, deflate, br Accept-Language: en-US,en;q=0.9 Cookie: _oauth_proxy=...  HTTP/1.1 400 Bad Request Cache-Control: no-cache, no-store, max-age=0, must-revalidate, proxy-revalidate, s-maxage=0 Content-Length: 91 Content-Type: application/json Date: Mon, 04 Mar 2019 13:03:19 GMT Gap-Auth: developer@cluster.local Gap-Upstream-Address: syndesis-server Strict-Transport-Security: max-age=31536000 ; includeSubDomains Syndesis-Xsrf-Token: awesome X-Application-Context: application X-Content-Type-Options: nosniff X-Frame-Options: DENY X-Xss-Protection: 1; mode=block  [{"error":"Pattern","message":"must match \"^[A-Za-z_][A-Za-z0-9_]*$\"","property":"name"}] ```</body>
		<created>2019-03-04 13:06:15</created>
		<closed>2019-03-04 13:27:17</closed>
	</bug>
	<bug>
		<id>4728</id>
		<title>"2nd step and the steps after" after Split step doesn't perform</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description. Let's have an integration: **DB select -&gt; Split -&gt; DB insert1** -&gt; DB insert2 -&gt; ... -&gt; final step  Only the **bold** steps perform (the first step after Split step is the last one that happens)  [2 steps after split-export.zip](https://github.com/syndesisio/syndesis/files/2925854/2.steps.after.split-export.zip)  1. suppose you have exactly any 3 records in CONTACT table  2. run the integration 3. Look at TODO table. If you can't see every 10 seconds new records as follows, it's wrong (if I get how Split step works):  **task column** first task first task first task final task final task final task</body>
		<created>2019-03-04 10:15:43</created>
		<closed>2019-03-05 15:17:23</closed>
	</bug>
	<bug>
		<id>4722</id>
		<title>Export unexist integration via Public API returns 500 Internal Server Error</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When I call public API for exporting integration which doesn't exist ``` /api/v1/public/integrations/unexistIntegration/export.zip -o export.zip ``` it returns 500 Internal Server Error and in the Server pod is: ``` 2019-03-01 17:59:18.799 ERROR [-,6e14aaae7ca3f580,6e14aaae7ca3f580,false] 1 --- [  XNIO-3 task-6] .s.e.v.h.e.SyndesisServerExceptionMapper : Internal Server Exception. No integrations to export javax.ws.rs.WebApplicationException: No integrations to export at io.syndesis.server.endpoint.v1.handler.external.PublicApiHandler.exportResources(PublicApiHandler.java:350) ~[server-endpoint-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_151] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_151] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151] at org.jboss.resteasy.core.MethodInjectorImpl.invoke(MethodInjectorImpl.java:140) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.internalInvokeOnTarget(ResourceMethodInvoker.java:509) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTargetAfterFilter(ResourceMethodInvoker.java:399) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.lambda$invokeOnTarget$0(ResourceMethodInvoker.java:363) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:358) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTarget(ResourceMethodInvoker.java:365) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:337) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:310) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:443) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.lambda$invoke$4(SynchronousDispatcher.java:233) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.lambda$preprocess$0(SynchronousDispatcher.java:139) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:358) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.preprocess(SynchronousDispatcher.java:142) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:219) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.ServletContainerDispatcher.service(ServletContainerDispatcher.java:227) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:56) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:51) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) ~[javax.servlet-api-3.1.0.jar!/:3.1.0] at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] ``` In my POV, it should return status 404 or message as response that integration doesn't exist.  </body>
		<created>2019-03-01 18:05:44</created>
		<closed>2019-03-04 13:50:26</closed>
	</bug>
	<bug>
		<id>4721</id>
		<title>State endpoint in Public API throws NullPointerException</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When I call Public API on `/api/v1/public/integrations/timer-to-log/state`, it returns 500 Internal Server Error and in the Server pod log is: ``` 019-03-01 17:49:42.204 ERROR [-,9d80ce0f284bacf4,9d80ce0f284bacf4,false] 1 --- [ XNIO-3 task-10] .s.e.v.h.e.SyndesisServerExceptionMapper : Internal Server Exception. null java.lang.NullPointerException: null at io.syndesis.server.endpoint.monitoring.MonitoringProviderImpl.getIntegrationStateDetails(MonitoringProviderImpl.java:45) ~[server-endpoint-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at io.syndesis.server.endpoint.v1.handler.external.PublicApiHandler.getIntegrationState(PublicApiHandler.java:468) ~[server-endpoint-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_151] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_151] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151] at org.jboss.resteasy.core.MethodInjectorImpl.invoke(MethodInjectorImpl.java:140) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.internalInvokeOnTarget(ResourceMethodInvoker.java:509) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTargetAfterFilter(ResourceMethodInvoker.java:399) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.lambda$invokeOnTarget$0(ResourceMethodInvoker.java:363) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:358) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTarget(ResourceMethodInvoker.java:365) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:337) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:310) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:443) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.lambda$invoke$4(SynchronousDispatcher.java:233) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.lambda$preprocess$0(SynchronousDispatcher.java:139) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:358) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.preprocess(SynchronousDispatcher.java:142) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:219) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.ServletContainerDispatcher.service(ServletContainerDispatcher.java:227) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:56) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:51) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) ~[javax.servlet-api-3.1.0.jar!/:3.1.0] at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:111) ~[spring-boot-actuator-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.authentication.preauth.AbstractPreAuthenticatedProcessingFilter.doFilter(AbstractPreAuthenticatedProcessingFilter.java:121) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.csrf.CsrfFilter.doFilterInternal(CsrfFilter.java:100) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:66) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.cloud.sleuth.instrument.web.TraceFilter.doFilter(TraceFilter.java:186) ~[spring-cloud-sleuth-core-1.2.6.RELEASE.jar!/:1.2.6.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.micrometer.spring.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:106) ~[micrometer-spring-legacy-1.1.2.jar!/:1.1.2] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:103) ~[spring-boot-actuator-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:65) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:132) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.server.Connectors.executeRootHandler(Connectors.java:336) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_151] at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_151] ``` </body>
		<created>2019-03-01 17:56:07</created>
		<closed>2019-03-04 13:51:16</closed>
	</bug>
	<bug>
		<id>4717</id>
		<title>Problem with privileges during installation</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I have a clean instance of minishift (full-reset) ``` syndesis minishift --full-reset --install --project syndesis --openshift-version 3.11.0 ``` Installation of Syndesis takes so long (20 minutes for me). During the installation, the pods are been created, terminated and again created. it is repeated several times. This error is repeated in the operator log: ``` {"level":"error","ts":1551456915.553912,"logger":"kubebuilder.controller","msg":"Reconciler error","controller":"syndesis-controller","request":"syndesis/app","error":"roles.rbac.authorization.k8s.io \"camel-k\" is forbidden: attempt to grant extra privileges: [{[*] [camel.apache.org] [*] [] []}] user=&amp;{system:serviceaccount:syndesis:syndesis-operator 8f4e4614-3c3c-11e9-8e73-5254003010a8 [system:serviceaccounts system:serviceaccounts:syndesis system:authenticated] map[]} ownerrules=[{[get] [ user.openshift.io] [users] [~] []} {[list] [ project.openshift.io] [projectrequests] [] []} {[get list] [ authorization.openshift.io] [clusterroles] [] []} {[get list watch] [rbac.authorization.k8s.io] [clusterroles] [] []} {[get list] [storage.k8s.io] [storageclasses] [] []} {[list watch] [ project.openshift.io] [projects] [] []} {[create] [ authorization.openshift.io] [selfsubjectrulesreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews] [] []} {[get] [] [] [] [/healthz /healthz/*]} {[get] [] [] [] [/version /version/* /api /api/* /apis /apis/* /oapi /oapi/* /openapi/v2 /swaggerapi /swaggerapi/* /swagger.json /swagger-2.0.0.pb-v1 /osapi /osapi/ /.well-known /.well-known/* /]} {[create] [ authorization.openshift.io] [selfsubjectrulesreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews] [] []} {[create] [authorization.k8s.io] [selfsubjectaccessreviews selfsubjectrulesreviews] [] []} {[create] [ build.openshift.io] [builds/docker builds/optimizeddocker] [] []} {[create] [ build.openshift.io] [builds/jenkinspipeline] [] []} {[create] [ build.openshift.io] [builds/source] [] []} {[get] [] [] [] [/api /api/* /apis /apis/* /healthz /openapi /openapi/* /swagger-2.0.0.pb-v1 /swagger.json /swaggerapi /swaggerapi/* /version /version/]} {[delete] [ oauth.openshift.io] [oauthaccesstokens oauthauthorizetokens] [] []} {[get] [] [] [] [/version /version/* /api /api/* /apis /apis/* /oapi /oapi/* /openapi/v2 /swaggerapi /swaggerapi/* /swagger.json /swagger-2.0.0.pb-v1 /osapi /osapi/ /.well-known /.well-known/* /]} {[impersonate] [authentication.k8s.io] [userextras/scopes.authorization.openshift.io] [] []} {[create get] [ build.openshift.io] [buildconfigs/webhooks] [] []} {[create delete deletecollection get list patch update watch] [] [pods pods/attach pods/exec pods/portforward pods/proxy] [] []} {[create delete deletecollection get list patch update watch] [] [configmaps endpoints persistentvolumeclaims replicationcontrollers replicationcontrollers/scale secrets serviceaccounts services services/proxy] [] []} {[get list watch] [] [bindings events limitranges namespaces/status pods/log pods/status replicationcontrollers/status resourcequotas resourcequotas/status] [] []} {[get list watch] [] [namespaces] [] []} {[impersonate] [] [serviceaccounts] [] []} {[create delete deletecollection get list patch update watch] [apps] [daemonsets deployments deployments/rollback deployments/scale replicasets replicasets/scale statefulsets statefulsets/scale] [] []} {[create delete deletecollection get list patch update watch] [autoscaling] [horizontalpodautoscalers] [] []} {[create delete deletecollection get list patch update watch] [batch] [cronjobs jobs] [] []} {[create delete deletecollection get list patch update watch] [extensions] [daemonsets deployments deployments/rollback deployments/scale ingresses networkpolicies replicasets replicasets/scale replicationcontrollers/scale] [] []} {[create delete deletecollection get list patch update watch] [policy] [poddisruptionbudgets] [] []} {[create delete deletecollection get list patch update watch] [networking.k8s.io] [networkpolicies] [] []} {[create delete deletecollection get list patch update watch] [ build.openshift.io] [buildconfigs buildconfigs/webhooks builds] [] []} {[get list watch] [ build.openshift.io] [builds/log] [] []} {[create] [ build.openshift.io] [buildconfigs/instantiate buildconfigs/instantiatebinary builds/clone] [] []} {[update] [ build.openshift.io] [builds/details] [] []} {[edit view] [build.openshift.io] [jenkins] [] []} {[create delete deletecollection get list patch update watch] [ apps.openshift.io] [deploymentconfigs deploymentconfigs/scale] [] []} {[create] [ apps.openshift.io] [deploymentconfigrollbacks deploymentconfigs/instantiate deploymentconfigs/rollback] [] []} {[get list watch] [ apps.openshift.io] [deploymentconfigs/log deploymentconfigs/status] [] []} {[create delete deletecollection get list patch update watch] [ image.openshift.io] [imagestreamimages imagestreammappings imagestreams imagestreams/secrets imagestreamtags] [] []} {[get list watch] [ image.openshift.io] [imagestreams/status] [] []} {[get update] [ image.openshift.io] [imagestreams/layers] [] []} {[create] [ image.openshift.io] [imagestreamimports] [] []} {[get] [ project.openshift.io] [projects] [] []} {[get list watch] [ quota.openshift.io] [appliedclusterresourcequotas] [] []} {[create delete deletecollection get list patch update watch] [ route.openshift.io] [routes] [] []} {[create] [ route.openshift.io] [routes/custom-host] [] []} {[get list watch] [ route.openshift.io] [routes/status] [] []} {[create delete deletecollection get list patch update watch] [ template.openshift.io] [processedtemplates templateconfigs templateinstances templates] [] []} {[create delete deletecollection get list patch update watch] [extensions networking.k8s.io] [networkpolicies] [] []} {[create delete deletecollection get list patch update watch] [ build.openshift.io] [buildlogs] [] []} {[get list watch] [] [resourcequotausages] [] []} {[get list create update delete deletecollection watch] [syndesis.io] [* */finalizers] [] []} {[get list create update delete deletecollection watch] [] [pods services endpoints persistentvolumeclaims configmaps secrets serviceaccounts] [] []} {[get list] [] [events] [] []} {[get list create update delete deletecollection watch] [rbac.authorization.k8s.io] [roles rolebindings] [] []} {[get list create update delete deletecollection watch] [template.openshift.io] [processedtemplates] [] []} {[get list create update delete deletecollection watch] [image.openshift.io] [imagestreams] [] []} {[get list create update delete deletecollection watch] [apps.openshift.io] [deploymentconfigs] [] []} {[get list create update delete deletecollection watch] [build.openshift.io] [buildconfigs] [] []} {[get list create update delete deletecollection watch] [authorization.openshift.io] [rolebindings] [] []} {[get list create update delete deletecollection watch] [route.openshift.io] [routes routes/custom-host] [] []} {[get list create update delete deletecollection watch] [camel.apache.org] [*] [] []} {[get list create update delete deletecollection watch] [monitoring.coreos.com] [alertmanagers prometheuses servicemonitors prometheusrules] [] []} {[get list create update delete deletecollection watch] [integreatly.org] [grafanadashboards] [] []} {[get list watch] [] [configmaps endpoints persistentvolumeclaims pods replicationcontrollers replicationcontrollers/scale serviceaccounts services] [] []} {[get list watch] [] [bindings events limitranges namespaces/status pods/log pods/status replicationcontrollers/status resourcequotas resourcequotas/status] [] []} {[get list watch] [] [namespaces] [] []} {[get list watch] [apps] [daemonsets deployments deployments/scale replicasets replicasets/scale statefulsets statefulsets/scale] [] []} {[get list watch] [autoscaling] [horizontalpodautoscalers] [] []} {[get list watch] [batch] [cronjobs jobs] [] []} {[get list watch] [extensions] [daemonsets deployments deployments/scale ingresses networkpolicies replicasets replicasets/scale replicationcontrollers/scale] [] []} {[get list watch] [policy] [poddisruptionbudgets] [] []} {[get list watch] [networking.k8s.io] [networkpolicies] [] []} {[get list watch] [ build.openshift.io] [buildconfigs buildconfigs/webhooks builds] [] []} {[get list watch] [ build.openshift.io] [builds/log] [] []} {[view] [build.openshift.io] [jenkins] [] []} {[get list watch] [ apps.openshift.io] [deploymentconfigs deploymentconfigs/scale] [] []} {[get list watch] [ apps.openshift.io] [deploymentconfigs/log deploymentconfigs/status] [] []} {[get list watch] [ image.openshift.io] [imagestreamimages imagestreammappings imagestreams imagestreamtags] [] []} {[get list watch] [ image.openshift.io] [imagestreams/status] [] []} {[get] [ project.openshift.io] [projects] [] []} {[get list watch] [ quota.openshift.io] [appliedclusterresourcequotas] [] []} {[get list watch] [ route.openshift.io] [routes] [] []} {[get list watch] [ route.openshift.io] [routes/status] [] []} {[get list watch] [ template.openshift.io] [processedtemplates templateconfigs templateinstances templates] [] []} {[get list watch] [ build.openshift.io] [buildlogs] [] []} {[get list watch] [] [resourcequotausages] [] []} {[get] [ image.openshift.io] [imagestreams/layers] [] []}] ruleResolutionErrors=[]","stacktrace":"github.com/syndesisio/syndesis/install/operator/vendor/github.com/go-logr/zapr.(*zapLogger).Error\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/github.com/go-logr/zapr/zapr.go:128\ngithub.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:215\ngithub.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func1\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:158\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.JitterUntil.func1\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:133\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:134\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.Until\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:88"} ``` After a lot of time (20 minutes for me) the Syndesis is installed. In the server log is this exception: ``` 2019-03-01 16:36:32.731 ERROR [-,,,] 1 --- [ning]: pollPods] i.s.s.l.j.c.ActivityTrackingController   : Unexpected Error occurred. io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: GET at: https://openshift.default.svc/api/v1/namespaces/syndesis/pods?labelSelector=syndesis.io/component%3Dintegration . Message: Forbidden!Configured service account doesn't have access. Service account may have been revoked. pods is forbidden: User "system:serviceaccount:syndesis:syndesis-server" cannot list pods in the namespace "syndesis": no RBAC policy matched. at io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:470) ~[kubernetes-client-3.1.4.fuse-710001.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:407) ~[kubernetes-client-3.1.4.fuse-710001.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:379) ~[kubernetes-client-3.1.4.fuse-710001.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:343) ~[kubernetes-client-3.1.4.fuse-710001.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:327) ~[kubernetes-client-3.1.4.fuse-710001.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.BaseOperation.list(BaseOperation.java:605) ~[kubernetes-client-3.1.4.fuse-710001.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.BaseOperation.list(BaseOperation.java:70) ~[kubernetes-client-3.1.4.fuse-710001.jar!/:na] at io.syndesis.server.logging.jsondb.controller.ActivityTrackingController.listPods(ActivityTrackingController.java:327) ~[server-logging-jsondb-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at io.syndesis.server.logging.jsondb.controller.ActivityTrackingController.pollPods(ActivityTrackingController.java:271) ~[server-logging-jsondb-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_151] at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) ~[na:1.8.0_151] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) ~[na:1.8.0_151] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) ~[na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_151] at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_151]  ``` However, after some time (+- 16minutes), the Syndesis is reinstalled again. So all pods except syndesis-operator are deleted and created again.</body>
		<created>2019-03-01 16:38:21</created>
		<closed>2019-03-04 21:59:14</closed>
	</bug>
	<bug>
		<id>4710</id>
		<title>Adding multiple aggregate steps after split</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Users can add multiple aggregate steps after a single split step which should not be allowed. But we can have multiple split steps in an integration each of them should be allowed to have a corresponding aggregate.  The rule should be that each split is just having a single aggregate. </body>
		<created>2019-03-01 08:41:46</created>
		<closed>2019-03-05 11:12:26</closed>
	</bug>
	<bug>
		<id>4707</id>
		<title>bug: Import endpoint in public API throws a NPE</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  When importing integrations that were exported using the all query param, the `import` endpoint throws a NullPointerException when imported integrations do have the tag being imported to record the `importedAt` tag property.   ``` java.lang.NullPointerException: null at io.syndesis.server.endpoint.v1.handler.external.PublicApiHandler.updateCDEnvironment(PublicApiHandler.java:560) ~[server-endpoint-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at io.syndesis.server.endpoint.v1.handler.external.PublicApiHandler.lambda$updateCDEnvironments$15(PublicApiHandler.java:554) ~[server-endpoint-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at java.util.ArrayList.forEach(ArrayList.java:1255) ~[na:1.8.0_151] at io.syndesis.server.endpoint.v1.handler.external.PublicApiHandler.updateCDEnvironments(PublicApiHandler.java:554) ~[server-endpoint-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at io.syndesis.server.endpoint.v1.handler.external.PublicApiHandler.importResources(PublicApiHandler.java:369) ~[server-endpoint-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_151] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_151] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151] ```</body>
		<created>2019-03-01 03:00:50</created>
		<closed>2019-03-01 14:54:40</closed>
	</bug>
	<bug>
		<id>4703</id>
		<title>Styling issue</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; There are still issue after the masthead upgrade. See screenshot. There is a rendering issue with some symbol and the padding seems off, with the text too near to the line above.    ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlisting the acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![screenshot from 2019-02-28 18-18-49](https://user-images.githubusercontent.com/1520602/53585065-5e485a80-3b85-11e9-8edf-8cd6e02ef7ef.png)  ## Request and Response Data &lt;!-- Many issues involve both the UI and its backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2019-02-28 17:20:34</created>
		<closed>2019-02-28 17:22:02</closed>
	</bug>
	<bug>
		<id>4702</id>
		<title>Public API proxy template doesn't set permission for service account</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I have a clean minishift instance with syndesis: `syndesis minishift --full-reset --install --project syndesis --openshift-version 3.11.0`  I create template for public [endpoint](https://github.com/syndesisio/syndesis/tree/master/install#create-template-for-public-api-endpoint) `oc create -f install/support/syndesis-public-oauth-proxy.yml`  After that, I create a new app ``` oc new-app --template=syndesis-public-oauthproxy \     -p PUBLIC_API_ROUTE_HOSTNAME= public-syndesis.192.168.42.4.nip.io \     -p OPENSHIFT_PROJECT=$(oc project -q) \     -p OPENSHIFT_OAUTH_CLIENT_SECRET=$(oc sa get-token syndesis-oauth-client) \     -p SAR_PROJECT=$(oc project -q) ``` The output looks good: ``` --&gt; Deploying template "syndesis/syndesis-public-oauthproxy" to project syndesis       syndesis-public-oauthproxy      ---------      Syndesis Public API is deployed to public-syndesis.192.168.42.4.nip.io.       * With parameters:         * PUBLIC_API_ROUTE_HOSTNAME=public-syndesis.192.168.42.4.nip.io         * OpenShift project to deploy into=syndesis         * OpenShift project to be used to authenticate the user against=syndesis         * OPENSHIFT_OAUTH_CLIENT_SECRET=&lt;TOKEN&gt;         * OAUTH_PROXY_TAG=v1.1.0         * Syndesis Image Registry=docker.io         * Image Stream Namespace=         * OAuth Cookie Secret=ENHr4n1W4DEnYOliL4LdCGXuu0WBkunj # generated  --&gt; Creating resources ...     serviceaccount "syndesis-public-oauthproxy" created     rolebinding.authorization.openshift.io "syndesis-public-oauthproxy:viewers" created     clusterrolebinding.authorization.openshift.io "syndesis-syndesis-auth-delegator" created     imagestream.image.openshift.io "syndesis-public-oauthproxy" created     service "syndesis-public-oauthproxy" created     route.route.openshift.io "syndesis-public-api" created     deploymentconfig.apps.openshift.io "syndesis-public-oauthproxy" created --&gt; Success     Access your application via route 'public-syndesis.192.168.42.4.nip.io'      Run 'oc status' to view your app. ``` But the syndesis-public-oauthproxy contains error in log: ``` unable to load OpenShift configuration: unable to retrieve authentication information for tokens: tokenreviews.authentication.k8s.io is forbidden: User "system:serviceaccount:syndesis:syndesis-public-oauthproxy" cannot create tokenreviews.authentication.k8s.io at the cluster scope: no RBAC policy matched ``` It is strange because the [delegator](https://github.com/syndesisio/syndesis/blob/master/install/support/syndesis-public-oauth-proxy.yml#L75) is successfully created according to log.  After add  permission manually ``` oc adm policy add-cluster-role-to-user system:auth-delegator system:serviceaccount:syndesis:syndesis-public-oauthproxy ``` the public-oauthproxy pod works.  For the reproducing this, it is necessary to have a fresh minishift instance. (--full-reset)</body>
		<created>2019-02-28 17:16:37</created>
		<closed>2019-03-11 13:07:30</closed>
	</bug>
	<bug>
		<id>4696</id>
		<title>Public API import endpoint throws an error</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Using the import endpoint in Syndesis public API causes an exception ``` Could not find message body reader for type: ...ImportFormDataInput... ``` This is caused by a missing RestEasy annotation `MultipartForm` on the import endpoint. </body>
		<created>2019-02-28 07:13:33</created>
		<closed>2019-03-01 14:54:17</closed>
	</bug>
	<bug>
		<id>4688</id>
		<title>Upgrade to 7.3. misses syndesis-db-metrics-config</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  When doing an upgrade, the upgrade pods hangs forever because the db-metrics exportert doesn't start. The reason is that it waits for a configmap syndesis-db-metrics-config, which is not present. The update scripts should add this missing CM when doing the update.  &lt;details&gt; &lt;summary&gt;Missing config map&lt;/summary&gt;  ``` oc get pods NAME                          READY     STATUS              RESTARTS   AGE syndesis-db-1-p2kwf           1/1       Running             0          1h syndesis-db-metrics-1-l8t6w   0/1       ContainerCreating   0          1h syndesis-meta-2-m799g         1/1       Running             0          1h syndesis-operator-2-wk6l7     1/1       Running             0          23m syndesis-prometheus-1-9xx5t   1/1       Running             0          1h syndesis-server-2-pw2v9       1/1       Running             0          1h syndesis-ui-2-hqldm           1/1       Running             0          1h syndesis-upgrade-latest       1/1       Running             0          1h todo-1-build                  0/1       Completed           0          3h todo-2-build                  0/1       Completed           0          1h  17:41  syndesis/syndesis   pr/revert-syndeses-renaming  oc describe pod syndesis-db-metrics-1-l8t6w Name:               syndesis-db-metrics-1-l8t6w Namespace:          myproject Priority:           0 PriorityClassName:  &lt;none&gt; Node:               localhost/192.168.64.69 Start Time:         Tue, 26 Feb 2019 15:13:00 +0100 Labels:             app=syndesis                     deployment=syndesis-db-metrics-1                     deploymentconfig=syndesis-db-metrics                     syndesis.io/app=syndesis                     syndesis.io/component=syndesis-db-metrics                     syndesis.io/type=infrastructure Annotations:        openshift.io/deployment-config.latest-version=1                     openshift.io/deployment-config.name=syndesis-db-metrics                     openshift.io/deployment.name=syndesis-db-metrics-1                     openshift.io/scc=restricted Status:             Pending IP: Controlled By:      ReplicationController/syndesis-db-metrics-1 Containers:   syndesis-db-metrics:     Container ID:     Image:          docker.io/wrouesnel/postgres_exporter@sha256:dd8051322ceb8995d3d7f116041a2116815e01e88232a90f635ebde8dcc4d3f4     Image ID:     Port:           9187/TCP     Host Port:      0/TCP     State:          Waiting       Reason:       ContainerCreating     Ready:          False     Restart Count:  0     Limits:       memory:  256Mi     Requests:       memory:   20Mi     Liveness:   http-get http://:9187/metrics delay=60s timeout=1s period=10s #success=1 #failure=5     Readiness:  http-get http://:9187/metrics delay=30s timeout=1s period=10s #success=1 #failure=5     Environment:       DATA_SOURCE_NAME:               postgresql://syndesis:rt1fQWr3w1XQcktX@syndesis-db:5432/syndesis?sslmode=disable       PG_EXPORTER_EXTEND_QUERY_PATH:  /etc/postgres/exporter/queries.yaml     Mounts:       /etc/postgres/exporter from syndesis-db-metrics-config (rw)       /var/run/secrets/kubernetes.io/serviceaccount from default-token-4667k (ro) Conditions:   Type              Status   Initialized       True   Ready             False   ContainersReady   False   PodScheduled      True Volumes:   syndesis-db-metrics-config:     Type:      ConfigMap (a volume populated by a ConfigMap)     Name:      syndesis-db-metrics-config     Optional:  false   default-token-4667k:     Type:        Secret (a volume populated by a Secret)     SecretName:  default-token-4667k     Optional:    false QoS Class:       Burstable Node-Selectors:  &lt;none&gt; Tolerations:     node.kubernetes.io/memory-pressure:NoSchedule Events:   Type     Reason       Age               From                Message   ----     ------       ----              ----                -------   Warning  FailedMount  1h (x31 over 2h)  kubelet, localhost  Unable to mount volumes for pod "syndesis-db-metrics-1-l8t6w_myproject(9f9e38b1-39d0-11e9-9b06-62d857d1f703)": timeout expired waiting for volumes to attach or mount for pod "myproject"/"syndesis-db-metrics-1-l8t6w". list of unmounted volumes=[syndesis-db-metrics-config]. list of unattached volumes=[syndesis-db-metrics-config default-token-4667k]   Warning  FailedMount  1h (x45 over 2h)  kubelet, localhost  MountVolume.SetUp failed for volume "syndesis-db-metrics-config" : configmaps "syndesis-db-metrics-config" not found ``` &lt;/details&gt;  @christophd would this something for you ? Should not be hard to fix, and is a good entry issue for getting to know the update process. // fyi @avano @heiko-braun  </body>
		<created>2019-02-26 18:28:35</created>
		<closed>2019-03-01 15:22:27</closed>
	</bug>
	<bug>
		<id>4684</id>
		<title>Google-sheets: unable to successfully refresh expired token </title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description After expiring acess token in integration I'm unable to reconnect from syndesis.  After clicking on "Reconnect" in google sheets connection created using oauth, I'm still getting in integration: ``` org.apache.camel.RuntimeCamelException: com.google.api.client.googleapis.json.GoogleJsonResponseException: 401 Unauthorized at org.apache.camel.component.google.sheets.GoogleSheetsProducer.doInvokeMethod(GoogleSheetsProducer.java:49) at org.apache.camel.util.component.AbstractApiProducer$1.run(AbstractApiProducer.java:86) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Caused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 401 Unauthorized at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146) at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1065) at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) at org.apache.camel.component.google.sheets.GoogleSheetsProducer.doInvokeMethod(GoogleSheetsProducer.java:47) ... 8 more  ```  ## Steps to reproduce  1. Create google-sheet connector using OAuth (from Settings page) 2. create simple ingegration where google-sheet is involved 3. After token expiration: stop integration  4. In Connection-&gt;Google Sheets click on reconnect, you get "Successfully authorized Syndesis's access" 5, Start integration again. Same exception in activities</body>
		<created>2019-02-26 16:15:24</created>
		<closed>2019-04-02 09:50:37</closed>
	</bug>
	<bug>
		<id>4683</id>
		<title>Uncheck tag in CI/CD dialog doesn't work</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  I have some tag (e.g. myTag) in first integration. I check this tag on second integration and save the dialog. When I want to uncheck the tag from the second integration, it doesn't work. When I open CI/CD dialog after unchecking, the tag is still checked.  When I click on Remove, the tag is unchecked.  ![output](https://user-images.githubusercontent.com/16251792/53419242-c78b6a80-39d9-11e9-8946-4a56c947b384.gif)  Step to reproduce: - create two simple integrations (e.g. timer -&gt; log ) - add some tag at first one - check this tag in second one and save - uncheck this tag in second one and save  </body>
		<created>2019-02-26 14:20:38</created>
		<closed>2019-03-07 14:05:57</closed>
	</bug>
	<bug>
		<id>4682</id>
		<title>ClassCastException when inserting static values to DB with a timer</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I want to add every minute the same todo task to the DB. So I created integration with 1-minute timer and Invoke SQL step with constant: ``` INSERT INTO TODO (task, completed) VALUES('syndesis1', 0) ``` ![image](https://user-images.githubusercontent.com/16251792/53413926-c0f6f600-39cd-11e9-8dd6-758880ac78f5.png)  Integration: [SimpleSyn1-export.zip](https://github.com/syndesisio/syndesis/files/2905578/SimpleSyn1-export.zip)  Every minute integration contains Error in the activity tab / integration pod log: ``` java.lang.ClassCastException: org.apache.camel.impl.DefaultMessage cannot be cast to java.util.Map at io.syndesis.connector.sql.common.JSONBeanUtil.toJSONBeans(JSONBeanUtil.java:175) at io.syndesis.connector.sql.customizer.SqlConnectorCustomizer.doAfterProducer(SqlConnectorCustomizer.java:60) at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at io.syndesis.integration.component.proxy.ComponentProxyProducer.process(ComponentProxyProducer.java:44) at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197) at org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79) at java.util.TimerThread.mainLoop(Timer.java:555) at java.util.TimerThread.run(Timer.java:505) ```  However, the values were successfully added to the DB. ![image](https://user-images.githubusercontent.com/16251792/53415262-14b70e80-39d1-11e9-96ab-1b88337c0b67.png)  Step to reproduced:  1. Import integration 2. Wait 3 minutes 3. In the Activity tab / integration log should be exception  4. However the data should be visible in todo app / sampledb</body>
		<created>2019-02-26 13:23:07</created>
		<closed>2019-03-08 14:51:38</closed>
	</bug>
	<bug>
		<id>4681</id>
		<title>[Deploy] Unable to deploy to dedicated OCP 3.10 with syndesises CRD</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  @rhuss @heiko-braun @tplevko more strange things here:  Installation from Roland's PR works on minishift with 3.10 version.  We also have an dedicated OCP cluster of version `3.10.45` and `3.10.101`:  ``` Server https://master.ignite-310.dos.fuse-qe.eng.rdu2.redhat.com:8443 openshift v3.10.45 kubernetes v1.10.0+b81c8f8 ```  ``` Server https://master.fusekle31.dos.fuse-qe.eng.rdu2.redhat.com:8443 openshift v3.10.101 kubernetes v1.10.0+b81c8f8 ```  Where I can't get it to work:  ``` {"level":"info","ts":1551182082.2748585,"logger":"cmd","msg":"Using template","template":"/conf/syndesis-template.yml"} {"level":"info","ts":1551182082.27491,"logger":"cmd","msg":"Go Version: go1.11"} {"level":"info","ts":1551182082.2749138,"logger":"cmd","msg":"Go OS/Arch: linux/amd64"} {"level":"info","ts":1551182082.2749166,"logger":"cmd","msg":"Version of operator-sdk: v0.5.0"} {"level":"info","ts":1551182082.2755861,"logger":"leader","msg":"Trying to become the leader."} {"level":"info","ts":1551182082.3557706,"logger":"leader","msg":"No pre-existing lock was found."} {"level":"info","ts":1551182082.3600082,"logger":"leader","msg":"Became the leader."} {"level":"info","ts":1551182082.4041228,"logger":"cmd","msg":"Registering Components."} {"level":"info","ts":1551182082.4063652,"logger":"kubebuilder.controller","msg":"Starting EventSource","controller":"syndesis-controller","source":"kind source: /, Kind="} {"level":"info","ts":1551182082.4076293,"logger":"cmd","msg":"Starting the Cmd."} {"level":"info","ts":1551182082.5079494,"logger":"kubebuilder.controller","msg":"Starting Controller","controller":"syndesis-controller"} {"level":"info","ts":1551182082.6081612,"logger":"kubebuilder.controller","msg":"Starting workers","controller":"syndesis-controller","worker count":1} {"level":"info","ts":1551182091.8083854,"logger":"controller","msg":"Reconciling Syndesis","Request.Namespace":"syndesis","Request.Name":"app"} {"level":"info","ts":1551182091.8084357,"logger":"controller","msg":"Running action","action":"*action.initializeAction"} {"level":"info","ts":1551182091.8222883,"logger":"action","msg":"Syndesis resource initialized","type":"initialize","name":"app","version":"latest"} {"level":"error","ts":1551182091.8242218,"logger":"controller","msg":"Error reconciling","action":"*action.initializeAction","phase":"","error":"the server could not find the requested resource (put syndesises.syndesis.io app)","stacktrace":"github.com/syndesisio/syndesis/install/operator/vendor/github.com/go-logr/zapr.(*zapLogger).Error\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/github.com/go-logr/zapr/zapr.go:128\ngithub.com/syndesisio/syndesis/install/operator/pkg/controller/syndesis.(*ReconcileSyndesis).Reconcile\n\t/go/src/github.com/syndesisio/syndesis/install/operator/pkg/controller/syndesis/syndesis_controller.go:119\ngithub.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:213\ngithub.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func1\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:158\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.JitterUntil.func1\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:133\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:134\ngithub.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait.Until\n\t/go/src/github.com/syndesisio/syndesis/install/operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:88"} ``` (that is btw the same problem I can see on minishift while doing upgrade from 7.2 to 7.3 - https://github.com/syndesisio/syndesis/pull/4659#issuecomment-466366602)  In all cases here are the steps used:  ``` checkout Roland's PR locally ./tools/bin/syndesis install --setup --local ./tools/bin/syndesis install --project syndesis -y --test-support --local ```   </body>
		<created>2019-02-26 12:16:05</created>
		<closed>2019-02-27 07:48:33</closed>
	</bug>
	<bug>
		<id>4680</id>
		<title>bad text positioning in customizations main screen</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem When opening the "Customizations" screen of Syndesis I experience a bad text positioning. (see attached screenshot)  ## Expected behavior The text is positioned without any spacing atm. There should be some spacing between the text and the upper and left.  ## Screenshot ![bildschirmfoto von 2019-02-26 12-42-06](https://user-images.githubusercontent.com/435853/53410501-4aa1c600-39c4-11e9-86ce-ff7526edd79a.png)  ## Request and Response Data &lt;!-- Many issues involve both the UI and its backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; </body>
		<created>2019-02-26 11:45:30</created>
		<closed>2019-06-05 17:18:40</closed>
	</bug>
	<bug>
		<id>4676</id>
		<title>OOM Error in TODO pod</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ x] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  The following OOM error has occurred several times when Syndesis is provisioned. I am using the Fuse Online 7.2 release to provision. https://gist.github.com/jbride/7164cb34311c009ea1d350f75c4788b3</body>
		<created>2019-02-26 05:04:17</created>
		<closed>2019-03-05 09:41:43</closed>
	</bug>
	<bug>
		<id>4674</id>
		<title>Move postgres exporter to syndesis-db pod</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Having the postgres prometheus exporter as a sidecar is a good practice. As part of the move, change the `readinessProve` and `livenessProbe` to tcp. This will solve https://github.com/syndesisio/syndesis/issues/4652 and https://github.com/syndesisio/syndesis/issues/4410.</body>
		<created>2019-02-25 14:15:12</created>
		<closed>2019-03-12 13:10:10</closed>
	</bug>
	<bug>
		<id>4672</id>
		<title>google-sheets: spreadsheet properties data shape should contain collection of sheets instead of single sheet object</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Currently I can't get properties of all sheets of spreadsheet, only the first one. I believe Spreadsheet properties data shape should contain collection of sheets instead of single sheet:  ![screenshot_20190225_124751](https://user-images.githubusercontent.com/6814482/53335464-d7348180-38fb-11e9-8daa-677511bd3c92.png)  This spreadsheet has 5 sheets but in messasge body is only one:  ``` Body: [[GoogleSpreadsheet [spreadsheetId=1_OLTcj_y8NwST9KHhg8etB10xr6t3TrzaFXwW2dhpXw, title=Test-Data, url=https://docs.google.com/spreadsheets/d/1_OLTcj_y8NwST9KHhg8etB10xr6t3TrzaFXwW2dhpXw/edit, sheet=GoogleSheet [sheet=0, index=0, title=Sheet1]]]] ```</body>
		<created>2019-02-25 11:56:22</created>
		<closed>2019-03-12 14:26:56</closed>
	</bug>
	<bug>
		<id>4668</id>
		<title>SyndesisHeaderFilter not filtering `Host` header</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  I think this used to work, or it might not have ever worked. If we create a WebHook to API client integration the `Host` header from the HTTP request to the WebHook will be passed to API service. On OpenShift this usually results with a `503` HTTP status.  Most likely the same happens with API provider to API client integrations, but I haven't tested it.  Ref #4102   </body>
		<created>2019-02-22 15:11:47</created>
		<closed>2019-02-27 08:41:48</closed>
	</bug>
	<bug>
		<id>4664</id>
		<title>google-sheets: add chart step: unable to specify target sheet,  new is always created</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description   "Add chart" step in google sheets connector is always creating new sheet. If sheetID is specified in datamapper then following exception is thrown:  ` org.apache.camel.RuntimeCamelException: com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request {   "code" : 400,   "errors" : [ {     "domain" : "global",     "message" : "Invalid requests[0].addChart: Cannot add chart to new sheet with ID: 545637411, a sheet with that ID already exists.",     "reason" : "badRequest"   } ],   "message" : "Invalid requests[0].addChart: Cannot add chart to new sheet with ID: 545637411, a sheet with that ID already exists.",   "status" : "INVALID_ARGUMENT" } at org.apache.camel.component.google.sheets.GoogleSheetsProducer.doInvokeMethod(GoogleSheetsProducer.java:49) at org.apache.camel.util.component.AbstractApiProducer$1.run(AbstractApiProducer.java:86) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Caused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request {   "code" : 400,   "errors" : [ {     "domain" : "global",     "message" : "Invalid requests[0].addChart: Cannot add chart to new sheet with ID: 545637411, a sheet with that ID already exists.",     "reason" : "badRequest"   } ],   "message" : "Invalid requests[0].addChart: Cannot add chart to new sheet with ID: 545637411, a sheet with that ID already exists.",   "status" : "INVALID_ARGUMENT" } at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146) at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1065) at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) at org.apache.camel.component.google.sheets.GoogleSheetsProducer.doInvokeMethod(GoogleSheetsProducer.java:47) ... 8 more ` </body>
		<created>2019-02-22 12:44:10</created>
		<closed>2019-03-20 13:51:16</closed>
	</bug>
	<bug>
		<id>4654</id>
		<title>Added empty string as CI/CD tag causes StringIndexOutOfBoundsException</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When I add empty string as a tag in the CI/CD dialog, on the server shows StringIndexOutOfBoundsException. After that, syndesis doesn't work. Log: [syndesis-server-1-5njvb.log](https://github.com/syndesisio/syndesis/files/2889377/syndesis-server-1-5njvb.log)  After redeploying only syndesis-server, the exception is still there. Redeploy log: [syndesis-server-2-f7b9n.log](https://github.com/syndesisio/syndesis/files/2889409/syndesis-server-2-f7b9n.log)   </body>
		<created>2019-02-21 13:23:36</created>
		<closed>2019-03-04 15:13:12</closed>
	</bug>
	<bug>
		<id>4652</id>
		<title>Syndesis-db-metrics doesn't work when syndesis-db is down</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I wanted to try [FuseOnlineDatabaseInstanceDown]( https://github.com/jamesnetherton/syndesis/blob/ec10dc4ec4ceb5bf90dd84e07fc7fd6c3ab9ddfe/doc/managing_environments/topics/alerting_sop.adoc#fuseonlinedatabaseinstancedown) alert from https://github.com/syndesisio/syndesis/issues/4151 For Grafana, Prometheus and AlertManager, I am using https://github.com/integr8ly/application-monitoring-operator.   When I scale syndesis-db to 0 due to simulate database down state for alerting, the OpenShift set syndesis-db-metrics as Unhealthy and pod as Not Ready. This causes that syndeis-db-metrics is set as DOWN in the Prometheus Targets.</body>
		<created>2019-02-21 12:10:04</created>
		<closed>2019-03-05 15:18:29</closed>
	</bug>
	<bug>
		<id>4631</id>
		<title>Google-sheet connection can't handle (unsplitted) result from another spreadsheet</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I have simple integration (from google-sheet (split results: no) -&gt; DM -&gt; google-sheet:append) that should copy data between spreadsheets. However only 1 row is copied.  Exchange body  from first sheet:  ``` [[{"A":"policyID","B":"statecode","C":"county","D":"eq_site_limit","E":"hu_site_limit","spreadsheetId":"1_OLTcj_y8NwST9KHhg8etB10xr6t3TrzaFXwW2dhpXw"}, {"A":"119736","B":"FL","C":"CLAY COUNTY","D":"498960","E":"498960","spreadsheetId":"1_OLTcj_y8NwST9KHhg8etB10xr6t3TrzaFXwW2dhpXw"}, {"A":"448094","B":"FL","C":"CLAY COUNTY","D":"1322376.3","E":"1322376.3","spreadsheetId":"1_OLTcj_y8NwST9KHhg8etB10xr6t3TrzaFXwW2dhpXw"}, {"A":"206893","B":"FL","C":"CLAY COUNTY","D":"190724.4","E":"190724.4","spreadsheetId":"1_OLTcj_y8NwST9KHhg8etB10xr6t3TrzaFXwW2dhpXw"}, {"A":"333743","B":"FL","C":"CLAY COUNTY","D":"0","E":"79520.76","spreadsheetId":"1_OLTcj_y8NwST9KHhg8etB10xr6t3TrzaFXwW2dhpXw"}, {"A":"172534","B":"FL","C":"CLAY COUNTY","D":"0","E":"254281.5","spreadsheetId":"1_OLTcj_y8NwST9KHhg8etB10xr6t3TrzaFXwW2dhpXw"}, {"A":"785275","B":"FL","C":"CLAY COUNTY","D":"0","E":"515035.62","spreadsheetId":"1_OLTcj_y8NwST9KHhg8etB10xr6t3TrzaFXwW2dhpXw"}, {"A":"995932","B":"FL","C":"CLAY COUNTY","D":"0","E":"19260000","spreadsheetId":"1_OLTcj_y8NwST9KHhg8etB10xr6t3TrzaFXwW2dhpXw"}, {"A":"223488","B":"FL","C":"CLAY COUNTY","D":"328500","E":"328500","spreadsheetId":"1_OLTcj_y8NwST9KHhg8etB10xr6t3TrzaFXwW2dhpXw"}, {"A":"433512","B":"FL","C":"CLAY COUNTY","D":"315000","E":"315000","spreadsheetId":"1_OLTcj_y8NwST9KHhg8etB10xr6t3TrzaFXwW2dhpXw"}, {"A":"142071","B":"FL","C":"CLAY COUNTY","D":"705600","E":"705600","spreadsheetId":"1_OLTcj_y8NwST9KHhg8etB10xr6t3TrzaFXwW2dhpXw"}, {"A":"253816","B":"FL","C":"CLAY COUNTY","D":"831498.3","E":"831498.3","spreadsheetId":"1_OLTcj_y8NwST9KHhg8etB10xr6t3TrzaFXwW2dhpXw"}, {"A":"894922","B":"FL","C":"CLAY COUNTY","D":"0","E":"24059.09","spreadsheetId":"1_OLTcj_y8NwST9KHhg8etB10xr6t3TrzaFXwW2dhpXw"}, {"A":"422834","B":"FL","C":"CLAY COUNTY","D":"0","E":"48115.94","spreadsheetId":"1_OLTcj_y8NwST9KHhg8etB10xr6t3TrzaFXwW2dhpXw"}, {"A":"582721","B":"FL","C":"CLAY COUNTY","D":"0","E":"28869.12","spreadsheetId":"1_OLTcj_y8NwST9KHhg8etB10xr6t3TrzaFXwW2dhpXw"}, {"A":"842700","B":"FL","C":"CLAY COUNTY","D":"0","E":"56135.64","spreadsheetId":"1_OLTcj_y8NwST9KHhg8etB10xr6t3TrzaFXwW2dhpXw"}, {"A":"874333","B":"FL","C":"CLAY COUNTY","D":"0","E":"48115.94","spreadsheetId":"1_OLTcj_y8NwST9KHhg8etB10xr6t3TrzaFXwW2dhpXw"},... ``` body before append to spreadsheet: ``` Body: [[{"A":"policyID","B":"statecode","C":"county","D":"eq_site_limit","E":"hu_site_limit"}]]  ``` Mapping: ![screenshot_20190219_135841](https://user-images.githubusercontent.com/6814482/53018838-a794fd80-3453-11e9-847a-4cb1e9626082.png) </body>
		<created>2019-02-19 13:35:59</created>
		<closed>2019-03-05 10:49:57</closed>
	</bug>
	<bug>
		<id>4629</id>
		<title>Unable to use basic filter with collection (was: Inconsistent behavior with SQL connector and message split)</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  I have following integration:  ``` 1. SQL - Periodic invocation - Select * from contact 2. AMQ - Publish messages to some queue ```  In this scenario, the list from SQL connector is automatically split into multiple messages for some reason even when I didn't specify the `split` step. So when I have 2 contacts in the database, I receive 2 messages in the queue.  Now I want to add a basic filter to the integration - since the split magic is being done, I might not need the explicit "split" step, so I create:  ``` 1. SQL - Periodic invocation - Select * from contact 2. Basic filter - last_name contains something (now I know something is wrong because I don't have the autocomplete for the field) 3. AMQ - Publish messages to some queue ```    Obviously, the integration fails with:  ``` org.apache.camel.spring.boot.CamelSpringBootInitializationException: java.lang.IllegalArgumentException: java.lang.IllegalStateException: No step properties defined for rule filter step at org.apache.camel.spring.boot.RoutesCollector.onApplicationEvent(RoutesCollector.java:250) ~[camel-spring-boot-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.spring.boot.RoutesCollector.onApplicationEvent(RoutesCollector.java:57) ~[camel-spring-boot-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:393) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:347) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:883) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.finishRefresh(EmbeddedWebApplicationContext.java:144) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at io.syndesis.example.Application.main(Application.java:13) [classes!/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_191] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_191] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_191] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_191] at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.Launcher.launch(Launcher.java:87) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.Launcher.launch(Launcher.java:50) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.PropertiesLauncher.main(PropertiesLauncher.java:595) [project-0.1-SNAPSHOT.jar:na] Caused by: java.lang.IllegalArgumentException: java.lang.IllegalStateException: No step properties defined for rule filter step at io.syndesis.integration.runtime.sb.IntegrationRuntimeAutoConfiguration$1.beforeApplicationStart(IntegrationRuntimeAutoConfiguration.java:94) ~[integration-runtime-springboot-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at org.apache.camel.spring.boot.RoutesCollector.onApplicationEvent(RoutesCollector.java:152) ~[camel-spring-boot-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] ... 24 common frames omitted Caused by: java.lang.IllegalStateException: No step properties defined for rule filter step at io.syndesis.integration.runtime.handlers.RuleFilterStepHandler.getFilterExpression(RuleFilterStepHandler.java:51) ~[integration-runtime-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at io.syndesis.integration.runtime.handlers.AbstractFilterStepHandler.handle(AbstractFilterStepHandler.java:36) ~[integration-runtime-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at io.syndesis.integration.runtime.handlers.RuleFilterStepHandler.handle(RuleFilterStepHandler.java:30) ~[integration-runtime-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at io.syndesis.integration.runtime.IntegrationRouteBuilder.configureFlow(IntegrationRouteBuilder.java:174) ~[integration-runtime-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at io.syndesis.integration.runtime.IntegrationRouteBuilder.configure(IntegrationRouteBuilder.java:104) ~[integration-runtime-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at org.apache.camel.builder.RouteBuilder.checkInitialized(RouteBuilder.java:462) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.builder.RouteBuilder.configureRoutes(RouteBuilder.java:402) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.builder.RouteBuilder.addRoutesToCamelContext(RouteBuilder.java:383) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.impl.DefaultCamelContext$1.call(DefaultCamelContext.java:1027) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.impl.DefaultCamelContext$1.call(DefaultCamelContext.java:1024) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.impl.DefaultCamelContext.doWithDefinedClassLoader(DefaultCamelContext.java:3270) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.impl.DefaultCamelContext.addRoutes(DefaultCamelContext.java:1024) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at io.syndesis.integration.runtime.sb.IntegrationRuntimeAutoConfiguration$1.beforeApplicationStart(IntegrationRuntimeAutoConfiguration.java:92) ~[integration-runtime-springboot-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] ... 25 common frames omitted  ```  Probably the culprit is https://github.com/syndesisio/syndesis/issues/562 , but I think it does not make sense now since we have the dedicated `split`</body>
		<created>2019-02-19 12:34:56</created>
		<closed>2019-04-02 10:45:13</closed>
	</bug>
	<bug>
		<id>4622</id>
		<title>After installing syndesis and creating sql -&gt; split -&gt; datamapper -&gt; sql integration, it can't find the mapping json</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Strange issue, when I deploy a fresh syndesis and I create following integration: ``` 1. SQL -&gt; Periodic invocation -&gt; Select * from contact 2. Split 3. Datamapper -&gt; first_name to task 4. SQL -&gt; Invoke SQL -&gt; INSERT INTO TODO (task, completed) VALUES (:#task, 3) ```  it always fails with:  ``` {"exchange":"i-LZ090nUQJqX4IRT04hEz","step":"-LZ08UOJxc057D6kFnL7","id":"i-LZ090rsQJqX4IRT04hIz","duration":137172121,"failure":"java.io.FileNotFoundException: Cannot find resource: mapping-flow-0-step-2.json in classpath for URI: mapping-flow-0-step-2.json\n\tat org.apache.camel.util.ResourceHelper.resolveMandatoryResourceAsInputStream(ResourceHelper.java:175)\n\tat org.apache.camel.component.ResourceEndpoint.loadResource(ResourceEndpoint.java:106)\n\tat org.apache.camel.component.ResourceEndpoint.getResourceAsInputStreamWithoutCache(ResourceEndpoint.java:95)\n\tat org.apache.camel.component.ResourceEndpoint.getResourceAsInputStream(ResourceEndpoint.java:82)\n\tat org.apache.camel.component.atlasmap.AtlasEndpoint.getOrCreateAtlasContext(AtlasEndpoint.java:308)\n\tat org.apache.camel.component.atlasmap.AtlasEndpoint.onExchange(AtlasEndpoint.java:241)\n\tat org.apache.camel.impl.ProcessorEndpoint$1.process(ProcessorEndpoint.java:71)\n\tat org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61)\n\tat org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148)\n\tat org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110)\n\tat org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548)\n\tat org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:138)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:101)\n\tat org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110)\n\tat io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79)\n\tat org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110)\n\tat org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548)\n\tat org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:138)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:101)\n\tat org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548)\n\tat org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201)\n\tat org.apache.camel.processor.MulticastProcessor.doProcessSequential(MulticastProcessor.java:715)\n\tat org.apache.camel.processor.MulticastProcessor.doProcessSequential(MulticastProcessor.java:638)\n\tat org.apache.camel.processor.MulticastProcessor.process(MulticastProcessor.java:248)\n\tat org.apache.camel.processor.Splitter.process(Splitter.java:122)\n\tat org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110)\n\tat org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548)\n\tat org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:138)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:101)\n\tat org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201)\n\tat org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197)\n\tat org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79)\n\tat java.util.TimerThread.mainLoop(Timer.java:555)\n\tat java.util.TimerThread.run(Timer.java:505)\n"} {"exchange":"i-LZ090nUQJqX4IRT04hEz","status":"done","failed":true} 2019-02-18 15:10:00.340  INFO 1 --- [           main] b.c.e.u.UndertowEmbeddedServletContainer : Undertow started on port(s) 8080 (http) 2019-02-18 15:10:00.360  WARN 1 --- [r://integration] o.a.camel.component.timer.TimerConsumer  : Error processing exchange. Exchange[i-LZ090nUQJqX4IRT04hEz]. Caused by: [java.io.FileNotFoundException - Cannot find resource: mapping-flow-0-step-2.json in classpath for URI: mapping-flow-0-step-2.json] java.io.FileNotFoundException: Cannot find resource: mapping-flow-0-step-2.json in classpath for URI: mapping-flow-0-step-2.json at org.apache.camel.util.ResourceHelper.resolveMandatoryResourceAsInputStream(ResourceHelper.java:175) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.component.ResourceEndpoint.loadResource(ResourceEndpoint.java:106) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.component.ResourceEndpoint.getResourceAsInputStreamWithoutCache(ResourceEndpoint.java:95) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.component.ResourceEndpoint.getResourceAsInputStream(ResourceEndpoint.java:82) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.component.atlasmap.AtlasEndpoint.getOrCreateAtlasContext(AtlasEndpoint.java:308) ~[camel-atlasmap-1.39.1.jar!/:na] at org.apache.camel.component.atlasmap.AtlasEndpoint.onExchange(AtlasEndpoint.java:241) ~[camel-atlasmap-1.39.1.jar!/:na] at org.apache.camel.impl.ProcessorEndpoint$1.process(ProcessorEndpoint.java:71) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) ~[integration-runtime-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.MulticastProcessor.doProcessSequential(MulticastProcessor.java:715) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.MulticastProcessor.doProcessSequential(MulticastProcessor.java:638) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.MulticastProcessor.process(MulticastProcessor.java:248) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.Splitter.process(Splitter.java:122) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at java.util.TimerThread.mainLoop(Timer.java:555) [na:1.8.0_191] at java.util.TimerThread.run(Timer.java:505) [na:1.8.0_191] ```  However, when I delete this failing integration and recreate it, it works OK. It always fails when I try to create it right after deploying syndesis  minishift v1.31.0+cfc599c openshift 3.11 latest syndesis</body>
		<created>2019-02-18 15:14:42</created>
		<closed>2019-02-21 18:52:29</closed>
	</bug>
	<bug>
		<id>4620</id>
		<title>[API provider]: Finish connection should declare topmost collection</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  In case a API provider response is defined as JSON array the finish connection should declare the topmost collection in its input shape so data mappers can detect those and perform topmost collection mapping.  At the moment the collection is not detected and the mapper just maps the first element in the collection to the response.</body>
		<created>2019-02-18 15:01:15</created>
		<closed>2019-02-20 06:55:37</closed>
	</bug>
	<bug>
		<id>4619</id>
		<title>[API provider] Edit integration page is empty</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  After create and publish of an integration with API provider start connection the edit page of that integration is empty.  ![bildschirmfoto 2019-02-18 um 15 37 31](https://user-images.githubusercontent.com/195264/52958300-1c086780-3394-11e9-9d8e-086e29a6a4a5.png)  ![bildschirmfoto 2019-02-18 um 15 37 47](https://user-images.githubusercontent.com/195264/52958310-232f7580-3394-11e9-8467-70770a462fc8.png)  Using Chrome on MacOS. No JS errors visible.  The API provider connection has been created from scratch with one single operation. Here is an export of the integration [TodoApi-export.zip](https://github.com/syndesisio/syndesis/files/2876114/TodoApi-export.zip)  </body>
		<created>2019-02-18 14:49:16</created>
		<closed>2019-02-25 08:08:01</closed>
	</bug>
	<bug>
		<id>4618</id>
		<title>[collection support]: Data mapper should select aggregate input shape as target</title>
		<body>When a data mapper is placed in front of an aggregate step the mapper does not select the shape of the aggregate as target document. Instead the next connector step input is selected as target shape.  ![Bildschirmfoto 2019-02-18 um 14.07.02.png](https://images.zenhubusercontent.com/5be31e5e6d41381168d0a8e7/74190bdd-3057-4f8d-9190-2da58320a155)  Steps to reproduce: - add finish connection - add aggregate step before that connection - add data mapper before aggregate step  Data mapper should pick aggregate input shape as target.</body>
		<created>2019-02-18 13:19:15</created>
		<closed>2019-03-13 12:05:50</closed>
	</bug>
	<bug>
		<id>4617</id>
		<title>Editing CI/CD tag without changes causes that the tag is removed</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When I click on edit and change the name, it works properly. However, when I click on edit but I don't change the name and click on Save, the Tag is deleted. ![output](https://user-images.githubusercontent.com/16251792/52949084-9973ae00-337b-11e9-92ad-24a6ae250ce8.gif) </body>
		<created>2019-02-18 12:35:58</created>
		<closed>2019-02-20 09:35:26</closed>
	</bug>
	<bug>
		<id>4613</id>
		<title>Error in logging into Java Console of Integration Pod</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x ] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  In earlier releases of Syndesis, it was possible to access the Java Console/Hawtio console of each Integration Pod.   ![http-log](https://user-images.githubusercontent.com/8625482/52942254-9beafd80-33a5-11e9-8a4a-ffb8175fce56.png)  With release 1.5, the Console is no longer accessible, this error is encountered.  ![js](https://user-images.githubusercontent.com/8625482/52942302-b45b1800-33a5-11e9-8141-6fd5ba3a7dc0.png) </body>
		<created>2019-02-18 09:50:44</created>
		<closed>2019-06-03 06:42:28</closed>
	</bug>
	<bug>
		<id>4612</id>
		<title>Invalid character</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Everywhere when is a button for editing is an invalid character.  E.g.  Edit name of integration (  ) ![image](https://user-images.githubusercontent.com/16251792/52941860-0f6f1980-336a-11e9-8f48-30c34dcaaeb3.png)  Edit name and description of integration. ![image](https://user-images.githubusercontent.com/16251792/52941938-2e6dab80-336a-11e9-971c-cd804be7e115.png)  Edit name and description of Connection ![image](https://user-images.githubusercontent.com/16251792/52941988-49d8b680-336a-11e9-84cc-3ce77c346ed0.png)  ![image](https://user-images.githubusercontent.com/16251792/52942090-93c19c80-336a-11e9-98a6-25ba4ab22463.png)  ![image](https://user-images.githubusercontent.com/16251792/52942102-9ae8aa80-336a-11e9-8f63-c67b727941bb.png)  ![image](https://user-images.githubusercontent.com/16251792/52942242-ea2edb00-336a-11e9-970c-3103c15388fb.png)     </body>
		<created>2019-02-18 09:49:22</created>
		<closed>2019-02-28 17:49:00</closed>
	</bug>
	<bug>
		<id>4610</id>
		<title>No way how to cancel additional step wizard</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When I click on add step button but I will realize that I don't want to any additional step, I don't have any option how to cancel step wizard. The page contains only Cancel button which cancels all integration wizard. The user can click on it thinking that that cancel button cancels just step wizard not whole integration wizard. After that, the complete configured integration is gone. So, in the worst case, the user can lose configuration which **models hours**. For that case, I have also already created a feature request https://github.com/syndesisio/syndesis/issues/4611  ![output](https://user-images.githubusercontent.com/16251792/52940288-738fde80-3366-11e9-879d-3f086f5150f4.gif)  On the video, you can see that I have complex integration but when I click on cancel, because I mistakenly thought that the button cancel only step wizard,the whole work is gone.  On the other hand, another misunderstanding for the user can be that when they click on cancel button during edit existing integration, the cancel button only cancels the actual wizard, not whole integration wizard as in the previous example. So the same Cancel button does two different things which can be really confusing for the users.  ![output](https://user-images.githubusercontent.com/16251792/52940593-35df8580-3367-11e9-97d8-a3e9a1d2abbd.gif)     </body>
		<created>2019-02-18 09:27:44</created>
		<closed>2019-03-11 15:30:48</closed>
	</bug>
	<bug>
		<id>4608</id>
		<title>consolidate font sizes in syndesis </title>
		<body>Introducing new font brought some inconsistency in font sizes and visibility of connection names: ![screenshot_20190218_094516](https://user-images.githubusercontent.com/6814482/52938782-d5e6e000-3362-11e9-94d6-e3188d0e2985.png) ![screenshot_20190218_095532](https://user-images.githubusercontent.com/6814482/52939010-5dccea00-3363-11e9-8e44-38f962d3c286.png)  </body>
		<created>2019-02-18 08:54:16</created>
		<closed>2019-03-06 10:16:21</closed>
	</bug>
	<bug>
		<id>4607</id>
		<title>DB-&gt;Google sheet integration error: Can not deserialize instance of java.util.LinkedHashMap out of START_ARRAY token</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I have simple integration from db to google sheets and I'm getting following exception during integration:  ` com.fasterxml.jackson.databind.JsonMappingException: Can not deserialize instance of java.util.LinkedHashMap out of START_ARRAY token at [Source: [{"spreadsheetId":"1IO54adO0Voj_JIGAtQQYPocB4wHFw2iTW7QDiFKSWYU","A":"Matej","B":"Foo","C":"Red Hat","D":"db","E":null}]; line: 1, column: 1] at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:270) at com.fasterxml.jackson.databind.DeserializationContext.reportMappingException(DeserializationContext.java:1247) at com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1122) at com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1075) at com.fasterxml.jackson.databind.deser.std.StdDeserializer._deserializeFromEmpty(StdDeserializer.java:892) at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:358) at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:27) at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:1626) at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1220) at io.syndesis.connector.sheets.GoogleSheetsUpdateValuesCustomizer.beforeProducer(GoogleSheetsUpdateValuesCustomizer.java:97) at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at io.syndesis.integration.component.proxy.ComponentProxyProducer.process(ComponentProxyProducer.java:44) at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197) at org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79) at java.util.TimerThread.mainLoop(Timer.java:555) at java.util.TimerThread.run(Timer.java:505) ` Fields in DM are now within a collection: ![screenshot_20190218_093956](https://user-images.githubusercontent.com/6814482/52938160-3c6afe80-3361-11e9-8e31-e8a08ab46acb.png)  </body>
		<created>2019-02-18 08:41:48</created>
		<closed>2019-02-19 16:09:17</closed>
	</bug>
	<bug>
		<id>4606</id>
		<title>[Deploy] Unable to deploy from master</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description With clean minishift:  ``` ./tools/bin/syndesis install --setup Installing Syndesis CRD  ./tools/bin/syndesis install --project syndesis -y --test-support Creating project syndesis Already on project "syndesis" on server "https://192.168.99.100:8443". ERROR: No CRD Syndesis installed or not enough permissions to read them. Please run --setup and/or --grant as cluster-admin. See 'syndesis install --help' for more information.  oc get crd NAME                                                                     AGE openshiftwebconsoleconfigs.webconsole.operator.openshift.io              21m servicecertsigneroperatorconfigs.servicecertsigner.config.openshift.io   24m syndeses.syndesis.io                                                     1m ``` </body>
		<created>2019-02-18 07:25:46</created>
		<closed>2019-02-25 13:50:26</closed>
	</bug>
	<bug>
		<id>4604</id>
		<title>Can't create an integration</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [*] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Click 'Add Integration' and arrive at:  &lt;img width="1173" alt="screen shot 2019-02-15 at 4 46 39 pm" src="https://user-images.githubusercontent.com/35576/52886200-8aa1b700-3141-11e9-8289-90b8f65d5154.png"&gt;  Where I can't connectors..    </body>
		<created>2019-02-15 21:48:58</created>
		<closed>2019-02-25 13:23:30</closed>
	</bug>
	<bug>
		<id>4603</id>
		<title>Quickstart install broke related to Camel-K</title>
		<body>https://github.com/syndesisio/syndesis-quickstarts/blob/master/README.md#install-syndesis  ```shell  bash &lt;(curl -sL https://syndes.is/start) ===================================================================== SYNDESIS master QUICKSTART  Hybrid integration on OpenShift made easy =====================================================================  Switched to context "minishift". --------------------------------------------------------------------- Creating project syndesis Already on project "syndesis" on server "https://192.168.42.117:8443". --------------------------------------------------------------------- --------------------------------------------------------------------- Creating ServiceAccount for OAuthClient serviceaccount "syndesis-oauth-client" created --------------------------------------------------------------------- --------------------------------------------------------------------- Creating Tempate syndesis template.template.openshift.io "syndesis" created ---------------------------------------------------------------------  --------------------------------------------------------------------- Creating new-app from syndesis --&gt; Deploying template "syndesis/syndesis" to project syndesis       syndesis      ---------      Syndesis is deployed to syndesis.192.168.42.117.nip.io.       * With parameters:         * ROUTE_HOSTNAME=syndesis.192.168.42.117.nip.io         * OPENSHIFT_MASTER=https://192.168.42.117:8443         * OpenShift Console URL=         * OpenShift project to deploy into=syndesis         * OpenShift project to be used to authenticate the user against=syndesis         * OPENSHIFT_OAUTH_CLIENT_SECRET=eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJzeW5kZXNpcyIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJzeW5kZXNpcy1vYXV0aC1jbGllbnQtdG9rZW4tbjI0YnciLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoic3luZGVzaXMtb2F1dGgtY2xpZW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiNDAyOGY0MDAtMzE2Ny0xMWU5LWFhNWYtYjY4NWMwMmY3NDQ3Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50OnN5bmRlc2lzOnN5bmRlc2lzLW9hdXRoLWNsaWVudCJ9.ZflA3hBhQXSNul0_mkJw3mvLFzeBubBEAd64DRNd3n2ntcfdRNVUsqxEKR0hB0IULpLQYRyYT2PulAiZXJVg7Prx-5oz0-qWtNWocCn2ekg45wsG6tXC7c0_p5u8wNkEtC6P2yzKRXR1ExrSUNvblbrgELrpM55LSoMuAAW3jh9NTKKKd6ZSGVy77ihMe_fLKv0gWPZ1tyWwJ5QLkBvn-du22rhil4BsleEi-1P_C5h_VUi14HKG1yhROYGjWwOPGMpt4DlHGUmro_qiRBdVPiwchxHSCbW_--m8Llbr1z7iluiQVDFPIQ8z64vMcf3kif-JGDRte3mQaUwo71GdJg         * Memory Limit=255Mi         * Namespace=openshift         * PostgreSQL Connection Username=syndesis         * PostgreSQL Connection Password=yCS7hrVrcdvSwLbi # generated         * PostgreSQL Database Name=syndesis         * PostgreSQL Volume Capacity=1Gi         * PostgreSQL SampleDB Connection Password=XAUlcJoXhIKpD5l1 # generated         * Test Support Enabled=false         * Demo Data Enabled=false         * Syndesis Image Registry=docker.io         * Enable Integration Deployment=true         * Image Stream Namespace=         * OAuth Cookie Secret=C1J5LAsBlPxm1JEm0O7xH1e0VbEQTvpm # generated         * SYNDESIS_ENCRYPT_KEY=mKIIjl8piWBFI5MsQIPxcCQvC5tehIwvpO2xDKyTJOi4xr11XnTqpmvDxx07VT1V # generated         * Prometheus Volume Capacity=1Gi         * Memory Limit=512Mi         * Meta Volume Capacity=1Gi         * Memory Limit=512Mi         * Memory Limit=800Mi         * Maximum number of integrations=1         * Integration state check interval=60         * Client side state authentication key=f4JFlbJWl4eibcOWH8knrejbb2DfGpwk # generated         * Client side state encryption key=2ggoNWORoFbnpKVLv5GuXcOAjDHwdws4 # generated         * Upgrade Volume Capacity=1Gi         * Expose services via 3scale=false  --&gt; Creating resources ...     imagestream "syndesis-server" created     imagestream "syndesis-ui" created     imagestream "syndesis-meta" created     imagestream "oauth-proxy" created     imagestream "prometheus" created     imagestream "postgres_exporter" created     imagestream "syndesis-s2i" created     secret "syndesis-oauth-proxy-cookie-secret" created     secret "syndesis-server-secret" created     secret "syndesis-global-config" created     service "syndesis-ui" created     deploymentconfig "syndesis-ui" created     configmap "syndesis-ui-config" created     configmap "syndesis-db-metrics-config" created     service "syndesis-db-metrics" created     deploymentconfig "syndesis-db-metrics" created     configmap "syndesis-sampledb-config" created     configmap "syndesis-db-conf" created     service "syndesis-db" created     persistentvolumeclaim "syndesis-db" created     deploymentconfig "syndesis-db" created     service "syndesis-meta" created     persistentvolumeclaim "syndesis-meta" created     deploymentconfig "syndesis-meta" created     configmap "syndesis-meta-config" created     service "syndesis-oauthproxy" created     route "syndesis" created     deploymentconfig "syndesis-oauthproxy" created     serviceaccount "syndesis-server" created     serviceaccount "syndesis-integration" created     service "syndesis-server" created     deploymentconfig "syndesis-server" created     configmap "syndesis-server-config" created     error: roles.rbac.authorization.k8s.io "camel-k" is forbidden: attempt to grant extra privileges: [PolicyRule{APIGroups:["camel.apache.org"], Resources:["*"], Verbs:["*"]}] user=&amp;{developer b003afc6-3166-11e9-bcd1-b685c02f7447 [system:authenticated:oauth system:authenticated] map[scopes.authorization.openshift.io:[user:full]]} ownerrules=[PolicyRule{APIGroups:["" "user.openshift.io"], Resources:["users"], ResourceNames:["~"], Verbs:["get"]} PolicyRule{APIGroups:["" "project.openshift.io"], Resources:["projectrequests"], Verbs:["list"]} PolicyRule{APIGroups:["" "authorization.openshift.io"], Resources:["clusterroles"], Verbs:["get" "list"]} PolicyRule{APIGroups:["rbac.authorization.k8s.io"], Resources:["clusterroles"], Verbs:["get" "list" "watch"]} PolicyRule{APIGroups:["storage.k8s.io"], Resources:["storageclasses"], Verbs:["get" "list"]} PolicyRule{APIGroups:["" "project.openshift.io"], Resources:["projects"], Verbs:["list" "watch"]} PolicyRule{APIGroups:["" "authorization.openshift.io"], Resources:["selfsubjectrulesreviews"], Verbs:["create"]} PolicyRule{APIGroups:["authorization.k8s.io"], Resources:["selfsubjectaccessreviews"], Verbs:["create"]} PolicyRule{NonResourceURLs:["/healthz" "/healthz/*"], Verbs:["get"]} PolicyRule{NonResourceURLs:["/version" "/version/*" "/api" "/api/*" "/apis" "/apis/*" "/oapi" "/oapi/*" "/openapi/v2" "/swaggerapi" "/swaggerapi/*" "/swagger.json" "/swagger-2.0.0.pb-v1" "/osapi" "/osapi/" "/.well-known" "/.well-known/*" "/"], Verbs:["get"]} PolicyRule{APIGroups:["" "authorization.openshift.io"], Resources:["selfsubjectrulesreviews"], Verbs:["create"]} PolicyRule{APIGroups:["authorization.k8s.io"], Resources:["selfsubjectaccessreviews"], Verbs:["create"]} PolicyRule{APIGroups:["" "project.openshift.io"], Resources:["projectrequests"], Verbs:["create"]} PolicyRule{APIGroups:["" "user.openshift.io"], Resources:["systemusers" "users"], ResourceNames:["system:admin"], Verbs:["impersonate"]} PolicyRule{APIGroups:["" "user.openshift.io"], Resources:["groups" "systemgroups"], ResourceNames:["system:masters"], Verbs:["impersonate"]} PolicyRule{APIGroups:["authorization.k8s.io"], Resources:["selfsubjectaccessreviews" "selfsubjectrulesreviews"], Verbs:["create"]} PolicyRule{APIGroups:["" "build.openshift.io"], Resources:["builds/docker" "builds/optimizeddocker"], Verbs:["create"]} PolicyRule{APIGroups:["" "build.openshift.io"], Resources:["builds/jenkinspipeline"], Verbs:["create"]} PolicyRule{APIGroups:["" "build.openshift.io"], Resources:["builds/source"], Verbs:["create"]} PolicyRule{NonResourceURLs:["/version" "/version/*" "/api" "/api/*" "/apis" "/apis/*" "/oapi" "/oapi/*" "/openapi/v2" "/swaggerapi" "/swaggerapi/*" "/swagger.json" "/swagger-2.0.0.pb-v1" "/osapi" "/osapi/" "/.well-known" "/.well-known/*" "/"], Verbs:["get"]} PolicyRule{NonResourceURLs:["/version" "/version/*" "/api" "/api/*" "/apis" "/apis/*" "/oapi" "/oapi/*" "/openapi/v2" "/swaggerapi" "/swaggerapi/*" "/swagger.json" "/swagger-2.0.0.pb-v1" "/osapi" "/osapi/" "/.well-known" "/.well-known/*" "/"], Verbs:["get"]} PolicyRule{APIGroups:["" "oauth.openshift.io"], Resources:["oauthaccesstokens" "oauthauthorizetokens"], Verbs:["delete"]} PolicyRule{APIGroups:["authentication.k8s.io"], Resources:["userextras/scopes.authorization.openshift.io"], Verbs:["impersonate"]} PolicyRule{APIGroups:["" "build.openshift.io"], Resources:["buildconfigs/webhooks"], Verbs:["create" "get"]} PolicyRule{APIGroups:[""], Resources:["pods" "pods/attach" "pods/exec" "pods/portforward" "pods/proxy"], Verbs:["create" "delete" "deletecollection" "get" "list" "patch" "update" "watch"]} PolicyRule{APIGroups:[""], Resources:["configmaps" "endpoints" "persistentvolumeclaims" "replicationcontrollers" "replicationcontrollers/scale" "secrets" "serviceaccounts" "services" "services/proxy"], Verbs:["create" "delete" "deletecollection" "get" "list" "patch" "update" "watch"]} PolicyRule{APIGroups:[""], Resources:["bindings" "events" "limitranges" "namespaces/status" "pods/log" "pods/status" "replicationcontrollers/status" "resourcequotas" "resourcequotas/status"], Verbs:["get" "list" "watch"]} PolicyRule{APIGroups:[""], Resources:["namespaces"], Verbs:["get" "list" "watch"]} PolicyRule{APIGroups:[""], Resources:["serviceaccounts"], Verbs:["impersonate"]} PolicyRule{APIGroups:["apps"], Resources:["daemonsets" "deployments" "deployments/rollback" "deployments/scale" "replicasets" "replicasets/scale" "statefulsets" "statefulsets/scale"], Verbs:["create" "delete" "deletecollection" "get" "list" "patch" "update" "watch"]} PolicyRule{APIGroups:["autoscaling"], Resources:["horizontalpodautoscalers"], Verbs:["create" "delete" "deletecollection" "get" "list" "patch" "update" "watch"]} PolicyRule{APIGroups:["batch"], Resources:["cronjobs" "jobs"], Verbs:["create" "delete" "deletecollection" "get" "list" "patch" "update" "watch"]} PolicyRule{APIGroups:["extensions"], Resources:["daemonsets" "deployments" "deployments/rollback" "deployments/scale" "ingresses" "networkpolicies" "replicasets" "replicasets/scale" "replicationcontrollers/scale"], Verbs:["create" "delete" "deletecollection" "get" "list" "patch" "update" "watch"]} PolicyRule{APIGroups:["policy"], Resources:["poddisruptionbudgets"], Verbs:["create" "delete" "deletecollection" "get" "list" "patch" "update" "watch"]} PolicyRule{APIGroups:["networking.k8s.io"], Resources:["networkpolicies"], Verbs:["create" "delete" "deletecollection" "get" "list" "patch" "update" "watch"]} PolicyRule{APIGroups:["authorization.k8s.io"], Resources:["localsubjectaccessreviews"], Verbs:["create"]} PolicyRule{APIGroups:["rbac.authorization.k8s.io"], Resources:["rolebindings" "roles"], Verbs:["create" "delete" "deletecollection" "get" "list" "patch" "update" "watch"]} PolicyRule{APIGroups:["" "authorization.openshift.io"], Resources:["rolebindings" "roles"], Verbs:["create" "delete" "deletecollection" "get" "list" "patch" "update" "watch"]} PolicyRule{APIGroups:["" "authorization.openshift.io"], Resources:["localresourceaccessreviews" "localsubjectaccessreviews" "subjectrulesreviews"], Verbs:["create"]} PolicyRule{APIGroups:["" "security.openshift.io"], Resources:["podsecuritypolicyreviews" "podsecuritypolicyselfsubjectreviews" "podsecuritypolicysubjectreviews"], Verbs:["create"]} PolicyRule{APIGroups:["" "authorization.openshift.io"], Resources:["rolebindingrestrictions"], Verbs:["get" "list" "watch"]} PolicyRule{APIGroups:["" "build.openshift.io"], Resources:["buildconfigs" "buildconfigs/webhooks" "builds"], Verbs:["create" "delete" "deletecollection" "get" "list" "patch" "update" "watch"]} PolicyRule{APIGroups:["" "build.openshift.io"], Resources:["builds/log"], Verbs:["get" "list" "watch"]} PolicyRule{APIGroups:["" "build.openshift.io"], Resources:["buildconfigs/instantiate" "buildconfigs/instantiatebinary" "builds/clone"], Verbs:["create"]} PolicyRule{APIGroups:["" "build.openshift.io"], Resources:["builds/details"], Verbs:["update"]} PolicyRule{APIGroups:["build.openshift.io"], Resources:["jenkins"], Verbs:["admin" "edit" "view"]} PolicyRule{APIGroups:["" "apps.openshift.io"], Resources:["deploymentconfigs" "deploymentconfigs/scale"], Verbs:["create" "delete" "deletecollection" "get" "list" "patch" "update" "watch"]} PolicyRule{APIGroups:["" "apps.openshift.io"], Resources:["deploymentconfigrollbacks" "deploymentconfigs/instantiate" "deploymentconfigs/rollback"], Verbs:["create"]} PolicyRule{APIGroups:["" "apps.openshift.io"], Resources:["deploymentconfigs/log" "deploymentconfigs/status"], Verbs:["get" "list" "watch"]} PolicyRule{APIGroups:["" "image.openshift.io"], Resources:["imagestreamimages" "imagestreammappings" "imagestreams" "imagestreams/secrets" "imagestreamtags"], Verbs:["create" "delete" "deletecollection" "get" "list" "patch" "update" "watch"]} PolicyRule{APIGroups:["" "image.openshift.io"], Resources:["imagestreams/status"], Verbs:["get" "list" "watch"]} PolicyRule{APIGroups:["" "image.openshift.io"], Resources:["imagestreams/layers"], Verbs:["get" "update"]} PolicyRule{APIGroups:["" "image.openshift.io"], Resources:["imagestreamimports"], Verbs:["create"]} PolicyRule{APIGroups:["" "project.openshift.io"], Resources:["projects"], Verbs:["delete" "get" "patch" "update"]} PolicyRule{APIGroups:["" "quota.openshift.io"], Resources:["appliedclusterresourcequotas"], Verbs:["get" "list" "watch"]} PolicyRule{APIGroups:["" "route.openshift.io"], Resources:["routes"], Verbs:["create" "delete" "deletecollection" "get" "list" "patch" "update" "watch"]} PolicyRule{APIGroups:["" "route.openshift.io"], Resources:["routes/custom-host"], Verbs:["create"]} PolicyRule{APIGroups:["" "route.openshift.io"], Resources:["routes/status"], Verbs:["get" "list" "watch"]} PolicyRule{APIGroups:["" "route.openshift.io"], Resources:["routes/status"], Verbs:["update"]} PolicyRule{APIGroups:["" "template.openshift.io"], Resources:["processedtemplates" "templateconfigs" "templateinstances" "templates"], Verbs:["create" "delete" "deletecollection" "get" "list" "patch" "update" "watch"]} PolicyRule{APIGroups:["extensions" "networking.k8s.io"], Resources:["networkpolicies"], Verbs:["create" "delete" "deletecollection" "get" "list" "patch" "update" "watch"]} PolicyRule{APIGroups:["" "build.openshift.io"], Resources:["buildlogs"], Verbs:["create" "delete" "deletecollection" "get" "list" "patch" "update" "watch"]} PolicyRule{APIGroups:[""], Resources:["resourcequotausages"], Verbs:["get" "list" "watch"]} PolicyRule{APIGroups:["" "authorization.openshift.io"], Resources:["resourceaccessreviews" "subjectaccessreviews"], Verbs:["create"]}] ruleResolutionErrors=[]     error: roles.rbac.authorization.k8s.io "camel-k" not found     service "todo" created     route "todo" created     imagestream "todo" created     buildconfig "todo" created     deploymentconfig "todo" created     rolebinding "syndesis:editors" created     rolebinding "syndesis:viewers" created     serviceaccount "syndesis-prometheus" created     configmap "syndesis-prometheus-config" created     service "syndesis-prometheus" created     persistentvolumeclaim "syndesis-prometheus" created     deploymentconfig "syndesis-prometheus" created     persistentvolumeclaim "syndesis-upgrade" created     template "syndesis-upgrade" created --&gt; Failed ```</body>
		<created>2019-02-15 21:21:07</created>
		<closed>2019-04-30 10:44:34</closed>
	</bug>
	<bug>
		<id>4594</id>
		<title>[Action configuration page] Checkboxes and labels are not aligned  </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  I saw this from @phantomjinx's demo this morning. It seems like the checkboxes for "Filter Old Results" and "Split Results" are not aligned with the text.   It seems like patternfly has a known issue with check/radio vertical alignment on linux distros, see https://github.com/patternfly/patternfly/issues/1122.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlisting the acceptance criteria. --&gt; Checkboxes and text should align.   ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  &lt;img width="535" alt="screen shot 2019-02-15 at 9 54 23 am" src="https://user-images.githubusercontent.com/24943812/52866733-4e546380-310d-11e9-95c4-88109ab53ae7.png"&gt;   ## Request and Response Data &lt;!-- Many issues involve both the UI and its backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4.  cc: @seanforyou23 @mcoker @syndesisio/uxd </body>
		<created>2019-02-15 15:40:48</created>
		<closed>2019-03-04 08:01:06</closed>
	</bug>
	<bug>
		<id>4593</id>
		<title>FHIR Search connector missing collection type data shape</title>
		<body>FHIR search connector is able to provide a collection as output data shape. The connector should define this collection type in its data shape so data mappers are able to detect that type.</body>
		<created>2019-02-15 15:36:05</created>
		<closed>2019-05-29 12:58:46</closed>
	</bug>
	<bug>
		<id>4590</id>
		<title>Unable to build master with clean maven repo and flash profile</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description `./tools/bin/syndesis build --backend --flash`  ``` [INFO] ------------------------------------------------------------------------ [INFO] Reactor Summary: [INFO]  [INFO] Connector .......................................... SUCCESS [  5.160 s] [INFO] Connector :: Support :: Util ....................... SUCCESS [  1.908 s] [INFO] Connector :: Support :: Verifier ................... SUCCESS [  1.437 s] [INFO] Connector :: Support :: Maven Plugin ............... SUCCESS [ 11.115 s] [INFO] Connector :: Twitter ............................... SUCCESS [  1.271 s] [INFO] Connector :: FTP ................................... SUCCESS [  0.362 s] [INFO] Connector :: SFTP .................................. SUCCESS [  0.319 s] [INFO] Connector :: Dropbox ............................... SUCCESS [  4.144 s] [INFO] Connector :: Support :: Test ....................... SUCCESS [  0.481 s] [INFO] Connector :: AWS S3 ................................ SUCCESS [01:12 min] [INFO] Connector :: ActiveMQ .............................. SUCCESS [ 13.917 s] [INFO] Connector :: AMQP .................................. SUCCESS [ 16.412 s] [INFO] Connector :: SQL ................................... SUCCESS [  6.795 s] [INFO] Connector :: MQTT .................................. SUCCESS [  2.786 s] [INFO] Connector :: Support :: Processor .................. SUCCESS [  0.827 s] [INFO] Connector :: HTTP .................................. SUCCESS [  3.435 s] [INFO] Connector :: Salesforce ............................ SUCCESS [ 11.603 s] [INFO] Connector :: Slack ................................. SUCCESS [  1.683 s] [INFO] Connector :: Gmail ................................. SUCCESS [  8.550 s] [INFO] Connector :: Timer ................................. SUCCESS [  3.892 s] [INFO] Connector :: ServiceNow ............................ SUCCESS [  9.216 s] [INFO] Connector :: Concur ................................ SUCCESS [  0.361 s] [INFO] Connector :: Kafka ................................. SUCCESS [  3.315 s] [INFO] Connector :: FHIR .................................. SUCCESS [ 25.019 s] [INFO] Connector :: Webhook ............................... SUCCESS [  0.884 s] [INFO] Connector :: Log ................................... SUCCESS [  0.050 s] [INFO] Connector :: Telegram .............................. SUCCESS [  2.910 s] [INFO] Connector :: IRC ................................... SUCCESS [  2.940 s] [INFO] Connector :: API Provider .......................... SUCCESS [  2.404 s] [INFO] Connector :: Google Calendar ....................... SUCCESS [  2.323 s] [INFO] Connector :: Google Sheets ......................... SUCCESS [ 47.796 s] [INFO] Connector :: Apache Kudu ........................... SUCCESS [ 16.847 s] [INFO] Connector :: OData ................................. FAILURE [  2.294 s] [INFO] Connector :: Support :: Catalog .................... SKIPPED [INFO] Connector :: REST Swagger .......................... SKIPPED [INFO] ------------------------------------------------------------------------ [INFO] BUILD FAILURE [INFO] ------------------------------------------------------------------------ [INFO] Total time: 04:46 min [INFO] Finished at: 2019-02-15T09:46:53-05:00 [INFO] Final Memory: 175M/584M [INFO] ------------------------------------------------------------------------ [ERROR] Failed to execute goal on project connector-odata: Could not resolve dependencies for project io.syndesis.connector:connector-odata:jar:1.6-SNAPSHOT: Could not find artifact io.syndesis.integration:integration-runtime:jar:tests:1.6-SNAPSHOT in jboss-fuse (https://origin-repository.jboss.org/nexus/content/groups/ea) -&gt; [Help 1] ```   </body>
		<created>2019-02-15 14:48:24</created>
		<closed>2019-02-19 13:03:24</closed>
	</bug>
	<bug>
		<id>4583</id>
		<title>google-scheets: unable to create chart</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Add charts step doesn't work. I have simple spreadsheet with few entries:  ![screenshot_20190215_102503](https://user-images.githubusercontent.com/6814482/52847248-f406d300-310b-11e9-8ebe-3de3ac4248bb.png) and simple mapping:  ![screenshot_20190215_102654](https://user-images.githubusercontent.com/6814482/52847374-49db7b00-310c-11e9-9b7b-7d30ce266388.png)   Following exception is thrown in integration:  ``` org.apache.camel.RuntimeCamelException: com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request {   "code" : 400,   "errors" : [ {     "domain" : "global",     "message" : "Invalid requests[0].addChart: ChartSourceRange ranges require all rows or all columns to have length of 1",     "reason" : "badRequest"   } ],   "message" : "Invalid requests[0].addChart: ChartSourceRange ranges require all rows or all columns to have length of 1",   "status" : "INVALID_ARGUMENT" } at org.apache.camel.component.google.sheets.GoogleSheetsProducer.doInvokeMethod(GoogleSheetsProducer.java:49) at org.apache.camel.util.component.AbstractApiProducer$1.run(AbstractApiProducer.java:86) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Caused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request {   "code" : 400,   "errors" : [ {     "domain" : "global",     "message" : "Invalid requests[0].addChart: ChartSourceRange ranges require all rows or all columns to have length of 1",     "reason" : "badRequest"   } ],   "message" : "Invalid requests[0].addChart: ChartSourceRange ranges require all rows or all columns to have length of 1",   "status" : "INVALID_ARGUMENT" } at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146) at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1065) at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) at org.apache.camel.component.google.sheets.GoogleSheetsProducer.doInvokeMethod(GoogleSheetsProducer.java:47) ... 8 more ``` </body>
		<created>2019-02-15 09:28:21</created>
		<closed>2019-02-28 16:06:03</closed>
	</bug>
	<bug>
		<id>4582</id>
		<title>Cancel button does not work when prompted to name integration</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  When creating new integration - I want to get back to editing integration from the integration naming screen. I expected this would be possible using the "cancel"button, but it doesn't seem to work.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlisting the acceptance criteria. --&gt; When pressing the cancel, I expected I would get back to the integration editor.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![out2](https://user-images.githubusercontent.com/4180208/52849667-dc324d80-3111-11e9-89fc-d928ae4bc378.gif)   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Select create integration 2. Select start connection 3. Select end connection 4. Press "Publish" button 5. Press cancel button - nothing happens </body>
		<created>2019-02-15 08:53:27</created>
		<closed>2019-02-21 14:23:17</closed>
	</bug>
	<bug>
		<id>4571</id>
		<title>UI freeze when creating new integration with no connections created</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; With fresh installation of Syndesis (not having any integrations and connections) when I click on Create Integration and the dialog appears, I am not able to get back to Home page or any other page (the UI freezes - when clicking on any link in menu or cancel button, it doesn't interact). The only way to open any link is to open it in new tab (I am using Chrome)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Have no Connections 2. Click on Create Integration 3. Try to cancel it or to click on anything in the menu </body>
		<created>2019-02-14 15:27:51</created>
		<closed>2019-02-14 16:41:20</closed>
	</bug>
	<bug>
		<id>4568</id>
		<title>[Datamapper][Split] Source fields are shown from both previous steps (SQL, Split)</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When I use the integration `SQL -&gt; Split -&gt; Datamapper -&gt; SQL -&gt; Aggregate`, this is what I see in datamapper: ![rf4v](https://user-images.githubusercontent.com/7081216/52790160-2a8a1280-3066-11e9-8974-d6c0e90df53f.png)    When I map `2- SQL Result` to a task, it fails with the following exception:  ``` 2019-02-14 13:31:38.310  WARN 1 --- [r://integration] o.a.c.component.atlasmap.AtlasEndpoint   : Null or non-String source document: docId='DOC.2 - SQL Result.572262': docId='DOC.2 - SQL Result.572262', path='null' 2019-02-14 13:31:38.323 ERROR 1 --- [r://integration] o.a.camel.processor.DefaultErrorHandler  : Failed delivery for (MessageId: i-LYgC8gNPNRr_qeWMwQ2z on ExchangeId: i-LYgC8gKPNRr_qeWMwQ1z). Exhausted after delivery attempt: 1 caught: io.atlasmap.api.AtlasException: Errors: [Source document 'DOC.2 - SQL Result.572262' doesn't exist: docId='DOC.2 - SQL Result.572262', path='/first_name'],  Message History --------------------------------------------------------------------------------------------------------------------------------------- RouteId              ProcessorId          Processor                                                                        Elapsed (ms) [-LYg9zdz6bChFdHo1b] [-LYg9zdz6bChFdHo1b] [timer://integration?period=60000                                              ] [      1413] [-LYg9zdz6bChFdHo1b] [setHeader2        ] [setHeader[Syndesis.STEP_ID]                                                   ] [         0] [-LYg9zdz6bChFdHo1b] [process1          ] [Processor@0x61a4d060                                                          ] [         1] [-LYg9zdz6bChFdHo1b] [step:-LYgBsjE6bChF] [pipeline                                                                      ] [         0] [-LYg9zdz6bChFdHo1b] [setHeader3        ] [setHeader[Syndesis.STEP_ID]                                                   ] [         0] [-LYg9zdz6bChFdHo1b] [to2               ] [atlas:mapping-flow-0-step-2.json?encoding=UTF-8&amp;sourceMapName=Syndesis.CAPTURE] [      1190] Stacktrace --------------------------------------------------------------------------------------------------------------------------------------- io.atlasmap.api.AtlasException: Errors: [Source document 'DOC.2 - SQL Result.572262' doesn't exist: docId='DOC.2 - SQL Result.572262', path='/first_name'],  at org.apache.camel.component.atlasmap.AtlasEndpoint.onExchange(AtlasEndpoint.java:266) ~[camel-atlasmap-1.39.1.jar!/:na] at org.apache.camel.impl.ProcessorEndpoint$1.process(ProcessorEndpoint.java:71) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) [integration-runtime-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.MulticastProcessor.doProcessSequential(MulticastProcessor.java:715) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.MulticastProcessor.doProcessSequential(MulticastProcessor.java:638) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.MulticastProcessor.process(MulticastProcessor.java:248) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.Splitter.process(Splitter.java:122) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at java.util.TimerThread.mainLoop(Timer.java:555) [na:1.8.0_191] at java.util.TimerThread.run(Timer.java:505) [na:1.8.0_191] {"exchange":"i-LYgC8d6PNRr_qeWMwQ-z","step":"-LYgBsjE6bChFdHo1bsq","id":"i-LYgC8gOPNRr_qeWMwQ3z","duration":1210992705,"failure":"io.atlasmap.api.AtlasException: Errors: [Source document 'DOC.2 - SQL Result.572262' doesn't exist: docId='DOC.2 - SQL Result.572262', path='/first_name'], \n\tat org.apache.camel.component.atlasmap.AtlasEndpoint.onExchange(AtlasEndpoint.java:266)\n\tat org.apache.camel.impl.ProcessorEndpoint$1.process(ProcessorEndpoint.java:71)\n\tat org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61)\n\tat org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148)\n\tat org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110)\n\tat org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548)\n\tat org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:138)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:101)\n\tat org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110)\n\tat io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79)\n\tat org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110)\n\tat org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548)\n\tat org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:138)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:101)\n\tat org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548)\n\tat org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201)\n\tat org.apache.camel.processor.MulticastProcessor.doProcessSequential(MulticastProcessor.java:715)\n\tat org.apache.camel.processor.MulticastProcessor.doProcessSequential(MulticastProcessor.java:638)\n\tat org.apache.camel.processor.MulticastProcessor.process(MulticastProcessor.java:248)\n\tat org.apache.camel.processor.Splitter.process(Splitter.java:122)\n\tat org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110)\n\tat org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548)\n\tat org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:138)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:101)\n\tat org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201)\n\tat org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197)\n\tat org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79)\n\tat java.util.TimerThread.mainLoop(Timer.java:555)\n\tat java.util.TimerThread.run(Timer.java:505)\n"} {"exchange":"i-LYgC8d6PNRr_qeWMwQ-z","status":"done","failed":true} 2019-02-14 13:31:38.331  WARN 1 --- [r://integration] o.a.camel.component.timer.TimerConsumer  : Error processing exchange. Exchange[i-LYgC8d6PNRr_qeWMwQ-z]. Caused by: [io.atlasmap.api.AtlasException - Errors: [Source document 'DOC.2 - SQL Result.572262' doesn't exist: docId='DOC.2 - SQL Result.572262', path='/first_name'], ] io.atlasmap.api.AtlasException: Errors: [Source document 'DOC.2 - SQL Result.572262' doesn't exist: docId='DOC.2 - SQL Result.572262', path='/first_name'],  at org.apache.camel.component.atlasmap.AtlasEndpoint.onExchange(AtlasEndpoint.java:266) ~[camel-atlasmap-1.39.1.jar!/:na] at org.apache.camel.impl.ProcessorEndpoint$1.process(ProcessorEndpoint.java:71) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) ~[integration-runtime-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.MulticastProcessor.doProcessSequential(MulticastProcessor.java:715) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.MulticastProcessor.doProcessSequential(MulticastProcessor.java:638) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.MulticastProcessor.process(MulticastProcessor.java:248) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.Splitter.process(Splitter.java:122) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) ~[camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79) [camel-core-2.21.0.fuse-730042.jar!/:2.21.0.fuse-730042] at java.util.TimerThread.mainLoop(Timer.java:555) [na:1.8.0_191] at java.util.TimerThread.run(Timer.java:505) [na:1.8.0_191]  ```  When I map from `1 - SQL Result` it seems to be working (although the ugly warning is still there): ``` 2019-02-14 13:36:24.875  WARN 1 --- [r://integration] o.a.c.component.atlasmap.AtlasEndpoint   : Null or non-String source document: docId='-LYgBsjE6bChFdHo1bsp': docId='-LYgBsjE6bChFdHo1bsp', path='null' {"exchange":"i-LYgDEbw9mPK12cz3-XGz","step":"-LYgBsjE6bChFdHo1bsq","id":"i-LYgDEfh9mPK12cz3-XKz","duration":1088527464} {"exchange":"i-LYgDEbw9mPK12cz3-XGz","step":"-LYgAGoJ6bChFdHo1bsp","id":"i-LYgDEwk9mPK12cz3-XMz","duration":20447413} {"exchange":"i-LYgDEbw9mPK12cz3-XGz","status":"done","failed":false}  ```  </body>
		<created>2019-02-14 13:37:59</created>
		<closed>2019-02-18 12:07:53</closed>
	</bug>
	<bug>
		<id>4562</id>
		<title>Flaky OData connector unit test on CircleCi</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  ODataReadRouteSplitResultsTest seems to fail from time to time on CircleCi.  See https://circleci.com/gh/syndesisio/syndesis/56953?utm_campaign=vcs-integration-link&amp;utm_medium=referral&amp;utm_source=github-checks-link  Simple build rerun has fixed the test.</body>
		<created>2019-02-14 08:31:21</created>
		<closed>2019-06-25 09:26:17</closed>
	</bug>
	<bug>
		<id>4557</id>
		<title>[Google Sheets] squeezed icon on settings page</title>
		<body>Google Sheets icon looks squeezed on settings page. Perhaps because PNG icon source is used instead of SVG?  ![Bildschirmfoto 2019-02-13 um 21.30.56.png](https://images.zenhubusercontent.com/5be31e5e6d41381168d0a8e7/3798c128-d0da-4f70-954f-c1866293dd60)</body>
		<created>2019-02-13 20:35:47</created>
		<closed>2019-03-06 09:10:51</closed>
	</bug>
	<bug>
		<id>4544</id>
		<title>google-sheets: pivot table doesn't start at beginning of the sheet</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Pivot table isn't created at beginning of the blank sheet but at others positions. In my case it was G2 and T2.  it looks like it's starting next to selected range ( when START property isn't specified). This might lead to overwrite data if we are getting only some subset of data. I'd suggest either make START property mandatory or just start from A1 if `sheetID` is different than `sourceSheetID`. WDYT?</body>
		<created>2019-02-13 09:51:21</created>
		<closed>2019-02-18 15:48:38</closed>
	</bug>
	<bug>
		<id>4542</id>
		<title>Unable to use OpenAPI document from URL to create API provider/custom API connector</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ x ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  I tried to create a new CustomAPI connector and API provider using the petstore swagger.json from this URL: http://petstore.swagger.io/v2/swagger.json  There is this message displayed: ```Unable to read OpenAPI document from: http://petstore.swagger.io/v2/swagger.json ```  The server pod error message: ``` 2019-02-13 07:55:46.548 ERROR [-,76d7f5dca706a24c,76d7f5dca706a24c,false] 1 --- [  XNIO-3 task-6] i.s.s.a.g.swagger.SwaggerAPIGenerator    : An error occurred while trying to validate a API -- ```  The local copy of petstore swagger.json works as expected.   Server log is attached:  [serverlog.txt](https://github.com/syndesisio/syndesis/files/2859367/serverlog.txt)   ## Screenshot ![unable_to_read_openapi_document](https://user-images.githubusercontent.com/4180208/52695846-cd129a80-2f6d-11e9-9ac4-d2fdef206b69.png) </body>
		<created>2019-02-13 08:02:23</created>
		<closed>2019-02-22 07:46:23</closed>
	</bug>
	<bug>
		<id>4535</id>
		<title>Embedded apicurio has height of 0</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; We're not showing the embedded Apicurio editor, the `&lt;div class="editor-outline"&gt;` has a computed height of `0`. This is on `Review/Edit` of Custom API connectors feature.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlisting the acceptance criteria. --&gt; See the whole editor.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![screenshot from 2019-02-12 15-53-29](https://user-images.githubusercontent.com/1306050/52644141-90e42900-2ede-11e9-9729-fee2a4c0f419.png)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Go to Customizations / API Client Connector 2. Provide any OpenAPI 2.0 document 3. Click on Review/Edit  </body>
		<created>2019-02-12 14:56:33</created>
		<closed>2019-02-13 14:28:42</closed>
	</bug>
	<bug>
		<id>4527</id>
		<title>Basic filter, advanced filter, split, template steps as "Finish connection"</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  It's possible now to set the basic filter, advanced filter, split, template steps as finish connections, which is however not right from user POV.  ## Screenshot ![end_step](https://user-images.githubusercontent.com/4180208/52631286-b3664a00-2ebe-11e9-8bd7-b7cc841f417e.png) </body>
		<created>2019-02-12 11:07:38</created>
		<closed>2019-02-22 08:30:51</closed>
	</bug>
	<bug>
		<id>4523</id>
		<title>NullPointerException - DataManager - server pod</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description NPE, more in the attached log.  I can't create an integration, syndesis freezes in an integration editor (might be only one of the symptoms)  [syndesis-server-1 (1).log](https://github.com/syndesisio/syndesis/files/2855196/syndesis-server-1.1.log) </body>
		<created>2019-02-12 10:06:02</created>
		<closed>2019-02-26 12:25:48</closed>
	</bug>
	<bug>
		<id>4520</id>
		<title>Twitter search "ignore previously found" is off center</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  When I select the search operation in twitter component, the "ignore previously found" text is off center with the checkbox and the popup help.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![tw_off_center](https://user-images.githubusercontent.com/4180208/52621243-12b86000-2ea7-11e9-98cf-9349df8a4913.png) </body>
		<created>2019-02-12 08:17:55</created>
		<closed>2019-03-04 08:00:23</closed>
	</bug>
	<bug>
		<id>4515</id>
		<title>Error handling update event ChangeEvent{kind=connection} after upgrade (related to the split step)</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description this is related to this: https://github.com/syndesisio/syndesis/commit/651e87f5aff91ce59fdb38258d2ae046b848f6aa  I deployed syndesis version `1.6.1-20190115`, created integration `periodic sql invocation (select * from contact) -&gt; log`  Then I upgraded to `1.6.1-20190211` and during the upgrade, the integration was edited to use the new split step. When the server pod starts, it throws this warning:  ``` 2019-02-11 16:46:12.986  WARN [-,,,] 1 --- [ler (scheduler)] i.s.s.u.c.b.IntegrationUpdateHandler     : Error handling update event ChangeEvent{kind=connection} java.util.NoSuchElementException: No value present at java.util.Optional.get(Optional.java:135) ~[na:1.8.0_151] at io.syndesis.common.model.support.Equivalencer.equivalent(Equivalencer.java:404) ~[common-model-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.common.model.support.Equivalencer.equivalent(Equivalencer.java:339) ~[common-model-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.server.update.controller.bulletin.IntegrationUpdateHandler.computeDeploymentDifferences(IntegrationUpdateHandler.java:413) [server-update-controller-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.server.update.controller.bulletin.IntegrationUpdateHandler.compute(IntegrationUpdateHandler.java:370) [server-update-controller-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.server.update.controller.bulletin.AbstractResourceUpdateHandler.process(AbstractResourceUpdateHandler.java:62) ~[server-update-controller-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.server.update.controller.bulletin.IntegrationUpdateHandler.process(IntegrationUpdateHandler.java:57) [server-update-controller-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.server.update.controller.ResourceUpdateController.run(ResourceUpdateController.java:107) [server-update-controller-1.6.1-20190211.jar!/:1.6.1-20190211] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_151] at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) ~[na:1.8.0_151] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) ~[na:1.8.0_151] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) ~[na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_151] at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_151] ```  When I create a new integration (the same, sql -&gt; log), similar warnings appear in the log:  ``` 2019-02-11 16:46:22.218  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [qwqe]: Starting deployment 2019-02-11 16:46:32.086  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [qwqe]: Deployment done 2019-02-11 16:46:32.321  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [qwqe]: Build started: false, isRunning: false, Deployment ready: false 2019-02-11 16:46:32.323  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [qwqe]: [PENDING] [{buildv1=172.30.1.1:5000/syndesis/i-qwqe:1, deploy=1}] 2019-02-11 16:46:32.324  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.i.IntegrationController          : Integration i-LYSRE95P3Q_r0Eymb11z : Setting status to Pending 2019-02-11 16:46:35.811  INFO [-,,,] 1 --- [oller Scheduler] i.s.s.c.i.IntegrationController          : Checking integrations for their status. 2019-02-11 16:47:32.425  INFO [-,,,] 1 --- [oller Scheduler] i.s.s.c.i.IntegrationController          : Integration i-LYSRE95P3Q_r0Eymb11z:1 : Desired status "Published" != current status "Unpublished" --&gt; calling status change handler 2019-02-11 16:47:32.425  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.i.IntegrationController          : Integration i-LYSRE95P3Q_r0Eymb11z : Start processing integration: i-LYSRE95P3Q_r0Eymb11z, version: 1 with handler:PublishHandler 2019-02-11 16:47:32.486  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [qwqe]: Build started: false, isRunning: false, Deployment ready: false 2019-02-11 16:47:32.487  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [qwqe]: Steps performed so far: {buildv1=172.30.1.1:5000/syndesis/i-qwqe:1} 2019-02-11 16:47:32.791  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [qwqe]: Skipped step buildv1 because already performed 2019-02-11 16:47:32.824  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [qwqe]: Starting deployment 2019-02-11 16:47:33.292  WARN [-,,,] 1 --- [ler (scheduler)] i.s.s.u.c.b.IntegrationUpdateHandler     : Error handling update event ChangeEvent{action=updated, kind=integration, id=i-LYSRE95P3Q_r0Eymb11z} java.util.NoSuchElementException: No value present at java.util.Optional.get(Optional.java:135) ~[na:1.8.0_151] at io.syndesis.common.model.support.Equivalencer.equivalent(Equivalencer.java:404) ~[common-model-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.common.model.support.Equivalencer.equivalent(Equivalencer.java:339) ~[common-model-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.server.update.controller.bulletin.IntegrationUpdateHandler.computeDeploymentDifferences(IntegrationUpdateHandler.java:413) [server-update-controller-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.server.update.controller.bulletin.IntegrationUpdateHandler.compute(IntegrationUpdateHandler.java:370) [server-update-controller-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.server.update.controller.bulletin.AbstractResourceUpdateHandler.process(AbstractResourceUpdateHandler.java:62) ~[server-update-controller-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.server.update.controller.bulletin.IntegrationUpdateHandler.process(IntegrationUpdateHandler.java:57) [server-update-controller-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.server.update.controller.ResourceUpdateController.run(ResourceUpdateController.java:128) [server-update-controller-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.server.update.controller.ResourceUpdateController.lambda$onEvent$0(ResourceUpdateController.java:90) [server-update-controller-1.6.1-20190211.jar!/:1.6.1-20190211] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_151] at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_151] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) ~[na:1.8.0_151] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) ~[na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_151] at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_151] 2019-02-11 16:47:35.812  INFO [-,,,] 1 --- [oller Scheduler] i.s.s.c.i.IntegrationController          : Checking integrations for their status. 2019-02-11 16:47:36.489  WARN [-,,,] 1 --- [ler (scheduler)] i.s.s.u.c.b.IntegrationUpdateHandler     : Error handling update event ChangeEvent{action=updated, kind=connection, id=5} java.util.NoSuchElementException: No value present at java.util.Optional.get(Optional.java:135) ~[na:1.8.0_151] at io.syndesis.common.model.support.Equivalencer.equivalent(Equivalencer.java:404) ~[common-model-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.common.model.support.Equivalencer.equivalent(Equivalencer.java:339) ~[common-model-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.server.update.controller.bulletin.IntegrationUpdateHandler.computeDeploymentDifferences(IntegrationUpdateHandler.java:413) [server-update-controller-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.server.update.controller.bulletin.IntegrationUpdateHandler.compute(IntegrationUpdateHandler.java:370) [server-update-controller-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.server.update.controller.bulletin.AbstractResourceUpdateHandler.process(AbstractResourceUpdateHandler.java:62) ~[server-update-controller-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.server.update.controller.bulletin.IntegrationUpdateHandler.process(IntegrationUpdateHandler.java:57) [server-update-controller-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.server.update.controller.ResourceUpdateController.run(ResourceUpdateController.java:128) [server-update-controller-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.server.update.controller.ResourceUpdateController.lambda$onEvent$0(ResourceUpdateController.java:90) [server-update-controller-1.6.1-20190211.jar!/:1.6.1-20190211] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_151] at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_151] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) ~[na:1.8.0_151] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) ~[na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_151] at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_151] 2019-02-11 16:47:37.194  WARN [-,,,] 1 --- [ler (scheduler)] i.s.s.u.c.b.IntegrationUpdateHandler     : Error handling update event ChangeEvent{action=updated, kind=connection, id=log} java.util.NoSuchElementException: No value present at java.util.Optional.get(Optional.java:135) ~[na:1.8.0_151] at io.syndesis.common.model.support.Equivalencer.equivalent(Equivalencer.java:404) ~[common-model-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.common.model.support.Equivalencer.equivalent(Equivalencer.java:339) ~[common-model-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.server.update.controller.bulletin.IntegrationUpdateHandler.computeDeploymentDifferences(IntegrationUpdateHandler.java:413) [server-update-controller-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.server.update.controller.bulletin.IntegrationUpdateHandler.compute(IntegrationUpdateHandler.java:370) [server-update-controller-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.server.update.controller.bulletin.AbstractResourceUpdateHandler.process(AbstractResourceUpdateHandler.java:62) ~[server-update-controller-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.server.update.controller.bulletin.IntegrationUpdateHandler.process(IntegrationUpdateHandler.java:57) [server-update-controller-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.server.update.controller.ResourceUpdateController.run(ResourceUpdateController.java:128) [server-update-controller-1.6.1-20190211.jar!/:1.6.1-20190211] at io.syndesis.server.update.controller.ResourceUpdateController.lambda$onEvent$0(ResourceUpdateController.java:90) [server-update-controller-1.6.1-20190211.jar!/:1.6.1-20190211] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_151] at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_151] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) ~[na:1.8.0_151] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) ~[na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_151] at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_151] 2019-02-11 16:47:42.814  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [qwqe]: Deployment done 2019-02-11 16:47:42.889  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [qwqe]: Build started: false, isRunning: false, Deployment ready: false 2019-02-11 16:47:42.890  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [qwqe]: [PENDING] [{buildv1=172.30.1.1:5000/syndesis/i-qwqe:1, deploy=2}] 2019-02-11 16:47:42.890  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.i.IntegrationController          : Integration i-LYSRE95P3Q_r0Eymb11z : Setting status to Pending ```  Otherwise, the integration seems to be working normally  EDIT: the logs are still about the first integration as it is trying to tell me that I should update it after infrastructure upgrade, but it can't because of some missing value</body>
		<created>2019-02-11 17:00:48</created>
		<closed>2019-03-01 15:32:39</closed>
	</bug>
	<bug>
		<id>4511</id>
		<title>[Google Sheeets] include grid data option is ignored</title>
		<body>Get spreadsheet customizer provides the option `includeGridData` which is `false` by default. When set to true the outcome is safely ignored by the customizer. Remove the option from the customizer as it is also unclear what Google API returns for spreadsheet get operation when this option enabled.</body>
		<created>2019-02-11 15:37:35</created>
		<closed>2019-02-18 15:58:51</closed>
	</bug>
	<bug>
		<id>4509</id>
		<title>Syndesis crashes when creating any integration</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When creating any integration, Syndesis stops working properly when building said integration, after that it alerts you that it can't connect to the server and in a few moments crashes completely.  I have attached log from syndesis-server pod, and even when syndesis-ui starts again and the status is running in openshift console, the ui does not work.  [log.txt](https://github.com/syndesisio/syndesis/files/2851495/log.txt)  </body>
		<created>2019-02-11 14:40:51</created>
		<closed>2019-02-14 16:33:43</closed>
	</bug>
	<bug>
		<id>4501</id>
		<title>[reset-db] In some deployments NPE happens in ActivityTrackingController</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description @zregvart I don't know when this happens but sometimes the reset-db fails with following exception  ``` 2019-02-11 09:32:05.136  WARN [-,a2f614435e64d59e,a2f614435e64d59e,false] 1 --- [  XNIO-3 task-8] i.s.s.e.v.h.tests.TestSupportHandler     : user pista is resetting DB 2019-02-11 09:32:05.137  WARN [-,a2f614435e64d59e,a2f614435e64d59e,false] 1 --- [  XNIO-3 task-8] i.s.s.e.v.h.tests.TestSupportHandler     : user pista is deleting all integration deploymets 2019-02-11 09:32:05.143  WARN [-,a2f614435e64d59e,a2f614435e64d59e,false] 1 --- [  XNIO-3 task-8] i.s.s.e.v.h.tests.TestSupportHandler     : user pista deleted all integration deploymets 2019-02-11 09:32:05.145 ERROR [-,a2f614435e64d59e,a2f614435e64d59e,false] 1 --- [  XNIO-3 task-8] .s.e.v.h.e.SyndesisServerExceptionMapper : Internal Server Exception. null  java.lang.NullPointerException: null at io.syndesis.server.logging.jsondb.controller.ActivityTrackingController.close(ActivityTrackingController.java:221) ~[server-logging-jsondb-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at io.syndesis.server.logging.jsondb.controller.ActivityTrackingController.stop(ActivityTrackingController.java:213) ~[server-logging-jsondb-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at java.util.LinkedHashMap$LinkedValues.forEach(LinkedHashMap.java:608) ~[na:1.8.0_151] at io.syndesis.server.endpoint.v1.handler.tests.TestSupportHandler.stopControllers(TestSupportHandler.java:139) ~[server-endpoint-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at io.syndesis.server.endpoint.v1.handler.tests.TestSupportHandler.resetDBToDefault(TestSupportHandler.java:85) ~[server-endpoint-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at sun.reflect.GeneratedMethodAccessor719.invoke(Unknown Source) ~[na:na] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151] at org.jboss.resteasy.core.MethodInjectorImpl.invoke(MethodInjectorImpl.java:140) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.internalInvokeOnTarget(ResourceMethodInvoker.java:509) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTargetAfterFilter(ResourceMethodInvoker.java:399) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.lambda$invokeOnTarget$0(ResourceMethodInvoker.java:363) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:358) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTarget(ResourceMethodInvoker.java:365) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:337) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:310) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:443) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.lambda$invoke$4(SynchronousDispatcher.java:233) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.lambda$preprocess$0(SynchronousDispatcher.java:139) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:358) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.preprocess(SynchronousDispatcher.java:142) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:219) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.ServletContainerDispatcher.service(ServletContainerDispatcher.java:227) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:56) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:51) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) ~[javax.servlet-api-3.1.0.jar!/:3.1.0] at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:111) ~[spring-boot-actuator-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.authentication.preauth.AbstractPreAuthenticatedProcessingFilter.doFilter(AbstractPreAuthenticatedProcessingFilter.java:121) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.csrf.CsrfFilter.doFilterInternal(CsrfFilter.java:100) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:66) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.cloud.sleuth.instrument.web.TraceFilter.doFilter(TraceFilter.java:186) ~[spring-cloud-sleuth-core-1.2.6.RELEASE.jar!/:1.2.6.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.micrometer.spring.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:106) ~[micrometer-spring-legacy-1.1.2.jar!/:1.1.2] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:103) ~[spring-boot-actuator-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:65) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:132) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.server.Connectors.executeRootHandler(Connectors.java:336) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_151] at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_151] ```  causing the reset-db http call return 500 and failing the test :sob: </body>
		<created>2019-02-11 09:35:36</created>
		<closed>2019-02-12 15:26:32</closed>
	</bug>
	<bug>
		<id>4492</id>
		<title>Errors when don't finishing adding a step</title>
		<body>![grafik](https://user-images.githubusercontent.com/99080/52498826-1c597380-2bda-11e9-9842-b0ddc85a559a.png)  While trying to add a step, but don't really chose one, and selecting "Save" for the integration, I ended up in this state shown above.</body>
		<created>2019-02-08 18:46:31</created>
		<closed>2019-05-16 19:16:09</closed>
	</bug>
	<bug>
		<id>4491</id>
		<title>Stranged default when using a Cron Timer</title>
		<body>![grafik](https://user-images.githubusercontent.com/99080/52498505-48c0c000-2bd9-11e9-8623-f9a61573d7c3.png)  The text field is initialized with '+' as separators. Shouldn't this be " " ?  BTW, from an UX point of view it would be far better to allow 5 input fields with labels like "minute" "hour" .... for every column, I never can memorize the order of these columns. </body>
		<created>2019-02-08 18:41:16</created>
		<closed>2019-03-04 14:11:10</closed>
	</bug>
	<bug>
		<id>4490</id>
		<title>Error when defining a simple Timer</title>
		<body>![grafik](https://user-images.githubusercontent.com/99080/52498316-c33d1000-2bd8-11e9-98ab-20fd65067dd9.png)  What does 'check your sorting arguments' mean ?</body>
		<created>2019-02-08 18:36:22</created>
		<closed>2019-02-09 13:41:44</closed>
	</bug>
	<bug>
		<id>4488</id>
		<title>API provider integration definition seems to be broken</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ x ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When trying to create an API provider based integration - it's not really working ATM  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![out](https://user-images.githubusercontent.com/4180208/52487528-240b1f00-2bbe-11e9-9978-b49d0e4c534a.gif)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create a new integration 2. Select URL for API definition - e.g. http://petstore.swagger.io/v2/swagger.json 3. select option e.g. GET /pet/{petId} 4. the view does not work right </body>
		<created>2019-02-08 15:27:13</created>
		<closed>2019-02-11 17:52:21</closed>
	</bug>
	<bug>
		<id>4487</id>
		<title>Creating API provider based integration - cancel/save/publish buttons behavior broken</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ x ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  I was trying to create new API based integration - the buttons cancel/save/publish seem to be broken in the API provider definition phase.   ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![out](https://user-images.githubusercontent.com/4180208/52487125-2751db00-2bbd-11e9-9635-e937dbb64069.gif)  </body>
		<created>2019-02-08 15:18:25</created>
		<closed>2019-02-13 09:30:43</closed>
	</bug>
	<bug>
		<id>4486</id>
		<title>"Please check your sorting arguments" when specifying "To: AMQ"</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Steps to reproduce: - `./syndesis install --project syndesis -y --test-support` - deploy amq broker, for example `https://raw.githubusercontent.com/syndesisio/syndesis-qe/master/utilities/src/main/resources/templates/syndesis-amq.yml` - `oc new-app syndesis-amq -p MQ_USERNAME=amq -p MQ_PASSWORD=topSecret` - create activemq connection - create route  - from AMQ (queue, "queue1") - everything ok at this point - to AMQ (queue, "queue2") - click "Next" and error message will pop up  Exception from server pod:  ``` 2019-02-08 15:01:02.169 ERROR [-,e472f3f5dd72f3f6,e472f3f5dd72f3f6,false] 1 --- [  XNIO-3 task-5] s.e.v.h.e.IllegalArgumentExceptionMapper : Illegal Argument on Call Not supported property type class java.lang.Boolean java.lang.IllegalArgumentException: Not supported property type class java.lang.Boolean at io.syndesis.server.endpoint.v1.handler.connection.ConnectionActionHandler.enrichWithMetadata(ConnectionActionHandler.java:113) ~[server-endpoint-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_151] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_151] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151] at org.jboss.resteasy.core.MethodInjectorImpl.invoke(MethodInjectorImpl.java:140) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.internalInvokeOnTarget(ResourceMethodInvoker.java:509) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTargetAfterFilter(ResourceMethodInvoker.java:399) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.lambda$invokeOnTarget$0(ResourceMethodInvoker.java:363) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:358) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTarget(ResourceMethodInvoker.java:365) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:337) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceLocatorInvoker.invokeOnTargetObject(ResourceLocatorInvoker.java:137) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceLocatorInvoker.invoke(ResourceLocatorInvoker.java:100) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:443) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.lambda$invoke$4(SynchronousDispatcher.java:233) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.lambda$preprocess$0(SynchronousDispatcher.java:139) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:358) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.preprocess(SynchronousDispatcher.java:142) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:219) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.ServletContainerDispatcher.service(ServletContainerDispatcher.java:227) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:56) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:51) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) ~[javax.servlet-api-3.1.0.jar!/:3.1.0] at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:111) ~[spring-boot-actuator-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.authentication.preauth.AbstractPreAuthenticatedProcessingFilter.doFilter(AbstractPreAuthenticatedProcessingFilter.java:121) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.csrf.CsrfFilter.doFilterInternal(CsrfFilter.java:124) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:66) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.cloud.sleuth.instrument.web.TraceFilter.doFilter(TraceFilter.java:186) ~[spring-cloud-sleuth-core-1.2.6.RELEASE.jar!/:1.2.6.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.micrometer.spring.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:106) ~[micrometer-spring-legacy-1.1.2.jar!/:1.1.2] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:103) ~[spring-boot-actuator-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:65) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:132) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.server.Connectors.executeRootHandler(Connectors.java:336) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_151] at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_151]  ```  ![leim](https://user-images.githubusercontent.com/7081216/52486244-ee186b80-2bba-11e9-8f97-7f757cd5c83a.png) </body>
		<created>2019-02-08 15:03:35</created>
		<closed>2019-02-12 15:24:40</closed>
	</bug>
	<bug>
		<id>4485</id>
		<title>Clicking cancel when adding first step does not cancel the action</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When creating new integration - if I e.g. add a connection to gmail, select receive step and then press cancel, the following action is unexpected - I'm redirected to the specification of second step, where the first step remains gmail.   ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![out](https://user-images.githubusercontent.com/4180208/52486166-b5789200-2bba-11e9-82fe-9856ba6c86a8.gif)   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create new integration 2. Select the Gmail connector 3. Select "Receive email" 4. press cancel 5. observe the strange behavior </body>
		<created>2019-02-08 15:01:52</created>
		<closed>2019-02-22 07:29:26</closed>
	</bug>
	<bug>
		<id>4484</id>
		<title>Can't create integration using twitter search as the first step - Please check your sorting arguments</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ x ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description It's not possible to create twitter integrations using the twitter search. Warning with "Please check your sorting arguments" is displayed.  ## Steps to reproduce 1. crete tw connection 2. create new integration with twitter search as the base - it's not possible  ![tw_based_integration](https://user-images.githubusercontent.com/4180208/52485453-2e76ea00-2bb9-11e9-8b8b-a36d0694ebb6.png)   </body>
		<created>2019-02-08 14:50:33</created>
		<closed>2019-02-11 14:11:43</closed>
	</bug>
	<bug>
		<id>4483</id>
		<title>[Datamapper] No supported source data type was found. Data type needs to be configured before Data Mapper step is added.</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Trying to use datamapper in AMQ-&gt;IRC integration:  1) start with AMQ subscribe step 2) specify output datashape as json instance with the specification `{"messageOut":"test"}` 3) add IRC publish message to channel step 4) specify input datashape as json instance with the specification `{"messageIn":"hello"}` 5) put datamapper in between the steps  ![wd3e](https://user-images.githubusercontent.com/7081216/52480027-d6d18200-2baa-11e9-913f-1cd8b18418a8.png)  </body>
		<created>2019-02-08 13:07:54</created>
		<closed>2019-02-13 08:50:02</closed>
	</bug>
	<bug>
		<id>4480</id>
		<title>Changes to the OpenAPI specification that do not modify flows are not saved</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  When editing OpenAPI details that do not affect any flows the updated OpenAPI specification is not stored.  For instance when changing the version property of the OpenAPI document. </body>
		<created>2019-02-08 12:25:27</created>
		<closed>2019-02-25 12:56:59</closed>
	</bug>
	<bug>
		<id>4477</id>
		<title>swagger-core adding superflous `responseSchema` property</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Seems that the Swagger API we use (`swagger-core`) is adding `responseSchema` elements to responses. This triggers schema violation in Apicurio.</body>
		<created>2019-02-08 10:09:33</created>
		<closed>2019-02-26 12:23:35</closed>
	</bug>
	<bug>
		<id>4476</id>
		<title>NumberFormatException at startup when response status of API provider flow is set</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  When the response status is set on a flow of an API provider integration the deployed integration fails to start.  [i-todo-5-brxh4.log](https://github.com/syndesisio/syndesis/files/2844497/i-todo-5-brxh4.log) </body>
		<created>2019-02-08 09:46:22</created>
		<closed>2019-02-22 10:54:55</closed>
	</bug>
	<bug>
		<id>4468</id>
		<title>Incorrectly formated OpenAPI specification served from the integration pod</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  If the example for a definition in an OpenAPI specification contains `\n` it will be taken literally and expanded into a newline breaking the JSON formatting and making the resulting OpenAPI specification invalid.  To reproduce try creating an API provider based integration using _from scratch_ and in the embedded Apicurio editor add a new Data type specifying an example containing newlines. For example:  ```json {    "value": "text" } ```  Then on publish try fetching the OpenAPI specification from the exposed integration pod:  ``` curl https://integration-route/openapi.json ```  This should result in a valid JSON, but it is not because of the example JSON being split over multiple lines, e.g.:  ``` {"swagger":"2.0","info":{"version":"0.0.0","title":"greeting api"},"paths":{"/people":{"get":{"summary":"List All people","description":"Gets a list of all `person` entities.","operationId":"getpeople","responses":{"200":{"description":"Successful response - returns an array of `person` entities.","schema":{"type":"array","items":{"$ref":"#/definitions/person"}},"responseSchema":{"type":"array","items":{"$ref":"#/definitions/person"}}}}},"post":{"summary":"Create a person","description":"Creates a new instance of a `person`.","operationId":"createperson","parameters":[{"in":"body","name":"body","description":"A new `person` to be created.","required":true,"schema":{"$ref":"#/definitions/person"}}],"responses":{"201":{"description":"Successful response."}}}},"/people/{personId}":{"get":{"summary":"Get a person","description":"Gets the details of a single instance of a `person`.","operationId":"getperson","parameters":[{"name":"personId","in":"path","description":"A unique identifier for a `person`.","required":true,"type":"string"}],"responses":{"200":{"description":"Successful response - returns a single `person`.","schema":{"$ref":"#/definitions/person"},"responseSchema":{"$ref":"#/definitions/person"}}}},"put":{"summary":"Update a person","description":"Updates an existing `person`.","operationId":"updateperson","parameters":[{"name":"personId","in":"path","description":"A unique identifier for a `person`.","required":true,"type":"string"},{"in":"body","name":"body","description":"Updated `person` information.","required":true,"schema":{"$ref":"#/definitions/person"}}],"responses":{"202":{"description":"Successful response."}}},"delete":{"summary":"Delete a person","description":"Deletes an existing `person`.","operationId":"deleteperson","parameters":[{"name":"personId","in":"path","description":"A unique identifier for a `person`.","required":true,"type":"string"}],"responses":{"204":{"description":"Successful response."}}}}},"definitions":{"person":{"type":"object","properties":{"name":{"type":"string"}},"title":"Root Type for person","description":"a ","example":"{     \"name\" : \"gary\" }"}}} ```</body>
		<created>2019-02-07 11:43:26</created>
		<closed>2019-04-02 13:15:10</closed>
	</bug>
	<bug>
		<id>4464</id>
		<title>Connection usage reports incorrect integration usage count</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem When inspecting connection details in the UI, it reports in how many integration the connection is used.  I have only one integration: `AMQ -&gt; HTTP -&gt; AMQ`, where both AMQ are from the same connection and when I navigate to AMQ connection details, I get `Usage: Used by 2 integrations`, so it counts one integration two times because it is used twice   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. create amq -&gt; amq integration with the same connection 2. inspect amq connection details</body>
		<created>2019-02-07 08:16:30</created>
		<closed>2019-03-08 15:38:51</closed>
	</bug>
	<bug>
		<id>4462</id>
		<title>The syndesis-server pod fails to start on OCP4</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [*] Bug report   [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  I deployed the Syndesis Operator on an OpenShift cluster created by the OpenShift installer. The operator was deployed successfully after the following commands: ``` $ oc new-project syndesis $ oc apply -f deploy/syndesis-crd.yml $ oc apply -f deploy/syndesis-operator.yml $ oc get templates -n syndesis  $ oc process syndesis-operator -p NAMESPACE=syndesis | oc create -f - ```  I then applied the Syndesis CR: ``` $ oc apply -f deploy/syndesis.yml ```     I then performed a search for available routes and found that a syndesis and todo route existed: ``` $ oc get routes NAME HOST/PORT PATH SERVICES PORT TERMINATION WILDCARD syndesis syndesis-syndesis2.apps.agreene2.devcluster.openshift.com syndesis-oauthproxy 8443 reencrypt/Redirect None todo todo-syndesis-syndesis2.apps.agreene2.devcluster.openshift.com / todo 8080 edge/Allow None ```  Visiting the syndesis route showed that requests for integrations and reservations were failing: ```      Failing Integration Requests: syndesis-syndesis.apps.clusteranik120.devcluster.openshift.com/api/v1/metrics/integrations     Failing Reservation Requests: syndesis-syndesis.apps.clusteranik120.devcluster.openshift.com/api/v1/event/reservations  ```  A quick review of the running pods showed that the syndesis-server pod kept restarting and could not reach a running state, the logs from a short lived pod are attached as [syndesis-server.txt](https://github.com/syndesisio/syndesis/files/2838207/syndesis-server.txt)     </body>
		<created>2019-02-06 21:02:22</created>
		<closed>2019-03-20 13:29:44</closed>
	</bug>
	<bug>
		<id>4459</id>
		<title>Declare DataShape name for Slack connector</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [x] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Declare DataShape name for Slack connector here, otherwise raw FQCN is used in the Data Mapper. https://github.com/syndesisio/syndesis/blob/master/app/connector/slack/src/main/resources/META-INF/syndesis/connector/slack.json#L11-L14  Just like this https://github.com/syndesisio/syndesis/blob/master/app/connector/twitter/src/main/resources/META-INF/syndesis/connector/twitter.json#L18</body>
		<created>2019-02-06 15:57:36</created>
		<closed>2019-03-05 11:49:20</closed>
	</bug>
	<bug>
		<id>4458</id>
		<title>Next button instead of Done</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Why is in the Invoke SQL Next button when after clicking on the button the step is configured. In the previous versions was there Done button. It is confusing to click on the Next button when no next configure page exists for this step.  For the final step, I choose PostgresDB and Invoke SQL and I insert SQL statement. ![image](https://user-images.githubusercontent.com/16251792/52346029-f76cd100-2a1e-11e9-8263-4980f9cb39b6.png) </body>
		<created>2019-02-06 14:19:28</created>
		<closed>2019-09-01 10:30:59</closed>
	</bug>
	<bug>
		<id>4441</id>
		<title>OpenAPI v3.0 customization freezes Syndesis frontend</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Trying to create an API client connector with OpenAPI v3.0 to freezes the frontend of Syndesis. Note that nowhere in the page is specified which version should be used. As an example I used [https://raw.githubusercontent.com/OAI/OpenAPI-Specification/master/examples/v3.0/petstore.yaml](https://raw.githubusercontent.com/OAI/OpenAPI-Specification/master/examples/v3.0/petstore.yaml). No link can be clicked, only way to get out of that situation is to enter a new URL or refresh. OpenAPI v2.0 work just fine.  </body>
		<created>2019-02-05 15:11:30</created>
		<closed>2019-06-06 07:38:43</closed>
	</bug>
	<bug>
		<id>4437</id>
		<title>StackOverflowError when trying to create custom API connector based on OpenHAB API</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  I was trying to create a custom API connector using the OpenHAB API specification, it however seems to be not possible.   The swagger.json example can be found here: http://demo.openhab.org:8080/rest/swagger.json  Attached the server log. [server_log.txt](https://github.com/syndesisio/syndesis/files/2831265/server_log.txt) </body>
		<created>2019-02-05 08:11:42</created>
		<closed>2019-03-12 06:59:39</closed>
	</bug>
	<bug>
		<id>4427</id>
		<title>Inability to create data mapping until first publish</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description It seems that it is not possible to create data mappings when first creating integrations, at least when working with templates. Either the data mapping reports an error that the data type of step below should be specified (step below was always template). ![screenshot from 2019-02-04 16-04-31](https://user-images.githubusercontent.com/46345469/52216633-ff016e00-2896-11e9-9dac-5fb2edb08886.png) Or it seemed like somehow was storing errors from previous mappings and trying to apply those (will provide a screenshot and steps to reproduce when I manage to reproduce it). You can get to data mapping configuration only after publishing it and later editing, only then is the data mapping accessible without any errors.  After publishing:  ![screenshot from 2019-02-04 16-14-52](https://user-images.githubusercontent.com/46345469/52217092-0aa16480-2898-11e9-9481-69f6a3c83425.png)   </body>
		<created>2019-02-04 15:15:50</created>
		<closed>2019-04-01 14:40:35</closed>
	</bug>
	<bug>
		<id>4425</id>
		<title>Eliminate log connection in favor of the log step</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [x] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description There's a log step and a log connection.  We can get rid of the log connection if we make it possible to use steps in the last spot in a flow.  1)  Remove this stuff -&gt; https://github.com/syndesisio/syndesis/blob/master/app/ui/src/app/integration/edit-page/flow-functions.ts#L170-L177 2)  Test it, revisit #1 if broken and repeat until working 3)  Ask someone nicely to remove the log connection  </body>
		<created>2019-02-04 14:39:49</created>
		<closed>2019-06-07 16:06:43</closed>
	</bug>
	<bug>
		<id>4413</id>
		<title>[Upgrade] Scripts in "minorVersion" folder are not handled during upgrade to daily build</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description This is related to community only, during productized build the productization handles this.  Currently, the upgrade doesn't work well for the daily version when upgrading between major versions with added functionality - the migration scripts are expected to be present in the directory with the exact name of the version we are upgrading to.  For example, we have this file https://github.com/syndesisio/syndesis/blob/master/tools/upgrade/migration/resource/1.6/01_db_metrics_config_map.sh in the `1.6` folder, that is not picked up automatically during an upgrade to `1.6.1-20190131`.  First thing that comes to my mind was to move the content of `1.6` folder to `current_daily_version` during the build of upgrade image if it is possible  @rhuss wdyt?</body>
		<created>2019-02-01 11:07:07</created>
		<closed>2019-03-21 10:22:27</closed>
	</bug>
	<bug>
		<id>4412</id>
		<title>[Rollback] Pretty-print failed steps doesn't print newlines</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11439**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When some step fails during rollback, it will be printed after the execution, I fixed the misspelled variable name in https://github.com/syndesisio/syndesis/pull/4411 , but then the new lines are not printed:  ``` ========================================== !!!!!!!!! Errors during Rollback !!!!!!!!!  The following rollback compensation steps caused an error     * migrate_db\n  The setup is very likely broken now and you have to manually fix it. Please check the log output above for any detailed error messages. ========================================== ``` </body>
		<created>2019-02-01 10:51:41</created>
		<closed>2019-09-07 11:29:27</closed>
	</bug>
	<bug>
		<id>4410</id>
		<title>[Rollback] db-metrics pod causes rollback to fail</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Trying to upgrade from `1.5.9` to `1.6.1-20190131`, with artificial rollback added after `upgrade_50_replace_template` Actually, there are 2 issues in rollback: - 1) upgrade scripts do not count with new pods introduced in the newer version, so the pod `syndesis-db-metrics` isn't deleted during rollback - 2) `syndesis-db-metrics` causes problems during rollback of `migrate-database`, because the `migrate-database` is searching for `syndesis-db` pod, that results in this response:  ``` oc get pod -o custom-columns=:.metadata.name | tail -n +2 | grep "syndesis-db" syndesis-db-1-xlgnh syndesis-db-metrics-1-jhcrl ``` and in this error:  ``` Unable to use a TTY - input is not a terminal or the right kind of file rpc error: code = 2 desc = oci runtime error: exec failed: container_linux.go:247: starting container process caused "exec: \"syndesis-db-metrics-1-jhcrl\": executable file not found in $PATH"  error: Internal error occurred: error executing command in container: read unix @-&gt;/var/run/docker.sock: read: connection reset by peer  ```  Full upgrade log:  ``` Logged into "https://192.168.99.100:8443" as "developer" using the token provided.  You have access to the following projects and can switch between them with 'oc project &lt;projectname&gt;':      default     kube-dns     kube-proxy     kube-public     kube-system     myproject     openshift     openshift-apiserver     openshift-controller-manager     openshift-core-operators     openshift-infra     openshift-node     openshift-service-cert-signer     openshift-web-console   * syndesis  Using project "syndesis". ### ----------------------------------------- ### PREFLIGHT CHECK ### Upgrade from 1.5.9 (1.5) --&gt; 1.6.1-20190131 ### ### --&gt; OK ### -----------------------------------------  ============================================= === STARTING UPGRADE TO SYNDESIS 1.6.1-20190131  =============================================  === * Backup Resource objects (prep_10_backup_resources)       - ConfigMap         * syndesis-db-conf         * syndesis-meta-config         * syndesis-prometheus-config         * syndesis-sampledb-config         * syndesis-server-config         * syndesis-ui-config       - Secret         * syndesis-global-config         * syndesis-oauth-proxy-cookie-secret         * syndesis-server-secret       - DeploymentConfig         * syndesis-db         * syndesis-meta         * syndesis-oauthproxy         * syndesis-prometheus         * syndesis-server         * syndesis-ui       - Service         * syndesis-db         * syndesis-meta         * syndesis-oauthproxy         * syndesis-prometheus         * syndesis-server         * syndesis-ui       - Route         * syndesis       - RoleBinding         * syndesis:viewers       - ServiceAccount         * syndesis-integration         * syndesis-prometheus         * syndesis-server       - Template         * syndesis         * syndesis-upgrade       - PersistentVolumeClaim         * syndesis-db         * syndesis-meta         * syndesis-prometheus         * syndesis-upgrade       - BuildConfig === * Stopping syndesis-server (prep_15_stop) deploymentconfig.apps.openshift.io "syndesis-server" scaled deploymentconfig.apps.openshift.io "syndesis-meta" scaled Waiting for syndesis-server to be scaled to 0 NAME                          READY     STATUS        RESTARTS   AGE httpendpoints-1-924kp         1/1       Running       0          4m i-upgrade-1-build             0/1       Completed     0          2m i-upgrade-2-4ghl6             1/1       Running       0          1m syndesis-db-1-497ws           1/1       Running       0          6m syndesis-meta-1-b9nzr         1/1       Running       0          6m syndesis-oauthproxy-1-62gc4   1/1       Running       0          6m syndesis-prometheus-1-sk6pv   1/1       Running       0          6m syndesis-server-1-7g8b4       1/1       Terminating   0          6m syndesis-ui-1-4l6t8           1/1       Running       0          6m todo-1-build                  0/1       Completed     0          6m todo-1-lzgql                  1/1       Running       0          5m syndesis-meta-1-b9nzr   1/1       Terminating   0         6m Sleeping 10s ... syndesis-server-1-7g8b4   0/1       Terminating   0         6m syndesis-meta-1-b9nzr   0/1       Terminating   0         6m Sleeping 10s ... syndesis-server-1-7g8b4   0/1       Terminating   0         6m syndesis-server-1-7g8b4   0/1       Terminating   0         6m syndesis-meta-1-b9nzr   0/1       Terminating   0         6m syndesis-meta-1-b9nzr   0/1       Terminating   0         6m Waiting for syndesis-meta to be scaled to 0 === * Backup database (prep_20_backup_db) === * Process new template to extract update resources (prep_40_process_template)       - Current Syndesis version "1.5.9"       - Not updating syndesis-server-config === * Migrate database (upgrade_10_migrate_db) Forwarding from 127.0.0.1:5433 -&gt; 5432 Forwarding from [::1]:5433 -&gt; 5432 Handling connection for 5433 Handling connection for 5433 Handling connection for 5433 Handling connection for 5433 Handling connection for 5433 Handling connection for 5433 Handling connection for 5433 Handling connection for 5433 Handling connection for 5433 Handling connection for 5433 11:39:09.831 Current database schema version: 27 11:39:09.837 Starting migration to version: 99 11:39:10.437 Migrating to schema: 98 Starting migration to schema 98 Fetching path: /integrations/:i-LXccIXuywlT-gjoXnd8z/ Migration to schema 98 completed 11:39:11.627 Migrating to schema: 99 Starting migration to schema 99 Fetching path: /integrations/:i-LXccIXuywlT-gjoXnd8z/ Migration to schema 99 completed 11:39:11.851 Migration done === * Stop all deployments (upgrade_20_stop_all)       - Stopping deployments syndesis-db syndesis-meta syndesis-oauthproxy syndesis-prometheus syndesis-server syndesis-ui deploymentconfig.apps.openshift.io "syndesis-db" scaled deploymentconfig.apps.openshift.io "syndesis-meta" scaled deploymentconfig.apps.openshift.io "syndesis-oauthproxy" scaled deploymentconfig.apps.openshift.io "syndesis-prometheus" scaled deploymentconfig.apps.openshift.io "syndesis-server" scaled deploymentconfig.apps.openshift.io "syndesis-ui" scaled Waiting for syndesis-db to be scaled to 0 Sleeping 10s ... NAME                          READY     STATUS        RESTARTS   AGE httpendpoints-1-924kp         1/1       Running       0          5m i-upgrade-1-build             0/1       Completed     0          3m i-upgrade-2-4ghl6             1/1       Running       0          2m syndesis-db-1-497ws           1/1       Terminating   0          6m syndesis-oauthproxy-1-62gc4   1/1       Terminating   0          6m syndesis-prometheus-1-sk6pv   1/1       Terminating   0          6m syndesis-ui-1-4l6t8           1/1       Terminating   0          6m todo-1-build                  0/1       Completed     0          6m todo-1-lzgql                  1/1       Running       0          6m syndesis-prometheus-1-sk6pv   0/1       Terminating   0         6m syndesis-oauthproxy-1-62gc4   0/1       Terminating   0         6m syndesis-ui-1-4l6t8   0/1       Terminating   0         6m syndesis-oauthproxy-1-62gc4   0/1       Terminating   0         6m syndesis-oauthproxy-1-62gc4   0/1       Terminating   0         6m syndesis-ui-1-4l6t8   0/1       Terminating   0         6m syndesis-ui-1-4l6t8   0/1       Terminating   0         6m syndesis-prometheus-1-sk6pv   0/1       Terminating   0         6m syndesis-prometheus-1-sk6pv   0/1       Terminating   0         6m Sleeping 10s ... Sleeping 10s ... syndesis-db-1-497ws   0/1       Terminating   0         7m syndesis-db-1-497ws   0/1       Terminating   0         7m syndesis-db-1-497ws   0/1       Terminating   0         7m syndesis-db-1-497ws   0/1       Terminating   0         7m Waiting for syndesis-meta to be scaled to 0 Waiting for syndesis-oauthproxy to be scaled to 0 Waiting for syndesis-prometheus to be scaled to 0 Waiting for syndesis-server to be scaled to 0 Waiting for syndesis-ui to be scaled to 0 === * Update resources (upgrade_40_update_resources)       - Executing any/01_ensure_sar_project_parameter.sh secret "syndesis-global-config" patched       - Executing 1.6.1-20190131/01_db_metrics_config_map.sh configmap "syndesis-db-metrics-config" created       - Executing 1.6.1-20190131/99-change-ui-config.sh configmap "syndesis-ui-config" replaced       - BuildConfig: update (replace)         * todo       - ConfigMap: skipped       - DeploymentConfig: update (replace)         * syndesis-db         * syndesis-db-metrics           not existing --&gt; trying to create deploymentconfig.apps.openshift.io "syndesis-db-metrics" created         * syndesis-meta         * syndesis-oauthproxy         * syndesis-prometheus         * syndesis-server         * syndesis-ui         * todo       - ImageStream: update (replace)         * oauth-proxy         * postgres_exporter           not existing --&gt; trying to create imagestream.image.openshift.io "postgres_exporter" created         * prometheus         * syndesis-meta         * syndesis-s2i         * syndesis-server         * syndesis-ui         * todo       - PersistentVolumeClaim: skipped       - RoleBinding: skipped       - Route: force update (delete/create)         * syndesis         * todo       - Secret: skipped       - Service: force update (delete/create)         * syndesis-db         * syndesis-meta         * syndesis-oauthproxy         * syndesis-prometheus         * syndesis-server         * syndesis-ui         * todo       - ServiceAccount: force update (delete/create)         * syndesis-integration         * syndesis-prometheus         * syndesis-server       - Template: update (replace)         * syndesis-upgrade === * Replace template (upgrade_50_replace_template)       * Replacing template 'syndesis' template.template.openshift.io "syndesis" deleted template.template.openshift.io "syndesis" replaced       * Updating version to 1.6.1-20190131 secret "syndesis-global-config" patched ====&gt; Error ==&gt; Rollback   ----- Rollback --- * Rolling back 'Replace template'       * Restoring syndesis from /tmp/backup/2019-02-01-1549017512/backup/resources/Template/syndesis.json template.template.openshift.io "syndesis" deleted template.template.openshift.io "syndesis" replaced       * Restoring old version 1.5.9 secret "syndesis-global-config" patched --- * Rolling back 'Update resources'       - BuildConfig: update (replace)       - ConfigMap: update (replace)         * syndesis-db-conf         * syndesis-meta-config         * syndesis-prometheus-config         * syndesis-sampledb-config         * syndesis-server-config         * syndesis-ui-config       - DeploymentConfig: update (replace)         * syndesis-db         * syndesis-meta         * syndesis-oauthproxy         * syndesis-prometheus         * syndesis-server         * syndesis-ui       - PersistentVolumeClaim: update (replace)         * syndesis-db         * syndesis-meta         * syndesis-prometheus         * syndesis-upgrade       - RoleBinding: update (replace)         * syndesis:viewers       - Route: force update (delete/create)         * syndesis       - Secret: update (replace)         * syndesis-global-config         * syndesis-oauth-proxy-cookie-secret         * syndesis-server-secret       - Service: force update (delete/create)         * syndesis-db         * syndesis-meta         * syndesis-oauthproxy         * syndesis-prometheus         * syndesis-server         * syndesis-ui       - ServiceAccount: force update (delete/create)         * syndesis-integration         * syndesis-prometheus         * syndesis-server       - Template: skipped --- * Rolling back 'Stop all deployments'       - Restarting deployments syndesis-db syndesis-db-metrics syndesis-meta syndesis-oauthproxy syndesis-prometheus syndesis-server syndesis-ui deploymentconfig.apps.openshift.io "syndesis-db" scaled deploymentconfig.apps.openshift.io "syndesis-db-metrics" scaled deploymentconfig.apps.openshift.io "syndesis-meta" scaled deploymentconfig.apps.openshift.io "syndesis-oauthproxy" scaled deploymentconfig.apps.openshift.io "syndesis-prometheus" scaled deploymentconfig.apps.openshift.io "syndesis-server" scaled deploymentconfig.apps.openshift.io "syndesis-ui" scaled Waiting for syndesis-db to be scaled to 1 NAME                          READY     STATUS              RESTARTS   AGE httpendpoints-1-924kp         1/1       Running             0          6m i-upgrade-1-build             0/1       Completed           0          4m i-upgrade-2-4ghl6             1/1       Running             0          3m syndesis-db-1-xlgnh           0/1       ContainerCreating   0          1s syndesis-db-metrics-1-jhcrl   0/1       ContainerCreating   0          1s syndesis-meta-3-hnfrq         0/1       ContainerCreating   0          1s syndesis-oauthproxy-1-6hkgj   0/1       Pending             0          1s syndesis-prometheus-1-hxm8x   0/1       Pending             0          1s syndesis-server-3-xcmm2       0/1       Pending             0          1s syndesis-ui-3-npgrr           0/1       Pending             0          0s todo-1-build                  0/1       Completed           0          7m todo-1-lzgql                  1/1       Running             0          7m Sleeping 10s ... syndesis-prometheus-1-hxm8x   0/1       ContainerCreating   0         2s syndesis-oauthproxy-1-6hkgj   0/1       ContainerCreating   0         4s syndesis-server-3-xcmm2   0/1       ContainerCreating   0         6s syndesis-db-metrics-1-jhcrl   0/1       Running   0         8s syndesis-ui-3-npgrr   0/1       Running   0         9s Sleeping 10s ... syndesis-db-1-xlgnh   0/1       Running   0         13s syndesis-oauthproxy-1-6hkgj   0/1       Running   0         13s syndesis-meta-3-hnfrq   0/1       Running   0         13s syndesis-server-3-xcmm2   0/1       Running   0         14s syndesis-prometheus-1-hxm8x   0/1       Running   0         14s syndesis-db-1-xlgnh   1/1       Running   0         14s syndesis-ui-3-npgrr   1/1       Running   0         14s syndesis-oauthproxy-1-6hkgj   1/1       Running   0         21s Waiting for syndesis-db-metrics to be scaled to 1 Sleeping 10s ... syndesis-meta-3-hnfrq   1/1       Running   0         28s Sleeping 10s ... syndesis-prometheus-1-hxm8x   1/1       Running   0         39s Sleeping 10s ... Sleeping 10s ... Sleeping 10s ... Sleeping 10s ... syndesis-server-3-xcmm2   1/1       Running   0         1m Sleeping 10s ... Sleeping 10s ... Sleeping 10s ... syndesis-db-metrics-1-jhcrl   0/1       Running   1         1m Sleeping 10s ... Sleeping 10s ... Sleeping 10s ... Sleeping 10s ... syndesis-db-metrics-1-jhcrl   1/1       Running   1         2m Waiting for syndesis-meta to be scaled to 1 Waiting for syndesis-oauthproxy to be scaled to 1 Waiting for syndesis-prometheus to be scaled to 1 Waiting for syndesis-server to be scaled to 1 Waiting for syndesis-ui to be scaled to 1 --- * Rolling back 'Migrate database' deploymentconfig.apps.openshift.io "syndesis-server" scaled deploymentconfig.apps.openshift.io "syndesis-meta" scaled Waiting for syndesis-server to be scaled to 0 Sleeping 10s ... NAME                          READY     STATUS        RESTARTS   AGE httpendpoints-1-924kp         1/1       Running       0          8m i-upgrade-1-build             0/1       Completed     0          6m i-upgrade-2-4ghl6             1/1       Running       0          5m syndesis-db-1-xlgnh           1/1       Running       0          2m syndesis-db-metrics-1-jhcrl   1/1       Running       1          2m syndesis-meta-3-hnfrq         1/1       Terminating   0          2m syndesis-oauthproxy-1-6hkgj   1/1       Running       0          2m syndesis-prometheus-1-hxm8x   1/1       Running       0          2m syndesis-server-3-xcmm2       1/1       Terminating   0          2m syndesis-ui-3-npgrr           1/1       Running       0          2m todo-1-build                  0/1       Completed     0          10m todo-1-lzgql                  1/1       Running       0          9m syndesis-server-3-xcmm2   0/1       Terminating   0         2m syndesis-meta-3-hnfrq   0/1       Terminating   0         2m syndesis-meta-3-hnfrq   0/1       Terminating   0         2m syndesis-meta-3-hnfrq   0/1       Terminating   0         2m syndesis-server-3-xcmm2   0/1       Terminating   0         2m syndesis-server-3-xcmm2   0/1       Terminating   0         2m Waiting for syndesis-meta to be scaled to 0 Unable to use a TTY - input is not a terminal or the right kind of file rpc error: code = 2 desc = oci runtime error: exec failed: container_linux.go:247: starting container process caused "exec: \"syndesis-db-metrics-1-jhcrl\": executable file not found in $PATH"  error: Internal error occurred: error executing command in container: read unix @-&gt;/var/run/docker.sock: read: connection reset by peer ====&gt; Rollback Error !! ====&gt; Continuing with rollback (specify --stop-on-rollback-error to stop here) --- * Rolling back 'Process new template to extract update resources' --- * Rolling back 'Backup database' --- * Rolling back 'Stopping syndesis-server' deploymentconfig.apps.openshift.io "syndesis-server" scaled deploymentconfig.apps.openshift.io "syndesis-meta" scaled Waiting for syndesis-server to be scaled to 1 Sleeping 10s ... NAME                          READY     STATUS              RESTARTS   AGE httpendpoints-1-924kp         1/1       Running             0          8m i-upgrade-1-build             0/1       Completed           0          6m i-upgrade-2-4ghl6             1/1       Running             0          6m syndesis-db-1-xlgnh           1/1       Running             0          2m syndesis-db-metrics-1-jhcrl   1/1       Running             1          2m syndesis-oauthproxy-1-6hkgj   1/1       Running             0          2m syndesis-prometheus-1-hxm8x   1/1       Running             0          2m syndesis-server-3-26x6d       0/1       ContainerCreating   0          1s syndesis-ui-3-npgrr           1/1       Running             0          2m todo-1-build                  0/1       Completed           0          10m todo-1-lzgql                  1/1       Running             0          10m syndesis-meta-3-ljqk6   0/1       Pending   0         0s syndesis-meta-3-ljqk6   0/1       Pending   0         0s syndesis-meta-3-ljqk6   0/1       ContainerCreating   0         0s syndesis-server-3-26x6d   0/1       Running   0         3s syndesis-meta-3-ljqk6   0/1       Running   0         3s Sleeping 10s ... Sleeping 10s ... Sleeping 10s ... syndesis-meta-3-ljqk6   1/1       Running   0         34s Sleeping 10s ... Sleeping 10s ... Sleeping 10s ... todo-2-build   0/1       Pending   0         1s todo-2-build   0/1       Pending   0         1s todo-2-build   0/1       Init:0/2   0         1s todo-2-build   0/1       Init:0/2   0         3s Sleeping 10s ... todo-2-build   0/1       Init:1/2   0         8s todo-2-build   0/1       Init:1/2   0         9s todo-2-build   0/1       PodInitializing   0         10s todo-2-build   1/1       Running   0         11s Sleeping 10s ... syndesis-server-3-26x6d   1/1       Running   0         1m Waiting for syndesis-meta to be scaled to 1  ```</body>
		<created>2019-02-01 10:46:56</created>
		<closed>2019-03-06 15:15:15</closed>
	</bug>
	<bug>
		<id>4407</id>
		<title>The Log step doesn't show body properly</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The Log step doesn't show body from webhook correctly. ![image](https://user-images.githubusercontent.com/16251792/52064074-21804800-2574-11e9-9889-ff5ae69fb359.png)  actual version: ``` Body: [[org.apache.camel.converter.stream.InputStreamCache@704f438]] before basic filter ``` previous version: ``` Body: [{"first_name":"John","company":"incorrect company"}] before basic filter ```  Step to reproduce: 1. import project  [Webhook.to.DB-export.zip](https://github.com/syndesisio/syndesis/files/2817834/Webhook.to.DB-export.zip) 2. Publish it 3. Post  ``` {"first_name":"John","company":"incorrect company"} ``` to the webhook 4. Look to the activity tab. </body>
		<created>2019-01-31 15:23:48</created>
		<closed>2019-02-05 09:47:02</closed>
	</bug>
	<bug>
		<id>4403</id>
		<title>Excessive Docker process mounts</title>
		<body>Firstly, this could be completely unrelated to Syndesis and may simply be a general docker problem on my system. However, putting it out there in case someone has more a clue than I.  So, running my laptop for a single day (turned on at 9am), worked for the day (maybe recompiled Syndesis images a few times and reloaded them into Openshift) then finished in the afternoon and left my laptop on. The laptop was not doing much of anything so left it running to come back to work the following morning - so 24 hours uptime.  Starting on the laptop and try to download a file in firefox but it cannot open a file dialog. Neither can meld or any other glib application since CPU load goes ridiculously high. This has happened before and I have always rebooted and its cleared. This time I attach gdb to both firefox and meld and this is what I saw:  ``` #0  0x00007f3d057e9add in mnt_table_next_fs () at /lib64/libmount.so.1 #1  0x00007f3d057ea03e in mnt_table_uniq_fs () at /lib64/libmount.so.1 #2  0x00007f3d05fe2739 in  () at /lib64/libgio-2.0.so.0 #3  0x00007f3d05fe54af in  () at /lib64/libgio-2.0.so.0 #4  0x00007f3d05da598a in g_type_create_instance () at /lib64/libgobject-2.0.so.0 #5  0x00007f3d05d88058 in  () at /lib64/libgobject-2.0.so.0 #6  0x00007f3d05d897a5 in g_object_new_with_properties () at /lib64/libgobject-2.0.so.0 #7  0x00007f3d05d8a361 in g_object_new () at /lib64/libgobject-2 ``` So libmount is being very busy with something.  Looking at mounts in /etc/mtab, it turns out those 24 hours have accrued 13467 mounts of which 98% are tmpfs mounts from docker, eg.  ``` tmpfs /home/openshift/docker-os/openshift.local.volumes/pods/35d86740-fc8a-11e8-972d-80fa5b4838ee/volumes/kubernetes.io~secret/registry-token-ng55c tmpfs rw,relatime 0 0 tmpfs /home/openshift/docker-os/openshift.local.volumes/pods/216f76ec-fc8a-11e8-972d-80fa5b4838ee/volumes/kubernetes.io~secret/webconsole-token-k5nvk tmpfs rw,relatime 0 0 tmpfs /home/openshift/docker-os/openshift.local.volumes/pods/216f76ec-fc8a-11e8-972d-80fa5b4838ee/volumes/kubernetes.io~secret/serving-cert tmpfs rw,relatime 0 0 tmpfs /home/openshift/docker-os/openshift.local.volumes/pods/b8611911-fc8d-11e8-972d-80fa5b4838ee/volumes/kubernetes.io~secret/syndesis-oauth-client-token-cszcc tmpfs rw,relatime 0 0 tmpfs /home/openshift/docker-os/openshift.local.volumes/pods/10bff5b4-181a-11e9-b9d4-80fa5b4838ee/volumes/kubernetes.io~secret/default-token-v9v6f tmpfs rw,relatime 0 0 tmpfs /home/openshift/docker-os/openshift.local.volumes/pods/b7fac6b9-fc8d-11e8-972d-80fa5b4838ee/volumes/kubernetes.io~secret/default-token-v9v6f tmpfs rw,relatime 0 0 tmpfs /home/openshift/docker-os/openshift.local.volumes/pods/88530d36-2309-11e9-aff1-80fa5b4838ee/volumes/kubernetes.io~secret/secret-volume tmpfs rw,relatime 0 0 tmpfs /home/openshift/docker-os/openshift.local.volumes/pods/88530d36-2309-11e9-aff1-80fa5b4838ee/volumes/kubernetes.io~secret/default-token-v9v6f tmpfs rw,relatime 0 0 /home/openshift/docker-os/openshift.local.volumes/pods/159ebdbd-248c-11e9-98bc-80fa5b4838ee/volumes/kubernetes.io~secret/syndesis-server-token-c7hmg ``` Now these mounts can be umounted but would appear to have been mounted multiple times - the average being about 10-12 (probably correlates with the number of times I have recompiled new images and republished new integrations during the day). So I have write a little script that loops through and unmounts them all.  It would be good to know if we are missing something in Syndesis since they are related to 'syndesis-server-token' and 'syndesis-prometheus-token-nhzc6' as I wouldn't have thought so many tmpfs mounts should occur is such a short time?? It might also be worthwhile to understand, if these are old mounts from defunct images, why they are not being cleaned up??  Any thoughts much appreciated.        </body>
		<created>2019-01-31 10:40:42</created>
		<closed>2019-02-25 13:03:15</closed>
	</bug>
	<bug>
		<id>4396</id>
		<title>Errors when going from the integration detail page into the editor</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  When you're in the integration detail page and then click on the "Edit Integration" button a bunch of javascript errors surface on the console, for example:  ![image](https://user-images.githubusercontent.com/351660/51987308-2fe53b80-2470-11e9-8f91-91729e41c56d.png)  </body>
		<created>2019-01-30 14:20:09</created>
		<closed>2019-02-04 14:55:29</closed>
	</bug>
	<bug>
		<id>4395</id>
		<title>View log in Openshift link seems to be wrong</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description In the Integration activity tab, there is a link saying View log in Openshift, but it won't take you to the log.  Note: I am running syndesis on Minishift but AFAIK that shouldn't change much because Openshift and Syndesis should both serve different ports so linking to /project/syndesis/browse/pods/pod-id won't take you to the Openshift console.  Also when changing the resulting URL to lead to Openshift you get a response 403, but changing it to /console//project/syndesis/browse/pods/pod-id seems to fix the issue and takes you to the desired log.</body>
		<created>2019-01-30 13:42:04</created>
		<closed>2019-02-11 14:26:03</closed>
	</bug>
	<bug>
		<id>4392</id>
		<title>Error messages not formatted correctly</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; On occasion, error toast messages in the UI are not formatted correctly, in that the message is displayed followed by [object Object]. Obviously, some json object is not be converted to a string.  An encountered example follows: `Failed to stop integration Error stopping integration: [object Object]` (This has been occurring after shutting down Openshift with an integration published then restarting it)  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlisting the acceptance criteria. --&gt; Error messages should be properly formatted with objects.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![error-message-object](https://user-images.githubusercontent.com/1634180/51983029-a04f8500-248f-11e9-813f-df9588d6af12.png)</body>
		<created>2019-01-30 13:05:24</created>
		<closed>2019-11-13 16:35:26</closed>
	</bug>
	<bug>
		<id>4389</id>
		<title>OutMessageCaptureProcessorTest is flaky</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I wonder if OutMessageCaptureProcessorTest is beyond help. It fails intermittently see:  https://circleci.com/gh/syndesisio/syndesis/53985  See also #3328 and #2658 </body>
		<created>2019-01-30 09:49:28</created>
		<closed>2019-02-19 14:41:41</closed>
	</bug>
	<bug>
		<id>4388</id>
		<title>[Upgrade] db-metrics and grafana can't start after upgrade due to missing resources</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  After upgrading from 1.5.9 to 1.6.1-20190130, the two mentioned pods can't be created because of missing configmaps:  ``` ---     ------       ----               ----                -------   Normal   Scheduled    19m                default-scheduler   Successfully assigned syndesis/syndesis-db-metrics-1-fmqlk to localhost   Warning  FailedMount  2m (x8 over 17m)   kubelet, localhost  Unable to mount volumes for pod "syndesis-db-metrics-1-fmqlk_syndesis(bd0c2c8e-2462-11e9-bb88-0800278b309a)": timeout expired waiting for volumes to attach or mount for pod "syndesis"/"syndesis-db-metrics-1-fmqlk". list of unmounted volumes=[syndesis-db-metrics-config]. list of unattached volumes=[syndesis-db-metrics-config default-token-5wrbk]   Warning  FailedMount  1m (x17 over 19m)  kubelet, localhost  MountVolume.SetUp failed for volume "syndesis-db-metrics-config" : configmaps "syndesis-db-metrics-config" not found ```  ``` Events:   Type     Reason       Age                 From                Message   ----     ------       ----                ----                -------   Normal   Scheduled    23m                 default-scheduler   Successfully assigned syndesis/syndesis-grafana-1-4w2g9 to localhost   Warning  FailedMount  21m (x8 over 23m)   kubelet, localhost  MountVolume.SetUp failed for volume "syndesis-grafana-etc" : configmaps "grafana-config" not found   Warning  FailedMount  21m (x8 over 23m)   kubelet, localhost  MountVolume.SetUp failed for volume "syndesis-grafana-datasource" : configmaps "syndesis-grafana-datasource-config" not found   Warning  FailedMount  12m (x13 over 23m)  kubelet, localhost  MountVolume.SetUp failed for volume "syndesis-grafana-dashboard" : configmaps "syndesis-grafana-dashboard-config" not found   Warning  FailedMount  2m (x9 over 21m)    kubelet, localhost  Unable to mount volumes for pod "syndesis-grafana-1-4w2g9_syndesis(bd2ea4d4-2462-11e9-bb88-0800278b309a)": timeout expired waiting for volumes to attach or mount for pod "syndesis"/"syndesis-grafana-1-4w2g9". list of unmounted volumes=[syndesis-grafana-etc syndesis-grafana-datasource syndesis-grafana-dashboard]. list of unattached volumes=[syndesis-grafana-etc syndesis-grafana-datasource syndesis-grafana-dashboard default-token-5wrbk] ```  </body>
		<created>2019-01-30 08:07:20</created>
		<closed>2019-02-04 08:15:13</closed>
	</bug>
	<bug>
		<id>4361</id>
		<title>Some UI instances of "OpenAPI Specification" should be "OpenAPI Document"</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem In the UI for creating an API Client Connector, instances of "OpenAPI Specification" should be "OpenAPI Document". The user does not upload the OpenAPI 2.0 Specification. The user uploads an OpenAPI document or file that conforms to the OpenAPI 2.0 Specification.  ## Expected behavior   ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![image](https://user-images.githubusercontent.com/25067106/51802682-60cc3300-221a-11e9-9d9f-ef69eddec0f4.png)  This needs to change in strings in  app/ui/src/assets/dictionary/en-GB.json  I can make this change. Let me know if I should go ahead and do this.  Does any other file have instances that appear in the UI? </body>
		<created>2019-01-27 15:08:14</created>
		<closed>2019-02-25 08:36:55</closed>
	</bug>
	<bug>
		<id>4308</id>
		<title>Reseting DB through test support endpoint takes a lot of time sometimes</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I thought it was related to the openstack environment, but I managed to reproduce on minishift as well. The resetDB endpoint is called before each test and after several tests, the resetDB starts to takes more and more time, on openstack I saw the call to take 50 minutes once.  There are some idle connections in the DB that may be related to that:  ```  pid  |        state        |          query_start          |                                                                                                                                                                                                                     query                                                                                                                                                                                                                       ------+---------------------+-------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------   130 | idle                | 2019-01-18 11:38:26.663967+00 | select path,value,ovalue from jsondb where path LIKE $1 order by path ASC   131 | idle in transaction | 2019-01-18 11:38:25.988674+00 | select path,value,ovalue from jsondb where path LIKE $1 order by path ASC   132 | active              | 2019-01-18 11:38:25.520318+00 | select path,value,ovalue from jsondb where path LIKE $1 order by path ASC   133 | idle                | 2019-01-18 11:37:38.739764+00 | select path,value,ovalue from jsondb where path LIKE $1 order by path ASC   134 | idle                | 2019-01-18 11:17:19.974948+00 | select path,value,ovalue from jsondb where path LIKE $1 order by path ASC   135 | idle                | 2019-01-18 11:33:39.611987+00 | select path,value,ovalue from jsondb where path LIKE $1 order by path ASC   136 | idle in transaction | 2019-01-18 10:07:44.501777+00 | SELECT p.proname,p.oid  FROM pg_catalog.pg_proc p, pg_catalog.pg_namespace n  WHERE p.pronamespace=n.oid AND n.nspname='pg_catalog' AND ( proname = 'lo_open' or proname = 'lo_close' or proname = 'lo_creat' or proname = 'lo_unlink' or proname = 'lo_lseek' or proname = 'lo_lseek64' or proname = 'lo_tell' or proname = 'lo_tell64' or proname = 'loread' or proname = 'lowrite' or proname = 'lo_truncate' or proname = 'lo_truncate64')   137 | idle                | 2019-01-18 11:12:03.668276+00 | COMMIT   138 | active              | 2019-01-18 11:38:23.892177+00 | select path,value,ovalue from jsondb where path LIKE $1 order by path ASC   139 | idle in transaction | 2019-01-18 11:19:48.943358+00 | SELECT data FROM filestore WHERE path=$1  8061 | active              | 2019-01-18 11:38:26.982092+00 | select pid,state,query_start,query from pg_stat_activity where pg_stat_activity.datname = current_database() (11 rows) ```  When I restart syndesis-server pod, all connections are cleared and resetDB is almost instant again.  This may be related to the excessive usage of reset db endpoint and customers may not hit that, but I would like to have a confirmation from ENG.</body>
		<created>2019-01-18 11:46:34</created>
		<closed>2019-02-06 11:10:15</closed>
	</bug>
	<bug>
		<id>4304</id>
		<title>The Last Processed time shows actual time when no message was processed</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The last processed section in the metrics tab shows time when the last message was processed. But when no message exists, the time is actual time. This can be confused because the user can suppose that some messages were processed in case the time was changed.  In my point of view, when no message cames into syndesis, last processed time would be "n/a" or the time when the integration was deployed (since date == last processed date).  When I send a message, the last processed section shows the time when the message was processed and after that, it behaves correctly and the time is changed after the next message.  ![output](https://user-images.githubusercontent.com/16251792/51323737-413e4900-1a69-11e9-9415-40009d689f0c.gif) On the video, you can see that the Last Processed time is being changed according to real time.  14:57 -&gt; 14:58 14:58 -&gt; 14:59 But after the first message was processed (14:59), the Last Processed time is not changed according to real-time (15:00, 15:01).  **Step to reproduced:**  1. Import integration  [Webhook to DB-export.zip](https://github.com/syndesisio/syndesis/files/2768830/Webhook.to.DB-export.zip) 2. Deploy integration 3. Look at The last processed time. 4. Wait 2 minutes and refresh the page. The time is changed to actual time but no message was processed. 5. Send message to webhook 6. After that, the last processed time shows when this message was processed. 6. Wait 2 minutes and refresh the page. The time is same as before when the message was processed.</body>
		<created>2019-01-17 14:06:54</created>
		<closed>2019-01-30 16:30:01</closed>
	</bug>
	<bug>
		<id>4303</id>
		<title>Since Time in the metrics tab sometimes shows actual time</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The metrics tab shows a date since the integration is active in the uptime section. But when I refresh the page (press F5) more times, sometimes the date is the same as the actual date which is incorrect because uptime is more than 0 minutes (e.g. 4minutes).  Integration:  [Webhook to DB-export.zip](https://github.com/syndesisio/syndesis/files/2768786/Webhook.to.DB-export.zip)  ![output](https://user-images.githubusercontent.com/16251792/51321437-0b966180-1a63-11e9-8f86-df9e7bda2abe.gif)   In video: e.g. Actual time 14:17 , uptime 4 minutes, Since 14:12 refresh -&gt; Actual time 14:17 , uptime 4 minutes, Since 14:12 refresh -&gt; Actual time 14:17 , uptime 4 minutes, Since **14:17**   (Which is invalid)</body>
		<created>2019-01-17 13:30:44</created>
		<closed>2019-06-16 16:43:29</closed>
	</bug>
	<bug>
		<id>4283</id>
		<title>Extensions tab displays "Ignite Help" and links to 7.1 doc</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; In my Fuse Online 7.2 evaluation, the Extensions tab displays "Ignite Help" as a label for a link to doc for developing extensions. The target of the link is 7.1 doc.  In the Syndesis staging site, the label is "Syndesis Help" and the link target is correctly to the 7.2 doc.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlisting the acceptance criteria. --&gt; For the downstream product, this label should be "Fuse Online Help".  The target link should be to the 7.2 doc: https://access.redhat.com/documentation/en-us/red_hat_fuse/7.2/html-single/integrating_applications_with_fuse_online/index#developing-extensions_custom  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![image](https://user-images.githubusercontent.com/25067106/51186620-07721480-18a8-11e9-98de-b067a8ed10e7.png)  Also, the Customizations &gt; API Client Connectors tab displays "Ignite" in the description in the Fuse Online 7.2 evaluation environment. In the Syndesis staging site, this description has "Syndesis" as the product name.   ![image](https://user-images.githubusercontent.com/25067106/51186961-d0503300-18a8-11e9-9809-8746cb1f77b4.png)  ## Request and Response Data &lt;!-- Many issues involve both the UI and its backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Open a Fuse Online 7.2 evaluation environment. 2. Click Customizations to see "Ignite" in the description.  3. Click the Extensions tab to see "Ignite" in the link.  </body>
		<created>2019-01-15 14:41:34</created>
		<closed>2019-04-24 17:20:32</closed>
	</bug>
	<bug>
		<id>4266</id>
		<title>Unstable GoogleSheets integration test breaks build</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  GoogleSheets integration test is unstable failing from time to time with following error:  ``` [INFO] Running org.apache.camel.component.google.sheets.stream.SheetsStreamConsumerIntegrationTest [ERROR] Tests run: 3, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 8.897 s &lt;&lt;&lt; FAILURE! - in org.apache.camel.component.google.sheets.stream.SheetsStreamConsumerIntegrationTest [ERROR] testConsumeValueRange(org.apache.camel.component.google.sheets.stream.SheetsStreamConsumerIntegrationTest)  Time elapsed: 7.586 s  &lt;&lt;&lt; ERROR! org.apache.camel.CamelExecutionException: Exception occurred during execution on the exchange: Exchange[ID-8a10ca970798-1547073284681-14-1] at org.apache.camel.component.google.sheets.stream.SheetsStreamConsumerIntegrationTest.testConsumeValueRange(SheetsStreamConsumerIntegrationTest.java:59) Caused by: org.apache.camel.RuntimeCamelException: java.lang.IllegalArgumentException: no JSON input found Caused by: java.lang.IllegalArgumentException: no JSON input found  [ERROR] testConsumeValueRange(org.apache.camel.component.google.sheets.stream.SheetsStreamConsumerIntegrationTest)  Time elapsed: 7.586 s  &lt;&lt;&lt; ERROR! com.consol.citrus.exceptions.TestCaseFailedException: java.lang.NullPointerException Caused by: com.consol.citrus.exceptions.CitrusRuntimeException: java.lang.NullPointerException Caused by: java.lang.NullPointerException ```</body>
		<created>2019-01-10 08:12:10</created>
		<closed>2019-03-20 10:37:50</closed>
	</bug>
	<bug>
		<id>4248</id>
		<title>Unable to validate Salesforce connection after importing an existing integration</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  I tried to import an [existing Integration](https://github.com/weimeilin79/fuseonlinewine/blob/master/fuse-online-exports/account-export.zip) I built earlier, and of the integration is showing I need to re-configure the Salesforce connection by updating it's secrets,   ![image](https://user-images.githubusercontent.com/2534483/50731730-e720b800-1139-11e9-9261-3b5f6fac9f52.png)  So I went ahead and update the OAuth in the setting, and then use the reconnect in the "Connection". The problem is that, after reconnecting, I was not able to VALIDATE the connection (the button is always disabled), so my integration keeps saying my resource needs configuration. The entire import is not usable.  ![image](https://user-images.githubusercontent.com/2534483/50731741-2bac5380-113a-11e9-91d6-fd98d73c2b3c.png)   I am sure my OAuth setting is correct, because I was able to create a new Salesforce connection with the same setting.   ![image](https://user-images.githubusercontent.com/2534483/50731752-8ba2fa00-113a-11e9-84fc-2cbb90c53843.png)   </body>
		<created>2019-01-06 03:38:23</created>
		<closed>2019-09-21 06:18:07</closed>
	</bug>
	<bug>
		<id>4238</id>
		<title>Slack connector validator not working properly</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I am able to add wrong  `Token for Accessing Slack API` parameter when creating slack connector and after that validate button finishes with success. Using slack connector with wrong token in an integration shows following error and throws NPE in syndesis-meta pod. The error in both meta pod and UI shows **plaintext** token (in my case it is the "a").   ![screenshot_20181221_144014](https://user-images.githubusercontent.com/14313995/50345223-8c2e7480-052e-11e9-8d6d-c3e7c7130c05.png) ![screenshot_20181221_144034](https://user-images.githubusercontent.com/14313995/50345222-8c2e7480-052e-11e9-9252-ece50b127f1e.png)   ``` 2018-12-21 13:34:31.468 ERROR 1 --- [ XNIO-3 task-15] i.s.connector.meta.v1.VerifierEndpoint   : Unable to fetch and process metadata for connector: slack, action: io.syndesis:slack-channel-consumer-connector 2018-12-21 13:34:31.489 ERROR 1 --- [ XNIO-3 task-15] i.s.c.meta.VerifierExceptionMapper       : Exception while handling request: POST /api/v1/connectors/slack/actions/io.syndesis:slack-channel-consumer-connector io.syndesis.common.util.SyndesisServerException: Get information about channels failed with token a has failed.. Unable to fetch and process metadata at io.syndesis.connector.support.verifier.api.MetadataRetrieval.handle(MetadataRetrieval.java:42) ~[connector-support-verifier-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at io.syndesis.connector.meta.v1.ConnectorEndpoint.actions(ConnectorEndpoint.java:87) ~[classes!/:1.6-SNAPSHOT] at sun.reflect.GeneratedMethodAccessor34.invoke(Unknown Source) ~[na:na] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151] at org.jboss.resteasy.core.MethodInjectorImpl.invoke(MethodInjectorImpl.java:140) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.internalInvokeOnTarget(ResourceMethodInvoker.java:509) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTargetAfterFilter(ResourceMethodInvoker.java:399) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.lambda$invokeOnTarget$0(ResourceMethodInvoker.java:363) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:358) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTarget(ResourceMethodInvoker.java:365) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:337) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:310) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:443) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.lambda$invoke$4(SynchronousDispatcher.java:233) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.lambda$preprocess$0(SynchronousDispatcher.java:139) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:358) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.preprocess(SynchronousDispatcher.java:142) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:219) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.ServletContainerDispatcher.service(ServletContainerDispatcher.java:227) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:56) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:51) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) ~[javax.servlet-api-3.1.0.jar!/:3.1.0] at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.AbstractRequestLoggingFilter.doFilterInternal(AbstractRequestLoggingFilter.java:244) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:111) ~[spring-boot-actuator-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:103) ~[spring-boot-actuator-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:65) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:132) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) ~[undertow-servlet-1.4.26.Final.jar!/:1.4.26.Final] at io.undertow.server.Connectors.executeRootHandler(Connectors.java:336) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_151] at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_151] Caused by: java.lang.IllegalStateException: Get information about channels failed with token a has failed. at io.syndesis.connector.slack.SlackMetaDataExtension.meta(SlackMetaDataExtension.java:86) ~[connector-slack-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at io.syndesis.connector.support.verifier.api.ComponentMetadataRetrieval.fetchMetaData(ComponentMetadataRetrieval.java:54) ~[connector-support-verifier-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at io.syndesis.connector.support.verifier.api.ComponentMetadataRetrieval.fetch(ComponentMetadataRetrieval.java:48) ~[connector-support-verifier-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] at io.syndesis.connector.meta.v1.ConnectorEndpoint.actions(ConnectorEndpoint.java:81) ~[classes!/:1.6-SNAPSHOT] ... 83 common frames omitted Caused by: java.lang.NullPointerException: null at io.syndesis.connector.slack.SlackMetaDataExtension.meta(SlackMetaDataExtension.java:73) ~[connector-slack-1.6-SNAPSHOT.jar!/:1.6-SNAPSHOT] ... 86 common frames omitted ```    </body>
		<created>2018-12-21 13:46:44</created>
		<closed>2019-02-11 09:58:48</closed>
	</bug>
	<bug>
		<id>4236</id>
		<title>Unable to specify data shape of a step</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When I add the [set body extension](https://github.com/syndesisio/syndesis-extensions/tree/master/syndesis-extension-body) I'm unable to define it's output shape.  Console log has the following exception: ``` main.415fc10759965e50db43.js:1 TypeError: Cannot read property 'name' of undefined     at n.initialize (11.a93bb2c2becc7d846af7.js:1)     at e._next (11.a93bb2c2becc7d846af7.js:1)     at e.__tryOrUnsub (polyfills.56ad22f0d399ab378e2a.js:1)     at e.next (polyfills.56ad22f0d399ab378e2a.js:1)     at e._next (polyfills.56ad22f0d399ab378e2a.js:1)     at e.next (polyfills.56ad22f0d399ab378e2a.js:1)     at e._next (polyfills.56ad22f0d399ab378e2a.js:1)     at e.next (polyfills.56ad22f0d399ab378e2a.js:1)     at t._subscribe (main.415fc10759965e50db43.js:1)     at t._trySubscribe (polyfills.56ad22f0d399ab378e2a.js:1) t.log @ main.415fc10759965e50db43.js:1 ```  This is the JSON describing the set body step: ```json {    "schemaVersion":"v1",    "name":"Set Body",    "description":"Set a body",    "icon":"data:image/svg+xml,...",    "extensionId":"io.syndesis.extensions:syndesis-extension-body",    "version":"1.0.0",    "actions":[       {          "id":"setBody",          "name":"Set Body",          "description":"Set your body",          "descriptor":{             "kind":"STEP",             "entrypoint":"io.syndesis.extension.body.SetBodyAction",             "inputDataShape":{                "kind":"any"             },             "outputDataShape":{                "kind":"any"             },             "propertyDefinitionSteps":[                {                   "description":"extension-properties",                   "name":"extension-properties",                   "properties":{                      "body":{                         "componentProperty":false,                         "deprecated":false,                         "description":"The body to set",                         "displayName":"Body",                         "javaType":"java.lang.String",                         "kind":"parameter",                         "required":false,                         "secret":false,                         "type":"string",                         "raw":false                      }                   }                }             ]          },          "tags":[             "body",             "extension"          ],          "actionType":"step"       }    ],    "dependencies":[       {          "type":"MAVEN",          "id":"io.syndesis.extension:extension-api:jar:1.3.10"       }    ],    "status":"Installed",    "uses":0,    "userId":"zregvart",    "lastUpdated":1545385459879,    "createdDate":1545385457784,    "extensionType":"Steps",    "id":"i-LUF8fWsxo4Wcrbyt7YMz" } ```  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlisting the acceptance criteria. --&gt; Be able to set the shape of the set body step.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![peek 2018-12-21 10-51](https://user-images.githubusercontent.com/1306050/50336438-7f9a2400-050e-11e9-9350-a7c5a69e113b.gif)  ## Request and Response Data &lt;!-- Many issues involve both the UI and its backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. import set body extension 2. add it to the integration 3. try to define the set body step data shape 4. </body>
		<created>2018-12-21 09:53:08</created>
		<closed>2019-04-10 17:13:58</closed>
	</bug>
	<bug>
		<id>4234</id>
		<title>Validating Kafka components always kills the Meta pod</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Trying to configure kafka component to AMQ Streams in the same cluster, but always throws OutOfMemoryError.   `2018-12-20 20:27:17.698  INFO 1 --- [  XNIO-3 task-1] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: --  | bootstrap.servers = [my-cluster-kafka-bootstrap.streams.svc:9091]  | client.id =  | connections.max.idle.ms = 10000  | metadata.max.age.ms = 300000  | metric.reporters = []  | metrics.num.samples = 2  | metrics.recording.level = INFO  | metrics.sample.window.ms = 30000  | receive.buffer.bytes = 65536  | reconnect.backoff.max.ms = 1000  | reconnect.backoff.ms = 50  | request.timeout.ms = 5000  | retries = 5  | retry.backoff.ms = 100  | sasl.client.callback.handler.class = null  | sasl.jaas.config = null  | sasl.kerberos.kinit.cmd = /usr/bin/kinit  | sasl.kerberos.min.time.before.relogin = 60000  | sasl.kerberos.service.name = null  | sasl.kerberos.ticket.renew.jitter = 0.05  | sasl.kerberos.ticket.renew.window.factor = 0.8  | sasl.login.callback.handler.class = null  | sasl.login.class = null  | sasl.login.refresh.buffer.seconds = 300  | sasl.login.refresh.min.period.seconds = 60  | sasl.login.refresh.window.factor = 0.8  | sasl.login.refresh.window.jitter = 0.05  | sasl.mechanism = GSSAPI  | security.protocol = PLAINTEXT  | send.buffer.bytes = 131072  | ssl.cipher.suites = null  | ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]  | ssl.endpoint.identification.algorithm = https  | ssl.key.password = null  | ssl.keymanager.algorithm = SunX509  | ssl.keystore.location = null  | ssl.keystore.password = null  | ssl.keystore.type = JKS  | ssl.protocol = TLS  | ssl.provider = null  | ssl.secure.random.implementation = null  | ssl.trustmanager.algorithm = PKIX  | ssl.truststore.location = null  | ssl.truststore.password = null  | ssl.truststore.type = JKS  |   | 2018-12-20 20:27:17.970  INFO 1 --- [  XNIO-3 task-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.0  | 2018-12-20 20:27:17.970  INFO 1 --- [  XNIO-3 task-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 3402a8361b734732    2018-12-20 20:29:51.370  INFO 1 --- [  XNIO-3 task-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.0 --  | 2018-12-20 20:29:51.370  INFO 1 --- [  XNIO-3 task-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 3402a8361b734732  | Terminating due to java.lang.OutOfMemoryError: Java heap space`   </body>
		<created>2018-12-20 20:33:14</created>
		<closed>2019-08-07 10:51:07</closed>
	</bug>
	<bug>
		<id>4227</id>
		<title>bash update_ocp.sh --version not working</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Following the [10.6. Upgrade Fuse Online on OCP](https://access.redhat.com/documentation/en-us/red_hat_fuse/7.2/html/integrating_applications_with_fuse_online/how-to-install-on-ocp_ug#upgrade-on-ocp_ocp) documentation   in step 4 I am told to run &lt;code&gt; $ bash update_ocp.sh --version &lt;/code&gt; but the script fails with  &lt;code&gt; update_ocp.sh: line 385: /Users/tmielke/Downloads/fuse_online_config.sh: No such file or directory &lt;/code&gt;  </body>
		<created>2018-12-13 14:27:24</created>
		<closed>2018-12-13 16:10:32</closed>
	</bug>
	<bug>
		<id>4224</id>
		<title>Integration Summary - "Connection modified" warning displayed when connection unmodified</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem There are warnings right after an integration newly created. (without any chance for a connection to be modified)  **A connection associated with this integration has been modified. To incorporate the changes, please edit the integration.**  Sometimes multiple same warnings. They don't go away even after republishing the integration. They might be tied with only some connections.  &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlisting the acceptance criteria. --&gt;  ## Screenshot ![conmod](https://user-images.githubusercontent.com/8707251/49877295-649c2580-fe25-11e8-950b-7728a5d47b49.png)  &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and its backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4.</body>
		<created>2018-12-13 10:21:10</created>
		<closed>2019-03-20 17:25:44</closed>
	</bug>
	<bug>
		<id>4219</id>
		<title>ConfigurationProperty type missing a few fields</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description In the react codebase we generate typescript interfaces from the swagger file.  The `ConfigurationProperty` interface seems to be missing a few fields.  Here's what's generated:  ```typescript export interface ConfigurationProperty {     type?: string;     defaultValue?: string;     displayName?: string;     deprecated?: boolean;     group?: string;     label?: string;     kind?: string;     description?: string;     enum?: PropertyValue[];     generator?: string;     placeholder?: string;     javaType?: string;     connectorValue?: string;     relation?: PropertyRelation[];     controlHint?: string;     labelHint?: string;     tags?: string[];     order?: OptionalInt; } ```  And here's what I've had to add locally to work around in the interim:  ```typescript export interface IConfigurationProperty extends ConfigurationProperty {   componentProperty?: boolean;   required?: boolean;   secret?: boolean; } ``` </body>
		<created>2018-12-11 13:53:48</created>
		<closed>2019-02-06 11:10:28</closed>
	</bug>
	<bug>
		<id>4212</id>
		<title>Integration name should be validated</title>
		<body>## This is a problem my lab user encounter  They name the integration with "dot" in it, and was not able to run the integration.   &lt;pre&gt;&lt;code&gt; [X] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  When creating integration, can we add an UI validation? I had an user created an integration with dot(".") in it, and it was saved ok, but when hit publish, it was not able to start.   Checked the logs, apparently the server is complaining about the naming, so it was not able to deploy, can you please add an validation in UI so it will never happen again? Thanks  ` 2018-12-10 18:12:34.995 ERROR [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [add.location]: [ERROR] Activation failure --  |   | javax.validation.ConstraintViolationException: Constraint Validations: name must match "^[a-z0-9]([-a-z0-9]*[a-z0-9])?$" on bean: Container(args=[], command=[], env=[EnvVar(name=LOADER_HOME, value=${JAVA_DATA_DIR}/syndesis/loader, valueFrom=null, additionalProperties={}), EnvVar(name=AB_JMX_EXPORTER_CONFIG, value=/tmp/src/prometheus-config.yml, valueFrom=null, additionalProperties={})], envFrom=[], image=docker-registry.default.svc:5000/fuse-f3668ffe-fc91-11e8-bd1e-0a580a800009/i-add.location:1, imagePullPolicy=Always, lifecycle=null, livenessProbe=null, name=i-add.location, ports=[ContainerPort(containerPort=8778, hostIP=null, hostPort=null, name=jolokia, protocol=null, additionalProperties={})], readinessProbe=null, resources=null, securityContext=null, stdin=null, stdinOnce=null, terminationMessagePath=null, terminationMessagePolicy=null, tty=null, volumeMounts=[VolumeMount(mountPath=/deployments/config, name=secret-volume, readOnly=false, subPath=null, additionalProperties={})], workingDir=null, additionalProperties={})  | at io.fabric8.kubernetes.api.builder.ValidationUtils.validate(ValidationUtils.java:36) ~[kubernetes-model-2.0.10.jar!/:2.0.10]  | at io.fabric8.kubernetes.api.model.ContainerBuilder.build(ContainerBuilder.java:81) ~[kubernetes-model-2.0.10.jar!/:2.0.10]  | at io.fabric8.kubernetes.api.model.PodSpecFluentImpl$ContainersNestedImpl.and(PodSpecFluentImpl.java:1063) ~[kubernetes-model-2.0.10.jar!/:2.0.10]  | at io.fabric8.kubernetes.api.model.PodSpecFluentImpl$ContainersNestedImpl.endContainer(PodSpecFluentImpl.java:1066) ~[kubernetes-model-2.0.10.jar!/:2.0.10]  | at io.syndesis.server.openshift.OpenShiftServiceImpl.ensureDeploymentConfig(OpenShiftServiceImpl.java:251) ~[server-openshift-1.4.8.fuse-710001-redhat-00001.jar!/:1.4.8.fuse-710001-redhat-00001]  | at io.syndesis.server.openshift.OpenShiftServiceImpl.deploy(OpenShiftServiceImpl.java:85) ~[server-openshift-1.4.8.fuse-710001-redhat-00001.jar!/:1.4.8.fuse-710001-redhat-00001]  | at io.syndesis.server.controller.integration.online.PublishHandler.deploy(PublishHandler.java:178) ~[server-controller-1.4.8.fuse-710001-redhat-00001.jar!/:1.4.8.fuse-710001-redhat-00001]  | at io.syndesis.server.controller.integration.online.PublishHandler$BuildStepPerformer.perform(PublishHandler.java:329) ~[server-controller-1.4.8.fuse-710001-redhat-00001.jar!/:1.4.8.fuse-710001-redhat-00001]  | at io.syndesis.server.controller.integration.online.PublishHandler.execute(PublishHandler.java:114) ~[server-controller-1.4.8.fuse-710001-redhat-00001.jar!/:1.4.8.fuse-710001-redhat-00001]  | at io.syndesis.server.controller.StateChangeHandler.execute(StateChangeHandler.java:33) [server-controller-1.4.8.fuse-710001-redhat-00001.jar!/:1.4.8.fuse-710001-redhat-00001]  | at io.syndesis.server.controller.integration.IntegrationController.lambda$callStateChangeHandler$11(IntegrationController.java:199) [server-controller-1.4.8.fuse-710001-redhat-00001.jar!/:1.4.8.fuse-710001-redhat-00001]  | at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_181]  | at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_181]  | at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_181]  `   </body>
		<created>2018-12-10 18:38:18</created>
		<closed>2019-02-07 12:44:12</closed>
	</bug>
	<bug>
		<id>4206</id>
		<title>Connector data shape inspections not generated in clean build</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  When doing a clean build the connector inspections for Java typed input/output data shapes are not generated.   This is leads to data mapper steps not being able to determine source and target data shapes at runtime. You will get `No source data type was found. Data Mapper requires at least one data type aware step prior to itself` errors when adding data mapper steps to your integrations.</body>
		<created>2018-12-05 16:55:26</created>
		<closed>2019-01-08 09:57:19</closed>
	</bug>
	<bug>
		<id>4192</id>
		<title>Final step doesn't show error in the activity log</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I have this integration. ![image](https://user-images.githubusercontent.com/16251792/49283126-2c91fb80-f491-11e8-8967-ccde9a581b97.png)  The final SQL insert contains a mistake (insert string data about company to the column which has date datatype).  ``` INSERT INTO contact (create_date) VALUES (:#company) ```  When I send data to webhook, the data maper add company string to the company input parameters and the last steps throws an exception. In the activity log is shown 'Errors found' but in the log is not the final step which contains this error.: ![screenshot from 2018-11-30 11-15-13](https://user-images.githubusercontent.com/16251792/49283320-b9d55000-f491-11e8-9aff-f07eb5459754.png)  When I delete data maper and I add incorrect value to the SQL as a constant ``` INSERT INTO contact (create_date) VALUES ('RedHat') ``` the error is shown in the log. ![image](https://user-images.githubusercontent.com/16251792/49283998-9ca18100-f493-11e8-90ec-d66e0d2ca9e1.png) ![image](https://user-images.githubusercontent.com/16251792/49284018-a925d980-f493-11e8-89fa-7dc3010cf6fc.png)    Integration:  [hook-to-db-with-db-export.zip](https://github.com/syndesisio/syndesis/files/2632837/hook-to-db-with-db-export.zip)  **Step to reproduce:**  1. Import and publish integration 2. Run command: (update webhook url according to integration) ``` curl -k -v https://i-webhook-to-db-with-mistake-syndesis.192.168.42.27.nip.io/webhook/test-webhook -d '{"first_name":"John","company":"Red Hat"}' -X POST -H "Content-Type: application/json" ```  3. Look to the activity log</body>
		<created>2018-11-30 10:34:43</created>
		<closed>2019-08-12 14:17:13</closed>
	</bug>
	<bug>
		<id>4191</id>
		<title>Update 1.5.x dictionary to state `7.2`</title>
		<body>See https://github.com/syndesisio/syndesis/blob/1.5.x/app/ui/src/assets/dictionary/en-GB.json#L319</body>
		<created>2018-11-30 08:10:12</created>
		<closed>2019-03-18 14:14:44</closed>
	</bug>
	<bug>
		<id>4182</id>
		<title>Insertion to DB inserts empty strings when a step with another insertion is before</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I have this integration ![image](https://user-images.githubusercontent.com/16251792/49222702-e0857f00-f3dc-11e8-9ef4-6c2f8d9aecd9.png) Integration gets data from webhook, inserts to DB static values (e.g. for some logging), maps webhook data to insert and inserts data to DB.  After sending data to webhook, ``` curl -k -v https://i-hook-to-db-with-db-syndesis.192.168.42.27.nip.io/webhook/test-webhook -d '{"first_name":"John","company":"Red Hat"}' -X POST -H "Content-Type: application/json" ```  DB **should** contain: ```  first_name | last_name |  company   | lead_source | create_date ------------+-----------+------------+-------------+-------------  middleSTEP |           | middleStep |             |  John       |           | Red Hat    |             | ```  but the contact from the last step has only empty strings. ```  first_name | last_name |  company   | lead_source | create_date ------------+-----------+------------+-------------+-------------  middleSTEP |           | middleStep |             |             |           |            |             | ```  When I delete middle step with insertion static data (first PostgesDB step), integraion works and integration inserts data from webhook to DB correctly ```  first_name | last_name |  company   | lead_source | create_date ------------+-----------+------------+-------------+-------------  John       |           | Red Hat    |             | ```  I looked to the data maper but the mapping data from webhook to final insert looks correct. ![image](https://user-images.githubusercontent.com/16251792/49223238-7b328d80-f3de-11e8-949f-4da791651118.png)  Integration:  [hook-to-db-with-db-export.zip](https://github.com/syndesisio/syndesis/files/2629213/hook-to-db-with-db-export.zip)  **Step to reproduce:**  1. Import and publish integration 2. Run command: (update webhook url according to integration) ``` curl -k -v https://i-hook-to-db-with-db-syndesis.192.168.42.27.nip.io/webhook/test-webhook -d '{"first_name":"John","company":"Red Hat"}' -X POST -H "Content-Type: application/json" ```  3. Look to the Syndesis-DB pod. The table should contains row with 'middleSTEP' values and one row which has **all values empty** ``` psql \connect sampledb SELECT * FROM contact; ```  4. Delete middle step from integration and republish 5. Run command for webhook again (step 2.) 6. Look to the DB pod again (step 3.)     The table should contains row with first name John and company RedHat</body>
		<created>2018-11-29 13:08:56</created>
		<closed>2019-03-20 10:15:52</closed>
	</bug>
	<bug>
		<id>4181</id>
		<title>Step which is after basic or advanced filter is in the activity log twice</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When I have some step after the advanced filter or basic filter, this step appears in the activity log twice. e.g. **1. Integration:** ![image](https://user-images.githubusercontent.com/16251792/49217560-31da4200-f3ce-11e8-8682-cdb50848483f.png)  ![image](https://user-images.githubusercontent.com/16251792/49219408-74eae400-f3d3-11e8-95d3-fda4246dd09d.png) You can see that DataMaper is there **after** Invoke SQL **again**. [Webhook to DB before-export.zip](https://github.com/syndesisio/syndesis/files/2628810/Webhook.to.DB.before-export.zip)  **2. Integration:** ![image](https://user-images.githubusercontent.com/16251792/49217316-87fab580-f3cd-11e8-813d-85e70db0a267.png) In the activity log, you can see that another **unknown** Log step with No output is after Invoke SQL but this step is not **defined**. ![image](https://user-images.githubusercontent.com/16251792/49219453-9ba91a80-f3d3-11e8-95dc-4346a097b499.png) ) [Webhook to DB advanced after-export.zip](https://github.com/syndesisio/syndesis/files/2628894/Webhook.to.DB.advanced.after-export.zip)  **3. Integration:** Same situation with Basic filter: ![image](https://user-images.githubusercontent.com/16251792/49219286-16256a80-f3d3-11e8-8126-05c3b07b75c2.png) ![image](https://user-images.githubusercontent.com/16251792/49219486-c1362400-f3d3-11e8-815b-8e3d72606b4e.png) In the activity log, you can see that another **unknown** Log step with No output is after Invoke SQL but this step is not **defined**. [Webhook to DB basic after-export.zip](https://github.com/syndesisio/syndesis/files/2628908/Webhook.to.DB.basic.after-export.zip)  **4. Integration:**  For integration without the advance of the basic filter, **no** extra steps appear after the finish step: ![image](https://user-images.githubusercontent.com/16251792/49219588-09eddd00-f3d4-11e8-93d6-8bf0ce8d1408.png) ![image](https://user-images.githubusercontent.com/16251792/49219610-12deae80-f3d4-11e8-94a5-4c7182ab4458.png) [Webhook to DB with connection-export.zip](https://github.com/syndesisio/syndesis/files/2628927/Webhook.to.DB.with.connection-export.zip)  **Step to reproduce:** 1. import integration: 2. publish it 3. in the command line, update endpoint for webhook and run ``` curl -k -v https://i-webhook-to-db-syndesis.192.168.42.27.nip.io/webhook/test-webhook -d '{"first_name":"John","company":"Red Hat"}' -X POST -H "Content-Type: application/json" ```</body>
		<created>2018-11-29 12:27:28</created>
		<closed>2019-05-27 16:00:24</closed>
	</bug>
	<bug>
		<id>4180</id>
		<title>/tools/bin/syndesis minishift --install --reset  fails against latest minishift</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  &lt;pre&gt;&lt;code&gt; $ minishift version minishift v1.27.0+707887e  $ ./tools/bin/syndesis minishift --install --reset  Add-on 'admin-user' enabled Starting minishift .... -- Starting profile 'minishift' -- Check if deprecated options are used ... OK -- Checking if https://github.com is reachable ... OK -- Checking if requested OpenShift version 'v3.9.0' is valid ... OK -- Checking if requested OpenShift version 'v3.9.0' is supported ... FAIL    Minishift does not support OpenShift version v3.9.0. You need to use a version &gt;= v3.10.0  ERROR: Last command exited with 1 &lt;/code&gt;&lt;/pre&gt; </body>
		<created>2018-11-28 14:44:43</created>
		<closed>2019-01-28 13:05:01</closed>
	</bug>
	<bug>
		<id>4173</id>
		<title>[Upgrade] Cannot extract minor version from "1.1"</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Just a cosmetical issue, the script can't parse minor version from string like "1.0" </body>
		<created>2018-11-28 09:34:17</created>
		<closed>2018-11-29 09:25:35</closed>
	</bug>
	<bug>
		<id>4167</id>
		<title>Integration Details History - old version's 'last published' field updated on configuration change</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem When editing an integration there is unexpected change of 'last published' information of the preceding version in Integration's version history. See the screencast, where Version 3 is updated when Version 4 is created. That is IMO unexpected as Version 3 shouldn't have been updated.  There seems to be conflict in meaning of the field. Should it provide value in the sense of 'This version published on' or 'This version was published until' .... currently we're mixing the information in a single value: -&gt; for a new version the value holds 'published on' -&gt; for a replaced version the value holds 'published until'  ## Screencast ![published](https://user-images.githubusercontent.com/11939909/49086802-b0f83a80-f255-11e8-80d1-3eb92dedb088.gif)    ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; I'd expect the value 'last published' to contain timestamp of publishing the integration (time of edit). </body>
		<created>2018-11-27 14:19:47</created>
		<closed>2019-04-03 12:36:20</closed>
	</bug>
	<bug>
		<id>4162</id>
		<title>The basic filter doesn't show any hints for the webhook property</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When I have (e.g.) the slack connection, the Basic filter gives me the hint, which values I can add to the property name. e.g. ![image](https://user-images.githubusercontent.com/16251792/49019144-8a6ecc80-f18d-11e8-8fd2-77c0664a1fb1.png)   But when I have a webhook which is defined with e.g. JSON instance {"first_name":"John","company":"Red Hat"} like: ![image](https://user-images.githubusercontent.com/16251792/49018648-3ca59480-f18c-11e8-9413-8c91b24134e3.png) the Basic filter doesn't give me any hint. ![image](https://user-images.githubusercontent.com/16251792/49018730-79718b80-f18c-11e8-9f09-c112c7593b40.png)  When I add _first_name_ to the input element, the integration works.  For users, it can be confusing when for some connection it works and for some, it doesn't work. They could think that when the Basic filter doesn't show properties, something is wrong in the steps before. I would expect that Basic filter shows me **first_name** and **company**.  </body>
		<created>2018-11-26 14:17:07</created>
		<closed>2019-03-05 13:58:37</closed>
	</bug>
	<bug>
		<id>4140</id>
		<title>Creating API Connector fails but no error displayed on UI</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  - Downloaded [this](https://github.com/open-banking/model-config) open-banking specification to use as an example; - In Syndesis:   - clicked on 'customizations' and, when prompted, selected the .yaml file;   - clicked Next.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; OpenAPI specification should be imported correctly.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; The progress spinner just keeps spinning and never returns: ![never-ending-wheel](https://user-images.githubusercontent.com/1634180/48941992-8f294b80-ef15-11e8-8f68-91686d79ccaa.png)  Poking into the console, its clear something has gone wrong: ![never-ending-console-errors](https://user-images.githubusercontent.com/1634180/48942003-94869600-ef15-11e8-9b37-ae4eeadf74bf.png) Looking at the source, it would appear that the request is created without due regard for errors generated. In this case: - action.payload is valid but contains an error, specifically "Unable to read OpenAPI specification from: openapi: "3.0.1"info:  version: "1.0.0-alpha1"  title: "pg-ledger API"  description: "API to ..." so maybe not a recognised format?? - action.payload.configuredproperties is undefined; - action.payload.configuredproperties.specification is also undefined; - action.payload.name is undefined hence attempts to read action.payload.specification.info fail and cause the exception  ![never-ending-source](https://user-images.githubusercontent.com/1634180/48941994-918ba580-ef15-11e8-8cca-9fb68126faf0.png)  Now, it may be the case that this OpenAPI specification is not valid. In which case it would be good to know why. However, more importantly error handling for non-valid files would be an advantage.  To escape the infinite spinner requires a page refresh of the browser.  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; See above. </body>
		<created>2018-11-23 11:58:17</created>
		<closed>2019-03-06 18:25:55</closed>
	</bug>
	<bug>
		<id>4133</id>
		<title>Install script ends with error when used more than 1 time</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11440**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When using install script more than once, it ends with error because the clusterroles already exists (they are not cleaned when the namespace is deleted).  But syndesis is deployed successfully   ``` ./syndesis install --project myproject -y Deleting project myproject project "myproject" deleted Creating project myproject Project still exists. Sleeping 10s ... Project still exists. Sleeping 10s ... Project still exists. Sleeping 10s ... Already on project "myproject" on server "https://192.168.99.100:8443". Deploying Syndesis operator Waiting for syndesis-operator to be scaled to 1 Sleeping 10s ... NAME                         READY     STATUS    RESTARTS   AGE syndesis-operator-1-deploy   0/1       Pending   0          2s syndesis-operator-1-deploy   0/1       Pending   0         2s syndesis-operator-1-deploy   0/1       ContainerCreating   0         2s syndesis-operator-1-hjw82   0/1       Pending   0         1s syndesis-operator-1-hjw82   0/1       Pending   0         1s syndesis-operator-1-hjw82   0/1       ContainerCreating   0         1s syndesis-operator-1-deploy   1/1       Running   0         4s syndesis-operator-1-hjw82   1/1       Running   0         3s syndesis-operator-1-deploy   0/1       Completed   0         6s syndesis-operator-1-deploy   0/1       Terminating   0         6s syndesis-operator-1-deploy   0/1       Terminating   0         6s ERROR: Cannot create remote resource https://raw.githubusercontent.com/syndesisio/syndesis/master/install/operator/deploy/syndesis-operator.yml  ===============================================================  serviceaccount "syndesis-operator" created role "syndesis-operator" created rolebinding "syndesis-operator:install" created rolebinding "syndesis-operator:view" created rolebinding "syndesis-operator:edit" created imagestream "syndesis-operator" created deploymentconfig "syndesis-operator" created Error from server (AlreadyExists): clusterroles.rbac.authorization.k8s.io "syndesis-operator:myproject" already exists Error from server (AlreadyExists): clusterrolebindings.authorization.openshift.io "syndesis-operator:oauth:myproject" already exists  ``` </body>
		<created>2018-11-22 13:03:06</created>
		<closed>2019-09-07 11:29:37</closed>
	</bug>
	<bug>
		<id>4131</id>
		<title>Unable to deploy syndesis from master</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Unable to deploy with current master  ``` oc logs -f syndesis-operator-1-kq87w                                                                                                                                                               11:19:47 time="2018-11-22T10:19:20Z" level=info msg="Go Version: go1.10.3" time="2018-11-22T10:19:20Z" level=info msg="Go OS/Arch: linux/amd64" time="2018-11-22T10:19:20Z" level=info msg="operator-sdk Version: 0.0.5+git" time="2018-11-22T10:19:20Z" level=info msg="Using template /conf/syndesis-template.yml" time="2018-11-22T10:19:20Z" level=info msg="Watching syndesis.io/v1alpha1, Syndesis, myproject, 5" time="2018-11-22T10:19:20Z" level=info msg="No legacy Syndesis installations detected in the myproject namespace" time="2018-11-22T10:19:20Z" level=info msg="Syndesis legacy installations check completed" time="2018-11-22T10:19:24Z" level=info msg="Syndesis resource app initialized: installing version latest" time="2018-11-22T10:19:24Z" level=info msg="Installing Syndesis resource app" time="2018-11-22T10:19:25Z" level=error msg="error syncing key (myproject/app): oauthclients.oauth.openshift.io is forbidden: User \"system:serviceaccount:myproject:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: User \"system:serviceaccount:myproject:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: clusterrole.rbac.authorization.k8s.io \"syndesis-operator\" not found" time="2018-11-22T10:19:25Z" level=info msg="Installing Syndesis resource app" time="2018-11-22T10:19:32Z" level=error msg="error syncing key (myproject/app): oauthclients.oauth.openshift.io is forbidden: User \"system:serviceaccount:myproject:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: User \"system:serviceaccount:myproject:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: clusterrole.rbac.authorization.k8s.io \"syndesis-operator\" not found" time="2018-11-22T10:19:32Z" level=info msg="Installing Syndesis resource app" time="2018-11-22T10:19:39Z" level=error msg="error syncing key (myproject/app): oauthclients.oauth.openshift.io is forbidden: User \"system:serviceaccount:myproject:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: User \"system:serviceaccount:myproject:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: clusterrole.rbac.authorization.k8s.io \"syndesis-operator\" not found" time="2018-11-22T10:19:39Z" level=info msg="Installing Syndesis resource app" time="2018-11-22T10:19:46Z" level=error msg="error syncing key (myproject/app): oauthclients.oauth.openshift.io is forbidden: User \"system:serviceaccount:myproject:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: User \"system:serviceaccount:myproject:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: clusterrole.rbac.authorization.k8s.io \"syndesis-operator\" not found" time="2018-11-22T10:19:46Z" level=info msg="Installing Syndesis resource app" time="2018-11-22T10:19:53Z" level=error msg="error syncing key (myproject/app): oauthclients.oauth.openshift.io is forbidden: User \"system:serviceaccount:myproject:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: User \"system:serviceaccount:myproject:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: clusterrole.rbac.authorization.k8s.io \"syndesis-operator\" not found" time="2018-11-22T10:19:53Z" level=info msg="Installing Syndesis resource app" time="2018-11-22T10:20:00Z" level=error msg="error syncing key (myproject/app): oauthclients.oauth.openshift.io is forbidden: User \"system:serviceaccount:myproject:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: User \"system:serviceaccount:myproject:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: clusterrole.rbac.authorization.k8s.io \"syndesis-operator\" not found" time="2018-11-22T10:20:00Z" level=info msg="Installing Syndesis resource app" time="2018-11-22T10:20:07Z" level=error msg="error syncing key (myproject/app): oauthclients.oauth.openshift.io is forbidden: User \"system:serviceaccount:myproject:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: User \"system:serviceaccount:myproject:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: clusterrole.rbac.authorization.k8s.io \"syndesis-operator\" not found" time="2018-11-22T10:20:07Z" level=info msg="Installing Syndesis resource app" time="2018-11-22T10:20:14Z" level=error msg="error syncing key (myproject/app): oauthclients.oauth.openshift.io is forbidden: User \"system:serviceaccount:myproject:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: User \"system:serviceaccount:myproject:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: clusterrole.rbac.authorization.k8s.io \"syndesis-operator\" not found" time="2018-11-22T10:20:14Z" level=info msg="Installing Syndesis resource app" time="2018-11-22T10:20:21Z" level=error msg="error syncing key (myproject/app): oauthclients.oauth.openshift.io is forbidden: User \"system:serviceaccount:myproject:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: User \"system:serviceaccount:myproject:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: clusterrole.rbac.authorization.k8s.io \"syndesis-operator\" not found" time="2018-11-22T10:20:21Z" level=info msg="Installing Syndesis resource app" time="2018-11-22T10:20:28Z" level=error msg="error syncing key (myproject/app): oauthclients.oauth.openshift.io is forbidden: User \"system:serviceaccount:myproject:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: User \"system:serviceaccount:myproject:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: clusterrole.rbac.authorization.k8s.io \"syndesis-operator\" not found" time="2018-11-22T10:20:28Z" level=info msg="Installing Syndesis resource app" time="2018-11-22T10:20:35Z" level=error msg="error syncing key (myproject/app): oauthclients.oauth.openshift.io is forbidden: User \"system:serviceaccount:myproject:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: User \"system:serviceaccount:myproject:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: clusterrole.rbac.authorization.k8s.io \"syndesis-operator\" not found" time="2018-11-22T10:20:35Z" level=info msg="Installing Syndesis resource app" time="2018-11-22T10:20:42Z" level=error msg="error syncing key (myproject/app): oauthclients.oauth.openshift.io is forbidden: User \"system:serviceaccount:myproject:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: User \"system:serviceaccount:myproject:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: clusterrole.rbac.authorization.k8s.io \"syndesis-operator\" not found" time="2018-11-22T10:20:42Z" level=info msg="Installing Syndesis resource app" time="2018-11-22T10:20:49Z" level=error msg="error syncing key (myproject/app): oauthclients.oauth.openshift.io is forbidden: User \"system:serviceaccount:myproject:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: User \"system:serviceaccount:myproject:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: clusterrole.rbac.authorization.k8s.io \"syndesis-operator\" not found"  ``` </body>
		<created>2018-11-22 11:07:26</created>
		<closed>2018-11-22 13:25:36</closed>
	</bug>
	<bug>
		<id>4126</id>
		<title>Unable to install syndesis into multiple namespaces in one cluster</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description with 1.5.6 tag it was possible to install 2 syndesises into 2 separate namespaces in one cluster. With master it is not possible.  ``` ./syndesis install --project first -y &lt;output omitted, everything alright&gt; ```  wait for first syndesis to deploy and then:  ``` ./syndesis install --project second -y Creating project second Already on project "second" on server "https://192.168.99.100:8443". Deploying Syndesis operator Waiting for syndesis-operator to be scaled to 1 Sleeping 10s ... NAME                         READY     STATUS    RESTARTS   AGE syndesis-operator-1-deploy   0/1       Pending   0          1s syndesis-operator-1-deploy   0/1       Pending   0         1s syndesis-operator-1-deploy   0/1       ContainerCreating   0         1s syndesis-operator-1-99bl9   0/1       Pending   0         2s syndesis-operator-1-99bl9   0/1       Pending   0         2s syndesis-operator-1-99bl9   0/1       ContainerCreating   0         2s syndesis-operator-1-deploy   1/1       Running   0         3s syndesis-operator-1-99bl9   1/1       Running   0         3s syndesis-operator-1-deploy   0/1       Completed   0         5s syndesis-operator-1-deploy   0/1       Terminating   0         5s syndesis-operator-1-deploy   0/1       Terminating   0         5s ERROR: Cannot create remote resource https://raw.githubusercontent.com/syndesisio/syndesis/master/install/operator/deploy/syndesis-operator.yml  ===============================================================  serviceaccount "syndesis-operator" created role "syndesis-operator" created rolebinding "syndesis-operator:install" created rolebinding "syndesis-operator:view" created rolebinding "syndesis-operator:edit" created imagestream "syndesis-operator" created deploymentconfig "syndesis-operator" created Error from server (AlreadyExists): clusterroles.rbac.authorization.k8s.io "syndesis-operator" already exists Error from server (AlreadyExists): clusterrolebindings.authorization.openshift.io "syndesis-operator:oauth" already exists ```  ``` oc logs -f syndesis-operator-1-99bl9 -n second time="2018-11-21T15:53:19Z" level=info msg="Go Version: go1.10.3" time="2018-11-21T15:53:19Z" level=info msg="Go OS/Arch: linux/amd64" time="2018-11-21T15:53:19Z" level=info msg="operator-sdk Version: 0.0.5+git" time="2018-11-21T15:53:19Z" level=info msg="Using template /conf/syndesis-template.yml" time="2018-11-21T15:53:19Z" level=info msg="Watching syndesis.io/v1alpha1, Syndesis, second, 5" time="2018-11-21T15:53:19Z" level=info msg="No legacy Syndesis installations detected in the second namespace" time="2018-11-21T15:53:19Z" level=info msg="Syndesis legacy installations check completed" time="2018-11-21T15:53:25Z" level=info msg="Syndesis resource app initialized: installing version latest" time="2018-11-21T15:53:25Z" level=info msg="Installing Syndesis resource app" time="2018-11-21T15:53:26Z" level=error msg="error syncing key (second/app): oauthclients.oauth.openshift.io is forbidden: User \"system:serviceaccount:second:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: User \"system:serviceaccount:second:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope" time="2018-11-21T15:53:26Z" level=info msg="Installing Syndesis resource app" time="2018-11-21T15:53:34Z" level=error msg="error syncing key (second/app): oauthclients.oauth.openshift.io is forbidden: User \"system:serviceaccount:second:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: User \"system:serviceaccount:second:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope" time="2018-11-21T15:53:34Z" level=info msg="Installing Syndesis resource app" time="2018-11-21T15:53:41Z" level=error msg="error syncing key (second/app): oauthclients.oauth.openshift.io is forbidden: User \"system:serviceaccount:second:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: User \"system:serviceaccount:second:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope" time="2018-11-21T15:53:41Z" level=info msg="Installing Syndesis resource app" time="2018-11-21T15:53:49Z" level=error msg="error syncing key (second/app): oauthclients.oauth.openshift.io is forbidden: User \"system:serviceaccount:second:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: User \"system:serviceaccount:second:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope"  ```  In the `second` namespace the operator periodically spawns and de-spawns syndesis pods  Running with `./syndesis install --project second -y --tag 1.5.6` tag - everything is ok  cc @zregvart #3984</body>
		<created>2018-11-21 16:03:34</created>
		<closed>2018-11-22 13:25:20</closed>
	</bug>
	<bug>
		<id>4125</id>
		<title>Duplicate header when using Webhook and API client connector in single Integration</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I get duplicate HTTP header error when creating an integration comprising of: 1. Webhook 2. Custom API invocation via API client connector 3. Data Mapper mapping fields from webhook to request body fields. ``` org.apache.http.client.ClientProtocolException at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:187) at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83) at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56) at org.apache.camel.component.http4.HttpProducer.executeMethod(HttpProducer.java:334) at org.apache.camel.component.http4.HttpProducer.process(HttpProducer.java:193) at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) at org.apache.camel.component.rest.RestProducer.process(RestProducer.java:86) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.component.connector.ConnectorProducer.process(ConnectorProducer.java:45) at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.util.AsyncProcessorHelper.process(AsyncProcessorHelper.java:109) at org.apache.camel.processor.Pipeline.process(Pipeline.java:80) at org.apache.camel.http.common.CamelServlet.doService(CamelServlet.java:214) at org.apache.camel.http.common.CamelServlet.service(CamelServlet.java:80) at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:111) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:103) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:64) at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:132) at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292) at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) at io.undertow.server.Connectors.executeRootHandler(Connectors.java:336) at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Caused by: org.apache.http.ProtocolException: Content-Length header already present at org.apache.http.protocol.RequestContent.process(RequestContent.java:97) at org.apache.http.protocol.ImmutableHttpProcessor.process(ImmutableHttpProcessor.java:133) at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:183) at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89) at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110) at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185) ... 88 more ```  </body>
		<created>2018-11-21 15:35:08</created>
		<closed>2019-03-06 17:25:56</closed>
	</bug>
	<bug>
		<id>4122</id>
		<title>Popovers are off-center</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem Looks like the arrow on the popover isn't centered on the edge of the popover body. Also at the moment, the arrow doesn't point at the center of the thing that triggered the popover, but that may be fixed if you can fix the arrow position in the popover.  ## Expected behavior The arrow in the popover should be centered horizontally/vertically in the popover, and the arrow should point at the center of the thing that triggered the popover.  ## Screenshot &lt;img width="1607" alt="screen shot 2018-11-20 at 4 52 06 pm" src="https://user-images.githubusercontent.com/35148959/48808088-468b4b80-ece5-11e8-9c08-08603e65ea06.png"&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. For this example, create a database to database integration and click on the orange warning icon. Though you might search the code for other instances of a popover, because I'm assuming this is an issue with all popovers.  cc @dongniwang </body>
		<created>2018-11-20 22:58:06</created>
		<closed>2019-01-28 15:34:23</closed>
	</bug>
	<bug>
		<id>4118</id>
		<title>Docker image size of s2i increases over time</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  While rebuilding the syndesis-s2i Docker image during development the image size increases from build to build. 1st build gives me an image size of 1.29 GB, 2nd build 1.8 GB and so on.   Saw that behavior both in s2i-s2i build within Minishift and locally with --docker flag.  Increasing image size is a threat to the disk space of the Minishift VM so reset of Minishift becomes mandatory at some time.</body>
		<created>2018-11-20 08:57:39</created>
		<closed>2019-02-11 08:32:03</closed>
	</bug>
	<bug>
		<id>4096</id>
		<title>Some Tooltips on Setting page are missing</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description On Setting page, the tooltips of 'Client ID' and 'Client Secret, etc...'on Salesforce and SAP Concur  are missing.    &lt;img width="1278" alt="2018-11-16 3 04 20" src="https://user-images.githubusercontent.com/34368385/48603375-2724b380-e9b1-11e8-9bcf-dc8e0a22e791.png"&gt;  &lt;img width="1297" alt="2018-11-16 3 09 07" src="https://user-images.githubusercontent.com/34368385/48603489-8b477780-e9b1-11e8-8f6d-923fd4cb9303.png"&gt;    </body>
		<created>2018-11-16 07:09:18</created>
		<closed>2019-01-28 15:36:46</closed>
	</bug>
	<bug>
		<id>4093</id>
		<title>Unable to deploy syndesis from master</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description After #3984 the operator can't deploy anything:  ``` ERROR: Cannot create remote resource https://raw.githubusercontent.com/syndesisio/syndesis/master/install/operator/deploy/syndesis-operator.yml  ===============================================================  serviceaccount "syndesis-operator" created role "syndesis-operator" created clusterrole "syndesis-operator" created rolebinding "syndesis-operator:install" created rolebinding "syndesis-operator:view" created rolebinding "syndesis-operator:edit" created imagestream "syndesis-operator" created deploymentconfig "syndesis-operator" created The clusterrolebindings "syndesis-operator:oauth" is invalid: subjects[0].namespace: Required value ```  ``` time="2018-11-15T13:59:08Z" level=info msg="Go Version: go1.10.3" time="2018-11-15T13:59:09Z" level=info msg="Go OS/Arch: linux/amd64" time="2018-11-15T13:59:09Z" level=info msg="operator-sdk Version: 0.0.5+git" time="2018-11-15T13:59:09Z" level=info msg="Using template /conf/syndesis-template.yml" time="2018-11-15T13:59:09Z" level=info msg="Watching syndesis.io/v1alpha1, Syndesis, syndesis, 5" time="2018-11-15T13:59:09Z" level=info msg="No legacy Syndesis installations detected in the syndesis namespace" time="2018-11-15T13:59:09Z" level=info msg="Syndesis legacy installations check completed" time="2018-11-15T13:59:26Z" level=info msg="Syndesis resource example initialized: installing version latest" time="2018-11-15T13:59:26Z" level=info msg="Installing Syndesis resource example" time="2018-11-15T13:59:26Z" level=error msg="error syncing key (syndesis/example): oauthclients.oauth.openshift.io is forbidden: User \"system:serviceaccount:syndesis:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: User \"system:serviceaccount:syndesis:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope" time="2018-11-15T13:59:26Z" level=info msg="Installing Syndesis resource example" time="2018-11-15T13:59:33Z" level=error msg="error syncing key (syndesis/example): oauthclients.oauth.openshift.io is forbidden: User \"system:serviceaccount:syndesis:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: User \"system:serviceaccount:syndesis:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope" time="2018-11-15T13:59:33Z" level=info msg="Installing Syndesis resource example" time="2018-11-15T13:59:41Z" level=error msg="error syncing key (syndesis/example): oauthclients.oauth.openshift.io is forbidden: User \"system:serviceaccount:syndesis:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: User \"system:serviceaccount:syndesis:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope" time="2018-11-15T13:59:41Z" level=info msg="Installing Syndesis resource example" time="2018-11-15T13:59:48Z" level=error msg="error syncing key (syndesis/example): oauthclients.oauth.openshift.io is forbidden: User \"system:serviceaccount:syndesis:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: User \"system:serviceaccount:syndesis:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope" time="2018-11-15T13:59:48Z" level=info msg="Installing Syndesis resource example" time="2018-11-15T13:59:55Z" level=error msg="error syncing key (syndesis/example): oauthclients.oauth.openshift.io is forbidden: User \"system:serviceaccount:syndesis:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: User \"system:serviceaccount:syndesis:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope" time="2018-11-15T13:59:55Z" level=info msg="Installing Syndesis resource example" time="2018-11-15T14:00:02Z" level=error msg="error syncing key (syndesis/example): oauthclients.oauth.openshift.io is forbidden: User \"system:serviceaccount:syndesis:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope: User \"system:serviceaccount:syndesis:syndesis-operator\" cannot create oauthclients.oauth.openshift.io at the cluster scope" time="2018-11-15T14:00:02Z" level=info msg="Installing Syndesis resource example" ```  minishift v1.26.1+1e20f27 openshift 3.10.0 </body>
		<created>2018-11-15 14:12:59</created>
		<closed>2018-11-21 16:03:17</closed>
	</bug>
	<bug>
		<id>4089</id>
		<title>CI build issues with ca.uhn.hapi.fhir:hapi-fhir-base:jar:3.5.0</title>
		<body>I've seen this quite a few times now. (re-run fixed it)  https://circleci.com/gh/syndesisio/syndesis/49983?utm_campaign=workflow-failed&amp;utm_medium=email&amp;utm_source=notification  ./tools/bin/syndesis build --batch-mode --module meta --docker | tee build_log.txt Modules: meta ============================================================================== ./mvnw -N --batch-mode install -Pflash ### Installing parent pom.xml [INFO] Scanning for projects... [INFO]  [INFO] ------------------------------------------------------------------------ [INFO] Building Syndesis 1.5-SNAPSHOT [INFO] ------------------------------------------------------------------------ [INFO]  [INFO] --- git-commit-id-plugin:2.2.2:revision (default) @ syndesis-parent --- [INFO]  [INFO] --- maven-assembly-plugin:3.1.0:single (create-tool-jar) @ syndesis-parent --- [INFO] Reading assembly descriptor: tools.xml [INFO] Building jar: /workspace/app/target/syndesis-parent-1.5-SNAPSHOT-tools.jar [INFO]  [INFO] --- dependency-scope-maven-plugin:0.8:check (default) @ syndesis-parent --- [INFO] Skipping plugin execution [INFO]  [INFO] --- maven-install-plugin:2.5.2:install (default-install) @ syndesis-parent --- [INFO] Installing /workspace/app/pom.xml to /root/.m2/repository/io/syndesis/syndesis-parent/1.5-SNAPSHOT/syndesis-parent-1.5-SNAPSHOT.pom [INFO] Installing /workspace/app/target/syndesis-parent-1.5-SNAPSHOT-tools.jar to /root/.m2/repository/io/syndesis/syndesis-parent/1.5-SNAPSHOT/syndesis-parent-1.5-SNAPSHOT-tools.jar [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 1.467 s [INFO] Finished at: 2018-11-14T21:20:36Z [INFO] Final Memory: 20M/66M [INFO] ------------------------------------------------------------------------ ============================================================================== ./mvnw --batch-mode -Pimage -Dfabric8.mode=kubernetes install -f meta ### Processing module meta ============================================================================== [INFO] Scanning for projects... [INFO]  [INFO] ------------------------------------------------------------------------ [INFO] Building Meta 1.5-SNAPSHOT [INFO] ------------------------------------------------------------------------ [INFO] Downloading from redhat.ga: https://maven.repository.redhat.com/ga/com/mycila/license-maven-plugin/maven-metadata.xml [INFO] Downloading from jboss_origin: https://origin-repository.jboss.org/nexus/content/groups/ea/com/mycila/license-maven-plugin/maven-metadata.xml [INFO] Downloading from jboss-fuse: https://origin-repository.jboss.org/nexus/content/groups/ea/org/springframework/spring-core/4.3.17.RELEASE/spring-core-4.3.17.RELEASE.pom [INFO] Downloading from mrrc-redhat: https://maven.repository.redhat.com/ga/org/springframework/spring-core/4.3.17.RELEASE/spring-core-4.3.17.RELEASE.pom [INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/springframework/spring-core/4.3.17.RELEASE/spring-core-4.3.17.RELEASE.pom [INFO] Downloading from spring-ext: https://repo.spring.io/ext-release-local/org/springframework/spring-core/4.3.17.RELEASE/spring-core-4.3.17.RELEASE.pom [INFO] Downloading from spring-milestones: https://repo.spring.io/milestone/org/springframework/spring-core/4.3.17.RELEASE/spring-core-4.3.17.RELEASE.pom [INFO] Downloaded from spring-milestones: https://repo.spring.io/milestone/org/springframework/spring-core/4.3.17.RELEASE/spring-core-4.3.17.RELEASE.pom (2.5 kB at 14 kB/s) [INFO] Downloading from jboss-fuse: https://origin-repository.jboss.org/nexus/content/groups/ea/org/springframework/spring-core/4.3.17.RELEASE/spring-core-4.3.17.RELEASE.jar [INFO] Downloading from jboss-fuse: https://origin-repository.jboss.org/nexus/content/groups/ea/ca/uhn/hapi/fhir/hapi-fhir-base/3.5.0/hapi-fhir-base-3.5.0.jar [INFO] Downloading from jboss-fuse: https://origin-repository.jboss.org/nexus/content/groups/ea/org/apache/commons/commons-text/1.4/commons-text-1.4.jar [INFO] Downloading from jboss-fuse: https://origin-repository.jboss.org/nexus/content/groups/ea/ca/uhn/hapi/fhir/hapi-fhir-structures-dstu3/3.5.0/hapi-fhir-structures-dstu3-3.5.0.jar [INFO] Downloading from jboss-fuse: https://origin-repository.jboss.org/nexus/content/groups/ea/ca/uhn/hapi/fhir/hapi-fhir-utilities/3.5.0/hapi-fhir-utilities-3.5.0.jar [INFO] Downloading from jboss-fuse: https://origin-repository.jboss.org/nexus/content/groups/ea/ca/uhn/hapi/fhir/hapi-fhir-structures-dstu2/3.5.0/hapi-fhir-structures-dstu2-3.5.0.jar [INFO] Downloading from mrrc-redhat: https://maven.repository.redhat.com/ga/org/springframework/spring-core/4.3.17.RELEASE/spring-core-4.3.17.RELEASE.jar [INFO] Downloading from mrrc-redhat: https://maven.repository.redhat.com/ga/ca/uhn/hapi/fhir/hapi-fhir-base/3.5.0/hapi-fhir-base-3.5.0.jar [INFO] Downloading from mrrc-redhat: https://maven.repository.redhat.com/ga/org/apache/commons/commons-text/1.4/commons-text-1.4.jar [INFO] Downloading from mrrc-redhat: https://maven.repository.redhat.com/ga/ca/uhn/hapi/fhir/hapi-fhir-structures-dstu3/3.5.0/hapi-fhir-structures-dstu3-3.5.0.jar [INFO] Downloading from mrrc-redhat: https://maven.repository.redhat.com/ga/ca/uhn/hapi/fhir/hapi-fhir-utilities/3.5.0/hapi-fhir-utilities-3.5.0.jar [INFO] Downloading from mrrc-redhat: https://maven.repository.redhat.com/ga/ca/uhn/hapi/fhir/hapi-fhir-structures-dstu2/3.5.0/hapi-fhir-structures-dstu2-3.5.0.jar [INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/springframework/spring-core/4.3.17.RELEASE/spring-core-4.3.17.RELEASE.jar [INFO] Downloading from central: https://repo.maven.apache.org/maven2/ca/uhn/hapi/fhir/hapi-fhir-base/3.5.0/hapi-fhir-base-3.5.0.jar [INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/apache/commons/commons-text/1.4/commons-text-1.4.jar [INFO] Downloading from central: https://repo.maven.apache.org/maven2/ca/uhn/hapi/fhir/hapi-fhir-structures-dstu3/3.5.0/hapi-fhir-structures-dstu3-3.5.0.jar [INFO] Downloading from central: https://repo.maven.apache.org/maven2/ca/uhn/hapi/fhir/hapi-fhir-utilities/3.5.0/hapi-fhir-utilities-3.5.0.jar [INFO] Downloading from central: https://repo.maven.apache.org/maven2/ca/uhn/hapi/fhir/hapi-fhir-structures-dstu2/3.5.0/hapi-fhir-structures-dstu2-3.5.0.jar [INFO] Downloading from spring-ext: https://repo.spring.io/ext-release-local/org/springframework/spring-core/4.3.17.RELEASE/spring-core-4.3.17.RELEASE.jar [INFO] Downloading from spring-milestones: https://repo.spring.io/milestone/org/springframework/spring-core/4.3.17.RELEASE/spring-core-4.3.17.RELEASE.jar [INFO] Downloaded from spring-milestones: https://repo.spring.io/milestone/org/springframework/spring-core/4.3.17.RELEASE/spring-core-4.3.17.RELEASE.jar (1.1 MB at 3.3 MB/s) [INFO] Downloading from jb-fuse-7-brew: http://download.eng.bos.redhat.com/brewroot/repos/jb-fuse-7-maven-build/latest/maven/ca/uhn/hapi/fhir/hapi-fhir-base/3.5.0/hapi-fhir-base-3.5.0.jar [INFO] Downloading from jb-fuse-7-brew: http://download.eng.bos.redhat.com/brewroot/repos/jb-fuse-7-maven-build/latest/maven/org/apache/commons/commons-text/1.4/commons-text-1.4.jar [INFO] Downloading from jb-fuse-7-brew: http://download.eng.bos.redhat.com/brewroot/repos/jb-fuse-7-maven-build/latest/maven/ca/uhn/hapi/fhir/hapi-fhir-structures-dstu3/3.5.0/hapi-fhir-structures-dstu3-3.5.0.jar [INFO] Downloading from jb-fuse-7-brew: http://download.eng.bos.redhat.com/brewroot/repos/jb-fuse-7-maven-build/latest/maven/ca/uhn/hapi/fhir/hapi-fhir-utilities/3.5.0/hapi-fhir-utilities-3.5.0.jar [INFO] Downloading from jb-fuse-7-brew: http://download.eng.bos.redhat.com/brewroot/repos/jb-fuse-7-maven-build/latest/maven/ca/uhn/hapi/fhir/hapi-fhir-structures-dstu2/3.5.0/hapi-fhir-structures-dstu2-3.5.0.jar [INFO] Downloading from bintray-dnault-maven: https://dl.bintray.com/dnault/maven/org/apache/commons/commons-text/1.4/commons-text-1.4.jar [INFO] Downloading from bintray-dnault-maven: https://dl.bintray.com/dnault/maven/ca/uhn/hapi/fhir/hapi-fhir-utilities/3.5.0/hapi-fhir-utilities-3.5.0.jar [INFO] Downloading from jitpack.io: https://jitpack.io/org/apache/commons/commons-text/1.4/commons-text-1.4.jar [INFO] Downloading from jitpack.io: https://jitpack.io/ca/uhn/hapi/fhir/hapi-fhir-utilities/3.5.0/hapi-fhir-utilities-3.5.0.jar [INFO] Downloading from oss-snapshot: https://oss.sonatype.org/content/repositories/snapshots/org/apache/commons/commons-text/1.4/commons-text-1.4.jar [INFO] Downloading from oss-snapshot: https://oss.sonatype.org/content/repositories/snapshots/ca/uhn/hapi/fhir/hapi-fhir-utilities/3.5.0/hapi-fhir-utilities-3.5.0.jar [INFO] ------------------------------------------------------------------------ [INFO] BUILD FAILURE [INFO] ------------------------------------------------------------------------ [INFO] Total time: 10.706 s [INFO] Finished at: 2018-11-14T21:20:47Z [INFO] Final Memory: 57M/190M [INFO] ------------------------------------------------------------------------ [ERROR] Failed to execute goal on project meta: Could not resolve dependencies for project io.syndesis.meta:meta:jar:1.5-SNAPSHOT: The following artifacts could not be resolved: ca.uhn.hapi.fhir:hapi-fhir-base:jar:3.5.0, org.apache.commons:commons-text:jar:1.4, ca.uhn.hapi.fhir:hapi-fhir-structures-dstu3:jar:3.5.0, ca.uhn.hapi.fhir:hapi-fhir-utilities:jar:3.5.0, ca.uhn.hapi.fhir:hapi-fhir-structures-dstu2:jar:3.5.0: Could not transfer artifact ca.uhn.hapi.fhir:hapi-fhir-base:jar:3.5.0 from/to central (https://repo.maven.apache.org/maven2): Access denied to: https://repo.maven.apache.org/maven2/ca/uhn/hapi/fhir/hapi-fhir-base/3.5.0/hapi-fhir-base-3.5.0.jar , ReasonPhrase:Forbidden. -&gt; [Help 1] [ERROR]  [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch. [ERROR] Re-run Maven using the -X switch to enable full debug logging. [ERROR]  [ERROR] For more information about the errors and possible solutions, please read the following articles: [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException ERROR: Last command exited with 1 Exited with code 1</body>
		<created>2018-11-14 22:50:34</created>
		<closed>2019-01-28 15:37:46</closed>
	</bug>
	<bug>
		<id>4081</id>
		<title>After upgrading from 7.1 to 7.2, user needs to reprovision the integration twice to get rid of the warnings</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description After upgrading from 1.4.9 to 1.5.6, the user is prompted to republish the integration because "its obsolete": ![1](https://user-images.githubusercontent.com/7081216/48403365-04369d00-e72e-11e8-9531-c5df91371940.png)  After doing that and a new version of the integration is published, there are new warnings that the connections were changed and user should edit the integration again: ![2](https://user-images.githubusercontent.com/7081216/48403432-20d2d500-e72e-11e8-9bf0-417e15c6d04b.png)  Steps to reproduce: 1. install 1.4.9 2. create some integration 3. upgrade to 1.5.6 or later 4. observe the warnings &amp; republish 5. after the integration is republished, to go the integration page and there should be new warnings</body>
		<created>2018-11-13 09:26:04</created>
		<closed>2019-04-26 11:04:33</closed>
	</bug>
	<bug>
		<id>4077</id>
		<title>DataMapper returns null from api client connector even though the value exists</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Data mapper is not able to take value from api client connector response, instead null is returned. The integration is between database and todo-app with usage of api client connector.  Check log body before and after data mapper step: ![screenshot_20181112_150814](https://user-images.githubusercontent.com/14313995/48354448-119e4980-e692-11e8-8198-32cfcc62d99c.png)  Data mapper: ![screenshot_20181112_150841](https://user-images.githubusercontent.com/14313995/48354466-1b27b180-e692-11e8-8bb2-088015854a09.png)   Integration: ![screenshot_20181112_150826](https://user-images.githubusercontent.com/14313995/48354480-22e75600-e692-11e8-8f15-4df8fb6d5923.png)    Steps to reproduce: Scenario @DB-custom-api-connector-DB in following feature file: https://github.com/syndesisio/syndesis-qe/blob/master/ui-tests/src/test/resources/features/integrations/api-client-connector.feature#L1   Syndesis version: 1.5.6.fuse-720003-redhat-00001   </body>
		<created>2018-11-12 14:59:46</created>
		<closed>2018-11-12 20:36:18</closed>
	</bug>
	<bug>
		<id>4074</id>
		<title>Build failed but deploying integration continue</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [x] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Friday, we have a problem in the Brno office that https://repo1.maven.org/ was unavailable (Access denied). In this case, my integration (AMQ-&gt;RESTapi) failed on building. However, deploying integration continue, and pod status is ImagePullBackOff (because image not found). After that, it tries to create new deploy and integration pod again but the result is the same (ImagePullBackOff). (In the example below, it tries 20 times)  ``` i-amq-to-rest-api-sample-integration-1-build     0/1       Error              0          20m i-amq-to-rest-api-sample-integration-20-deploy   1/1       Running            0          25s i-amq-to-rest-api-sample-integration-20-l6w87    0/1       ImagePullBackOff   0          23s ```  But why Syndesis continue in deployment when the build failed? I would expect that state of integration is set to failed or error.  integration description (oc describe pod i-amq-to-rest-api-sample-integration-20-l6w87): ``` Events:   Type     Reason     Age                From                Message   ----     ------     ----               ----                -------   Normal   Scheduled  44s                default-scheduler   Successfully assigned i-amq-to-rest-api-sample-integration-18-m2pdb to localhost   Normal   Pulling    27s (x2 over 43s)  kubelet, localhost  pulling image "172.30.1.1:5000/myproject/i-amq-to-rest-api-sample-integration:1"   Warning  Failed     27s (x2 over 43s)  kubelet, localhost  Failed to pull image "172.30.1.1:5000/myproject/i-amq-to-rest-api-sample-integration:1": rpc error: code = Unknown desc = Error: image myproject/i-amq-to-rest-api-sample-integration:1 not found   Warning  Failed     27s (x2 over 43s)  kubelet, localhost  Error: ErrImagePull   Normal   BackOff    13s (x2 over 42s)  kubelet, localhost  Back-off pulling image "172.30.1.1:5000/myproject/i-amq-to-rest-api-sample-integration:1"   Warning  Failed     13s (x2 over 42s)  kubelet, localhost  Error: ImagePullBackOff ```  build (oc logs i-amq-to-rest-api-sample-integration-1-build): ``` Preparing to build temp.builder.openshift.io/myproject/i-amq-to-rest-api-sample-integration-1:0a118d1c Copying sources from "/tmp/build/inputs" to "/tmp/upload/src" Clean build will be performed Running "assemble" in "temp.builder.openshift.io/myproject/i-amq-to-rest-api-sample-integration-1:0a118d1c" ================================================================== Starting S2I Java Build ..... S2I source build for Maven detected Using custom maven settings from /tmp/src/configuration/settings.xml Using MAVEN_OPTS '-XX:+UseG1GC -XX:+UseStringDeduplication -Xmx310m' Found pom.xml ... Running 'mvn -Dmaven.repo.local=/tmp/artifacts/m2 -s /tmp/src/configuration/settings.xml package -DskipTests -Dmaven.javadoc.skip=true -Dmaven.site.skip=true -Dmaven.source.skip=true -Djacoco.skip=true -Dcheckstyle.skip=true -Dfindbugs.skip=true -Dpmd.skip=true -Dfabric8.skip=true -e -B ' Apache Maven 3.3.9 (Red Hat 3.3.9-2.8) Maven home: /opt/rh/rh-maven33/root/usr/share/maven Java version: 1.8.0_181, vendor: Oracle Corporation Java home: /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.181-3.b13.el7_5.x86_64/jre Default locale: en_US, platform encoding: ANSI_X3.4-1968 OS name: "linux", version: "3.10.0-862.14.4.el7.x86_64", arch: "amd64", family: "unix" [INFO] Error stacktraces are turned on. [INFO] Scanning for projects... [INFO] [INFO] ------------------------------------------------------------------------ [INFO] Building Syndesis Integrations :: AMQ to REST API Sample Integration 0.1-SNAPSHOT [INFO] ------------------------------------------------------------------------ [INFO] Downloading: https://repo1.maven.org/maven2/org/apache/camel/camel-jacksonxml/2.21.0.fuse-720040-redhat-00001/camel-jacksonxml-2.21.0.fuse-720040-redhat-00001.pom [INFO] Downloading: https://maven.repository.redhat.com/ga/org/apache/camel/camel-jacksonxml/2.21.0.fuse-720040-redhat-00001/camel-jacksonxml-2.21.0.fuse-720040-redhat-00001.pom [INFO] Downloading: https://repository.jboss.org/nexus/content/groups/ea/org/apache/camel/camel-jacksonxml/2.21.0.fuse-720040-redhat-00001/camel-jacksonxml-2.21.0.fuse-720040-redhat-00001.pom [INFO] Downloading: https://repo1.maven.org/maven2/org/apache/camel/camel-jacksonxml/2.21.0.fuse-720040-redhat-00001/camel-jacksonxml-2.21.0.fuse-720040-redhat-00001.pom [INFO] Downloading: https://repository.jboss.org/org/apache/camel/camel-jacksonxml/2.21.0.fuse-720040-redhat-00001/camel-jacksonxml-2.21.0.fuse-720040-redhat-00001.pom [INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/camel/camel-jacksonxml/2.21.0.fuse-720040-redhat-00001/camel-jacksonxml-2.21.0.fuse-720040-redhat-00001.pom [INFO] ------------------------------------------------------------------------ [INFO] BUILD FAILURE [INFO] ------------------------------------------------------------------------ [INFO] Total time: 4.344 s [INFO] Finished at: 2018-11-09T13:39:07+00:00 [INFO] Final Memory: 25M/84M [INFO] ------------------------------------------------------------------------ [ERROR] Failed to execute goal on project project: Could not resolve dependencies for project io.syndesis.integrations:project:jar:0.1-SNAPSHOT: Failed to collect dependencies at org.apache.camel:camel-jacksonxml:jar:2.21.0.fuse-720040-redhat-00001: Failed to read artifact descriptor for org.apache.camel:camel-jacksonxml:jar:2.21.0.fuse-720040-redhat-00001: Could not transfer artifact org.apache.camel:camel-jacksonxml:pom:2.21.0.fuse-720040-redhat-00001 from/to maven.central (https://repo1.maven.org/maven2): Access denied to: https://repo1.maven.org/maven2/org/apache/camel/camel-jacksonxml/2.21.0.fuse-720040-redhat-00001/camel-jacksonxml-2.21.0.fuse-720040-redhat-00001.pom , ReasonPhrase:Forbidden. -&gt; [Help 1] org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal on project project: Could not resolve dependencies for project io.syndesis.integrations:project:jar:0.1-SNAPSHOT: Failed to collect dependencies at org.apache.camel:camel-jacksonxml:jar:2.21.0.fuse-720040-redhat-00001 at org.apache.maven.lifecycle.internal.LifecycleDependencyResolver.getDependencies(LifecycleDependencyResolver.java:221) at org.apache.maven.lifecycle.internal.LifecycleDependencyResolver.resolveProjectDependencies(LifecycleDependencyResolver.java:127) at org.apache.maven.lifecycle.internal.MojoExecutor.ensureDependenciesAreResolved(MojoExecutor.java:245) at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:199) at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153) at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145) at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:116) at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:80) at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:51) at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128) at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:307) at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:193) at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:106) at org.apache.maven.cli.MavenCli.execute(MavenCli.java:863) at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:288) at org.apache.maven.cli.MavenCli.main(MavenCli.java:199) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289) at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229) at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415) at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356) Caused by: org.apache.maven.project.DependencyResolutionException: Could not resolve dependencies for project io.syndesis.integrations:project:jar:0.1-SNAPSHOT: Failed to collect dependencies at org.apache.camel:camel-jacksonxml:jar:2.21.0.fuse-720040-redhat-00001 at org.apache.maven.project.DefaultProjectDependenciesResolver.resolve(DefaultProjectDependenciesResolver.java:180) at org.apache.maven.lifecycle.internal.LifecycleDependencyResolver.getDependencies(LifecycleDependencyResolver.java:195) ... 23 more Caused by: org.eclipse.aether.collection.DependencyCollectionException: Failed to collect dependencies at org.apache.camel:camel-jacksonxml:jar:2.21.0.fuse-720040-redhat-00001 at org.eclipse.aether.internal.impl.DefaultDependencyCollector.collectDependencies(DefaultDependencyCollector.java:291) at org.eclipse.aether.internal.impl.DefaultRepositorySystem.collectDependencies(DefaultRepositorySystem.java:316) at org.apache.maven.project.DefaultProjectDependenciesResolver.resolve(DefaultProjectDependenciesResolver.java:172) ... 24 more Caused by: org.eclipse.aether.resolution.ArtifactDescriptorException: Failed to read artifact descriptor for org.apache.camel:camel-jacksonxml:jar:2.21.0.fuse-720040-redhat-00001 at org.apache.maven.repository.internal.DefaultArtifactDescriptorReader.loadPom(DefaultArtifactDescriptorReader.java:282) at org.apache.maven.repository.internal.DefaultArtifactDescriptorReader.readArtifactDescriptor(DefaultArtifactDescriptorReader.java:198) at org.eclipse.aether.internal.impl.DefaultDependencyCollector.resolveCachedArtifactDescriptor(DefaultDependencyCollector.java:535) at org.eclipse.aether.internal.impl.DefaultDependencyCollector.getArtifactDescriptorResult(DefaultDependencyCollector.java:519) at org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:409) at org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:363) at org.eclipse.aether.internal.impl.DefaultDependencyCollector.process(DefaultDependencyCollector.java:351) at org.eclipse.aether.internal.impl.DefaultDependencyCollector.collectDependencies(DefaultDependencyCollector.java:254) ... 26 more Caused by: org.eclipse.aether.resolution.ArtifactResolutionException: Could not transfer artifact org.apache.camel:camel-jacksonxml:pom:2.21.0.fuse-720040-redhat-00001 from/to maven.central (https://repo1.maven.org/maven2): Access denied to: https://repo1.maven.org/maven2/org/apache/camel/camel-jacksonxml/2.21.0.fuse-720040-redhat-00001/camel-jacksonxml-2.21.0.fuse-720040-redhat-00001.pom , ReasonPhrase:Forbidden. at org.eclipse.aether.internal.impl.DefaultArtifactResolver.resolve(DefaultArtifactResolver.java:444) at org.eclipse.aether.internal.impl.DefaultArtifactResolver.resolveArtifacts(DefaultArtifactResolver.java:246) at org.eclipse.aether.internal.impl.DefaultArtifactResolver.resolveArtifact(DefaultArtifactResolver.java:223) at org.apache.maven.repository.internal.DefaultArtifactDescriptorReader.loadPom(DefaultArtifactDescriptorReader.java:267) ... 33 more Caused by: org.eclipse.aether.transfer.ArtifactTransferException: Could not transfer artifact org.apache.camel:camel-jacksonxml:pom:2.21.0.fuse-720040-redhat-00001 from/to maven.central (https://repo1.maven.org/maven2): Access denied to: https://repo1.maven.org/maven2/org/apache/camel/camel-jacksonxml/2.21.0.fuse-720040-redhat-00001/camel-jacksonxml-2.21.0.fuse-720040-redhat-00001.pom , ReasonPhrase:Forbidden. at org.eclipse.aether.connector.basic.ArtifactTransportListener.transferFailed(ArtifactTransportListener.java:43) at org.eclipse.aether.connector.basic.BasicRepositoryConnector$TaskRunner.run(BasicRepositoryConnector.java:355) at org.eclipse.aether.util.concurrency.RunnableErrorForwarder$1.run(RunnableErrorForwarder.java:67) at org.eclipse.aether.connector.basic.BasicRepositoryConnector$DirectExecutor.execute(BasicRepositoryConnector.java:581) at org.eclipse.aether.connector.basic.BasicRepositoryConnector.get(BasicRepositoryConnector.java:249) at org.eclipse.aether.internal.impl.DefaultArtifactResolver.performDownloads(DefaultArtifactResolver.java:520) at org.eclipse.aether.internal.impl.DefaultArtifactResolver.resolve(DefaultArtifactResolver.java:421) ... 36 more Caused by: org.apache.maven.wagon.authorization.AuthorizationException: Access denied to: https://repo1.maven.org/maven2/org/apache/camel/camel-jacksonxml/2.21.0.fuse-720040-redhat-00001/camel-jacksonxml-2.21.0.fuse-720040-redhat-00001.pom , ReasonPhrase:Forbidden. at org.apache.maven.wagon.providers.http.AbstractHttpClientWagon.fillInputData(AbstractHttpClientWagon.java:1001) at org.apache.maven.wagon.providers.http.AbstractHttpClientWagon.fillInputData(AbstractHttpClientWagon.java:960) at org.apache.maven.wagon.StreamWagon.getInputStream(StreamWagon.java:116) at org.apache.maven.wagon.StreamWagon.getIfNewer(StreamWagon.java:88) at org.apache.maven.wagon.StreamWagon.get(StreamWagon.java:61) at org.eclipse.aether.transport.wagon.WagonTransporter$GetTaskRunner.run(WagonTransporter.java:560) at org.eclipse.aether.transport.wagon.WagonTransporter.execute(WagonTransporter.java:427) at org.eclipse.aether.transport.wagon.WagonTransporter.get(WagonTransporter.java:404) at org.eclipse.aether.connector.basic.BasicRepositoryConnector$GetTaskRunner.runTask(BasicRepositoryConnector.java:447) at org.eclipse.aether.connector.basic.BasicRepositoryConnector$TaskRunner.run(BasicRepositoryConnector.java:350) ... 41 more [ERROR] [ERROR] Re-run Maven using the -X switch to enable full debug logging. [ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles: [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException Aborting due to error code 1 for Maven build assemble failed with rc=1 error: build error: non-zero (13) exit code from brew-pulp- ```</body>
		<created>2018-11-12 13:02:29</created>
		<closed>2019-03-27 18:11:18</closed>
	</bug>
	<bug>
		<id>4073</id>
		<title>No bean could be found in the registry for: connector-rest-swagger-http4 of type: org.apache.camel.spi.RestProducerFactory</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Error in the pod log during the deploying integration AMQ -&gt; REST API (todo app) which is described in the [Fuse online tutorials](https://access.redhat.com/documentation/en-us/red_hat_fuse/7.0/html-single/ignite_sample_integration_tutorials/#amq-to-rest-api). It has never be published and it is stuck in the 'starting' state.  I have tried it on the _syndesis-1.5.6.fuse-720003_ tag and there it works.  Log: ``` Error starting ApplicationContext. To display the auto-configuration report re-run your application with 'debug' enabled. 2018-11-12 11:38:05.702 ERROR 1 --- [           main] o.s.boot.SpringApplication               : Application startup failed org.apache.camel.RuntimeCamelException: org.apache.camel.FailedToCreateRouteException: Failed to create route -LR6gW5c-5Suhf6Okebp: Route(-LR6gW5c-5Suhf6Okebp)[[From[sjms-0-0]] -&gt; [SetHeader[S... because of Failed to create Producer for endpoint: swagger-operation-0-3?operationId=operation-1. Reason: org.apache.camel.NoSuchBeanException: No bean could be found in the registry for: connector-rest-swagger-http4 of type: org.apache.camel.spi.RestProducerFactory at org.apache.camel.util.ObjectHelper.wrapRuntimeCamelException(ObjectHelper.java:1830) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.spring.SpringCamelContext.start(SpringCamelContext.java:136) ~[camel-spring-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.spring.SpringCamelContext.onApplicationEvent(SpringCamelContext.java:174) ~[camel-spring-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:393) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:347) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:883) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.finishRefresh(EmbeddedWebApplicationContext.java:144) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546) ~[spring-context-4.3.19.RELEASE.jar!/:4.3.19.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) ~[spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.16.RELEASE.jar!/:1.5.16.RELEASE] at io.syndesis.example.Application.main(Application.java:13) [classes!/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_151] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_151] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151] at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.Launcher.launch(Launcher.java:87) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.Launcher.launch(Launcher.java:50) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.PropertiesLauncher.main(PropertiesLauncher.java:595) [project-0.1-SNAPSHOT.jar:na] Caused by: org.apache.camel.FailedToCreateRouteException: Failed to create route -LR6gW5c-5Suhf6Okebp: Route(-LR6gW5c-5Suhf6Okebp)[[From[sjms-0-0]] -&gt; [SetHeader[S... because of Failed to create Producer for endpoint: swagger-operation-0-3?operationId=operation-1. Reason: org.apache.camel.NoSuchBeanException: No bean could be found in the registry for: connector-rest-swagger-http4 of type: org.apache.camel.spi.RestProducerFactory at org.apache.camel.impl.RouteService.warmUp(RouteService.java:147) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.impl.DefaultCamelContext.doWarmUpRoutes(DefaultCamelContext.java:3947) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.impl.DefaultCamelContext.safelyStartRouteServices(DefaultCamelContext.java:3854) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.impl.DefaultCamelContext.doStartOrResumeRoutes(DefaultCamelContext.java:3640) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.impl.DefaultCamelContext.doStartCamel(DefaultCamelContext.java:3492) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.impl.DefaultCamelContext.access$000(DefaultCamelContext.java:209) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.impl.DefaultCamelContext$2.call(DefaultCamelContext.java:3251) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.impl.DefaultCamelContext$2.call(DefaultCamelContext.java:3247) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.impl.DefaultCamelContext.doWithDefinedClassLoader(DefaultCamelContext.java:3270) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.impl.DefaultCamelContext.doStart(DefaultCamelContext.java:3247) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.impl.DefaultCamelContext.start(DefaultCamelContext.java:3163) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.spring.SpringCamelContext.start(SpringCamelContext.java:133) ~[camel-spring-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] ... 24 common frames omitted Caused by: org.apache.camel.FailedToCreateProducerException: Failed to create Producer for endpoint: swagger-operation-0-3?operationId=operation-1. Reason: org.apache.camel.NoSuchBeanException: No bean could be found in the registry for: connector-rest-swagger-http4 of type: org.apache.camel.spi.RestProducerFactory at org.apache.camel.impl.ProducerCache.doGetProducer(ProducerCache.java:584) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.impl.ProducerCache.acquireProducer(ProducerCache.java:168) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.processor.SendProcessor.doStart(SendProcessor.java:248) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:60) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.processor.WrapProcessor.doStart(WrapProcessor.java:52) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:60) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:104) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:90) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.processor.RedeliveryErrorHandler.doStart(RedeliveryErrorHandler.java:1472) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.support.ChildServiceSupport.start(ChildServiceSupport.java:44) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.support.ChildServiceSupport.start(ChildServiceSupport.java:31) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:60) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:104) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:90) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.processor.interceptor.DefaultChannel.doStart(DefaultChannel.java:160) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:60) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:104) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:62) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:104) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:90) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.processor.MulticastProcessor.doStart(MulticastProcessor.java:1186) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:60) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.processor.WrapProcessor.doStart(WrapProcessor.java:52) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:60) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:104) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:90) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.processor.RedeliveryErrorHandler.doStart(RedeliveryErrorHandler.java:1472) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.support.ChildServiceSupport.start(ChildServiceSupport.java:44) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.support.ChildServiceSupport.start(ChildServiceSupport.java:31) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:60) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:104) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:90) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.processor.interceptor.DefaultChannel.doStart(DefaultChannel.java:160) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:60) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:104) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:62) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:104) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:90) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.processor.MulticastProcessor.doStart(MulticastProcessor.java:1186) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:60) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:104) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:90) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.processor.DelegateAsyncProcessor.doStart(DelegateAsyncProcessor.java:80) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.impl.RouteService.startChildService(RouteService.java:370) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.impl.RouteService.doWarmUp(RouteService.java:196) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.impl.RouteService.warmUp(RouteService.java:145) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] ... 36 common frames omitted Caused by: org.apache.camel.NoSuchBeanException: No bean could be found in the registry for: connector-rest-swagger-http4 of type: org.apache.camel.spi.RestProducerFactory at org.apache.camel.component.rest.RestEndpoint.createProducer(RestEndpoint.java:316) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.component.rest.swagger.RestSwaggerEndpoint.createProducerFor(RestSwaggerEndpoint.java:286) ~[camel-rest-swagger-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.component.rest.swagger.RestSwaggerEndpoint.createProducer(RestSwaggerEndpoint.java:191) ~[camel-rest-swagger-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.component.connector.DefaultConnectorEndpoint.createProducer(DefaultConnectorEndpoint.java:51) ~[camel-connector-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] at org.apache.camel.impl.ProducerCache.doGetProducer(ProducerCache.java:573) ~[camel-core-2.21.0.fuse-720029.jar!/:2.21.0.fuse-720029] ... 99 common frames omitted 2018-11-12 11:38:05.704  INFO 1 --- [           main] ationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@40e6dfe1: startup date [Mon Nov 12 11:37:55 UTC 2018]; root of context hierarchy 2018-11-12 11:38:05.706  INFO 1 --- [           main] o.s.c.support.DefaultLifecycleProcessor  : Stopping beans in phase 2147483647 2018-11-12 11:38:05.706  INFO 1 --- [           main] o.s.c.support.DefaultLifecycleProcessor  : Stopping beans in phase 0 2018-11-12 11:38:05.707  INFO 1 --- [           main] o.s.j.e.a.AnnotationMBeanExporter        : Unregistering JMX-exposed beans on shutdown ``` [i-amq-to-todo-integration-3-nhmzs.log](https://github.com/syndesisio/syndesis/files/2571768/i-amq-to-todo-integration-3-nhmzs.log) </body>
		<created>2018-11-12 12:09:52</created>
		<closed>2018-11-23 09:28:34</closed>
	</bug>
	<bug>
		<id>4066</id>
		<title>Upgrade: Unable to upgrade from 7.1 to 7.2 because of SAR_PROJECT</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Similar issue to #3840 , when trying to upgrade from 7.1 to 7.2.CR1, the upgrade fails because of  `error: unknown parameter name "SAR_PROJECT"` ```  Currently there is #4010 still present in the productized operator image, so that needs to be worked-around first to reproduce the issue  ============================================= === STARTING UPGRADE TO SYNDESIS 1.2  ============================================= === * Backup Resource objects (prep_10_backup_resources)       - ConfigMap         * syndesis-db-conf         * syndesis-meta-config         * syndesis-prometheus-config         * syndesis-sampledb-config         * syndesis-server-config         * syndesis-ui-config       - Secret         * syndesis-global-config         * syndesis-oauth-proxy-cookie-secret         * syndesis-server-secret       - DeploymentConfig         * syndesis-db         * syndesis-meta         * syndesis-oauthproxy         * syndesis-prometheus         * syndesis-server         * syndesis-ui       - Service         * syndesis-db         * syndesis-meta         * syndesis-oauthproxy         * syndesis-prometheus         * syndesis-server         * syndesis-ui       - Route         * syndesis       - RoleBinding         * syndesis:editors         * syndesis:viewers       - ServiceAccount         * syndesis-integration         * syndesis-prometheus         * syndesis-server       - Template         * syndesis-upgrade       - PersistentVolumeClaim         * syndesis-db         * syndesis-meta         * syndesis-prometheus       - BuildConfig === * Stopping syndesis-server (prep_10_stop) deploymentconfig "syndesis-server" scaled deploymentconfig "syndesis-meta" scaled Waiting for syndesis-server to be scaled to 0 NAME                          READY     STATUS        RESTARTS   AGE syndesis-db-1-lcjnq           1/1       Running       0          3m syndesis-meta-1-n4h78         1/1       Terminating   0          3m syndesis-oauthproxy-2-j2nkq   1/1       Running       0          50s syndesis-operator-2-ppm4j     1/1       Running       0          35s syndesis-prometheus-1-jsnjq   1/1       Running       0          3m syndesis-ui-1-gpbjq           1/1       Running       0          3m syndesis-upgrade-1.2-1        1/1       Running       0          30s todo-1-4xrz8                  1/1       Running       0          1m todo-1-build                  0/1       Completed     0          3m Waiting for syndesis-meta to be scaled to 0 Sleeping 10s ... syndesis-meta-1-n4h78   0/1       Terminating   0         3m syndesis-meta-1-n4h78   0/1       Terminating   0         3m syndesis-meta-1-n4h78   0/1       Terminating   0         3m === * Stopping syndesis-server (prep_15_stop) deploymentconfig "syndesis-server" scaled deploymentconfig "syndesis-meta" scaled Waiting for syndesis-server to be scaled to 0 NAME                          READY     STATUS      RESTARTS   AGE syndesis-db-1-lcjnq           1/1       Running     0          3m syndesis-oauthproxy-2-j2nkq   1/1       Running     0          1m syndesis-operator-2-ppm4j     1/1       Running     0          50s syndesis-prometheus-1-jsnjq   1/1       Running     0          3m syndesis-ui-1-gpbjq           1/1       Running     0          3m syndesis-upgrade-1.2-1        1/1       Running     0          45s todo-1-4xrz8                  1/1       Running     0          2m todo-1-build                  0/1       Completed   0          3m Waiting for syndesis-meta to be scaled to 0 === * Backup database (prep_20_backup_db) === * Backup Resource objects (prep_30_backup_resources)       - ConfigMap         * syndesis-db-conf         * syndesis-meta-config         * syndesis-prometheus-config         * syndesis-sampledb-config         * syndesis-server-config         * syndesis-ui-config       - Secret         * syndesis-global-config         * syndesis-oauth-proxy-cookie-secret         * syndesis-server-secret       - DeploymentConfig         * syndesis-db         * syndesis-meta         * syndesis-oauthproxy         * syndesis-prometheus         * syndesis-server         * syndesis-ui       - Service         * syndesis-db         * syndesis-meta         * syndesis-oauthproxy         * syndesis-prometheus         * syndesis-server         * syndesis-ui       - Route         * syndesis       - RoleBinding         * syndesis:editors         * syndesis:viewers       - ServiceAccount         * syndesis-integration         * syndesis-prometheus         * syndesis-server       - Template         * syndesis-upgrade       - PersistentVolumeClaim         * syndesis-db         * syndesis-meta         * syndesis-prometheus       - BuildConfig === * Process new template to extract update resources (prep_40_process_template)       - Current Syndesis version "1.4" error: unknown parameter name "SAR_PROJECT" ====&gt; Error ==&gt; Rollback  ----- Rollback --- * Rolling back 'Process new template to extract update resources' --- * Rolling back 'Backup Resource objects' --- * Rolling back 'Backup database' --- * Rolling back 'Stopping syndesis-server' deploymentconfig "syndesis-server" scaled deploymentconfig "syndesis-meta" scaled Waiting for syndesis-server to be scaled to 1 Sleeping 10s ... NAME                          READY     STATUS      RESTARTS   AGE syndesis-db-1-lcjnq           1/1       Running     0          4m syndesis-meta-1-5rnbl         1/1       Running     0          37s syndesis-oauthproxy-2-j2nkq   1/1       Running     0          2m syndesis-operator-2-ppm4j     1/1       Running     0          1m syndesis-prometheus-1-jsnjq   1/1       Running     0          4m syndesis-server-1-2wfjz       0/1       Running     0          39s syndesis-ui-1-gpbjq           1/1       Running     0          4m syndesis-upgrade-1.2-1        1/1       Running     0          1m todo-1-4xrz8                  1/1       Running     0          3m todo-1-build                  0/1       Completed   0          4m syndesis-server-1-2wfjz   1/1       Running   0         46s Waiting for syndesis-meta to be scaled to 1 --- * Rolling back 'Stopping syndesis-server' deploymentconfig "syndesis-server" scaled deploymentconfig "syndesis-meta" scaled Waiting for syndesis-server to be scaled to 1 NAME                          READY     STATUS      RESTARTS   AGE syndesis-db-1-lcjnq           1/1       Running     0          4m syndesis-meta-1-5rnbl         1/1       Running     0          52s syndesis-oauthproxy-2-j2nkq   1/1       Running     0          2m syndesis-operator-2-ppm4j     1/1       Running     0          2m syndesis-prometheus-1-jsnjq   1/1       Running     0          4m syndesis-server-1-2wfjz       1/1       Running     0          54s syndesis-ui-1-gpbjq           1/1       Running     0          4m syndesis-upgrade-1.2-1        1/1       Running     0          2m todo-1-4xrz8                  1/1       Running     0          3m todo-1-build                  0/1       Completed   0          4m Waiting for syndesis-meta to be scaled to 1 --- * Rolling back 'Backup Resource objects' ``` </body>
		<created>2018-11-09 11:50:25</created>
		<closed>2018-11-10 19:29:10</closed>
	</bug>
	<bug>
		<id>4064</id>
		<title>Upgrade: Missing migration script for s2i image</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Since #3464 is not done for 7.2, we need a migration script to bump the s2i imagestream tag to "1.5" like it was done here for 7.1: https://github.com/syndesisio/syndesis/blob/master/tools/upgrade/migration/resource/1.1/03_server_config_map_upgrade.sh#L22  It should be in "1.2" folder </body>
		<created>2018-11-09 09:40:02</created>
		<closed>2018-11-13 14:19:06</closed>
	</bug>
	<bug>
		<id>4056</id>
		<title>Stop/Start integration should not result in new container</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [*] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When I Stop and Start the same integration w/o editing it, it should not build a new container. Instead it should be able to simply spin up a new pod using the old container, same integration version, but I guess a new deployment version.  Maybe it's simply because we call the `update` and not `updateTargetState` on a Start. I think we should only call `update` if the integration was updated. </body>
		<created>2018-11-08 11:02:10</created>
		<closed>2019-02-15 17:01:16</closed>
	</bug>
	<bug>
		<id>4055</id>
		<title>Missing icon custom connector after import</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [*] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The icon should be exported along with the integration, so that on import it reappears  &lt;img width="599" alt="screen shot 2018-11-08 at 11 09 07 am" src="https://user-images.githubusercontent.com/35576/48191951-c230e400-e346-11e8-9600-22615298ea17.png"&gt;  Todo API icon is missing on fresh install and re-import.  https://github.com/syndesisio/syndesis-quickstarts/raw/master/db-2-api-connector/DB-2-APIConnector-export.zip</body>
		<created>2018-11-08 10:09:56</created>
		<closed>2018-12-06 11:33:00</closed>
	</bug>
	<bug>
		<id>4054</id>
		<title>Missing images after integration creation</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; &lt;/code&gt;&lt;/pre&gt;  ## The problem The console of Fuse Online appears as such, without images, after an integration was created.  ![huh](https://user-images.githubusercontent.com/8625482/48188169-12746a00-e378-11e8-9469-9b27f2276bc9.png)  ![online](https://user-images.githubusercontent.com/8625482/48188309-75fe9780-e378-11e8-9295-1b571d11dad1.png)  ![qn](https://user-images.githubusercontent.com/8625482/48189605-8cf2b900-e37b-11e8-95dd-637bdee1e043.png)   ## Expected behavior Images should be present on the console.  ## Request and Response Data An integration involving a webhook and a log connector was created, that led to this error.  Seems to be a repeat of this issue: https://github.com/syndesisio/syndesis/issues/2973 </body>
		<created>2018-11-08 09:04:14</created>
		<closed>2019-02-13 17:54:02</closed>
	</bug>
	<bug>
		<id>4050</id>
		<title>Integration generator is generating Java 1.5 Maven project</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Not sure if it makes any difference (it will only if we generate 1.6+ Java code from the API provider thinggy), but this:  https://github.com/syndesisio/syndesis/blob/e4884127e211eb822dcf7ba608e17d2b587ba4c4/app/integration/project-generator/src/main/resources/io/syndesis/integration/project/generator/templates/pom.xml.mustache#L22  Is not setting the `maven-compiler` source/target property, so it defaults to 1.5. </body>
		<created>2018-11-07 21:30:07</created>
		<closed>2019-02-13 17:54:03</closed>
	</bug>
	<bug>
		<id>4046</id>
		<title>OAuth Application Management shows successful registration message even if nothing is entered</title>
		<body>## The problem when Ok is clicked without entering the Client Id/Secret, we still see the registration successful message, when in effect we havent done anything at all.   ## Screenshot ![image](https://user-images.githubusercontent.com/39506194/48136762-76ab0700-e26e-11e8-9f41-fc603566fc4f.png) </body>
		<created>2018-11-07 14:21:15</created>
		<closed>2018-12-10 16:45:19</closed>
	</bug>
	<bug>
		<id>4026</id>
		<title>org.springframework:spring-core vulnerabilities </title>
		<body>https://github.com/syndesisio/syndesis/network/alert/app/pom.xml/org.springframework:spring-core/open  org.springframework:spring-core  OpenGitHub opened this alert 20 days ago 8 org.springframework:spring-core vulnerabilities found in app/pom.xml 20 days ago Remediation  Upgrade org.springframework:spring-core to version 4.3.18 or later. For example:  ``` &lt;dependency&gt;   &lt;groupId&gt;org.springframework&lt;/groupId&gt;   &lt;artifactId&gt;spring-core&lt;/artifactId&gt;   &lt;version&gt;[4.3.18,)&lt;/version&gt; &lt;/dependency&gt; ``` Always verify the validity and compatibility of suggestions with your codebase.  Details  CVE-2018-1275 More information  high severity Vulnerable versions: &lt; 4.3.16 Patched version: 4.3.16 Spring Framework, versions 5.0 prior to 5.0.5 and versions 4.3 prior to 4.3.16 and older unsupported versions, allow applications to expose STOMP over WebSocket endpoints with a simple, in-memory STOMP broker through the spring-messaging module. A malicious user (or attacker) can craft a message to the broker that can lead to a remote code execution attack. This CVE addresses the partial fix for CVE-2018-1270 in the 4.3.x branch of the Spring Framework.  CVE-2018-1272 More information  moderate severity Vulnerable versions: &lt; 4.3.15 Patched version: 4.3.15 Spring Framework, versions 5.0 prior to 5.0.5 and versions 4.3 prior to 4.3.15 and older unsupported versions, provide client-side support for multipart requests. When Spring MVC or Spring WebFlux server application (server A) receives input from a remote client, and then uses that input to make a multipart request to another server (server B), it can be exposed to an attack, where an extra multipart is inserted in the content of the request from server A, causing server B to use the wrong value for a part it expects. This could to lead privilege escalation, for example, if the part content represents a username or user roles.  CVE-2018-1271 More information  moderate severity Vulnerable versions: &lt; 4.3.15 Patched version: 4.3.15 Spring Framework, versions 5.0 prior to 5.0.5 and versions 4.3 prior to 4.3.15 and older unsupported versions, allow applications to configure Spring MVC to serve static resources (e.g. CSS, JS, images). When static resources are served from a file system on Windows (as opposed to the classpath, or the ServletContext), a malicious user can send a request using a specially crafted URL that can lead a directory traversal attack.  CVE-2018-1270 More information  high severity Vulnerable versions: &lt; 4.3.16 Patched version: 4.3.16 Spring Framework, versions 5.0 prior to 5.0.5 and versions 4.3 prior to 4.3.15 and older unsupported versions, allow applications to expose STOMP over WebSocket endpoints with a simple, in-memory STOMP broker through the spring-messaging module. A malicious user (or attacker) can craft a message to the broker that can lead to a remote code execution attack.  CVE-2018-1257 More information  moderate severity Vulnerable versions: &lt; 4.3.17 Patched version: 4.3.17 Spring Framework, versions 5.0.x prior to 5.0.6, versions 4.3.x prior to 4.3.17, and older unsupported versions allows applications to expose STOMP over WebSocket endpoints with a simple, in-memory STOMP broker through the spring-messaging module. A malicious user (or attacker) can craft a message to the broker that can lead to a regular expression, denial of service attack.  CVE-2018-1199 More information  high severity Vulnerable versions: &gt;= 4.3.0, &lt; 4.3.14 Patched version: 4.3.14 Spring Security (Spring Security 4.1.x before 4.1.5, 4.2.x before 4.2.4, and 5.0.x before 5.0.1; and Spring Framework 4.3.x before 4.3.14 and 5.0.x before 5.0.3) does not consider URL path parameters when processing security constraints. By adding a URL path parameter with special encodings, an attacker may be able to bypass a security constraint. The root cause of this issue is a lack of clarity regarding the handling of path parameters in the Servlet Specification. Some Servlet containers include path parameters in the value returned for getPathInfo() and some do not. Spring Security uses the value returned by getPathInfo() as part of the process of mapping requests to security constraints. In this particular attack, different character encodings used in path parameters allows secured Spring MVC static resource URLs to be bypassed.  CVE-2018-11040 More information  moderate severity Vulnerable versions: &gt;= 4.3.0, &lt; 4.3.18 Patched version: 4.3.18 Spring Framework, versions 5.0.x prior to 5.0.7 and 4.3.x prior to 4.3.18 and older unsupported versions, allows web applications to enable cross-domain requests via JSONP (JSON with Padding) through AbstractJsonpResponseBodyAdvice for REST controllers and MappingJackson2JsonView for browser requests. Both are not enabled by default in Spring Framework nor Spring Boot, however, when MappingJackson2JsonView is configured in an application, JSONP support is automatically ready to use through the "jsonp" and "callback" JSONP parameters, enabling cross-domain requests.  CVE-2018-11039 More information  moderate severity Vulnerable versions: &gt;= 4.3.0, &lt; 4.3.18 Patched version: 4.3.18 Spring Framework (versions 5.0.x prior to 5.0.7, versions 4.3.x prior to 4.3.18, and older unsupported versions) allow web applications to change the HTTP request method to any HTTP method (including TRACE) using the HiddenHttpMethodFilter in Spring MVC. If an application has a pre-existing XSS vulnerability, a malicious user (or attacker) can use this filter to escalate to an XST (Cross Site Tracing) attack.</body>
		<created>2018-11-05 15:39:28</created>
		<closed>2018-11-15 12:30:25</closed>
	</bug>
	<bug>
		<id>4024</id>
		<title>org.apache.activemq:activemq-client vulnerability</title>
		<body>https://github.com/syndesisio/syndesis/network/alert/app/pom.xml/org.apache.activemq:activemq-client/open  org.apache.activemq:activemq-client  OpenGitHub opened this alert 17 days ago 1 org.apache.activemq:activemq-client vulnerability found in app/pom.xml 17 days ago Remediation  Upgrade org.apache.activemq:activemq-client to version 5.15.16 or later. For example:  ``` &lt;dependency&gt;   &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt;   &lt;artifactId&gt;activemq-client&lt;/artifactId&gt;   &lt;version&gt;[5.15.16,)&lt;/version&gt; &lt;/dependency&gt; ``` Always verify the validity and compatibility of suggestions with your codebase.  Details  CVE-2018-11775 More information  moderate severity Vulnerable versions: &lt; 5.15.16 Patched version: 5.15.16 TLS hostname verification when using the Apache ActiveMQ Client before 5.15.6 was missing which could make the client vulnerable to a MITM attack between a Java application using the ActiveMQ client and the ActiveMQ server. This is now enabled by default.</body>
		<created>2018-11-05 15:38:09</created>
		<closed>2018-11-13 09:36:34</closed>
	</bug>
	<bug>
		<id>4021</id>
		<title>Connection Details - disabled Validate button for OAuth connections</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; After creating a OAuth based connection (Gmail, Google Calendar, Twitter,...) and opening the connection details page, the 'Validate' button is not clickable.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; The button should be enabled.    ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![screenshot from 2018-11-05 11-32-12](https://user-images.githubusercontent.com/11939909/47992974-a206e800-e0ee-11e8-9eab-26754ee7e356.png)</body>
		<created>2018-11-05 10:35:04</created>
		<closed>2019-06-14 10:47:58</closed>
	</bug>
	<bug>
		<id>4017</id>
		<title>Settings page - input fields not updated on change</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; The Forms in Settings page (OAuth Application Management) don't reflect the changes made. The contents of the changed fields of a form are not reflected immediately in the form itself. There are two scenarios: 1. When an empty form is filled, and saved, after collapsing and reopening the entry the values are gone. When user navigates Home and back to Settings, then values are there showed properly. 2. When a filled in form is removed, after confirming the Delete warning dialog, and expanding the deleted entry again, the values are still in the input fields. Again when I after removing navigate to Home and back to Settings the fields are in sync.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; The changes submitted should be immediately reflected in the form's contents. </body>
		<created>2018-11-02 15:17:42</created>
		<closed>2018-12-06 15:56:56</closed>
	</bug>
	<bug>
		<id>4016</id>
		<title>Twitter mention works only for account itself</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I have the integration for Twitter that when someone mention me, this tweet is added to DB.  I notice that this works only when I mention myself in my account (_Listener Bot in the video_). When I mention myself in another account (_Syndesis Talky in the video_), it doesn't work.   This work-flow worked because our tests use this case when _Syndesis Talky_ mention _Listener Bot_ in the tweet and Connection in the Syndesis is set for _Listener Bot_.  In the video below, both tweet should appear in integration but only tweet which is in the account which is in the connection for integration appears. (click on gif to show it in the original size) ![output](https://user-images.githubusercontent.com/16251792/47901478-5c44e800-de80-11e8-98f9-804405fa1fd6.gif) </body>
		<created>2018-11-02 09:19:50</created>
		<closed>2018-11-05 12:54:53</closed>
	</bug>
	<bug>
		<id>4013</id>
		<title>After Deleting all integrations, number of messages still shows up</title>
		<body>After Deleting all integrations, number of messages still shows up, technically these messages are not reachable, since they are tied to the integrations and integrations are no longer available  ## Expected behavior The messages related to the integrations deleted shouldnt show up on the summary page.  ![image](https://user-images.githubusercontent.com/39506194/47867082-e3d61c80-ddd6-11e8-8b9a-533a30e4062a.png)  ## Tasks involved / Steps to Reproduce  1. Create an integration, such that messages are populated 2. Delete the integration and navigate to the summary page 3. We can see that the number of integrations shows up as 0, but the messages still shows up as 55. 4. These messages arent reachable in any way after the integrations are deleted. </body>
		<created>2018-11-01 17:08:09</created>
		<closed>2019-05-26 20:28:18</closed>
	</bug>
	<bug>
		<id>4010</id>
		<title>Unable to upgrade using operator - upgrade pod - pod has unbound PersistentVolumeClaims</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I tried to upgrade from "1.4.9" to "latest" (because currently there is still hardcoded "latest" upgrade pod in operator image #3924). Then I tried from "1.5.5" to "latest" with the same result - upgrade pod won't start because of this: ![up1](https://user-images.githubusercontent.com/7081216/47850659-4aa70600-ddd6-11e8-84a6-ca2160f5c462.png)  There is also this error in the operator log: ``` time="2018-11-01T11:58:12Z" level=error msg="error syncing key (myproject/app): object is being deleted: persistentvolumeclaims \"syndesis-upgrade\" already exists" ```  steps to reproduce: ./syndesis install -s ./syndesis install --project myproject --tag 1.4.9 wait for syndesis to install deploy new operator image, for example 1.5.6 version  minishift v1.26.1+1e20f27 openshift 3.10</body>
		<created>2018-11-01 12:17:29</created>
		<closed>2018-11-26 13:18:22</closed>
	</bug>
	<bug>
		<id>4008</id>
		<title>Still can't delete a connection after deleting the integration</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [*] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description After deleting an integration, I still can't delete the connections that were used by it, until I hard-refresh the connection page. The `delete` is greyed out until then.</body>
		<created>2018-10-31 15:27:46</created>
		<closed>2019-05-21 20:21:28</closed>
	</bug>
	<bug>
		<id>4003</id>
		<title>API provider still showing up on Connections page </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  The API provider still shows up on the Home, Create a Connection wizard, and Connections page as a regular connection.   Thought this is fixed via https://github.com/syndesisio/syndesis/issues/3889, but I'm using 1.5.6 and it's still showing up.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  It should not show up on those pages.   ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  &lt;img width="1406" alt="screen shot 2018-10-30 at 3 58 50 pm" src="https://user-images.githubusercontent.com/24943812/47746589-bbc2ae00-dc5c-11e8-81cb-74147457c40c.png"&gt;  &lt;img width="924" alt="screen shot 2018-10-30 at 3 59 16 pm" src="https://user-images.githubusercontent.com/24943812/47746609-c8df9d00-dc5c-11e8-8568-79afa030d89a.png"&gt;  &lt;img width="1421" alt="screen shot 2018-10-30 at 3 59 40 pm" src="https://user-images.githubusercontent.com/24943812/47746648-d85ee600-dc5c-11e8-9d04-a9f49aa2c61b.png"&gt;   cc: @gashcrumb @nicolaferraro @riccardo-forina </body>
		<created>2018-10-30 20:00:56</created>
		<closed>2018-10-31 18:56:51</closed>
	</bug>
	<bug>
		<id>4000</id>
		<title>character encoding issue when integrating twitter2gmail</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [*] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Use search term 'Syndesis'. and send from twitter to gmail.  Email comes in looking like  &lt;img width="1114" alt="screen shot 2018-10-30 at 3 49 17 pm" src="https://user-images.githubusercontent.com/35576/47726901-b1ec7b00-dc5b-11e8-8f28-fe7ea07dbdb6.png"&gt;  I'm using Paul's scenario.  https://youtu.be/Pfysm8W8sco  ![utf-8-encoding-issues-better-drink-my-own-pee](https://user-images.githubusercontent.com/35576/47727239-5a024400-dc5c-11e8-9108-65e5b883c13f.jpg) </body>
		<created>2018-10-30 14:52:32</created>
		<closed>2019-02-27 16:59:20</closed>
	</bug>
	<bug>
		<id>3999</id>
		<title>No way to specify alternative response for API Provider based on request and previous steps outcome</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11452**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When implementing API Provider operations, there is no way to gracefully handle situations when e.g. a requested item does not exist or a POSTed item already exists. These situations end up returning the stack trace in the body and 500 as the response status.  ## Steps to reproduce (note this is just an example, there are other situations where we would want to change the response based on the outcome of previous steps) 1. Create an API Provider integration from the TODO API spec 2. Implement the Fetch task operation 3. Add a postgres connection with `select * from todo where id = :#id` 4. Add the appropriate mappings from the request to postgres and from postgres to response 5. Publish the integration 6. Go to {integration-url}/api/42 (or some other non-existent id) in the browser, the full stacktrace is returned with http status 500  </body>
		<created>2018-10-30 13:35:31</created>
		<closed>2019-09-07 11:45:46</closed>
	</bug>
	<bug>
		<id>3996</id>
		<title>Warning dialog in API provider is blank</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When I want to cancel API provider, the shown dialog is blank. Buttons works.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![image](https://user-images.githubusercontent.com/16251792/47706075-9ddb5600-dc28-11e8-9535-7a75b61b67da.png)  ## Tasks involved / Steps to Reproduce 1. Click on Create Integration 2. Select API Provider 3. Click on Cancel button </body>
		<created>2018-10-30 08:51:28</created>
		<closed>2018-10-31 11:55:35</closed>
	</bug>
	<bug>
		<id>3988</id>
		<title>Connection icons in IVP don't appear immediately</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem The start/finish connection icons in the IVP don't show up when you choose the connection type.  ## Expected behavior When you click a connection to use, it's icon should appear in the selected white circle (icon placeholder) in the IVP.  ## Screenshot  ## Log as finish connection &lt;img width="1593" alt="screen shot 2018-10-29 at 4 09 25 pm" src="https://user-images.githubusercontent.com/35148959/47680585-39bb8200-db95-11e8-9bd3-a31c276de5d6.png"&gt;  ## API integration &lt;img width="1593" alt="screen shot 2018-10-29 at 4 06 02 pm" src="https://user-images.githubusercontent.com/35148959/47680587-39bb8200-db95-11e8-9290-e93d3061af05.png"&gt;  ## DB as start connection &lt;img width="1593" alt="screen shot 2018-10-29 at 4 05 46 pm" src="https://user-images.githubusercontent.com/35148959/47680588-39bb8200-db95-11e8-89b8-35f86a4db813.png"&gt;    ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create an integration 2. See icon brokenness  cc @dongniwang </body>
		<created>2018-10-29 21:14:17</created>
		<closed>2018-11-05 14:37:19</closed>
	</bug>
	<bug>
		<id>3986</id>
		<title>Add step before step doesn't work</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When I have integration with one step and I want to add another step before that step, the page is blank and in the web console is the errors: `TypeError: "this.currentFlowService.getPreviousStepWithDataShape(...) is undefined"` `TypeError: "right-hand side of 'in' should be an object, got undefined"` But when I want to add another step after that step, everything works fine. So I am able to add middle-steps **only** before the Finish Connection.    ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![image](https://user-images.githubusercontent.com/16251792/47651560-db39d800-db83-11e8-83b0-603377d66f30.png)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create integration 2. For starting integration set timer 3. For ending integration set DB 4. Add middle step (e.g. log) 5. Add step after middle step (e.g. another log, works) 6. Add step before middle step  (Sorry for quality of gif, I don't know why ffmpeg convert it like this) ![output](https://user-images.githubusercontent.com/16251792/47658618-928a1b00-db93-11e8-9b5d-dfe1b41c9a80.gif)   </body>
		<created>2018-10-29 15:08:48</created>
		<closed>2018-10-30 11:47:15</closed>
	</bug>
	<bug>
		<id>3985</id>
		<title>Handle polling consumer issues in all polling connectors</title>
		<body>This is a generic version of the specific issues discovered in DropBox #3486.  Essentially when consumers throw exceptions they are simply logged and not sent as an empty message with an exception. This is to avoid generating such messages on every poll.  Without the `bridgeErrorHandler` property, Syndesis users will never know that the route has been essentially disabled due to this error in the first step. </body>
		<created>2018-10-29 14:00:23</created>
		<closed>2019-02-06 17:10:07</closed>
	</bug>
	<bug>
		<id>3974</id>
		<title>API Provider - return path icon is not being displayed in the IVP when configuring a flow</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  When configuring a flow in API Provider integration, the return path icon is not being displayed in the IVP. Instead, the API Provider is being shown for the return path.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  Display return path icon for return path configuration.   ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  Current behavior:  &lt;img width="347" alt="screen shot 2018-10-26 at 11 49 39 am" src="https://user-images.githubusercontent.com/24943812/47578154-a2e19200-d916-11e8-96df-919e9538beda.png"&gt;  Correct behavior: &lt;img width="147" alt="screen shot 2018-10-26 at 12 00 45 pm" src="https://user-images.githubusercontent.com/24943812/47578213-cf95a980-d916-11e8-9f52-2f7949028c93.png"&gt;   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Go to staging site 2. Create integration with API provider  3. Select a flow  4. Now you can see two API provider icons... </body>
		<created>2018-10-26 16:02:14</created>
		<closed>2018-10-26 19:44:05</closed>
	</bug>
	<bug>
		<id>3957</id>
		<title>Most connection disappeared</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [*] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I think we are a little too aggressive with hiding things  &lt;img width="1024" alt="screen shot 2018-10-25 at 10 11 14 am" src="https://user-images.githubusercontent.com/35576/47491623-83316780-d84b-11e8-9103-610b605d015e.png"&gt;  It's probably a regression from: #3889</body>
		<created>2018-10-25 09:51:43</created>
		<closed>2018-10-25 17:19:07</closed>
	</bug>
	<bug>
		<id>3954</id>
		<title>IVP expand button tooltip is behind the connection cards </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; The tooltip of the exapand IVP button is covered by the connection cards in the create integration flow.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  The tooltip should appear above the connection cards so users can see what's on the tooltip.   ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![screen shot 2018-10-24 at 1 11 45 pm](https://user-images.githubusercontent.com/24943812/47448839-0d67c600-d78f-11e8-9eb5-e878762eeacc.png)    ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Go to staging site  2. Click "Create Integration"  3. Hover over the expand button   </body>
		<created>2018-10-24 17:18:01</created>
		<closed>2018-11-14 09:41:08</closed>
	</bug>
	<bug>
		<id>3925</id>
		<title>Can't publish an integration with a dot in the name</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I tried to publish an integration with a dot (`.`) in the name, got an error: ``` 2018-10-22 10:32:03.355 ERROR [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [test-no-basepath-api.json]: [ERROR] Activation failure javax.validation.ConstraintViolationException: Constraint Validations: name must match "^[a-z0-9]([-a-z0-9]*[a-z0-9])?$" on bean: Container(args=[], command=[], env=[EnvVar(name=LOADER_HOME, value=${JAVA_DATA_DIR}/syndesis/loader, valueFrom=null, additionalProperties={}), EnvVar(name=AB_JMX_EXPORTER_CONFIG, value=/tmp/src/prometheus-config.yml, valueFrom=null, additionalProperties={})], envFrom=[], image=172.30.1.1:5000/syndesis/i-test-no-basepath-api.json:1, imagePullPolicy=Always, lifecycle=null, livenessProbe=null, name=i-test-no-basepath-api.json, ports=[ContainerPort(containerPort=8778, hostIP=null, hostPort=null, name=jolokia, protocol=null, additionalProperties={})], readinessProbe=null, resources=null, securityContext=null, stdin=null, stdinOnce=null, terminationMessagePath=null, terminationMessagePolicy=null, tty=null, volumeMounts=[VolumeMount(mountPath=/deployments/config, name=secret-volume, readOnly=false, subPath=null, additionalProperties={})], workingDir=null, additionalProperties={}) at io.fabric8.kubernetes.api.builder.ValidationUtils.validate(ValidationUtils.java:36) ~[kubernetes-model-2.0.10.jar!/:2.0.10] at io.fabric8.kubernetes.api.model.ContainerBuilder.build(ContainerBuilder.java:81) ~[kubernetes-model-2.0.10.jar!/:2.0.10] at io.fabric8.kubernetes.api.model.PodSpecFluentImpl$ContainersNestedImpl.and(PodSpecFluentImpl.java:1063) ~[kubernetes-model-2.0.10.jar!/:2.0.10] at io.fabric8.kubernetes.api.model.PodSpecFluentImpl$ContainersNestedImpl.endContainer(PodSpecFluentImpl.java:1066) ~[kubernetes-model-2.0.10.jar!/:2.0.10] at io.syndesis.server.openshift.OpenShiftServiceImpl.ensureDeploymentConfig(OpenShiftServiceImpl.java:253) ~[server-openshift-1.5-SNAPSHOT.jar!/:1.5-SNAPSHOT] at io.syndesis.server.openshift.OpenShiftServiceImpl.deploy(OpenShiftServiceImpl.java:87) ~[server-openshift-1.5-SNAPSHOT.jar!/:1.5-SNAPSHOT] at io.syndesis.server.controller.integration.online.PublishHandler.deploy(PublishHandler.java:182) ~[server-controller-1.5-SNAPSHOT.jar!/:1.5-SNAPSHOT] at io.syndesis.server.controller.integration.online.PublishHandler$BuildStepPerformer.perform(PublishHandler.java:333) ~[server-controller-1.5-SNAPSHOT.jar!/:1.5-SNAPSHOT] at io.syndesis.server.controller.integration.online.PublishHandler.execute(PublishHandler.java:115) ~[server-controller-1.5-SNAPSHOT.jar!/:1.5-SNAPSHOT] at io.syndesis.server.controller.StateChangeHandler.execute(StateChangeHandler.java:33) [server-controller-1.5-SNAPSHOT.jar!/:1.5-SNAPSHOT] at io.syndesis.server.controller.integration.IntegrationController.lambda$callStateChangeHandler$11(IntegrationController.java:199) [server-controller-1.5-SNAPSHOT.jar!/:1.5-SNAPSHOT] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_151] at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_151] ```</body>
		<created>2018-10-22 10:37:25</created>
		<closed>2018-10-25 12:14:38</closed>
	</bug>
	<bug>
		<id>3922</id>
		<title>Autovacuum not reclaiming disk space</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  We had a Syndesis instance (1.4.10, 76bc7c6f389f65ba0518bdd05823d247f4870a90) running for ~3 days (2 days 17 hours) with 6 integrations generating 730K messages.  The `syndesis-db` (1GiB) volume was on the verge of running out of disk space (12MiB left). And `VACUUM FULL jsondb` could not be run:  ``` ERROR:  could not extend file "base/16385/16845": No space left on device HINT:  Check free disk space. STATEMENT:  VACUUM FULL ANALYSE jsondb; ```  Fetching activities resulted in 504 (Gateway timeout).  With ~30K rows in `jsondb` table the overwhelming majority of disk space was taken up with deleted rows. That were not vacuumed by autovacuum.  The only way to get the stream of activities was to copy the table content to a new table, drop the `jsondb` table, rename the new table to `jsondb` and recreate indexes.  i.e. ``` &gt; SELECT * INTO jsondb2 FROM jsondb; &gt; DROP TABLE jsondb; &gt; ALTER TABLE jsondb2 RENAME TO jsondb; &gt; CREATE UNIQUE INDEX jsondb_pkey ON jsondb USING btree (path); &gt; CREATE INDEX jsondb_idx ON jsondb USING btree (idx, value) WHERE (idx IS NOT NULL) ```  I think we should try to tune the `autovacuum` so that the disk space is reclaimed (autovacuum will never perform `VACUUM FULL`) or bring back the DB maintenance job to perform `VACUUM FULL`.  The level of severity depends on how we envision the users using Syndesis, if this level of activity is acceptable (looks to me like it should be), then this feels like `p0`.</body>
		<created>2018-10-22 09:00:47</created>
		<closed>2018-11-01 12:24:52</closed>
	</bug>
	<bug>
		<id>3917</id>
		<title>Upgrade Spring Boot due to vulnerabilities found</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [*] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description &gt; 8 org.springframework:spring-core vulnerabilities found in app/pom.xml 3 days ago &gt; Remediation &gt;  &gt; Upgrade org.springframework:spring-core to version 4.3.18 or later.  We also need to coordinate versions with Camel, so this is a little more complex then changing the version number in the pom. On a quick try @zregvart reported some tests started failing. We prob want to do this sooner rather then later.  ![yummy](https://user-images.githubusercontent.com/35576/47214139-4d006d80-d39d-11e8-827f-23b552787c21.jpg)   https://github.com/syndesisio/syndesis/network/alert/app/pom.xml/org.springframework:spring-core/open</body>
		<created>2018-10-19 10:34:08</created>
		<closed>2018-11-09 07:58:08</closed>
	</bug>
	<bug>
		<id>3914</id>
		<title>Add $id property to the JSON schema URI in the DataShape</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [*] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description We need to follow this up with a change that includes the syndesis JSON schema URI in the data shape so that `ResponseCustomizer` can detect the need to unwrap the response here:  https://github.com/syndesisio/syndesis/blob/9e99679cd43adf3cfe171d4218ec4f31b2ea83a0/app/connector/rest-swagger/src/main/java/io/syndesis/connector/rest/swagger/ResponseCustomizer.java#L64  That means we need to add `$id`[1] property to the unified JSON schemas. Similar to how the WebHook connector does it:  https://github.com/syndesisio/syndesis/blob/9e99679cd43adf3cfe171d4218ec4f31b2ea83a0/app/connector/webhook/src/main/java/io/syndesis/connector/webhook/WebhookConnectorCustomizer.java#L39  https://github.com/syndesisio/syndesis/blob/9e99679cd43adf3cfe171d4218ec4f31b2ea83a0/app/connector/webhook/src/main/java/io/syndesis/connector/webhook/WebhookConnectorCustomizer.java#L82  [1] https://json-schema.org/understanding-json-schema/structuring.html#the-id-property </body>
		<created>2018-10-19 09:26:06</created>
		<closed>2018-11-16 08:41:37</closed>
	</bug>
	<bug>
		<id>3909</id>
		<title>Getting quotes in responses with the unified responses</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  From https://github.com/syndesisio/syndesis/issues/3851#issuecomment-430986258 when the body of the response is defined as a simple type (string, numeric, ...) the request contains that value quoted.  For example, given the unified response of:  ```json {   "body": "hello" } ```  The HTTP response body is literally `"hello"` (with quotes).</body>
		<created>2018-10-18 18:27:34</created>
		<closed>2019-01-09 11:15:47</closed>
	</bug>
	<bug>
		<id>3904</id>
		<title>Connection step goes poof if I cancel the action the second time</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; I create/edit an integration and add a connection/action as a step. If I go and click on it again to edit the action settings and click on cancel, the connection/action disappears from the integration view pane.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Shouldn't disappear just like that it's rude.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![peek 2018-10-18 16-24](https://user-images.githubusercontent.com/1306050/47161635-baa38f80-d2f2-11e8-9480-60c028b93144.gif)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create/edit an integration 2. Add a connection step (in my case custom API provider) 3. Set desired action settings, click done 4. Click again on the new connection step to edit 5. Click cancel 6. Poof </body>
		<created>2018-10-18 14:29:00</created>
		<closed>2018-11-08 09:47:31</closed>
	</bug>
	<bug>
		<id>3903</id>
		<title>Odd paddings lead to off-center icons</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The icons in the integration details screen (perhaps in other places) are off-center.  ![screenshot_2018-10-18 syndesis 2](https://user-images.githubusercontent.com/1306050/47160921-3c92b900-d2f1-11e8-8148-389283612f4e.png)  I got it nicely centered when I changed this CSS:  ```diff --- old.css2018-10-18 16:18:20.246386177 +0200 +++ new.css2018-10-18 16:18:00.807432404 +0200 @@ -1,12 +1,12 @@  .step-block .icon {      border-radius: 100px;      border-style: solid;      border-width: 3px;      border-color: #0088ce; -    padding: 11px; -    width: 55px; -    height: 55px; +    padding: 13px; +    width: 56px; +    height: 56px;      margin: 0 auto 5px;      background-color: #fff;      position: relative;  } ```  Now it looks like: ![screenshot_2018-10-18 syndesis 3](https://user-images.githubusercontent.com/1306050/47161220-e7a37280-d2f1-11e8-94be-d1ce97e0f373.png)  And my OCD induced eye twitch has stopped.</body>
		<created>2018-10-18 14:22:18</created>
		<closed>2018-10-18 21:08:07</closed>
	</bug>
	<bug>
		<id>3889</id>
		<title>Hide the API provider connection from the connections page?</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The API connector shows up on the connection page as a regular connection.  It also shows up as a connector in the first step of the create connection wizard, but it shouldn't be available here either.  ![image](https://user-images.githubusercontent.com/351660/47098767-da0ebf80-d201-11e8-8134-3e709c3b887c.png)  @nicolaferraro @riccardo-forina @dongniwang </body>
		<created>2018-10-17 15:44:16</created>
		<closed>2018-10-26 06:30:16</closed>
	</bug>
	<bug>
		<id>3888</id>
		<title>IVP background and expansion widgety thing scrolls with the page</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Imported @KurtStam's API provider example and noticed when scrolling the page down this happens:  ![image](https://user-images.githubusercontent.com/351660/47097184-dded1280-d1fe-11e8-8039-391198e109dc.png)  The expander and background probably shouldn't scroll with the page?  I wonder, should the IVP handle it's own scrolling separate from the main area?  @dongniwang @michael-coker FYI </body>
		<created>2018-10-17 15:23:35</created>
		<closed>2018-10-18 18:23:02</closed>
	</bug>
	<bug>
		<id>3887</id>
		<title>Google Calendar connector: Update Event form values not overriding the values coming in through flow</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11441**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When using an Update Event step in combination with an incoming Event instance (resulting from Get by id, or Get events actions) the values from the Update Event form are not being set.  The only way to achieve that is placing a Data Mapper before the Update Event step and map fields only partially (those that I don't want to update) and then in 'Update Event' form I can specify the values to update. (Or set the values as constants in data mapper, which I think is even worse option.)  To rephrase a bit, if I specify both mapping and form value, then form value is ignored. When considering the following simple scenario this can be surprising to user. (As they have explicitly set the values to the form.)  Scenario: I'd like to be also able to send the event through the flow with/without a data mapper, just chaining actions 'Get a specific Event' -&gt; 'Update Event', where the form of update step would have the overriding values specified.  In more complex scenarios, where I want to dynamically set all the values of event, this is not an issue, as data mapper works as expected.</body>
		<created>2018-10-17 14:23:45</created>
		<closed>2019-09-07 11:29:46</closed>
	</bug>
	<bug>
		<id>3875</id>
		<title>The Add a Step or Add a Connection items dissappear from the popup menu after clicking the corresponding button</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description In some cases, the popup menu in the left sidebar in Integration editor only shows one of the menu items (either Add a Connection or Add a Step). This happens when the user clicks e.g. Add a Connection in the main view, goes through with adding the connection, then tries to add a Step using the sidebar.  ## Steps to Reproduce 1. Create a new integration, any start and end connection, plus one intermediate step (of any type) 2. In the main view, click the Add a Connection button, the tooltips in the sidebar appear with just the Add Connection item (this is expected, we are adding a connection) 3. Select any type of connection and finish its wizard 4. Back in the integration editor, the popup menus in the sidebar now only have Add a connection option, no Add a step  ## Workaround When the popup menu only has one item, the respective button in the main view can be clicked to reveal the other item.  ## Screenshot ![screenshot_2018-10-17_09-57-56](https://user-images.githubusercontent.com/9480152/47071173-2bfc1900-d1f3-11e8-94c9-cb08d920529a.png)   </body>
		<created>2018-10-17 08:00:13</created>
		<closed>2018-10-24 19:09:36</closed>
	</bug>
	<bug>
		<id>3871</id>
		<title>Wrong warning on Twitter &gt; Salesforce integration</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem As Twitter output DataShape (java) and Salesforce input DataShape (json) are both datamapper aware shapes, the warning on the Salesforce finish connector should encourage user to add Data Mapper step. This `Define the data type` link doesn't do anything.  ## Expected behavior Have a link to add a Data Mapper step in between Twitter and Salesforce there  ## Screenshot ![screenshot from 2018-10-16 16-13-00](https://user-images.githubusercontent.com/265462/47044818-310f8880-d15f-11e8-82c4-e21cf8b7ebac.png)  </body>
		<created>2018-10-16 20:23:15</created>
		<closed>2018-10-18 08:48:52</closed>
	</bug>
	<bug>
		<id>3865</id>
		<title>Remove all non Syndesis message headers at the API provider start processor</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description We need to remove all non-Syndesis Camel message headers on reception of a HTTP request in the API provider-based integrations. If we don't they will be used by subsequent connectors/Camel components and they will cause issues.  Typical example is the `Host` header which will make the API client fail the request due to virtual host mismatch at the API service. </body>
		<created>2018-10-16 15:10:24</created>
		<closed>2018-11-16 15:22:22</closed>
	</bug>
	<bug>
		<id>3863</id>
		<title>Google Calendar connector: Update/Create event actions date parsing issue</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Method createGoogleEvent method relies on concatenation of date and time part of the datetime. But the time part can be missing. The resulting stacktraces with more info: - Create event ``` java.text.ParseException: Unparseable date: "2018-10-01 null" at java.text.DateFormat.parse(DateFormat.java:366) at io.syndesis.connector.calendar.GoogleCalendarSendEventCustomizer.createGoogleEvent(GoogleCalendarSendEventCustomizer.java:169) at io.syndesis.connector.calendar.GoogleCalendarSendEventCustomizer.beforeProducer(GoogleCalendarSendEventCustomizer.java:112) at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at io.syndesis.integration.component.proxy.ComponentProxyProducer.process(ComponentProxyProducer.java:44) at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.access$100(Pipeline.java:43) at org.apache.camel.processor.Pipeline$1.done(Pipeline.java:157) at org.apache.camel.processor.CamelInternalProcessor$InternalCallback.done(CamelInternalProcessor.java:262) at org.apache.camel.processor.RedeliveryErrorHandler$2.done(RedeliveryErrorHandler.java:560) at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.lambda$process$0(ActivityTrackingInterceptStrategy.java:93) at org.apache.camel.processor.Pipeline$1.done(Pipeline.java:166) at org.apache.camel.processor.CamelInternalProcessor$InternalCallback.done(CamelInternalProcessor.java:262) at org.apache.camel.processor.RedeliveryErrorHandler$2.done(RedeliveryErrorHandler.java:560) at org.apache.camel.processor.SendProcessor$1.done(SendProcessor.java:160) at org.apache.camel.processor.Pipeline$1.done(Pipeline.java:166) at org.apache.camel.util.component.AbstractApiProducer$1.run(AbstractApiProducer.java:98) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) ``` - Update event ``` java.text.ParseException: Unparseable date: "2018-10-01 null" at java.text.DateFormat.parse(DateFormat.java:366) at io.syndesis.connector.calendar.GoogleCalendarUpdateEventCustomizer.createGoogleEvent(GoogleCalendarUpdateEventCustomizer.java:174) at io.syndesis.connector.calendar.GoogleCalendarUpdateEventCustomizer.beforeProducer(GoogleCalendarUpdateEventCustomizer.java:116) at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at io.syndesis.integration.component.proxy.ComponentProxyProducer.process(ComponentProxyProducer.java:44) at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.access$100(Pipeline.java:43) at org.apache.camel.processor.Pipeline$1.done(Pipeline.java:157) at org.apache.camel.processor.CamelInternalProcessor$InternalCallback.done(CamelInternalProcessor.java:262) at org.apache.camel.processor.RedeliveryErrorHandler$2.done(RedeliveryErrorHandler.java:560) at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.lambda$process$0(ActivityTrackingInterceptStrategy.java:93) at org.apache.camel.processor.Pipeline$1.done(Pipeline.java:166) at org.apache.camel.processor.CamelInternalProcessor$InternalCallback.done(CamelInternalProcessor.java:262) at org.apache.camel.processor.RedeliveryErrorHandler$2.done(RedeliveryErrorHandler.java:560) at org.apache.camel.processor.SendProcessor$1.done(SendProcessor.java:160) at org.apache.camel.processor.Pipeline$1.done(Pipeline.java:166) at org.apache.camel.util.component.AbstractApiProducer$1.run(AbstractApiProducer.java:98) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) ``` </body>
		<created>2018-10-16 13:22:56</created>
		<closed>2018-10-29 13:38:26</closed>
	</bug>
	<bug>
		<id>3861</id>
		<title>Remove PVC from upgrade template</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Follow up from #3460.  After all customers and managed clusters are upgraded to Fuse 7.1.1+, we can remove the PVC declaration from the upgrade template in the list of syndesis resources (only from the upgrade template, the PVC will remain on the main list of Syndesis resources).  This can be a 7.2, 7.2.1 or 7.3 issue, depending on when the upgrade status. </body>
		<created>2018-10-16 13:13:37</created>
		<closed>2019-10-21 14:14:58</closed>
	</bug>
	<bug>
		<id>3857</id>
		<title>Integration fails to start when using custom API client in a API-provider based integration </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; The integration fails to start with: ``` Caused by: java.lang.IllegalArgumentException: Component servlet is not a RestProducerFactory at org.apache.camel.component.rest.RestEndpoint.createProducer(RestEndpoint.java:312) ~[camel-core-2.21.2.jar:2.21.2] at org.apache.camel.component.rest.swagger.RestSwaggerEndpoint.createProducerFor(RestSwaggerEndpoint.java:282) ~[camel-rest-swagger-2.21.2.jar:2.21.2] at org.apache.camel.component.rest.swagger.RestSwaggerEndpoint.createProducer(RestSwaggerEndpoint.java:187) ~[camel-rest-swagger-2.21.2.jar:2.21.2] at org.apache.camel.component.connector.DefaultConnectorEndpoint.createProducer(DefaultConnectorEndpoint.java:51) ~[camel-connector-2.21.2.jar:2.21.2] at org.apache.camel.impl.ProducerCache.doGetProducer(ProducerCache.java:573) ~[camel-core-2.21.2.jar:2.21.2] ... 91 common frames omitted ``` I think we need to add `componentName` `rest-swagger` connector property and set it to `http4`.  Probably related to #3800, i.e. the above could fix that also. (cc @nicolaferraro)  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Not to blow up if both are used.  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create API client for the TODO app (via TODO OpenAPI spec) at `http://$(minishift ip).nip.io/swagger.json` 2. Create connection for the new TODO connector (using http scheme for the host, and bogus username/password) 3. Create API-provider based integration with arbitrary OpenAPI specification 4. In one of the flows add the TODO connection 5. Publish the integration  </body>
		<created>2018-10-16 11:50:44</created>
		<closed>2018-10-19 10:23:59</closed>
	</bug>
	<bug>
		<id>3854</id>
		<title>Template step - {{variable}} mapping by Data Mapper doesn't work</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description What's wrong in short: No data are mapped to a variable used in a template. If I use **{{variable}} text** as a template and map any data to {{variable}}, output is **" text"**    **Steps to reproduce by creating an integration DB -&gt; Datamapper -&gt; Template step -&gt; Datamapper -&gt; DB** 1. Create a new integration  2. Add **PostgresDB** start connection - select **PeriodicSQL Invocation** - **SQL Statement:** select * from contact limit 1 - **Period:** 20 seconds or similar 3. Add **PostgresDB** finish connection - select **Invoke SQL** - **SQL Statement:** insert into contact values (:#param) 4. Add **Template** step - create or upload template: **{{template_param}} Bill** 5. Add **Data Mapper** step between **Start connection** and **Template** - create mapping: **first_name** -&gt; **template_param** 6. Add **Data Mapper** step between **Template** and **Finish connection**  - create mapping: **message** -&gt; **first_name** (message is a result of the template with all it's mapped variables in step 5) 7. **Publish** the integration  Take a look at the contact table in the database. There should appear a new row with first column containing **Joe Bill** each 20 secs. Joe from the DB, Bill from the template.  But the new rows contain only Bill. Joe hasn't been mapped to {{template_param}} variable in the template</body>
		<created>2018-10-16 10:17:38</created>
		<closed>2018-10-18 09:32:39</closed>
	</bug>
	<bug>
		<id>3851</id>
		<title>Error in Data Mapper step when creating an API Provider with simple return type</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When the response type of an operation in API Provider is a primitive type (string, int etc), trying to add a Data Mapper step causes an error:  ![screenshot_2018-10-16_09-56-23](https://user-images.githubusercontent.com/9480152/47001304-6e0d5800-d12a-11e8-8610-d03025029d0e.png)  Minimal openapi json:  ``` {   "swagger": "2.0",   "info": {     "title": "Todo App API",     "description": "Example Todo Application API",     "version": "1.0.0",     "license": {       "name": "Apache 2.0",       "url": "http://www.apache.org/licenses/LICENSE-2.0.html"     }   },   "host": "todo-syndesis.my-minishift.syndesis.io",   "basePath": "/api",   "schemes": [     "http"   ],   "paths": {     "/{id}": {       "get": {         "tags": [           "tasks",           "fetching"         ],         "summary": "Fetch task",         "description": "Fetches task by given identifier",         "parameters": [           {             "in": "path",             "name": "id",             "type": "integer",             "format": "int64",             "description": "Task identifier",             "required": true           }         ],         "responses": {           "200": {             "description": "All is good",             "schema": {               "type": "string"             }           }         }       }     }   } }  ``` </body>
		<created>2018-10-16 08:03:10</created>
		<closed>2018-11-06 07:23:42</closed>
	</bug>
	<bug>
		<id>3846</id>
		<title>Missing data shape for in Beer API</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description API provider based integration created from the [Beer API](https://raw.githubusercontent.com/Apicurio/api-samples/master/beer/beer-api_2.0.json) doesn't contain `outputShape` for the `POST /beer` operation even though the specification defines that the request body is a `Beer` object.  ```yaml paths:   /beers:     post:       summary: Add a Beer       description: Adds a beer to the data set.       operationId: addBeer       parameters:         - name: body           in: body           description: The beer to add.           schema:             $ref: '#/definitions/Beer'       responses:         '201':           description: Beer was added. definitions:   Beer:     title: Root Type for Beer     description: The root of the Beer type's schema.     required: []     type: object     properties:       id:         format: int32         type: integer       name:         type: string       style:         type: string       abv:         format: double         type: number       ibu:         format: double         type: number       ounces:         format: double         type: number       breweryId:         format: int32         type: integer ```  </body>
		<created>2018-10-15 18:08:30</created>
		<closed>2018-10-18 11:29:07</closed>
	</bug>
	<bug>
		<id>3844</id>
		<title>Empty first column in the integration flow view</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When an API provider-based integration is created using a specification that for operations doesn't specify summary or description the first column in the integration flow list is empty.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; We should generate a name for the connector action similar to how we generate one for the custom API clients. Something like `Receives POST request to /my/operation`.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![screenshot_2018-10-15 syndesis](https://user-images.githubusercontent.com/1306050/46968860-af632080-d0b4-11e8-9813-5a66d717399c.png)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create an API-provider based integration using the attached specification 2. Notice that the flow list has blank first column   [spec.json.txt](https://github.com/syndesisio/syndesis/files/2479959/spec.json.txt) </body>
		<created>2018-10-15 18:01:55</created>
		<closed>2018-10-23 12:20:24</closed>
	</bug>
	<bug>
		<id>3840</id>
		<title>Unable to upgrade syndesis due to:   Required value: template.parameters[4]: parameter SAR_PROJECT is required and must be specified</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I've tried upgrade of syndesis (from latest) but it's without any success due to:   `error: unable to process template  | Required value: template.parameters[4]: parameter SAR_PROJECT is required and must be specified`  full log:  ``` Now using project "syndesis" on server "https://172.30.0.1:443 ". --  | ### -----------------------------------------  | ### PREFLIGHT CHECK  | ### Upgrade from latest (latest) --&gt; latest  | ###  | ### --&gt; OK  | ### -----------------------------------------  | =============================================  | === STARTING UPGRADE TO SYNDESIS latest  | =============================================  | === * Backup Resource objects (prep_10_backup_resources)  | - ConfigMap  | * syndesis-db-conf  | * syndesis-meta-config  | * syndesis-prometheus-config  | * syndesis-sampledb-config  | * syndesis-server-config  | * syndesis-ui-config  | - Secret  | * syndesis-global-config  | * syndesis-oauth-proxy-cookie-secret  | * syndesis-server-secret  | - DeploymentConfig  | * syndesis-db  | * syndesis-meta  | * syndesis-oauthproxy  | * syndesis-prometheus  | * syndesis-server  | * syndesis-ui  | - Service  | * syndesis-db  | * syndesis-meta  | * syndesis-oauthproxy  | * syndesis-prometheus  | * syndesis-server  | * syndesis-ui  | - Route  | * syndesis  | - RoleBinding  | * syndesis:editors  | * syndesis:viewers  | - ServiceAccount  | * syndesis-integration  | * syndesis-prometheus  | * syndesis-server  | - Template  | * syndesis-upgrade  | - PersistentVolumeClaim  | * syndesis-db  | * syndesis-meta  | * syndesis-prometheus  | * syndesis-upgrade  | - BuildConfig  | === * Stopping syndesis-server (prep_15_stop)  | deploymentconfig "syndesis-server" scaled  | deploymentconfig "syndesis-meta" scaled  | Waiting for syndesis-server to be scaled to 0  | Sleeping 10s ...  | NAME                          READY     STATUS        RESTARTS   AGE  | syndesis-db-1-qngv8           1/1       Running       0          3m  | syndesis-meta-1-qpzkp         1/1       Terminating   0          3m  | syndesis-oauthproxy-1-nttks   1/1       Running       0          3m  | syndesis-operator-1-d4nst     1/1       Running       0          3m  | syndesis-prometheus-1-lldtd   1/1       Running       0          3m  | syndesis-server-1-75wv2       0/1       Terminating   1          3m  | syndesis-ui-1-qfkxq           1/1       Running       0          3m  | syndesis-upgrade-latest       1/1       Running       0          40s  | todo-1-build                  0/1       Completed     0          3m  | todo-1-c8ztg                  1/1       Running       0          2m  | syndesis-meta-1-qpzkp   0/1       Terminating   0         3m  | syndesis-server-1-75wv2   0/1       Terminating   1         3m  | syndesis-server-1-75wv2   0/1       Terminating   1         3m  | syndesis-meta-1-qpzkp   0/1       Terminating   0         3m  | syndesis-meta-1-qpzkp   0/1       Terminating   0         3m  | Waiting for syndesis-meta to be scaled to 0  | === * Backup database (prep_20_backup_db)  | === * Process new template to extract update resources (prep_40_process_template)  | - Current Syndesis version "latest"  | error: unable to process template  | Required value: template.parameters[4]: parameter SAR_PROJECT is required and must be specified  | ====&gt; Error ==&gt; Rollback  | ----- Rollback  | --- * Rolling back 'Process new template to extract update resources'  | --- * Rolling back 'Backup database'  | --- * Rolling back 'Stopping syndesis-server'  | deploymentconfig "syndesis-server" scaled  | deploymentconfig "syndesis-meta" scaled  | Waiting for syndesis-server to be scaled to 1  | NAME                          READY     STATUS              RESTARTS   AGE  | syndesis-db-1-qngv8           1/1       Running             0          3m  | syndesis-meta-1-jhbql         0/1       ContainerCreating   0          2s  | syndesis-oauthproxy-1-nttks   1/1       Running             0          3m  | syndesis-operator-1-d4nst     1/1       Running             0          3m  | syndesis-prometheus-1-lldtd   1/1       Running             0          3m  | syndesis-server-1-vdflz       0/1       Running             0          4s  | syndesis-ui-1-qfkxq           1/1       Running             0          3m  | syndesis-upgrade-latest       1/1       Running             0          56s  | todo-1-build                  0/1       Completed           0          3m  | todo-1-c8ztg                  1/1       Running             0          2m  | syndesis-meta-1-jhbql   0/1       Running   0         2s  | Sleeping 10s ...  | Sleeping 10s ...  | syndesis-meta-1-jhbql   1/1       Running   0         26s  | Sleeping 10s ...  | syndesis-server-1-vdflz   1/1       Running   0         40s  | Waiting for syndesis-meta to be scaled to 1  | --- * Rolling back 'Backup Resource objects' ```  ### Steps to reproduce 1. install syndesis on minishift (latest) 2. Try to upgrade syndesis (Catalog -&gt; syndesis-upgrade) </body>
		<created>2018-10-15 15:37:53</created>
		<closed>2018-10-19 15:13:17</closed>
	</bug>
	<bug>
		<id>3833</id>
		<title>DataMapper : inconsistent field mapping visiualization </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  I define the mapping between two large objects: - a SalesForce Case object - a ServiceNow Incident object   When defining the map, everything work as expected but when I'm getting back to my integration to change the mapping, the lines connecting the fields to map are inconsistent.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;   ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![syndesis](https://user-images.githubusercontent.com/1868933/46944627-d3057700-d072-11e8-97c4-b9d75e89b4d9.gif)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create an integration between SalesForce and ServiceNow 2. Map Case to Incident 3. Publish the integration 4. Edit the integration </body>
		<created>2018-10-15 10:09:00</created>
		<closed>2018-10-25 09:20:31</closed>
	</bug>
	<bug>
		<id>3831</id>
		<title>Missing icons for intermediate steps</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Missing icons for intermediate steps  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![image](https://user-images.githubusercontent.com/1868933/46943778-b10af500-d070-11e8-9220-b1128d3cba8e.png)  </body>
		<created>2018-10-15 09:56:21</created>
		<closed>2018-10-16 09:08:47</closed>
	</bug>
	<bug>
		<id>3828</id>
		<title>Google Calendar Connector: Get a specific Event NPE for event without start/end time specification</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description For an event, that has only start/end date specified (whole day event) the 'Get a specific Event' action fails with NPE: ``` java.lang.NullPointerException at io.syndesis.connector.calendar.GoogleCalendarGetEventCustomizer.afterProducer(GoogleCalendarGetEventCustomizer.java:92) at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.access$100(Pipeline.java:43) at org.apache.camel.processor.Pipeline$1.done(Pipeline.java:157) at org.apache.camel.util.component.AbstractApiProducer$1.run(AbstractApiProducer.java:98) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) ``` </body>
		<created>2018-10-15 08:46:06</created>
		<closed>2018-10-29 13:20:19</closed>
	</bug>
	<bug>
		<id>3827</id>
		<title>Google Calendar Connector: Create Event NPE on empty attendees list</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I get error coming from parsing an empty attendees list i.e. when I don't provide any value in the 'Guest list' field.  When I do provide the list, action works fine (I noticed a minor thing - when there are multiple values separated by a comma, there has to be no space around the comma. This could lead to user's confusion, trimming the separated values would help.)  ``` java.lang.NullPointerException at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:871) at com.google.common.base.Splitter.splitToList(Splitter.java:408) at io.syndesis.connector.calendar.GoogleCalendarSendEventCustomizer.getAttendeesList(GoogleCalendarSendEventCustomizer.java:151) at io.syndesis.connector.calendar.GoogleCalendarSendEventCustomizer.createGoogleEvent(GoogleCalendarSendEventCustomizer.java:176) at io.syndesis.connector.calendar.GoogleCalendarSendEventCustomizer.beforeProducer(GoogleCalendarSendEventCustomizer.java:109) at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at io.syndesis.integration.component.proxy.ComponentProxyProducer.process(ComponentProxyProducer.java:44) at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.access$100(Pipeline.java:43) at org.apache.camel.processor.Pipeline$1.done(Pipeline.java:157) at org.apache.camel.processor.CamelInternalProcessor$InternalCallback.done(CamelInternalProcessor.java:262) at org.apache.camel.processor.RedeliveryErrorHandler$2.done(RedeliveryErrorHandler.java:560) at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.lambda$process$0(ActivityTrackingInterceptStrategy.java:93) at org.apache.camel.processor.Pipeline$1.done(Pipeline.java:166) at org.apache.camel.processor.CamelInternalProcessor$InternalCallback.done(CamelInternalProcessor.java:262) at org.apache.camel.processor.RedeliveryErrorHandler$2.done(RedeliveryErrorHandler.java:560) at org.apache.camel.processor.SendProcessor$1.done(SendProcessor.java:160) at org.apache.camel.processor.Pipeline$1.done(Pipeline.java:166) at org.apache.camel.util.component.AbstractApiProducer$1.run(AbstractApiProducer.java:98) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) ``` </body>
		<created>2018-10-15 08:31:25</created>
		<closed>2018-10-15 12:16:10</closed>
	</bug>
	<bug>
		<id>3823</id>
		<title>Unable to upload .json spec for API Provider connection in Chrome</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description    I have Syndesis 1.5.4-2018-1012 installed on my Linux CSB laptop (running RHEL 7). I cloned the quickstart:    git clone https://github.com/syndesisio/syndesis-quickstarts.git  So I have a local copy of task-api.json.   In Firefox, I can drag it in or upload it. In Chrome, I get:  'task-api.json' is not a valid file. Only files that end in '.json' can be uploaded.  To reproduce:  Open Syndesis in Chrome. Click Create Integration.  Click API Provider. Click Choose File.  Navigate to and select syndesis-quickstarts/api-provider/task-api.json. Click Open.  Syndesis displays: 'task-api.json' is not a valid file. Only files that end in '.json' can be uploaded.  Click Cancel and Yes. Click Create Integration.  Click API Provider.  Drag syndesis-quickstarts/api-provider/task-api.json into the drop area.  Syndesis displays: 'task-api.json' is not a valid file. Only files that end in '.json' can be uploaded.  In Firefox, doing this with the same file is successful.   </body>
		<created>2018-10-12 19:01:49</created>
		<closed>2018-10-22 16:19:26</closed>
	</bug>
	<bug>
		<id>3817</id>
		<title>#3712 is inconsistent in 1.4.9 build</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description https://github.com/syndesisio/syndesis/commit/ef0589de9fc293502466bfb79abaf6de02f47525 reverted changes in templates from https://github.com/syndesisio/syndesis/pull/3712/commits PR. Due to that https://github.com/syndesisio/syndesis/issues/3460 is still present. Marking as blocker as it should be fided in 7.1.1</body>
		<created>2018-10-12 14:05:36</created>
		<closed>2018-10-16 10:35:21</closed>
	</bug>
	<bug>
		<id>3814</id>
		<title>Google Calendar Connector - 'Update step' not allowing single field update</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11442**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Google Calendar connector action 'Update Event' doesn't allow partial update of an event.  This issue applies to a use-case where Update Event is used on its own, not depending on a data input from preceding step, e.g. timer -&gt; 'Update event'.  When user specifies calendar and eventId, and changes only 'location' in the form, I would expect, that only that single field is being attempted to be updated.  Pre-filling values into the form is not a valid solution, as it is valid only design time, not during runtime (event could have been updated meanwhile). Rather we'd need to handle the form input as a selective update, see https://developers.google.com/calendar/v3/reference/events/patch .  To illustrate the issue, what I see is, that event the date/time fields are being attempted to be updated even though I set only 'location' in the form. The error I get: ``` org.apache.camel.RuntimeCamelException: com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request {   "code" : 400,   "errors" : [ {     "domain" : "global",     "message" : "Missing end time.",     "reason" : "required"   } ],   "message" : "Missing end time." } at org.apache.camel.component.google.calendar.GoogleCalendarProducer.doInvokeMethod(GoogleCalendarProducer.java:51) at org.apache.camel.util.component.AbstractApiProducer$1.run(AbstractApiProducer.java:86) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Caused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request {   "code" : 400,   "errors" : [ {     "domain" : "global",     "message" : "Missing end time.",     "reason" : "required"   } ],   "message" : "Missing end time." } at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146) at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1065) at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) at org.apache.camel.component.google.calendar.GoogleCalendarProducer.doInvokeMethod(GoogleCalendarProducer.java:49) ... 8 more ```</body>
		<created>2018-10-12 07:31:55</created>
		<closed>2019-09-07 11:30:02</closed>
	</bug>
	<bug>
		<id>3807</id>
		<title>API Provider Data Type Mismatch</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11568**  ## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When you provider Todo App swagger to API Provider a data type mismatch occurs on unimplemented flows:  ![image](https://user-images.githubusercontent.com/674767/46811671-35900780-cd41-11e8-894c-f04272893466.png)  ![image](https://user-images.githubusercontent.com/674767/46811728-5193a900-cd41-11e8-9294-737bb1cd299c.png)   </body>
		<created>2018-10-11 14:36:07</created>
		<closed>2019-09-07 12:46:47</closed>
	</bug>
	<bug>
		<id>3804</id>
		<title>Export fails to exports the OpenAPI ResourceDefinition</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [*] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description So upon importing let's say the TaskAPI-export.zip on  https://github.com/KurtStam/syndesis-quickstarts/tree/master/api-provider  It won't create any rest routes, leaving the end user frustrated. No errors are reported and all looks ok, but no endpoint is deployed. </body>
		<created>2018-10-11 13:13:10</created>
		<closed>2018-10-30 12:31:23</closed>
	</bug>
	<bug>
		<id>3803</id>
		<title>Google Calendar Connector - 'Create event' action cannot instantiate DateTime class when using data mapper</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When using 'Create Event' action of Google Calendar Connector in combination with Data Mapper I am getting error. I am mapping to DateTime class, but that cannot be instantiated by data mapper, see following stacktrace.  ``` io.atlasmap.api.AtlasException: Errors: [Unexpected exception is thrown while populating target field: Could not instantiate class: com.google.api.client.util.DateTime, segment: /start/date: docId='-LOYCLASsRGI0zByb7R1', path='/start/date/value'], [Unexpected exception is thrown while populating target field: Could not instantiate class: com.google.api.client.util.DateTime, segment: /start/date: docId='-LOYCLASsRGI0zByb7R1', path='/start/date/value'], [Unexpected exception is thrown while populating target field: Could not instantiate class: com.google.api.client.util.DateTime, segment: /start/date: docId='-LOYCLASsRGI0zByb7R1', path='/start/date/value'], [Unexpected exception is thrown while populating target field: Could not instantiate class: com.google.api.client.util.DateTime, segment: /start/date: docId='-LOYCLASsRGI0zByb7R1', path='/start/date/value'],  at org.apache.camel.component.atlasmap.AtlasEndpoint.onExchange(AtlasEndpoint.java:213) at org.apache.camel.impl.ProcessorEndpoint$1.process(ProcessorEndpoint.java:71) at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.MulticastProcessor.doProcessSequential(MulticastProcessor.java:715) at org.apache.camel.processor.MulticastProcessor.doProcessSequential(MulticastProcessor.java:638) at org.apache.camel.processor.MulticastProcessor.process(MulticastProcessor.java:248) at org.apache.camel.processor.Splitter.process(Splitter.java:122) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197) at org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79) at java.util.TimerThread.mainLoop(Timer.java:555) at java.util.TimerThread.run(Timer.java:505) ``` </body>
		<created>2018-10-11 13:09:23</created>
		<closed>2018-10-29 13:23:17</closed>
	</bug>
	<bug>
		<id>3802</id>
		<title>No error msg when running out of # of allowed integrations</title>
		<body>When I start a second integration it simply goes back to 'Stopped' after trying to deploy. No error msg.  This is super confusing and a bug for sure. It starts ok after shutting down the first integration.</body>
		<created>2018-10-11 12:06:27</created>
		<closed>2018-11-09 17:51:35</closed>
	</bug>
	<bug>
		<id>3801</id>
		<title>[1.4.9] Unable to login to syndesis on openshift pro</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description After installation from template to openshift Pro  I'm unable to login into syndesis with message: 500 Internal Error  #### Version OpenShift Master: v3.9.41 Kubernetes Master:v1.9.1+a0ce1bc657 OpenShift Web Console:v3.9.41 Syndesis 1.4.9  Log from syndesis-oauthproxy pod ``` 2018/10/11 09:19:26 provider.go:572: 200 GET https://172.30.0.1/.well-known/oauth-authorization-server  { --  | "issuer": "https://api.pro-us-east-1.openshift.com ",  | "authorization_endpoint": "https://api.pro-us-east-1.openshift.com/oauth/authorize ",  | "token_endpoint": "https://api.pro-us-east-1.openshift.com/oauth/token ",  | "scopes_supported": [  | "user:check-access",  | "user:full",  | "user:info",  | "user:list-projects",  | "user:list-scoped-projects"  | ],  | "response_types_supported": [  | "code",  | "token"  | ],  | "grant_types_supported": [  | "authorization_code",  | "implicit"  | ],  | "code_challenge_methods_supported": [  | "plain",  | "S256"  | ]  | }  | 2018/10/11 09:19:26 oauthproxy.go:201: mapping path "/api/" =&gt; upstream "http://syndesis-server/api/ "  | 2018/10/11 09:19:26 oauthproxy.go:201: mapping path "/mapper/" =&gt; upstream "http://syndesis-server/mapper/ "  | 2018/10/11 09:19:26 oauthproxy.go:201: mapping path "/" =&gt; upstream "http://syndesis-ui/ "  | 2018/10/11 09:19:26 oauthproxy.go:222: compiled skip-auth-regex =&gt; "/logout"  | 2018/10/11 09:19:26 oauthproxy.go:222: compiled skip-auth-regex =&gt; "/[^/]+\\.(png\|jpg\|eot\|svg\|ttf\|woff\|woff2)"  | 2018/10/11 09:19:26 oauthproxy.go:222: compiled skip-auth-regex =&gt; "/api/v1/swagger.*"  | 2018/10/11 09:19:26 oauthproxy.go:222: compiled skip-auth-regex =&gt; "/api/v1/index.html"  | 2018/10/11 09:19:26 oauthproxy.go:222: compiled skip-auth-regex =&gt; "/api/v1/credentials/callback"  | 2018/10/11 09:19:26 oauthproxy.go:222: compiled skip-auth-regex =&gt; "/api/v1/version"  | 2018/10/11 09:19:26 oauthproxy.go:228: OAuthProxy configured for  Client ID: system:serviceaccount:syndesis:syndesis-oauth-client  | 2018/10/11 09:19:26 oauthproxy.go:238: Cookie settings: name:_oauth_proxy secure(https):true httponly:true expiry:168h0m0s domain:&lt;default&gt; refresh:disabled  | 2018/10/11 09:19:26 http.go:56: HTTP: listening on 127.0.0.1:4180  | 2018/10/11 09:19:26 http.go:96: HTTPS: listening on [::]:8443  | 2018/10/11 09:21:58 oauthproxy.go:635: error redeeming code (client:10.128.12.1:50836): got 400 from "https://api.pro-us-east-1.openshift.com/oauth/token " {"error":"unauthorized_client","error_description":"The client is not authorized to request a token using this method."}  | 2018/10/11 09:21:58 oauthproxy.go:434: ErrorPage 500 Internal Error Internal Error  | 2018/10/11 09:22:01 oauthproxy.go:635: error redeeming code (client:10.128.12.1:50836): got 400 from "https://api.pro-us-east-1.openshift.com/oauth/token " {"error":"unauthorized_client","error_description":"The client is not authorized to request a token using this method."}  | 2018/10/11 09:22:01 oauthproxy.go:434: ErrorPage 500 Internal Error Internal Error ```  #### Steps to reproduce   run on onpenshift pro  ``` oc create -f https://raw.githubusercontent.com/syndesisio/syndesis/master/install/support/serviceaccount-as-oauthclient-restricted.yml oc create -f https://raw.githubusercontent.com/syndesisio/syndesis/1.4.9/install/syndesis.yml oc new-app syndesis -p OPENSHIFT_MASTER=$(oc whoami --show-server) -p OPENSHIFT_PROJECT=$(oc project -q) -p ROUTE_HOSTNAME=syndesis.b9ad.pro-us-east-1.openshiftapps.com ```   </body>
		<created>2018-10-11 09:40:17</created>
		<closed>2018-10-11 10:38:27</closed>
	</bug>
	<bug>
		<id>3800</id>
		<title>NullPointerException during integration to Rest API</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I want to create integration AMQ -&gt; Todo app which is described in the [Fuse online tutorials](https://access.redhat.com/documentation/en-us/red_hat_fuse/7.0/html-single/ignite_sample_integration_tutorials/#amq-to-rest-api). I created AMQ connection, imported extension ([Damage Reporter](https://github.com/syndesisio/fuse-online-sample-extension/releases)), created REST API connector (Customization -&gt; API Client Connectors) and REST API connection for TODO application, created integration. However, it has never be published and it is stuck in the 'starting' state.  Same situation happens in our test which integrates DB -&gt; Todo custom api connector   In the integration log in the OpenShift is NPE: ``` 2018-10-11 08:54:17.978 ERROR 1 --- [           main] o.s.boot.SpringApplication               : Application startup failed org.apache.camel.RuntimeCamelException: org.apache.camel.FailedToCreateRouteException: Failed to create route -LOXHluBCImTo_Sgidtn: Route(-LOXHluBCImTo_Sgidtn)[[From[sjms-0-0]] -&gt; [SetHeader[S... because of Failed to create Producer for endpoint: swagger-operation-0-3?operationId=operation-1. Reason: org.apache.camel.RuntimeCamelException: Cannot auto create component: null at org.apache.camel.util.ObjectHelper.wrapRuntimeCamelException(ObjectHelper.java:1830) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.spring.SpringCamelContext.start(SpringCamelContext.java:136) ~[camel-spring-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.spring.SpringCamelContext.onApplicationEvent(SpringCamelContext.java:174) ~[camel-spring-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172) ~[spring-context-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165) ~[spring-context-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139) ~[spring-context-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:393) ~[spring-context-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:347) ~[spring-context-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:883) ~[spring-context-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.finishRefresh(EmbeddedWebApplicationContext.java:144) ~[spring-boot-1.5.13.RELEASE.jar!/:1.5.13.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546) ~[spring-context-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) ~[spring-boot-1.5.13.RELEASE.jar!/:1.5.13.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.13.RELEASE.jar!/:1.5.13.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.13.RELEASE.jar!/:1.5.13.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.13.RELEASE.jar!/:1.5.13.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.13.RELEASE.jar!/:1.5.13.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.13.RELEASE.jar!/:1.5.13.RELEASE] at io.syndesis.example.Application.main(Application.java:13) [classes!/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_151] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_151] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151] at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.Launcher.launch(Launcher.java:87) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.Launcher.launch(Launcher.java:50) [project-0.1-SNAPSHOT.jar:na] at org.springframework.boot.loader.PropertiesLauncher.main(PropertiesLauncher.java:595) [project-0.1-SNAPSHOT.jar:na] Caused by: org.apache.camel.FailedToCreateRouteException: Failed to create route -LOXHluBCImTo_Sgidtn: Route(-LOXHluBCImTo_Sgidtn)[[From[sjms-0-0]] -&gt; [SetHeader[S... because of Failed to create Producer for endpoint: swagger-operation-0-3?operationId=operation-1. Reason: org.apache.camel.RuntimeCamelException: Cannot auto create component: null at org.apache.camel.impl.RouteService.warmUp(RouteService.java:147) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.impl.DefaultCamelContext.doWarmUpRoutes(DefaultCamelContext.java:3947) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.impl.DefaultCamelContext.safelyStartRouteServices(DefaultCamelContext.java:3854) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.impl.DefaultCamelContext.doStartOrResumeRoutes(DefaultCamelContext.java:3640) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.impl.DefaultCamelContext.doStartCamel(DefaultCamelContext.java:3492) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.impl.DefaultCamelContext.access$000(DefaultCamelContext.java:209) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.impl.DefaultCamelContext$2.call(DefaultCamelContext.java:3251) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.impl.DefaultCamelContext$2.call(DefaultCamelContext.java:3247) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.impl.DefaultCamelContext.doWithDefinedClassLoader(DefaultCamelContext.java:3270) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.impl.DefaultCamelContext.doStart(DefaultCamelContext.java:3247) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.impl.DefaultCamelContext.start(DefaultCamelContext.java:3163) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.spring.SpringCamelContext.start(SpringCamelContext.java:133) ~[camel-spring-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] ... 24 common frames omitted Caused by: org.apache.camel.FailedToCreateProducerException: Failed to create Producer for endpoint: swagger-operation-0-3?operationId=operation-1. Reason: org.apache.camel.RuntimeCamelException: Cannot auto create component: null at org.apache.camel.impl.ProducerCache.doGetProducer(ProducerCache.java:584) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.impl.ProducerCache.acquireProducer(ProducerCache.java:168) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.processor.SendProcessor.doStart(SendProcessor.java:248) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:60) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.processor.WrapProcessor.doStart(WrapProcessor.java:52) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:60) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:104) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:90) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.processor.RedeliveryErrorHandler.doStart(RedeliveryErrorHandler.java:1472) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.support.ChildServiceSupport.start(ChildServiceSupport.java:44) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.support.ChildServiceSupport.start(ChildServiceSupport.java:31) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:60) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:104) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:90) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.processor.interceptor.DefaultChannel.doStart(DefaultChannel.java:160) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:60) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:104) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:62) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:104) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:90) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.processor.MulticastProcessor.doStart(MulticastProcessor.java:1186) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:60) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.processor.WrapProcessor.doStart(WrapProcessor.java:52) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:60) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:104) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:90) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.processor.RedeliveryErrorHandler.doStart(RedeliveryErrorHandler.java:1472) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.support.ChildServiceSupport.start(ChildServiceSupport.java:44) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.support.ChildServiceSupport.start(ChildServiceSupport.java:31) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:60) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:104) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:90) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.processor.interceptor.DefaultChannel.doStart(DefaultChannel.java:160) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:60) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:104) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:62) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:104) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:90) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.processor.MulticastProcessor.doStart(MulticastProcessor.java:1186) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:60) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:104) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:90) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.processor.DelegateAsyncProcessor.doStart(DelegateAsyncProcessor.java:80) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.impl.RouteService.startChildService(RouteService.java:370) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.impl.RouteService.doWarmUp(RouteService.java:196) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.impl.RouteService.warmUp(RouteService.java:145) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] ... 36 common frames omitted Caused by: org.apache.camel.RuntimeCamelException: Cannot auto create component: null at org.apache.camel.impl.DefaultCamelContext.getComponent(DefaultCamelContext.java:489) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.impl.DefaultCamelContext.getComponent(DefaultCamelContext.java:453) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.spi.RestProducerFactoryHelper.setupComponent(RestProducerFactoryHelper.java:56) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.component.rest.RestEndpoint.createProducer(RestEndpoint.java:350) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.component.rest.swagger.RestSwaggerEndpoint.createProducerFor(RestSwaggerEndpoint.java:286) ~[camel-rest-swagger-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.component.rest.swagger.RestSwaggerEndpoint.createProducer(RestSwaggerEndpoint.java:191) ~[camel-rest-swagger-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.component.connector.DefaultConnectorEndpoint.createProducer(DefaultConnectorEndpoint.java:51) ~[camel-connector-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] at org.apache.camel.impl.ProducerCache.doGetProducer(ProducerCache.java:573) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] ... 99 common frames omitted Caused by: java.lang.NullPointerException: null at java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1645) ~[na:1.8.0_151] at org.apache.camel.impl.DefaultCamelContext.getComponent(DefaultCamelContext.java:472) ~[camel-core-2.21.0.fuse-720028.jar!/:2.21.0.fuse-720028] ... 106 common frames omitted  ```  Whole log: [i-amq-12-bhq8t.log](https://github.com/syndesisio/syndesis/files/2468286/i-amq-12-bhq8t.log) </body>
		<created>2018-10-11 09:36:56</created>
		<closed>2018-10-17 07:42:31</closed>
	</bug>
	<bug>
		<id>3794</id>
		<title>Remove nested alert inside of data mismatch popover</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem in the IVP, when there is a data mismatch, the popover has an embedded alert that looks weird.  ## Expected behavior Should just be a normal popover.  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create an integration with a data mismatch 2. Click warning icon to display popover </body>
		<created>2018-10-10 15:30:36</created>
		<closed>2018-10-11 18:13:31</closed>
	</bug>
	<bug>
		<id>3793</id>
		<title>Google Calendar Connector: 'Get a specific Event' not failing gracefully</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; User is presented with a stack trace without any description of an error.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Ideally an error message, plus optionally with an error code/stacktrace.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![screenshot from 2018-10-10 16-15-20](https://user-images.githubusercontent.com/11939909/46743414-4a20c100-cca9-11e8-972b-9deb660bd61f.png)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Use a Google calendar action 'Get a specific Event' 2. Specify non-existent event id 3. Publish such integration </body>
		<created>2018-10-10 14:31:28</created>
		<closed>2018-10-10 15:10:27</closed>
	</bug>
	<bug>
		<id>3791</id>
		<title>UI - Google Calendar Connector: Receive Events 'Query for events' description</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; The purpose of the form field labeled 'Query for events' is not clear. I miss the information that/how it actually filters the events retrieved for the calendar.  What it appears to do is a full-word search in events' fields, checked summary and description so far, Behaves in following manner:  1. events e1 with description 'An old event' and e2 with description 'An old event2'  2. 'Query for events' set to 'An old event' retrieves only e1, not e2.  It might be desired behavior, but it's hard to tell, due to insufficient description of the field purpose. </body>
		<created>2018-10-10 13:46:14</created>
		<closed>2018-10-12 07:43:54</closed>
	</bug>
	<bug>
		<id>3790</id>
		<title>Google Calendar Connector: confusing option to alter polling behaviour</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Receive events action option 'Consume from the last event update date on the next poll' is source of confusion for the user.  It assures, that in consecutive poll it returns only events that take place after the 'last update date' of current poll.  The thing is that it compares two unrelated values - based on last update of events it returns only events that take place after it.  Side effect of this is that user can't get past events that were updated recently (added link with recording or similar).  It would make much more sense for the action to return events updated after the 'previous poll last update date' to have only a diff between the two polls.  We should aspire to sanitize this filtering option.</body>
		<created>2018-10-10 12:18:07</created>
		<closed>2018-10-17 12:12:38</closed>
	</bug>
	<bug>
		<id>3789</id>
		<title>Switching between multiple Data Mapper steps in an integration does not update the view</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When there are two (or more) Data Mapper steps in an integration, opening one of them and then selecting the other one in the sidebar, it appears to get selected in the sidebar, but the main view is not updated (i.e. it's still showing the old data mapper's content).  Switching to some other step first or closing the Data Mapper and opening it for the other steps works as a workaround.  ![dm](https://user-images.githubusercontent.com/9480152/46731849-1d11e580-cc8c-11e8-874f-45447f78bfdd.gif)      </body>
		<created>2018-10-10 10:58:29</created>
		<closed>2018-10-16 13:13:41</closed>
	</bug>
	<bug>
		<id>3787</id>
		<title>Atlasmap does not handle null values very well</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [*] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I mapped a SQL select and one of the fields has a NULL value. I get the following stack trace  io.atlasmap.api.AtlasException: Errors: [Unexpected exception is thrown while populating target field: null: docId='i-LOSEnaMz-xodY4Bu__Gz', path='/completed'], [Unexpected exception is thrown while populating target field: null: docId='i-LOSEnaMz-xodY4Bu__Gz', path='/completed'], [Unexpected exception is thrown while populating target field: null: docId='i-LOSEnaMz-xodY4Bu__Gz', path='/completed'],  at org.apache.camel.component.atlasmap.AtlasEndpoint.onExchange(AtlasEndpoint.java:213) at org.apache.camel.impl.ProcessorEndpoint$1.process(ProcessorEndpoint.java:71) at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.component.direct.DirectBlockingProducer.process(DirectBlockingProducer.java:53) at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:97) at org.apache.camel.http.common.CamelServlet.doService(CamelServlet.java:214) at org.apache.camel.http.common.CamelServlet.service(CamelServlet.java:80) at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:111) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:106) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:64) at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:132) at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292) at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) at io.undertow.server.Connectors.executeRootHandler(Connectors.java:336) at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)  EXPECTED BEHAVIOR  That it would simply set the value to NULL.</body>
		<created>2018-10-10 09:38:52</created>
		<closed>2019-04-17 20:00:42</closed>
	</bug>
	<bug>
		<id>3786</id>
		<title>Integration fails to start with with empty log step</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [x] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; If the user adds a logging step to the integration without checking any of the checkboxes (Message Context, Message Body) or providing a message to log. The integration fails to start.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; We can either validate so that the user specifies something to log, we can provide a default if nothing is provided to log or we can skip the logging if nothing is provided.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![screenshot_2018-10-10 syndesis](https://user-images.githubusercontent.com/1306050/46726254-488dd380-cc7e-11e8-949c-fa6005c7486f.png)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Either add validation 2. Provide default 3. Or don't add log to route definition in LogStepHandler  [i-log-me-baby-one-more-time-12-qjwsc.log](https://github.com/syndesisio/syndesis/files/2464026/i-log-me-baby-one-more-time-12-qjwsc.log) </body>
		<created>2018-10-10 09:28:55</created>
		<closed>2018-10-15 13:25:54</closed>
	</bug>
	<bug>
		<id>3780</id>
		<title>API Provider 501 status default</title>
		<body>When I implement a flow, the return status stays on 501, it should be now automatically set to 200.</body>
		<created>2018-10-09 15:27:45</created>
		<closed>2018-10-23 08:50:03</closed>
	</bug>
	<bug>
		<id>3774</id>
		<title>Cannot create API Provider integration from YAML</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  The API Provider starting step only allows JSON, URL or manual way of defining APIs, no YAML. This is similar to #3578, so the solution should probably be the same</body>
		<created>2018-10-09 09:33:43</created>
		<closed>2018-10-16 11:43:26</closed>
	</bug>
	<bug>
		<id>3766</id>
		<title>Invalid Cert error on minishift stop/start</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [*] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  .... You are logged in as:     User:     developer     Password: &lt;any value&gt;  To login as administrator:     oc login -u system:admin   error: The server uses a certificate signed by unknown authority. You may need to use the --certificate-authority flag to provide the path to a certificate file for the certificate authority, or --insecure-skip-tls-verify to bypass the certificate check and use insecure connections. Could not set oc CLI context for 'minishift' profile: Error during setting 'minishift' as active profile: Unable to login to cluster  To Reproduce:  Install Syndesis using  sy minishift --full-reset --install  then   minishift stop  and on   minishift start  I get the error above. </body>
		<created>2018-10-08 14:03:45</created>
		<closed>2018-11-03 17:07:24</closed>
	</bug>
	<bug>
		<id>3764</id>
		<title>Mark API Provider as tech preview</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  API Provider is technology preview and should be marked as.</body>
		<created>2018-10-08 12:08:16</created>
		<closed>2018-10-16 11:44:57</closed>
	</bug>
	<bug>
		<id>3761</id>
		<title>Slack connection - Delay time doesn't work</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I have integration Slack -&gt; PostgreSQL. For Read Messages, I have set Delay to 8 minutes and Maximum Messages to Retrieve to 2. Maximum Messages work but Delay field doesn't work for me. Every time when I post message to the channel, immediately I see message in the integration metrics and saved in the DB.  </body>
		<created>2018-10-08 08:46:45</created>
		<closed>2018-10-17 08:28:42</closed>
	</bug>
	<bug>
		<id>3746</id>
		<title>API provider exposure/discovery consistency</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I'm labelling this as a bug as lack of consistency usually is.  We need to align how we do exposure/discovery in Apicurito generated project using fabric8-maven-plugin and in Syndesis.  From Syndesis point of view:  1. `basePath` handling  `basePath` should be taken from the uploaded OpenAPI 2.0 specification, if present, and it should determine the servlet mapping (contextPath) for the Camel Servlet. If not present it should default to `/` and the servlet mapping should be `/*`.  2. remove `discovery.3scale.net/path` annotation  We specify `basePath` in the generated REST DSL and set the CamelServlet mapping, it's also set as `basePath` in the generated Swagger document. So we don't need to specify `discovery.3scale.net/path` annotation as it would calculate the path to the API with duplicate base path.  3. OpenAPI 2.0 specification serving  We should serve the OpenAPI 2.0 specification from `/openapi.json`, this should be the provided OpenAPI 2.0 specification not the auto-generated one from REST DSL.  @KurtStam @chirino please review and add additional changes we need to be consistent across all projects  ## Related, additional report from Kurt  In the swagger for https://github.com/KurtStam/syndesis-quickstarts/tree/master/api-provider, no contextPath is specific. So as far as the user is concerned the URL at which the API runs is {$externalURL}/todo  however it is  {$externalURL}/api/todo  There is another issue opened on this why we are doing this, but if we keep doing it then we should include the /api part in the externalURL. It's complete guess work for the enduser right now.</body>
		<created>2018-10-04 16:32:06</created>
		<closed>2018-11-01 10:09:55</closed>
	</bug>
	<bug>
		<id>3743</id>
		<title>'Update Event' Google Calendar connector action input shape issue</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I have troubles using the Update Event (io.syndesis:google-calendar-update-event-connector) action as an end step.  The action itself defines properties, e.g. eventId, which needs to be specified for Event identification. Its input shape is com.google.api.services.calendar.model.Event. When the preceding step is a mapper step, then I can map to all the fields of com.google.api.services.calendar.model.Event, but I can't fill in any of the properties (eventId in my case).  When I map only to Event class fields (i.e. not eventId property) I get following error: ``` org.apache.camel.RuntimeCamelException: Error invoking update with {eventId=null, calendarId=jbossqa.fuse@gmail.com, content={id=1pig4rhkl3qtji5s9l8e2l9f3j, kind=calendar#event, location=new-location, status=confirmed, summary=test1}}: Required parameter eventId must be specified. -- at org.apache.camel.util.component.ApiMethodHelper.invokeMethod(ApiMethodHelper.java:514) ~[camel-core-2.21.0.fuse-720021.jar!/:2.21.0.fuse-720021] at org.apache.camel.util.component.AbstractApiProducer.doInvokeMethod(AbstractApiProducer.java:120) ~[camel-core-2.21.0.fuse-720021.jar!/:2.21.0.fuse-720021] at org.apache.camel.component.google.calendar.GoogleCalendarProducer.doInvokeMethod(GoogleCalendarProducer.java:43) ~[camel-google-calendar-2.21.0.fuse-720021.jar!/:2.21.0.fuse-720021] at org.apache.camel.util.component.AbstractApiProducer$1.run(AbstractApiProducer.java:86) ~[camel-core-2.21.0.fuse-720021.jar!/:2.21.0.fuse-720021] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_151] at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_151] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) [na:1.8.0_151] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) [na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_151] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_151] Caused by: java.lang.NullPointerException: Required parameter eventId must be specified. at com.google.api.client.repackaged.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:229) ~[google-http-client-1.22.0.jar!/:1.22.0] at com.google.api.client.util.Preconditions.checkNotNull(Preconditions.java:140) ~[google-http-client-1.22.0.jar!/:1.22.0] at com.google.api.services.calendar.Calendar$Events$Update.&lt;init&gt;(Calendar.java:5492) ~[google-api-services-calendar-v3-rev291-1.22.0.jar!/:na] at com.google.api.services.calendar.Calendar$Events.update(Calendar.java:5463) ~[google-api-services-calendar-v3-rev291-1.22.0.jar!/:na] at sun.reflect.GeneratedMethodAccessor407.invoke(Unknown Source) ~[na:na] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151] at org.apache.camel.util.component.ApiMethodHelper.invokeMethod(ApiMethodHelper.java:506) ~[camel-core-2.21.0.fuse-720021.jar!/:2.21.0.fuse-720021] ... 10 common frames omitted ``` I believe this is a valid use case, when the flow starts with google calendar 'From' action and ending with google calendar 'To' action, for example when user wants to change locations of all events scheduled to another location (due to its unavailability or sth).</body>
		<created>2018-10-04 13:18:08</created>
		<closed>2018-10-05 11:54:04</closed>
	</bug>
	<bug>
		<id>3741</id>
		<title>'Send Event' Google Calendar connector action description issue</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The description of the action Send Event (io.syndesis:google-calendar-insert-event-connector) is malformed. This needs a refinement (problematic part is  '...from to...'). `Send an event from to the Calendar account that this connection is authorized to access.` </body>
		<created>2018-10-04 12:54:31</created>
		<closed>2018-10-05 12:57:08</closed>
	</bug>
	<bug>
		<id>3740</id>
		<title>'Get a specific Event' Google calendar action has wrong pattern defined</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Google Calendar connector action 'Get a specific Event'(io.syndesis:google-calendar-get-event-connector) is defined with Pattern 'To'.  I think it is wrong, as a get operation is typically a starting step. This way this action is useless. </body>
		<created>2018-10-04 12:47:27</created>
		<closed>2018-10-05 11:47:59</closed>
	</bug>
	<bug>
		<id>3738</id>
		<title>NPE when trying to save an integration</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [*] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description New API Provider Integration cannot save due to NPE.  I tried importing  https://raw.githubusercontent.com/KurtStam/syndesis-quickstarts/master/beer-api.json  and I'm getting the following NPE stack in my server log:  ] at io.syndesis.server.endpoint.v1.handler.api.ApiHandler.createIntegrationFromAPI(ApiHandler.java:84) ~[server-endpoint-1.5-SNAPSHOT.jar!/:1.5-SNAPSHOT] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_151] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_151] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151] at org.jboss.resteasy.core.MethodInjectorImpl.invoke(MethodInjectorImpl.java:140) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.internalInvokeOnTarget(ResourceMethodInvoker.java:509) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTargetAfterFilter(ResourceMethodInvoker.java:399) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.lambda$invokeOnTarget$0(ResourceMethodInvoker.java:363) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:358) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTarget(ResourceMethodInvoker.java:365) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:337) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:310) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:443) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.lambda$invoke$4(SynchronousDispatcher.java:233) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.lambda$preprocess$0(SynchronousDispatcher.java:139) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:358) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.preprocess(SynchronousDispatcher.java:142) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:219) [resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.ServletContainerDispatcher.service(ServletContainerDispatcher.java:227) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:56) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:51) ~[resteasy-jaxrs-3.6.1.Final.jar!/:3.6.1.Final] at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) ~[javax.servlet-api-3.1.0.jar!/:3.1.0] at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) ~[spring-boot-1.5.13.RELEASE.jar!/:1.5.13.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:111) ~[spring-boot-actuator-1.5.13.RELEASE.jar!/:1.5.13.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.authentication.preauth.AbstractPreAuthenticatedProcessingFilter.doFilter(AbstractPreAuthenticatedProcessingFilter.java:121) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.csrf.CsrfFilter.doFilterInternal(CsrfFilter.java:124) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:66) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at org.springframework.cloud.sleuth.instrument.web.TraceFilter.doFilter(TraceFilter.java:186) ~[spring-cloud-sleuth-core-1.2.6.RELEASE.jar!/:1.2.6.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:106) ~[spring-boot-actuator-1.5.13.RELEASE.jar!/:1.5.13.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:64) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:132) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.server.Connectors.executeRootHandler(Connectors.java:336) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_151] at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_151]  and the UI looks like:  &lt;img width="505" alt="screen shot 2018-10-04 at 2 27 16 pm" src="https://user-images.githubusercontent.com/35576/46473843-5f7c8380-c7af-11e8-9ffd-a197078b24c3.png"&gt;  It is unclear if this is pilot error but even so it probably should handle this more graceful.</body>
		<created>2018-10-04 12:28:50</created>
		<closed>2018-10-31 08:54:24</closed>
	</bug>
	<bug>
		<id>3729</id>
		<title>Remove `Exchange.HTTP_URI` header before HTTP request in rest-swagger connector</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description When chaining WebHook connector with API client connector the `Exchange.HTTP_URI` header is set on the Camel message. This will override any URL configured on the HTTP4 component endpoint we configure via rest-swagger connector making the chaining of WebHook and API client connectors impossible. </body>
		<created>2018-10-03 19:12:34</created>
		<closed>2018-10-24 09:24:33</closed>
	</bug>
	<bug>
		<id>3727</id>
		<title>UT010029: Stream is closed with WebHook connector</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [b] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description WebHook connector reads the HTTP body as `InputStream` and replaces it with Syndesis specific JSON containing parameters/body. The binding (`org.apache.camel.http.common.DefaultHttpBinding`) that created the message (`org.apache.camel.http.common.HttpMessage`) reads from the `InputStream` of the `HttpServletRequest` and closes the stream. If the next processor in the exchange is a `org.apache.camel.processor.Pipeline` `org.apache.camel.util.ExchangeHelper::copyResults` is invoked and ends up calling `HttpMessage::createBody` that ends up calling `DefaultHttpBinding::parseBody` reading the `InputStream` for the second time. At this time the `InputStream` is already closed so `UT010029: Stream is closed` is reported.  ``` Caused by: java.io.IOException: UT010029: Stream is closed at io.undertow.servlet.spec.ServletInputStreamImpl.available(ServletInputStreamImpl.java:237) ~[undertow-servlet-1.4.25.Final.jar:1.4.25.Final] at org.apache.camel.http.common.HttpConverter.toInputStream(HttpConverter.java:86) ~[camel-http-common-2.21.1.jar:2.21.1] at org.apache.camel.http.common.HttpHelper.readRequestBodyFromServletRequest(HttpHelper.java:193) ~[camel-http-common-2.21.1.jar:2.21.1] at org.apache.camel.http.common.DefaultHttpBinding.parseBody(DefaultHttpBinding.java:577) ~[camel-http-common-2.21.1.jar:2.21.1] at org.apache.camel.http.common.HttpMessage.createBody(HttpMessage.java:78) ~[camel-http-common-2.21.1.jar:2.21.1] ```</body>
		<created>2018-10-03 18:09:53</created>
		<closed>2019-08-08 09:14:43</closed>
	</bug>
	<bug>
		<id>3725</id>
		<title>Data mapper step isn't available for </title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [  x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  If I want to create an integration **Whatever -&gt; DB** I can't use (is not available) **Datamapper step** (e.g. if I want to insert any data into DB from a previous connection) ![todbintegration](https://user-images.githubusercontent.com/8707251/46415068-c99c1680-c724-11e8-88bc-330c28b2fa1f.png)</body>
		<created>2018-10-03 13:56:26</created>
		<closed>2018-10-05 08:29:05</closed>
	</bug>
	<bug>
		<id>3719</id>
		<title>Default Connection Values aren't passed to MetaDataExtensions </title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  When creating a Connection based on default values, connection properties aren't passed to MetadaExtensions. Re-entering default values in the Connection solves the problem.  Thanks! </body>
		<created>2018-10-02 15:28:30</created>
		<closed>2018-10-04 14:46:15</closed>
	</bug>
	<bug>
		<id>3718</id>
		<title>OpenApi validation API doesn't return the by tags action report</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  The two OpenApi validation API we have now on the app (the one used by the Api Connector `/api/v1/connectors/custom/info` and the one used by the Api Provider `/api/v1/apis/info`) don't return the `actionsSummary.actionCountByTags` property.  Here is a sample request/response:  `curl 'https://.../api/v1/apis/info' ....omissis... --data-binary $'------WebKitFormBoundaryZBwc8DOncJAAcjUH\r\nContent-Disposition: form-data; name="specification"\r\n\r\nhttps://raw.githubusercontent.com/Apicurio/api-samples/master/beer/beer-api_2.0.json\r\n------WebKitFormBoundaryZBwc8DOncJAAcjUH--\r\n' --compressed`  ``` {   "actionsSummary": {     "totalActions": 12   },   "description": "An OpenAPI 2.0 version of the Beer API.",   "errors": [     {       "error": "validation",       "message": "array is too short: must have at least 1 elements but instance has 0 elements",       "property": "/definitions/Beer/required"     }   ],   "warnings": [     {       "error": "missing-response-schema",       "message": "Operation POST /beers does not provide a response schema for code 201"     },     {       "error": "missing-response-schema",       "message": "Operation PUT /beers/{beerId} does not provide a response schema for code 202"     },     {       "error": "missing-response-schema",       "message": "Operation DELETE /beers/{beerId} does not provide a response schema for code 204"     },     {       "error": "missing-response-schema",       "message": "Operation POST /breweries does not provide a response schema for code 201"     },     {       "error": "missing-response-schema",       "message": "Operation PUT /breweries/{breweryId} does not provide a response schema for code 202"     },     {       "error": "missing-response-schema",       "message": "Operation DELETE /breweries/{breweryId} does not provide a response schema for code 204"     },     {       "error": "missing-response-schema",       "message": "Operation POST /breweries/{breweryId}/beers does not provide a response schema for code 201"     }   ],   "name": "Beer API 2.0",   "configuredProperties": {     "specification": "{\"swagger\":\"2.0\",\"info\":{\"title\":\"Beer API 2.0\",\"description\":\"An OpenAPI 2.0 version of the Beer API.\",\"license\":{\"name\":\"Apache 2.0\",\"url\":\"https://www.apache.org/licenses/LICENSE-2.0\"},\"version\":\"1.0.0\"},\"paths\":{\"/beers\":{\"get\":{\"summary\":\"Get All Beers\",\"description\":\"Returns all of the beers.\",\"operationId\":\"getAllBeers\",\"parameters\":[{\"name\":\"style\",\"in\":\"query\",\"description\":\"Optional: filter by the style of the beer (e.g. lager).\",\"type\":\"string\"}],\"responses\":{\"200\":{\"description\":\"All the beers!\",\"schema\":{\"type\":\"array\",\"items\":{\"$ref\":\"#/definitions/Beer\"}}}}},\"post\":{\"summary\":\"Add a Beer\",\"description\":\"Adds a beer to the data set.\",\"operationId\":\"addBeer\",\"parameters\":[{\"name\":\"body\",\"in\":\"body\",\"description\":\"The beer to add.\",\"schema\":{\"$ref\":\"#/definitions/Beer\"}}],\"responses\":{\"201\":{\"description\":\"Beer was added.\"}}}},\"/beers/{beerId}\":{\"get\":{\"summary\":\"Get a Single Beer\",\"description\":\"Returns full information about a single beer.\",\"operationId\":\"getBeer\",\"responses\":{\"200\":{\"description\":\"A single beer.\",\"schema\":{\"$ref\":\"#/definitions/Beer\"}}}},\"put\":{\"summary\":\"Update a Beer\",\"description\":\"Updates information about a single beer.\",\"operationId\":\"updateBeer\",\"parameters\":[{\"name\":\"body\",\"in\":\"body\",\"description\":\"The beer to update.\",\"schema\":{\"$ref\":\"#/definitions/Beer\"}}],\"responses\":{\"202\":{\"description\":\"The beer was updated.\"}}},\"delete\":{\"summary\":\"Delete a Beer\",\"description\":\"Removes a single beer from the data set.\",\"operationId\":\"deleteBeer\",\"responses\":{\"204\":{\"description\":\"The beer was deleted.\"}}},\"parameters\":[{\"name\":\"beerId\",\"in\":\"path\",\"description\":\"The unique ID of a beer.\",\"required\":true,\"type\":\"integer\",\"format\":\"int32\"}]},\"/breweries\":{\"get\":{\"summary\":\"Get All Breweries\",\"description\":\"Returns a list of all breweries.\",\"operationId\":\"getAllBreweries\",\"parameters\":[{\"name\":\"city\",\"in\":\"query\",\"description\":\"Optional: filter by city.\",\"type\":\"string\"},{\"name\":\"state\",\"in\":\"query\",\"description\":\"Optional: filter by state.\",\"type\":\"string\"}],\"responses\":{\"200\":{\"description\":\"Returns all breweries.\",\"schema\":{\"type\":\"array\",\"items\":{\"$ref\":\"#/definitions/Brewery\"}}}}},\"post\":{\"summary\":\"Add a Brewery\",\"description\":\"Adds a single brewery to the data set.\",\"operationId\":\"addBrewery\",\"parameters\":[{\"name\":\"body\",\"in\":\"body\",\"description\":\"New brewery info.\",\"schema\":{\"$ref\":\"#/definitions/Brewery\"}}],\"responses\":{\"201\":{\"description\":\"Brewery successfully added.\"}}}},\"/breweries/{breweryId}\":{\"get\":{\"summary\":\"Get Brewery Info\",\"description\":\"Returns full information about a single brewery.\",\"operationId\":\"getBrewery\",\"responses\":{\"200\":{\"description\":\"Information about a brewery.\",\"schema\":{\"$ref\":\"#/definitions/Brewery\"}}}},\"put\":{\"summary\":\"Update a Brewery\",\"description\":\"Updates information about a single brewery.\",\"operationId\":\"updateBrewery\",\"parameters\":[{\"name\":\"body\",\"in\":\"body\",\"description\":\"Updated brewery information.\",\"schema\":{\"$ref\":\"#/definitions/Brewery\"}}],\"responses\":{\"202\":{\"description\":\"Brewery was updated.\"}}},\"delete\":{\"summary\":\"Delete a Brewery\",\"description\":\"Removes a single brewery from the data set.\",\"operationId\":\"deleteBrewery\",\"responses\":{\"204\":{\"description\":\"Brewery was deleted.\"}}},\"parameters\":[{\"name\":\"breweryId\",\"in\":\"path\",\"description\":\"Unique ID of a brewery.\",\"required\":true,\"type\":\"integer\",\"format\":\"int32\"}]},\"/breweries/{breweryId}/beers\":{\"get\":{\"summary\":\"Get Beers From the Brewery\",\"description\":\"Returns all of the beers made by the brewery.\",\"operationId\":\"listBreweryBeers\",\"responses\":{\"200\":{\"description\":\"The list of beers for the brewery.\",\"schema\":{\"type\":\"array\",\"items\":{\"$ref\":\"#/definitions/Beer\"}}}}},\"post\":{\"summary\":\"Add a Beer to the Brewery\",\"description\":\"Adds a single beer to the data set for this brewery.\",\"operationId\":\"addBeerToBrewery\",\"parameters\":[{\"name\":\"body\",\"in\":\"body\",\"description\":\"Information about a new beer.\",\"schema\":{\"$ref\":\"#/definitions/Beer\"}}],\"responses\":{\"201\":{\"description\":\"Beer was added.\"}}},\"parameters\":[{\"name\":\"breweryId\",\"in\":\"path\",\"description\":\"The unique ID of a brewery.\",\"required\":true,\"type\":\"integer\",\"format\":\"int32\"}]}},\"definitions\":{\"Beer\":{\"title\":\"Root Type for Beer\",\"description\":\"The root of the Beer type's schema.\",\"required\":[],\"type\":\"object\",\"properties\":{\"id\":{\"format\":\"int32\",\"type\":\"integer\"},\"name\":{\"type\":\"string\"},\"style\":{\"type\":\"string\"},\"abv\":{\"format\":\"double\",\"type\":\"number\"},\"ibu\":{\"format\":\"double\",\"type\":\"number\"},\"ounces\":{\"format\":\"double\",\"type\":\"number\"},\"breweryId\":{\"format\":\"int32\",\"type\":\"integer\"}}},\"Brewery\":{\"title\":\"Root Type for Brewery\",\"description\":\"The root of the Brewery type's schema.\",\"type\":\"object\",\"properties\":{\"id\":{\"format\":\"int32\",\"type\":\"integer\"},\"name\":{\"type\":\"string\"},\"city\":{\"type\":\"string\"},\"state\":{\"type\":\"string\"}}}},\"tags\":[{\"name\":\"beer\",\"description\":\"\"},{\"name\":\"hops\",\"description\":\"\"},{\"name\":\"brewing\",\"description\":\"\"}]}"   } } ```</body>
		<created>2018-10-02 14:34:53</created>
		<closed>2018-10-10 11:58:40</closed>
	</bug>
	<bug>
		<id>3717</id>
		<title>Syndesis Server running at 75% CPU</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description The syndesis-server pod takes a lot of CPU! If left untamed it has a tendency to swipe 3 CPUs. If limited by Openshift to 1 CPU then it runs smoothly with 75% (while its couple of subordinate threads reside on 50%+). See htop screenshot.  By profiling the server, it is possible to get an idea of what is taking up the CPU time. The IntegrationUpdateHandler validates all integrations (including deleted integrations!) by calling validators on each integrations fetched from the DataManager. The trouble is the NoDuplicateValidator then fetches all the integrations from the DataManager in order to test for duplicates:  IntegrationUpdateHandler: ``` List&lt;Integration&gt; integrations = DataManager.fetchAll(Integration.class ...) for (Integration integration : integrations) {   ...   messages.addAll(computeValidatorMessages(supplier, integration));   ... } ```  NoDuplicateIntegrationValidator: ``` ... final Set&lt;String&gt; names = dataManager.fetchAll(Integration.class).getItems().stream() ... ```  Fetching integrations from the DataManager is expensive and slow in this case since there is no caching of the integrations (or at least caching is not used since a DataAccessObject is available for the Integration [class](https://github.com/phantomjinx/syndesis/blob/master/app/server/dao/src/main/java/io/syndesis/server/dao/manager/DataManager.java#L216)).</body>
		<created>2018-10-02 13:32:38</created>
		<closed>2018-10-15 15:29:27</closed>
	</bug>
	<bug>
		<id>3714</id>
		<title>TypeError: Cannot read property 'low' of undefined</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When trying to edit specification of API provider based integration an error is issued on the console: ``` exception-handler.service.ts:19 TypeError: Cannot read property 'low' of undefined     at ValidationProblemComponent.push../node_modules/apicurio-design-studio/esm5/apicurio-design-studio.js.ValidationProblemComponent.icon (apicurio-design-studio.js:9260)     at Object.eval [as updateRenderer] (ValidationProblemComponent.html:2)     at Object.debugUpdateRenderer [as updateRenderer] (core.js:10782)     at checkAndUpdateView (core.js:10158)     at callViewAction (core.js:10394)     at execEmbeddedViewsAction (core.js:10357)     at checkAndUpdateView (core.js:10154)     at callViewAction (core.js:10394)     at execComponentViewsAction (core.js:10336)     at checkAndUpdateView (core.js:10159) ```  The error count increases if I hover over the `Issues`.  I think it might be related, I can't seem to add a response via `Add a response` link in the Responses section of an operation.  Perhaps we're missing something with the new Apicurio version, perhaps in setup or in dependency.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![peek 2018-10-02 12-45](https://user-images.githubusercontent.com/1306050/46344341-27573280-c641-11e8-9e08-dea12941ebc8.gif)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create new API provider based integration 2. Select `Create from scratch` 3. Add path (I chose `/`) 4. Create Operation (I chose for `GET`) </body>
		<created>2018-10-02 10:49:04</created>
		<closed>2018-10-02 12:57:37</closed>
	</bug>
	<bug>
		<id>3696</id>
		<title>Copying to clipboard of exposed integration isn't on Firefox</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Copy to clipboard of the URL in the integration details page is working in Chrome but not in Firefox.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Should copy the URL to clipboard in Firefox.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![peek 2018-09-28 12-59](https://user-images.githubusercontent.com/1306050/46204792-b7823880-c31e-11e8-9984-7517aabfd8d6.gif)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create an integration that will be exposed (WebHook or API provider) 2. Publish 3. Try to copy the URL from integration details page </body>
		<created>2018-09-28 11:03:24</created>
		<closed>2019-06-11 09:08:47</closed>
	</bug>
	<bug>
		<id>3694</id>
		<title>Adding flow step to API provider based integration yields error</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; I can't seem to edit a flow to add a step to it. The browser console emits an error:  ``` main.bd08e7b5ad2ce0b417ba.js:1 TypeError: Cannot read property 'action' of undefined     at n.ngOnChanges (11.bb2047dff352bcbffb47.js:1)     at main.bd08e7b5ad2ce0b417ba.js:1     at main.bd08e7b5ad2ce0b417ba.js:1     at $a (main.bd08e7b5ad2ce0b417ba.js:1)     at Sl (main.bd08e7b5ad2ce0b417ba.js:1)     at Object.updateDirectives (11.bb2047dff352bcbffb47.js:1)     at Object.updateDirectives (main.bd08e7b5ad2ce0b417ba.js:1)     at Xa (main.bd08e7b5ad2ce0b417ba.js:1)     at il (main.bd08e7b5ad2ce0b417ba.js:1)     at rl (main.bd08e7b5ad2ce0b417ba.js:1) ```  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; I should be able to edit and add steps as needed to the flow.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![peek 2018-09-28 12-34](https://user-images.githubusercontent.com/1306050/46203905-8a805680-c31b-11e8-83a2-47418f416a90.gif)   ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt; I only see `GET` requests to `/api/v1/integrations/i-LNUix7uR6BhTm3sXS83z` and `/api/v1/monitoring/integrations/i-LNUix7uR6BhTm3sXS83z`, probably unrelated.  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create API provider based integration 2. Try to edit one of the flows to add a step  [console-log.txt](https://github.com/syndesisio/syndesis/files/2427874/console-log.txt) </body>
		<created>2018-09-28 10:48:26</created>
		<closed>2018-10-08 11:43:16</closed>
	</bug>
	<bug>
		<id>3688</id>
		<title>Create Connection from API Client Connector Fails Silently</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  * Create an API Client Connector based on the attached Swagger file. Complete the Wizard successfully * Create a new Integration * Create a Connection based on the API Client Connector. * Complete Wizard, (providing host details) and click on 'Create'  Expected Result: * Connection created successfully  Actual Result * Create button does nothing - no obvious error generated.  [greetings-api.json.txt](https://github.com/syndesisio/syndesis/files/2425967/greetings-api.json.txt)   </body>
		<created>2018-09-27 21:25:12</created>
		<closed>2018-10-10 08:18:31</closed>
	</bug>
	<bug>
		<id>3687</id>
		<title>parameter SAR_PROJECT is required and must be specified</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I get the following exception when I run the command given in the quickstart doc.  `error: error processing template "myproject/syndesis": Template.template.openshift.io "syndesis" is invalid: template.parameters[4]: Required value: template.parameters[4]: parameter SAR_PROJECT is required and must be specified`  "oc new-app syndesis \     -p ROUTE_HOSTNAME=syndesis.$(minishift ip).nip.io \     -p OPENSHIFT_MASTER=$(oc whoami --show-server) \     -p OPENSHIFT_PROJECT=$(oc project -q) \     -p OPENSHIFT_OAUTH_CLIENT_SECRET=$(oc sa get-token syndesis-oauth-client)"  Doc: https://syndesis.io/quickstart/#template-selection</body>
		<created>2018-09-27 14:45:07</created>
		<closed>2018-10-19 08:37:34</closed>
	</bug>
	<bug>
		<id>3672</id>
		<title>OAuth settings `Register` out of sync with OAuth</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; I've set the OAuth settings for GMail and saved them. The row with the GMail still offered `Register` (the button). I can still see after I reload the browser.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; If OAuth settings are given and saved `Register` should not be shown and `Edit` and `Remove` buttons should be given instead.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![peek 2018-09-26 14-10](https://user-images.githubusercontent.com/1306050/46079323-23399980-c197-11e8-85eb-d1981cf4df2c.gif)   ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  &lt;details&gt; &lt;summary&gt;Request - response&lt;/summary&gt; &lt;pre&gt; GET /api/v1/setup/oauth-apps?per_page=50 HTTP/1.1  HTTP/1.1 200 OK Cache-Control: no-cache, no-store, max-age=0, must-revalidate, proxy-revalidate, s-maxage=0 Content-Type: application/json Date: Wed, 26 Sep 2018 12:19:44 GMT Gap-Auth: zregvart@cluster.local Gap-Upstream-Address: syndesis-server Strict-Transport-Security: max-age=31536000 ; includeSubDomains Syndesis-Xsrf-Token: awesome X-Application-Context: application X-Content-Type-Options: nosniff X-Frame-Options: DENY X-Xss-Protection: 1; mode=block Transfer-Encoding: chunked  {"items":[{"id":"calendar","name":"Calendar","properties":{"clientId":{"deprecated":false,"labelHint":"The client ID that Google provides when you register a client application.","displayName":"Client ID","group":"common","javaType":"java.lang.String","kind":"parameter","required":true,"secret":false,"type":"string","raw":true,"tags":["oauth-client-id"],"order":1},"clientSecret":{"deprecated":false,"labelHint":"The client secret that Google provides when you register a client application.","displayName":"Client Secret","group":"common","javaType":"java.lang.String","kind":"parameter","required":true,"secret":true,"type":"string","raw":true,"tags":["oauth-client-secret"],"order":2},"authorizationUrl":{"componentProperty":true,"deprecated":false,"description":"The access token","displayName":"Authorization URL","group":"security","javaType":"java.lang.String","kind":"property","label":"security","required":false,"secret":true,"type":"hidden","tags":["oauth-authorization-url"]},"tokenUrl":{"componentProperty":true,"deprecated":false,"description":"The access token","displayName":"Token URL","group":"security","javaType":"java.lang.String","kind":"property","label":"security","required":false,"secret":true,"type":"hidden","tags":["oauth-access-token-url"]},"googleScopes":{"deprecated":false,"labelHint":"UserId","displayName":"Scopes","group":"common","javaType":"java.lang.String","kind":"parameter","required":true,"secret":false,"type":"hidden","raw":true,"tags":["oauth-scope"]}},"configuredProperties":{"authorizationUrl":"https://accounts.google.com/o/oauth2/v2/auth","tokenUrl":"https://accounts.google.com/o/oauth2/token","googleScopes":"https://www.googleapis.com/auth/calendar"},"isDerived":false},{"icon":"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAxMjguMzAyIDEyNy45NzYiIGhlaWdodD0iNDgzLjY4NyIgd2lkdGg9IjQ4NC45MiI+PGcgZmlsbD0iI2ZjYjkxMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMTM0LjAxNSAtNjMuOTAxKSI+PHBhdGggZD0iTS0xMzQuMDE1IDYzLjkwMXYxMjcuOTc2SC01LjcxM1Y2My45MDF6bTE0LjQwMSAxNC4zNjVoOTkuNXY5OS4yNDdoLTk5LjV6Ii8+PHBhdGggZD0iTS03Mi43MzQgOTQuMjQyYTM0LjIxMyAzNC4yMTMgMCAwIDAtMzQuMjEzIDM0LjIxMyAzNC4yMTMgMzQuMjEzIDAgMCAwIDM0LjIxMyAzNC4yMTJBMzQuMjEzIDM0LjIxMyAwIDAgMC00OC4zMDcgMTUyLjRsLTEwLjU3Mi0xMC41NzJhMTkuMjc3IDE5LjI3NyAwIDAgMS0xMy44NTUgNS45MDQgMTkuMjc3IDE5LjI3NyAwIDAgMS0xOS4yNzctMTkuMjc2IDE5LjI3NyAxOS4yNzcgMCAwIDEgMTkuMjc3LTE5LjI3NyAxOS4yNzcgMTkuMjc3IDAgMCAxIDEzLjc1MiA1Ljc3NWwxMC41NDUtMTAuNTQ2YTM0LjIxMyAzNC4yMTMgMCAwIDAtMjQuMjk3LTEwLjE2NXoiLz48Y2lyY2xlIGN4PSItNDQuNDAyIiBjeT0iMTI4LjU1IiByPSI4LjgzIi8+PC9nPjwvc3ZnPg==","id":"concur","name":"SAP Concur","properties":{"clientId":{"componentProperty":true,"deprecated":false,"description":"Client ID received from Concur upon registration.","displayName":"Client ID","group":"producer","javaType":"java.lang.String","kind":"property","label":"producer","required":true,"secret":false,"type":"string","tags":["oauth-client-id"],"order":2},"clientSecret":{"componentProperty":true,"deprecated":false,"description":"Client Secret received from Concur upon registration.","displayName":"Client Secret","group":"producer","javaType":"java.lang.String","kind":"property","label":"producer","required":true,"secret":true,"type":"string","tags":["oauth-client-secret"],"order":3},"authorizationEndpoint":{"componentProperty":true,"defaultValue":"https://us.api.concursolutions.com/oauth2/v0/authorize","deprecated":false,"description":"Authorization URL consists of base URL and ends with &lt;code&gt;/authorize&lt;/code&gt;. Base URL differs based on geolocation and should be received from Concur upon registration.","displayName":"Authorization URL","group":"producer","javaType":"java.lang.String","kind":"property","label":"producer","required":true,"secret":false,"type":"string","tags":["oauth-authorization-url"],"order":6},"tokenEndpoint":{"componentProperty":true,"defaultValue":"https://us.api.concursolutions.com/oauth2/v0/token","deprecated":false,"description":"Token URL consists of base URL and ends with &lt;code&gt;/token&lt;/code&gt;. Base URL differs based on geolocation and should be received from Concur upon registration.","displayName":"Token URL","group":"producer","javaType":"java.lang.String","kind":"property","label":"producer","required":true,"secret":false,"type":"string","tags":["oauth-access-token-url"],"order":7},"oauthScopes":{"componentProperty":true,"defaultValue":"ATTEND CONFIG CONREQ ERECPT EVS EXPRPT CCARD BANK EXTRCT FISVC FOP GHOST IMAGE INSGHT INVPMT INVPO INVTV INVVEN ITINER JOBLOG LIST MTNG NOTIF PAYBAT RCTIMG SUPSVC TAXINV TRVPRF PASSV EMERG TSAI TMCSP MEDIC UNUTX TRVPTS TRVREQ TWS USER COMPANY","deprecated":false,"description":"Scopes required as a list of space-delimited, case-sensitive strings. Scopes limit access and do not grant any additional permission beyond that which the user already has. Consult the Concur API documentation on the available Scopes.","displayName":"Scopes","group":"producer","javaType":"java.lang.String","kind":"property","label":"producer","required":true,"secret":false,"type":"string","tags":["oauth-scope"],"order":8},"host":{"componentProperty":true,"defaultValue":"https://us.api.concursolutions.com","deprecated":false,"description":"API Endpoint used to access Concur instance in the form of https://hostname:port. This value depends on the geolocation received from Concur upon registration.","displayName":"API Endpoint","group":"producer","javaType":"java.lang.String","kind":"property","label":"producer","required":true,"secret":false,"type":"string","tags":["host"],"order":10}},"configuredProperties":{"authorizationEndpoint":"https://us.api.concursolutions.com/oauth2/v0/authorize","tokenEndpoint":"https://us.api.concursolutions.com/oauth2/v0/token","oauthScopes":"ATTEND CONFIG CONREQ ERECPT EVS EXPRPT CCARD BANK EXTRCT FISVC FOP GHOST IMAGE INSGHT INVPMT INVPO INVTV INVVEN ITINER JOBLOG LIST MTNG NOTIF PAYBAT RCTIMG SUPSVC TAXINV TRVPRF PASSV EMERG TSAI TMCSP MEDIC UNUTX TRVPTS TRVREQ TWS USER COMPANY","host":"https://us.api.concursolutions.com"},"isDerived":false},{"icon":"data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4NCjwhLS0gR2VuZXJhdG9yOiBB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%0D%0ATDI4MC45LDAuNkwyODAuOSwwLjZ6Ii8+DQo8L2c+DQo8L3N2Zz4NCg==","id":"gmail","name":"Gmail","properties":{"clientId":{"deprecated":false,"labelHint":"The client ID that Google provides when you register a client application.","displayName":"Client ID","group":"common","javaType":"java.lang.String","kind":"parameter","required":true,"secret":false,"type":"string","raw":true,"tags":["oauth-client-id"],"order":1},"clientSecret":{"deprecated":false,"labelHint":"The client secret that Google provides when you register a client application.","displayName":"Client Secret","group":"common","javaType":"java.lang.String","kind":"parameter","required":true,"secret":true,"type":"string","raw":true,"tags":["oauth-client-secret"],"order":2},"authorizationUrl":{"componentProperty":true,"deprecated":false,"description":"The access token","displayName":"Authorization URL","group":"security","javaType":"java.lang.String","kind":"property","label":"security","required":false,"secret":true,"type":"hidden","tags":["oauth-authorization-url"]},"tokenUrl":{"componentProperty":true,"deprecated":false,"description":"The access token","displayName":"Token URL","group":"security","javaType":"java.lang.String","kind":"property","label":"security","required":false,"secret":true,"type":"hidden","tags":["oauth-access-token-url"]},"googleScopes":{"deprecated":false,"labelHint":"UserId","displayName":"Scopes","group":"common","javaType":"java.lang.String","kind":"parameter","required":true,"secret":false,"type":"hidden","raw":true,"tags":["oauth-scope"]}},"configuredProperties":{"clientId":"x","clientSecret":"y"},"isDerived":true},{"icon":"db:i-LJVFZAG9vPlUJgDdJYnz","id":"i-LJVFZ9-9vPlUJgDdJYmz","name":"Swagger Petstore Aug","properties":{"clientId":{"componentProperty":true,"deprecated":false,"description":"OAuth Client ID, sometimes called Consumer Key","displayName":"OAuth Client ID","group":"producer","javaType":"java.lang.String","kind":"property","label":"producer","required":false,"secret":false,"type":"string","tags":["oauth-client-id"],"order":2},"clientSecret":{"componentProperty":true,"deprecated":false,"description":"OAuth Client Secret, sometimes called Consumer Secret","displayName":"OAuth Client Secret","group":"producer","javaType":"java.lang.String","kind":"property","label":"producer","required":false,"secret":true,"type":"string","tags":["oauth-client-secret"],"order":3},"authorizationEndpoint":{"componentProperty":true,"defaultValue":"https://petstore.swagger.io/oauth/dialog","deprecated":false,"description":"URL for the start of the OAuth flow","displayName":"OAuth Authorization Endpoint URL","group":"producer","javaType":"java.lang.String","kind":"property","label":"producer","required":true,"secret":false,"type":"string","tags":["oauth-authorization-url"],"order":6},"tokenEndpoint":{"componentProperty":true,"deprecated":false,"description":"URL to fetch the OAuth Access token","displayName":"OAuth Token Endpoint URL","group":"producer","javaType":"java.lang.String","kind":"property","label":"producer","required":false,"secret":false,"type":"string","tags":["oauth-access-token-url"],"order":7},"oauthScopes":{"componentProperty":true,"defaultValue":"write:pets read:pets","deprecated":false,"description":"URL to fetch the OAuth Access token","displayName":"OAuth Scopes","group":"producer","javaType":"java.lang.String","kind":"property","label":"producer","required":false,"secret":false,"type":"string","tags":["oauth-scope"],"order":8}},"configuredProperties":{"authorizationEndpoint":"https://petstore.swagger.io/oauth/dialog","tokenEndpoint":"https://petstore.swagger.io/oauth/dialog","oauthScopes":"write:pets read:pets"},"isDerived":false},{"icon":"data:image/svg+xml;base64,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","id":"salesforce","name":"Salesforce","properties":{"clientId":{"componentProperty":true,"deprecated":false,"description":"OAuth Consumer Key of the connected app configured in the Salesforce instance setup. Typically a connected app needs to be configured but one can be provided by installing a package.","displayName":"Client ID","group":"security","javaType":"java.lang.String","kind":"property","label":"common,security","required":true,"secret":false,"type":"string","tags":["oauth-client-id"],"order":3},"clientSecret":{"componentProperty":true,"deprecated":false,"description":"OAuth Consumer Secret of the connected app configured in the Salesforce instance setup.","displayName":"Client Secret","group":"security","javaType":"java.lang.String","kind":"property","label":"common,security","required":true,"secret":true,"type":"string","tags":["oauth-client-secret"],"order":4}},"configuredProperties":{"clientId":"3MVG9HxRZv05HarQgbVnUCmM2tkjkzhnnBDnqmjDcF4_etycsPYWPiqTT_l6bzfsjGPnWjLfNonnhiybUqv7E","clientSecret":"3108740475354201001"},"isDerived":true},{"icon":"data:image/svg+xml;base64,PHN2ZyBpZD0iTGF5ZXJfMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2aWV3Qm94PSIwIDAgMzAwIDI0My44Ij48c3R5bGU+PC9zdHlsZT48cGF0aCBkPSJNOTQuMyAyNDMuOGMxMTMuMiAwIDE3NS4xLTkzLjggMTc1LjEtMTc1LjEgMC0yLjctLjEtNS4zLS4yLTggMTItOC43IDIyLjUtMTkuNSAzMC43LTMxLjktMTEgNC45LTIyLjkgOC4yLTM1LjMgOS43IDEyLjctNy42IDIyLjUtMTkuNyAyNy4xLTM0LTExLjkgNy4xLTI1LjEgMTIuMi0zOS4xIDE0LjlDMjQxLjQgNy41IDIyNS40IDAgMjA3LjcgMGMtMzQgMC02MS42IDI3LjYtNjEuNiA2MS41IDAgNC44LjUgOS41IDEuNiAxNC01MS4xLTIuNS05Ni41LTI3LTEyNi44LTY0LjItNS4zIDkuMS04LjMgMTkuNy04LjMgMzAuOSAwIDIxLjQgMTAuOSA0MC4yIDI3LjQgNTEuMi0xMC4xLS4zLTE5LjYtMy4xLTI3LjktNy43di44YzAgMjkuOCAyMS4yIDU0LjcgNDkuNCA2MC4zLTUuMiAxLjQtMTAuNiAyLjItMTYuMiAyLjItNCAwLTcuOC0uNC0xMS42LTEuMSA3LjggMjQuNSAzMC42IDQyLjIgNTcuNSA0Mi43QzcwLjEgMjA3LjIgNDMuNSAyMTcgMTQuNyAyMTdjLTUgMC05LjktLjMtMTQuNy0uOSAyNy4yIDE3LjUgNTkuNiAyNy43IDk0LjMgMjcuNyIgZmlsbD0iIzFkYTFmMiIvPjwvc3ZnPg==","id":"twitter","name":"Twitter","properties":{"consumerKey":{"componentProperty":true,"deprecated":false,"labelHint":"The consumer key","displayName":"Consumer Key","group":"security","javaType":"java.lang.String","kind":"property","label":"security","required":true,"secret":true,"type":"string","tags":["oauth-client-id"]},"consumerSecret":{"componentProperty":true,"deprecated":false,"labelHint":"The consumer secret","displayName":"Consumer Secret","group":"security","javaType":"java.lang.String","kind":"property","label":"security","required":true,"secret":true,"type":"string","tags":["oauth-client-secret"]}},"isDerived":false}],"totalCount":6} &lt;/pre&gt; &lt;/details&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-09-26 12:25:03</created>
		<closed>2018-09-26 17:46:14</closed>
	</bug>
	<bug>
		<id>3646</id>
		<title>Can create a flow without ID through REST API</title>
		<body>This is a bug.  User (through REST API) can create an Integration with Flow which doesn't have id specified. The Integration is created, and works well. But when trying to edit the Integration through web interface, the flow is not visible after clicking 'Edit integration' and all the screen seems broken (no buttons or links).  Either the Flow id needs to be enforced via REST API, or web interface need to overcome this deficiency.  </body>
		<created>2018-09-21 14:25:57</created>
		<closed>2018-10-11 15:49:30</closed>
	</bug>
	<bug>
		<id>3637</id>
		<title>API provider integration details page shows tons of notifications for an imported integration </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; This is still a WIP feature but just wanted to open this issue to track the behavior of inline notifications.   As shown in the screenshot, on an API provider integration details page, we're showing tons of inline notifications. Users have to scroll ~ 3 times to get to the main content of the page.   @riccardo-forina mentioned that this behavior only happens to an imported integration. If create an API provider integration from scratch, then we don't see this. And it seems like this only happens to integration that was published at some point.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Short term: maybe we can do something from the UX/UI side to group the notifications or have some kind of mechnism to magically show them upon user's request.   Long term: need a more sustainable solution to show notifications. Maybe notification drawer? https://www.patternfly.org/pattern-library/communication/notification-drawer/   ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  &lt;img width="1440" alt="screen shot 2018-09-19 at 2 10 49 pm" src="https://user-images.githubusercontent.com/24943812/45822948-8ff5f500-bcba-11e8-8067-430c80185529.png"&gt;   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4.  cc: @lburgazzoli @nicolaferraro @gashcrumb @syndesisio/uxd </body>
		<created>2018-09-20 14:30:42</created>
		<closed>2018-10-17 15:40:57</closed>
	</bug>
	<bug>
		<id>3636</id>
		<title>Use base path from the OpenAPI specification</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  I think it's a bug that we have fixed base path of `/api` for API provider generated integrations. The OpenAPI specification mandates the base path, and we should abide by that.  The url mapping here:  https://github.com/syndesisio/syndesis/blob/faeaa61ef038f62cbcf64e23d422c8cc864d564e/app/connector/api-provider/src/main/java/io/syndesis/connector/apiprovider/ApiProviderServletAutoConfiguration.java#L34  Should be parameterized from the base path of the specification. </body>
		<created>2018-09-20 12:58:32</created>
		<closed>2018-10-18 13:30:40</closed>
	</bug>
	<bug>
		<id>3632</id>
		<title>Integration - Add a Step: loading wheel stuck turning</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description 1. go to Create Integration 2. select Timer and Log as start and finish connections 3. Add a Step between these 2 connections (Log and Advanced filter are available)  It doesn't matter what step you choose. The loading wheel is turning and turning...infinitely.   The problem may be when there are no attributes that could be filtered, logged or mapped. There should be accessible only those integration steps that make sense.  I suppose this is not limited only to these 2 connections.  ![loadingwheelstuck](https://user-images.githubusercontent.com/8707251/45807682-532efb80-bcc4-11e8-9c12-9662fd2edaa7.png) </body>
		<created>2018-09-20 09:06:25</created>
		<closed>2018-09-20 13:52:44</closed>
	</bug>
	<bug>
		<id>3617</id>
		<title>Logging is broken in the UI</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  The UI app uses [`typescript-logging`](https://github.com/mreuvers/typescript-logging/) to log on the console, but nothing actually gets logged to the console.</body>
		<created>2018-09-18 16:06:20</created>
		<closed>2018-09-18 16:57:45</closed>
	</bug>
	<bug>
		<id>3613</id>
		<title>Wrong number of filtered items in some sections</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Sections with a filterable list don't show the right result number if filtering is implemented using the `objectPropertyFilter` pipe.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  The number of results should be right.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![filter-bug](https://user-images.githubusercontent.com/966316/45693865-55774580-bb5e-11e8-9f18-c1272d9fbb88.gif)  In this gif the bug is reproduced in the Settings page and in the Operations page of an integration of type API Provider. The Integrations list page is unaffected because filtering is implemented without the pipe.  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Go to any section that uses the `objectPropertyFilter` pipe. Eg. the "Settings" page. 2. Search something that's present in the list. Eg. "mail". </body>
		<created>2018-09-18 14:20:42</created>
		<closed>2018-09-19 14:05:21</closed>
	</bug>
	<bug>
		<id>3587</id>
		<title>[UI] syndesis-loading children is evaluated regardless of its loading state</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  Children elements of the `syndesis-loading` component are parsed regardless of the loading state of the component.  A simple example to try it out is the following:  ``` // example.component.ts export class Example {    alert = alert; }  // examle.component.html &lt;syndesis-loading [loading]="true"&gt;   {{ alert("sorry, still evaluated!") }} &lt;/syndesis-loading&gt; ```   ## Workaround  The following code does what you'd expect it to do.  ``` // example.component.ts export class Example {    alert = alert; }  // examle.component.html &lt;ng-container *ngIf="true; else content"&gt;   &lt;syndesis-loading loading="true"&gt;&lt;/syndesis-loading&gt; &lt;/ng-container&gt;  &lt;ng-template #content&gt;   {{ alert("this will not be called!") }} &lt;/ng-template&gt; ```</body>
		<created>2018-09-13 12:22:52</created>
		<closed>2018-09-14 16:14:08</closed>
	</bug>
	<bug>
		<id>3582</id>
		<title>Edit Slack connection - replacing token by webhook doesn't work</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description  I created a Slack connection with TOKEN. If I want to remove TOKEN and set WEBHOOK URL instead (on Connection Details page), both fields stay filled after clicking **Save** button.  I have no idea if this can cause any problem but it is confusing. At least.</body>
		<created>2018-09-12 14:55:37</created>
		<closed>2018-09-14 13:54:22</closed>
	</bug>
	<bug>
		<id>3578</id>
		<title>Api connector swagger supported format</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description I was not able to find if and why did we stop supporting .yaml format when creating api connectors. It worked on 7.1 but now on master there is this note that we only support .json:  ![screenshot_20180912_103836](https://user-images.githubusercontent.com/14313995/45412849-091c9900-b678-11e8-9248-65db1fdf588f.png)  If we wanted to do this change, can you please point me to the correct issue with discussion/decision regarding this topic? </body>
		<created>2018-09-12 08:45:13</created>
		<closed>2018-10-18 07:53:57</closed>
	</bug>
	<bug>
		<id>3564</id>
		<title>Query parameters are not set in the API-Connector</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [*] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  Found by @mcada   ## Description The DELETE action for listitems has a path of /common/listitems/{id},   https://developer.concur.com/api-explorer/v3-0/ListItems.html#/  however it also has a required query parameter called listId. The id and the listId are both available as parameters. The id is set in the RestProducer by substituting the {id} with the value of the id, however the listId query parameters is never set on the request as listId is never identified as a queryParameter.  This makes the request to concur fail. I'mn still trying to figure out what code is supposed to identify it as a queryParameter so that it can be set. Maybe it's a bug in camel-core altogether.  So to be clear; this happens with all type of HTTP requests GET/UPDATE/DELETE with query parameters like  /common/listitems/{id}?listId={listId} </body>
		<created>2018-09-06 18:17:27</created>
		<closed>2018-09-14 08:40:54</closed>
	</bug>
	<bug>
		<id>3561</id>
		<title>Unable to edit imported integrations</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  When importing the integrations attached to https://github.com/syndesisio/syndesis/issues/3531, the integration summary properly shows the integration steps but when to integration is edited, the shown pages is the one for an empty integration.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  We should be able to edit imported integrations.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  * **Integration Summary**  ![image](https://user-images.githubusercontent.com/1868933/45149201-493bd180-b1c9-11e8-8d5c-e67635285195.png)  * **Integration Editor**  ![image](https://user-images.githubusercontent.com/1868933/45149225-58228400-b1c9-11e8-8e80-a455d72e637c.png)   ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Import  db_custom_api_db.zip 2. Edit the integration  </body>
		<created>2018-09-06 09:44:15</created>
		<closed>2018-09-07 10:02:32</closed>
	</bug>
	<bug>
		<id>3558</id>
		<title>Version in Fuse Online support page still contains "Ignite"</title>
		<body>See https://issues.jboss.org/browse/ENTESB-9453 for details</body>
		<created>2018-09-05 18:45:25</created>
		<closed>2018-09-19 14:53:46</closed>
	</bug>
	<bug>
		<id>3556</id>
		<title>Investigate bogus atlasmap meta data</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## Description Some of the atlasmap meta data in the integration mapping looks wrong ``` {   "AtlasMapping": {     "jsonType": "io.atlasmap.v2.AtlasMapping",     "dataSource": [       {         "jsonType": "io.atlasmap.json.v2.JsonDataSource",         "id": "-LLdvH9B1M9-vP0iui9i",         "uri": "atlas:json:-LLdvH9B1M9-vP0iui9i",         "dataSourceType": "SOURCE"       },       {         "jsonType": "io.atlasmap.json.v2.JsonDataSource",         "id": "DOC.2 - Data Mapper (Request).593557",         "uri": "atlas:json:undefined",         "dataSourceType": "SOURCE"       },       {         "jsonType": "io.atlasmap.json.v2.JsonDataSource",         "id": "-LLdvPE01M9-vP0iui9i",         "uri": "atlas:json:-LLdvPE01M9-vP0iui9i",         "dataSourceType": "SOURCE"       },       {         "jsonType": "io.atlasmap.json.v2.JsonDataSource",         "id": "-LLdvN3q1M9-vP0iui9i",         "uri": "atlas:json:-LLdvN3q1M9-vP0iui9i",         "dataSourceType": "TARGET",         "template": null       }     ],     "mappings": {       "mapping": [         {           "jsonType": "io.atlasmap.v2.Mapping",           "mappingType": "MAP",           "id": "mapping.15747",           "inputField": [             {               "jsonType": "io.atlasmap.json.v2.JsonField",               "name": "id",               "path": "/id",               "fieldType": "INTEGER",               "docId": "-LLdvPE01M9-vP0iui9i",               "userCreated": false             }           ],           "outputField": [             {               "jsonType": "io.atlasmap.json.v2.JsonField",               "name": "COMPANY",               "path": "/COMPANY",               "fieldType": "STRING",               "docId": "-LLdvN3q1M9-vP0iui9i",               "userCreated": false             }           ]         }       ]     },     "name": "UI.542875",     "lookupTables": {       "lookupTable": []     },     "constants": {       "constant": []     },     "properties": {       "property": []     }   } } ``` </body>
		<created>2018-09-05 15:33:45</created>
		<closed>2018-09-05 18:24:52</closed>
	</bug>
	<bug>
		<id>3551</id>
		<title>Spike: Changing config of a used connection is not picked up</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## Description &lt;!-- Describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; As it looks like that changing a connection which is used in an integration, is not picked up by integration which are using it. Every integration has a copy of a connection, so when a connection changes all integration's copies need to be updated too. the curse of a document based NoSQL Db.  Specifically when updating an imported Todo API connector connection, and changing the host name, this change gets not reflected in the integration. // @heiko-braun </body>
		<created>2018-09-05 08:58:11</created>
		<closed>2019-02-04 19:39:00</closed>
	</bug>
	<bug>
		<id>3550</id>
		<title>Salesforce on-create,on-update not triggered (part 2)</title>
		<body>We need to cleanup and properly fix https://github.com/syndesisio/syndesis/issues/3533</body>
		<created>2018-09-05 08:47:17</created>
		<closed>2018-10-08 10:46:06</closed>
	</bug>
	<bug>
		<id>3546</id>
		<title>Hide technical connector/connections</title>
		<body>Currently there are a number of connector/connections that are included in Syndesis for technical reasons, but not useful from a user perspective. The list includes: - Timer - Log - Webhook - API Provider (new)  Syndesis backend needs a connector/connection pair in order to display actions in the UI. E.g. I cannot start from a webhook action if I don't create a webhook connection first. But the webhook connection has no parameters and has no meaning for the user. That's why we create default (empty) connections for those connectors at server startup.  I'm wondering why we're keeping them visible in the syndesis UI in the connection list and we don't just hide them.  I think we can mark them as "technical-connector" and hide them from the list of available connections and connection create page. Wdyt @gaughan, @kcbabo.  We can also plan a refactoring of the syndesis model to eliminate the need for always having a underlying connection, but it will be a major one.</body>
		<created>2018-09-05 06:26:42</created>
		<closed>2018-10-17 21:18:09</closed>
	</bug>
	<bug>
		<id>3540</id>
		<title>After upgrading the integration can't be edited</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## Description &lt;!-- Describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  I'm upgrading the syndesis infrastructure with 1 integration (timer -&gt; log) running. After the upgrade, the UI shows that the integration should be republished: ![upgrade1](https://user-images.githubusercontent.com/7081216/45032798-f6d8a480-b052-11e8-90fe-3d0eaee44c4f.png)  However, when I click on "edit integration", all things from the integration are gone: ![upgrade2](https://user-images.githubusercontent.com/7081216/45032818-03f59380-b053-11e8-9838-a18a3cf86bd6.png)  When I try to stop and start the integration, the camel xml is empty:  ``` 2018-09-04 12:54:33.380 DEBUG 1 --- [           main] .i.r.IntegrationRuntimeAutoConfiguration : Routes: --  | &lt;?xml version="1.0" encoding="UTF-8" standalone="yes"?&gt;  | &lt;routes xmlns="http://camel.apache.org/schema/spring"/&gt; ```  Steps to reproduce: 1. deploy syndesis version 1 2. create integration 3. upgrade syndesis to version 2 4. edit s2i imagestream tag in syndesis-server-config to use s2i from version 2 and restart server to pick up the changes 5. try to edit the integration to pick up newer artifacts</body>
		<created>2018-09-04 13:03:56</created>
		<closed>2018-09-27 13:51:21</closed>
	</bug>
	<bug>
		<id>3539</id>
		<title>Editor choose connection page broken</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  ![image](https://user-images.githubusercontent.com/351660/45032577-29b57500-b020-11e8-861a-890c917f5d75.png)  Most likely from the addition of the API provider connection which doesn't have any actions, page just needs to be updated to handle this case anyways as part of the API provider epic.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  The page works.  ## Steps to reproduce  1. Create a new connection using the "API Provider" connection 2.  Create a new integration and you'll hit the above.   </body>
		<created>2018-09-04 12:56:43</created>
		<closed>2018-09-10 12:50:53</closed>
	</bug>
	<bug>
		<id>3536</id>
		<title>Spike: Route timeout when getting the connection</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  As happened on our eval cluster, a user create a connection which cause the connections endpoint to run into 30s timeout on the router.  Not sure what it actually was, but please see the DB dump attached. Hopefully we will be able to reproduce the issue.  [db_dump.zip](https://github.com/syndesisio/syndesis/files/2345536/db_dump.zip)</body>
		<created>2018-09-03 12:41:48</created>
		<closed>2018-12-25 15:56:07</closed>
	</bug>
	<bug>
		<id>3533</id>
		<title>Salesforce on-create,on-update not triggered in CR2 prod build</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  I have SF(on-create, lead) -&gt; LOG integration, but the on-create event on field "Lead" is not starting the integration when there is a new lead created in salesforce. This does not work on CR2 prod build, but it is working on 1.4.7 upstream tag.  There is nothing in the logs, just that the integration was started:  ``` Starting the Java application using /opt/run-java/run-java.sh ... exec java -javaagent:/opt/jolokia/jolokia.jar=config=/opt/jolokia/etc/jolokia.properties -javaagent:/opt/prometheus/jmx_prometheus_javaagent.jar=9779:/tmp/src/prometheus-config.yml -XX:+UseParallelGC -XX:GCTimeRatio=4 -XX:AdaptiveSizePolicyWeight=90 -XX:MinHeapFreeRatio=20 -XX:MaxHeapFreeRatio=40 -XX:+ExitOnOutOfMemoryError -cp . -jar /deployments/project-0.1-SNAPSHOT.jar I&gt; No access restrictor found, access to any MBean is allowed Jolokia: Agent started with URL https://172.17.0.10:8778/jolokia/       _______.                 _               _     /       |                 | |             (_)    |   (----`_   _  ____    _ | |  ____   ___  _   ___     \   \   | | | ||  _ \  / || | / _  ) /___)| | /___) .----)   |  | |_| || | | |( (_| |( (/ / |___ || ||___ | |_______/    \__  ||_| |_| \____| \____)(___/ |_|(___/ ============ (____/ =================================== :: Integration ::  :: v   2018-09-01 08:31:06.718  INFO 1 --- [           main] io.syndesis.example.Application          : Starting Application on i-sf-2-jnmkf with PID 1 (/deployments/project-0.1-SNAPSHOT.jar started by jboss in /deployments) 2018-09-01 08:31:06.732 DEBUG 1 --- [           main] io.syndesis.example.Application          : Running with Spring Boot v1.5.13.RELEASE, Spring v4.3.17.RELEASE 2018-09-01 08:31:06.733  INFO 1 --- [           main] io.syndesis.example.Application          : No active profile set, falling back to default profiles: default 2018-09-01 08:31:06.970  INFO 1 --- [           main] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@75f9eccc: startup date [Sat Sep 01 08:31:06 UTC 2018]; root of context hierarchy 2018-09-01 08:31:10.297  INFO 1 --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.apache.camel.spring.boot.CamelAutoConfiguration' of type [org.apache.camel.spring.boot.CamelAutoConfiguration$$EnhancerBySpringCGLIB$$c70462ee] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2018-09-01 08:31:11.287  INFO 1 --- [           main] org.xnio                                 : XNIO version 3.3.8.Final 2018-09-01 08:31:11.323  INFO 1 --- [           main] org.xnio.nio                             : XNIO NIO Implementation Version 3.3.8.Final 2018-09-01 08:31:11.398  WARN 1 --- [           main] io.undertow.websockets.jsr               : UT026009: XNIO worker was not set on WebSocketDeploymentInfo, the default worker will be used 2018-09-01 08:31:11.399  WARN 1 --- [           main] io.undertow.websockets.jsr               : UT026010: Buffer pool was not set on WebSocketDeploymentInfo, the default pool will be used 2018-09-01 08:31:11.444  INFO 1 --- [           main] io.undertow.servlet                      : Initializing Spring embedded WebApplicationContext 2018-09-01 08:31:11.445  INFO 1 --- [           main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 4483 ms 2018-09-01 08:31:11.777  INFO 1 --- [           main] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/] 2018-09-01 08:31:11.784  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'metricsFilter' to: [/*] 2018-09-01 08:31:11.786  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*] 2018-09-01 08:31:11.787  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*] 2018-09-01 08:31:11.787  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*] 2018-09-01 08:31:11.787  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*] 2018-09-01 08:31:11.787  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'webRequestLoggingFilter' to: [/*] 2018-09-01 08:31:11.787  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'applicationContextIdFilter' to: [/*] 2018-09-01 08:31:12.292  INFO 1 --- [           main] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@75f9eccc: startup date [Sat Sep 01 08:31:06 UTC 2018]; root of context hierarchy 2018-09-01 08:31:12.436  INFO 1 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) 2018-09-01 08:31:12.437  INFO 1 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity&lt;java.util.Map&lt;java.lang.String, java.lang.Object&gt;&gt; org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest) 2018-09-01 08:31:12.485  INFO 1 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler] 2018-09-01 08:31:12.485  INFO 1 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler] 2018-09-01 08:31:12.554  INFO 1 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler] 2018-09-01 08:31:13.048  INFO 1 --- [           main] o.a.c.s.boot.CamelAutoConfiguration      : Using custom InterceptStrategy with id: integrationLoggingInterceptStrategy and implementation: io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy@6eeade6c 2018-09-01 08:31:13.342  INFO 1 --- [           main] o.a.c.i.converter.DefaultTypeConverter   : Type converters loaded (core: 194, classpath: 2) 2018-09-01 08:31:14.596  INFO 1 --- [           main] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/health || /health.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,java.security.Principal) 2018-09-01 08:31:14.864  INFO 1 --- [           main] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup 2018-09-01 08:31:14.881  INFO 1 --- [           main] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 0 2018-09-01 08:31:14.925 DEBUG 1 --- [           main] o.a.camel.spring.boot.RoutesCollector    : Post-processing CamelContext bean: sf 2018-09-01 08:31:14.936 DEBUG 1 --- [           main] o.a.camel.spring.boot.RoutesCollector    : CamelContextConfiguration found. Invoking beforeApplicationStart: io.syndesis.integration.runtime.IntegrationRuntimeAutoConfiguration$1@4c1f22f3 2018-09-01 08:31:14.998  INFO 1 --- [           main] i.s.i.runtime.IntegrationRouteBuilder    : Loading integration from: classpath:syndesis/integration/integration.json 2018-09-01 08:31:16.344 DEBUG 1 --- [           main] i.s.i.runtime.IntegrationRouteBuilder    : Step kind: endpoint, handler: io.syndesis.integration.runtime.handlers.ConnectorStepHandler 2018-09-01 08:31:16.484  INFO 1 --- [           main] i.s.i.c.proxy.ComponentProxyComponent    : Register component: salesforce-1 (type: org.apache.camel.component.salesforce.SalesforceComponent) with scheme: salesforce and alias: salesforce-salesforce-1 2018-09-01 08:31:16.497  INFO 1 --- [           main] org.eclipse.jetty.util.log               : Logging initialized @12677ms to org.eclipse.jetty.util.log.Slf4jLog 2018-09-01 08:31:16.500  INFO 1 --- [           main] o.a.c.util.jsse.SSLContextParameters     : Available providers: SUN version 1.8. 2018-09-01 08:31:16.712  INFO 1 --- [           main] o.a.c.c.s.internal.SalesforceSession     : Login at Salesforce loginUrl: https://login.salesforce.com/services/oauth2/token 2018-09-01 08:31:17.643  INFO 1 --- [           main] o.a.c.c.s.internal.SalesforceSession     : Login successful 2018-09-01 08:31:17.648  WARN 1 --- [           main] o.a.c.c.salesforce.SalesforceComponent   : Missing property packages, getSObject* operations will NOT work without property rawPayload=true 2018-09-01 08:31:17.650 DEBUG 1 --- [           main] i.s.i.c.proxy.ComponentProxyComponent    : Starting connector: salesforce-1 2018-09-01 08:31:17.728 DEBUG 1 --- [           main] i.s.i.runtime.IntegrationRouteBuilder    : Step kind: endpoint, handler: io.syndesis.integration.runtime.handlers.ConnectorStepHandler 2018-09-01 08:31:17.749 DEBUG 1 --- [           main] i.s.i.c.proxy.ComponentProxyComponent    : Starting connector: log-2 2018-09-01 08:31:17.758 DEBUG 1 --- [           main] o.a.camel.spring.boot.RoutesCollector    : CamelContextConfiguration found. Invoking beforeApplicationStart: io.syndesis.integration.runtime.jmx.IntegrationMetadataAutoConfiguration$1@749c877b 2018-09-01 08:31:17.760  INFO 1 --- [           main] r.j.IntegrationMetadataAutoConfiguration : Added Syndesis MBean Service 2018-09-01 08:31:17.760 DEBUG 1 --- [           main] o.a.camel.spring.boot.RoutesCollector    : CamelContextConfiguration found. Invoking beforeApplicationStart: io.syndesis.integration.runtime.logging.IntegrationLoggingAutoConfiguration$1@2b95e48b 2018-09-01 08:31:17.805  INFO 1 --- [           main] o.a.camel.spring.SpringCamelContext      : Apache Camel 2.21.0.fuse-710018-redhat-00001 (CamelContext: sf) is starting 2018-09-01 08:31:17.811  INFO 1 --- [           main] o.a.camel.spring.SpringCamelContext      : StreamCaching is enabled on CamelContext: sf 2018-09-01 08:31:17.828  INFO 1 --- [           main] o.a.c.m.ManagedManagementStrategy        : JMX is enabled 2018-09-01 08:31:18.195  INFO 1 --- [           main] i.s.i.c.proxy.ComponentProxyComponent    : Connector resolved: salesforce-1 -&gt; salesforce-salesforce-1://syndesis_Lead_c?notifyForFields=ALL&amp;notifyForOperationCreate=true&amp;notifyForOperationDelete=false&amp;notifyForOperationUndelete=false&amp;notifyForOperationUpdate=false&amp;sObjectClass=io.syndesis.connector.salesforce.SalesforceIdentifier&amp;sObjectQuery=SELECT+Id+FROM+Lead&amp;updateTopic=true 2018-09-01 08:31:18.349  INFO 1 --- [           main] i.s.i.c.proxy.ComponentProxyComponent    : Connector resolved: log-2 -&gt; log://syndesis-log?level=INFO&amp;showAll=true 2018-09-01 08:31:18.385  INFO 1 --- [           main] o.a.c.impl.DefaultStreamCachingStrategy  : StreamCaching in use with spool directory: /tmp/camel/camel-tmp-b30e4464-019d-4b26-9b46-c3c35bccb8c3 and rules: [Spool &gt; 128K body size] 2018-09-01 08:31:24.044  INFO 1 --- [           main] i.s.i.r.jmx.CamelContextMetadataMBean    : Registered mbean io.syndesis.camel:context=sf,type=context,name="sf" 2018-09-01 08:31:24.583  INFO 1 --- [           main] o.a.c.c.s.i.streaming.PushTopicHelper    : Found existing topic syndesis_Lead_c: {"attributes":{"type":"PushTopic","url":"/services/data/v34.0/sobjects/PushTopic/0IF0Y000000Xl3dWAC"},"Query":"SELECT Id FROM Lead","Description":"Topic created by Camel Salesforce component","NotifyForOperationDelete":false,"NotifyForOperationUndelete":false,"IsActive":true,"NotifyForFields":"All","NotifyForOperations":"Create","NotifyForOperationCreate":true,"NotifyForOperationUpdate":false,"ApiVersion":34.0,"Id":"0IF0Y000000Xl3dWAC","Name":"syndesis_Lead_c"} 2018-09-01 08:31:24.594  INFO 1 --- [           main] o.a.c.c.s.i.s.SubscriptionHelper         : Subscribing to channel /topic/syndesis_Lead_c... 2018-09-01 08:31:24.601  INFO 1 --- [           main] o.a.camel.spring.SpringCamelContext      : Route: -LLJF5Vx_TDQe8bCwwcq started and consuming from: salesforce-salesforce-1://syndesis_Lead_c?notifyForFields=ALL&amp;notifyForOperationCreate=true&amp;notifyForOperationDelete=false&amp;notifyForOperationUndelete=false&amp;notifyForOperationUpdate=false&amp;sObjectClass=io.syndesis.connector.salesforce.SalesforceIdentifier&amp;sObjectQuery=SELECT+Id+FROM+Lead&amp;updateTopic=true 2018-09-01 08:31:24.604  INFO 1 --- [           main] o.a.camel.spring.SpringCamelContext      : Total 1 routes, of which 1 are started 2018-09-01 08:31:24.634  INFO 1 --- [           main] o.a.camel.spring.SpringCamelContext      : Apache Camel 2.21.0.fuse-710018-redhat-00001 (CamelContext: sf) started in 6.836 seconds 2018-09-01 08:31:24.637 DEBUG 1 --- [           main] o.a.camel.spring.boot.RoutesCollector    : CamelContextConfiguration found. Invoking afterApplicationStart: io.syndesis.integration.runtime.IntegrationRuntimeAutoConfiguration$1@4c1f22f3 2018-09-01 08:31:24.707  INFO 1 --- [ent@25ad25f5-29] o.a.c.c.s.i.s.SubscriptionHelper         : Subscribed to channel /topic/syndesis_Lead_c 2018-09-01 08:31:25.764 DEBUG 1 --- [           main] .i.r.IntegrationRuntimeAutoConfiguration : Routes:  &lt;?xml version="1.0" encoding="UTF-8" standalone="yes"?&gt; &lt;routes xmlns="http://camel.apache.org/schema/spring"&gt;     &lt;route customId="true" id="-LLJF5Vx_TDQe8bCwwcq"&gt;         &lt;from customId="true" id="-LLJF5Vx_TDQe8bCwwcq" uri="salesforce-1"/&gt;         &lt;setHeader headerName="Syndesis.STEP_ID" id="setHeader1"&gt;             &lt;constant&gt;-LLJF5Vx_TDQe8bCwwcq&lt;/constant&gt;         &lt;/setHeader&gt;         &lt;process id="process1"/&gt;         &lt;pipeline customId="true" id="step:-LLJF8Wp_TDQe8bCwwcq"&gt;             &lt;setHeader headerName="Syndesis.STEP_ID" id="setHeader2"&gt;                 &lt;constant&gt;-LLJF8Wp_TDQe8bCwwcq&lt;/constant&gt;             &lt;/setHeader&gt;             &lt;to id="to1" uri="log-2"/&gt;             &lt;process id="process2"/&gt;         &lt;/pipeline&gt;     &lt;/route&gt; &lt;/routes&gt;  2018-09-01 08:31:25.764 DEBUG 1 --- [           main] o.a.camel.spring.boot.RoutesCollector    : CamelContextConfiguration found. Invoking afterApplicationStart: io.syndesis.integration.runtime.jmx.IntegrationMetadataAutoConfiguration$1@749c877b 2018-09-01 08:31:25.764 DEBUG 1 --- [           main] o.a.camel.spring.boot.RoutesCollector    : CamelContextConfiguration found. Invoking afterApplicationStart: io.syndesis.integration.runtime.logging.IntegrationLoggingAutoConfiguration$1@2b95e48b 2018-09-01 08:31:25.864  INFO 1 --- [           main] b.c.e.u.UndertowEmbeddedServletContainer : Undertow started on port(s) 8080 (http) 2018-09-01 08:31:25.880  INFO 1 --- [           main] io.syndesis.example.Application          : Started Application in 20.446 seconds (JVM running for 22.061) ```  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. deploy cr2 2. create sf connection 3. deploy sf (on-create, lead) -&gt; log integration 4. create lead in sf 5. the integration is not triggered </body>
		<created>2018-09-01 08:38:34</created>
		<closed>2018-09-05 08:43:54</closed>
	</bug>
	<bug>
		<id>3516</id>
		<title>[operator] unable to build operator image</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Building all the syndesis images fails on syndesis-operator with:  ``` ============================================================================== Building syndesis-operator ============================================================================== Building on Minishift Installing rsync on Minishift tput: unknown terminal "unknown"  Installing additional packages on the root filesystem might exceed the allocated overlay size and lock the Minishift VM. Proceed with the installation at your own risk. For more information, see https://docs.openshift.org/latest/minishift/troubleshooting/troubleshooting-misc.html#root-filesystem-exceeds-overlay-size tput: unknown terminal "unknown"  Loaded plugins: fastestmirror Determining fastest mirrors  * base: mirror.switch.ch  * extras: mirror.switch.ch  * updates: mirror.switch.ch Resolving Dependencies --&gt; Running transaction check ---&gt; Package rsync.x86_64 0:3.1.2-4.el7 will be installed --&gt; Finished Dependency Resolution  Dependencies Resolved  ================================================================================  Package         Arch             Version                  Repository      Size ================================================================================ Installing:  rsync           x86_64           3.1.2-4.el7              base           403 k  Transaction Summary ================================================================================ Install  1 Package  Total download size: 403 k Installed size: 815 k Downloading packages: Public key for rsync-3.1.2-4.el7.x86_64.rpm is not installed warning: /var/cache/yum/x86_64/7/base/packages/rsync-3.1.2-4.el7.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEY Retrieving key from file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 Importing GPG key 0xF4A80EB5:  Userid     : "CentOS-7 Key (CentOS 7 Official Signing Key) &lt;security@centos.org&gt;"  Fingerprint: 6341 ab27 53d7 8a78 a7c2 7bb1 24c6 a8a7 f4a8 0eb5  Package    : centos-release-7-5.1804.el7.centos.2.x86_64 (@updates/$releasever)  From       : /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 Running transaction check Running transaction test Transaction test succeeded Running transaction   Installing : rsync-3.1.2-4.el7.x86_64                                     1/1    Verifying  : rsync-3.1.2-4.el7.x86_64                                     1/1   Installed:   rsync.x86_64 0:3.1.2-4.el7                                                      Complete! Rsync local sources to Minishift VM to /opt/syndesis Warning: Permanently added '192.168.42.43' (ECDSA) to the list of known hosts. Received disconnect from 192.168.42.43 port 22:2: Too many authentication failures Disconnected from 192.168.42.43 port 22 rsync: connection unexpectedly closed (0 bytes received so far) [sender] rsync error: unexplained error (code 255) at io.c(226) [sender=3.1.3] ERROR: Last command exited with 255 ``` ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  We should be able to build all the images.  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1.  syndesis build --all-images --clean --flash --dependencies </body>
		<created>2018-08-30 14:32:29</created>
		<closed>2018-09-07 13:01:28</closed>
	</bug>
	<bug>
		<id>3515</id>
		<title>[Operator] -registry seems to be ignored, upgrade image always pulled from docker.io</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  When `-registry` argument is used in the operator image, it seems to be ignored. We have currently `fuse-online-operator:1.1-4` image that specifies our docker registry:  ``` "Entrypoint": [                 "/usr/local/bin/syndesis-operator",                 "-template",                 "/conf/syndesis-template.yml",                 "-registry",                 "registry.access.redhat.com"             ] ```  but when the operator tries to upgrade 7.0.1 to 7.1, it tries to pull the image from docker hub:  ``` Failed to pull image "docker.io/fuse7/fuse-ignite-upgrade:1.1-8": rpc error: code = Unknown desc = Error: image fuse7/fuse-ignite-upgrade:1.1-8 not found ```  I tried to modify the upstream 1.4.7 operator image to specify my own registry:  ``` FROM syndesis/syndesis-operator:1.4.7  ENTRYPOINT [ "/usr/local/bin/syndesis-operator", "-template", "/conf/syndesis-template.yml", "-registry", "myregistry" ] ```  and after deploying that image, it still pulls docker.io.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; To pull from repository that is specified in `-registry`  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-08-30 13:56:22</created>
		<closed>2018-08-31 08:13:16</closed>
	</bug>
	<bug>
		<id>3514</id>
		<title>Syndesis template for deploying "the old way" references syndesis-operator service account</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  In the "old school" template, that is used to deploy syndesis without the operator, we reference `syndesis-operator` service account that is obviously not present.   https://github.com/syndesisio/syndesis/blob/master/install/syndesis.yml#L1632  This will cause problems with upgrade in the environments where the operator can't be used.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Upgrading "the old way" by deploying the upgrade pod should not require the `syndesis-operator` service account  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-08-30 07:58:21</created>
		<closed>2018-09-27 13:35:59</closed>
	</bug>
	<bug>
		<id>3506</id>
		<title>Bug with transformation after a Timer connector</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release)[ [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; The UI fails if you try to apply any operation after a  Timer connector.   ## Screenshot ![screenshot from 2018-08-29 16-53-16](https://user-images.githubusercontent.com/1520602/44795904-1895df80-abac-11e8-820d-55124cfc61bd.png)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1.  create a simple integration from timer to log 2. add an intermediate Simple filter step 3. 4.  &lt;details&gt;   &lt;summary&gt;&lt;b&gt;Click to expand&lt;/b&gt;&lt;/summary&gt; &lt;pre&gt;&lt;code&gt; TypeError: "this.getPreviousStepsWithDataShape(...).reverse(...)[0] is undefined" getPreviousStepWithDataShapehttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/10.c03fb1e51e50fa5c4409.js:1:15919loadFormhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/10.c03fb1e51e50fa5c4409.js:1:58130routeSubscriptionhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/10.c03fb1e51e50fa5c4409.js:1:59262__tryOrUnsubhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:52947nexthttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:52089_nexthttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:51121nexthttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:50804_nexthttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:43796nexthttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:50804_subscribehttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:390133_trySubscribehttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:45108_trySubscribehttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:875146subscribehttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:44894callhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:43477subscribehttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:44812ngOnInithttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/10.c03fb1e51e50fa5c4409.js:1:59032ahttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:639733ahttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:639133ahttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:638031Slhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:649126buhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/10.c03fb1e51e50fa5c4409.js:1:300551updateDirectiveshttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:645907Xahttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:637679ilhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:644626rlhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:644289Xahttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:637704ilhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:644626nlhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:644024Xahttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:637826ilhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:644626rlhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:644289Xahttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:637704ilhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:644626rlhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:644289Xahttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:637704ilhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:644626nlhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:644024Xahttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:637826detectChangeshttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:619201tickhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:574630tickhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:574591nexthttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:572965invokehttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:9337onInvokehttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:564145invokehttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:9264runhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:4497runhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:564852nexthttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:572942ohttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:562669__tryOrUnsubhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:52947nexthttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:52089_nexthttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:51121nexthttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:50804nexthttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:874577emithttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:562435ynhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:565301onHasTaskhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:564290hasTaskhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:10331_updateTaskCounthttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:10598_updateTaskCounthttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:6780runTaskhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:5400vhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:12241invokeTaskhttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:11142ghttps://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:22032_https://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:22264 main.77eef8c1bdeef6a93ae7.js:1:2603073 zUnb/At&lt;/t.prototype.log https://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:2603073 zUnb/At&lt;/t.prototype.handleError https://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:2602971 next https://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:570878 CcnG/fn&lt;/t.prototype.subscribe/o&lt; https://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:562669 FFOo/l&lt;/e.prototype.__tryOrUnsub https://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:52947 FFOo/l&lt;/e.prototype.next https://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:52089 FFOo/f&lt;/e.prototype._next https://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:51121 FFOo/f&lt;/e.prototype.next https://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:50804 K9Ia/d&lt;/t.prototype.next https://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:874577 CcnG/fn&lt;/t.prototype.emit https://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:562435 onHandleError/&lt; https://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:564455 0TWp/&lt;/&lt;/u&lt;/t.prototype.invoke https://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:9337 0TWp/&lt;/&lt;/i&lt;/e.prototype.run https://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:4497 CcnG/hn&lt;/e.prototype.runOutsideAngular https://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:565164 onHandleError https://syndesis-staging.b6ff.rh-idev.openshiftapps.com/main.77eef8c1bdeef6a93ae7.js:1:564417 0TWp/&lt;/&lt;/u&lt;/t.prototype.handleError https://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:9417 0TWp/&lt;/&lt;/i&lt;/e.prototype.runTask https://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:5242 0TWp/&lt;/&lt;/c&lt;/e.invokeTask https://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:11106 e/this.invoke&lt; https://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:10991 u/n.args[0] https://syndesis-staging.b6ff.rh-idev.openshiftapps.com/polyfills.4b6f2a37458cb8a6e58c.js:1:26294  &lt;/code&gt;&lt;/pre&gt; &lt;/details&gt;   ```json {"componentScheme":"timer","inputDataShape":{"kind":"none"},"outputDataShape":{"kind":"none"},"propertyDefinitionSteps":[{"description":"Period","name":"Period","properties":{"period":{"componentProperty":false,"defaultValue":"60000","deprecated":false,"description":"Period","labelHint":"Delay between scheduling (executing).","displayName":"Period","javaType":"long","kind":"parameter","required":true,"secret":false,"type":"duration"}}}],"configuredProperties":{"timerName":"syndesis-timer"},"_meta":{}} ``` </body>
		<created>2018-08-29 14:58:53</created>
		<closed>2018-08-30 12:31:52</closed>
	</bug>
	<bug>
		<id>3505</id>
		<title>Unable to list activities:  504 (Gateway Time-out) in 1.4.7</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem In my long running scenario with 6 integrations (3 of 6 contains more than 4 elements), I'm not able to list activities after couple of hours(~12).   ### Java script console log:  ``` i-LKvs0nhYGDn4JCJzcZDz:1 Failed to load resource: the server responded with a status of 504 (Gateway Time-out) http-error.interceptor.ts:52 Error performing GET request to https://soak.b9ad.pro-us-east-1.openshiftapps.com/api/v1/activity/integrations/i-LKvs0nhYGDn4JCJzcZDz :  HttpErrorResponse{headers: HttpHeaders, status: 504, statusText: "Gateway Time-out", url: "https://soak.b9ad.pro-us-east-1.openshiftapps.com/i/v1/activity/integrations/i-LKvs0nhYGDn4JCJzcZDz", ok: false,} (anonymous) @ http-error.interceptor.ts:52 push../node_modules/rxjs/_esm5/internal/operators/tap.js.TapSubscriber._error @ tap.js:102 push../node_modules/rxjs/_esm5/internal/Subscriber.js.Subscriber.error @ Subscriber.js:106 onLoad @ http.js:1556 push../node_modules/zone.js/dist/zone.js.ZoneDelegate.invokeTask @ zone.js:421 onInvokeTask @ core.js:3662 push../node_modules/zone.js/dist/zone.js.ZoneDelegate.invokeTask @ zone.js:420 push../node_modules/zone.js/dist/zone.js.Zone.runTask @ zone.js:188 push../node_modules/zone.js/dist/zone.js.ZoneTask.invokeTask @ zone.js:496 invokeTask @ zone.js:1540 globalZoneAwareCallback @ zone.js:1566 exception-handler.service.ts:19 Error: Uncaught (in promise): Error: Cannot parse given Error object Error: Cannot parse given Error object     at Object.ErrorStackParser$$parse [as parse] (error-stack-parser.js:74)     at Object.&lt;anonymous&gt; (stacktrace.js:106)     at new ZoneAwarePromise (zone.js:891)     at Object.StackTrace$$fromError [as fromError] (stacktrace.js:105)     at MessageUtils.js:168     at new ZoneAwarePromise (zone.js:891)     at Function.push../node_modules/typescript-logging/dist/commonjs/utils/MessageUtils.js.MessageFormatUtils.renderError (MessageUtils.js:166)     at _loop_1 (AbstractCategoryLogger.js:321)     at CategoryConsoleLoggerImpl.push../node_modules/typescript-logging/dist/commonjs/log/category/AbstractCategoryLogger.js.AbstractCategoryLogger._logInternal (AbstractCategoryLogger.js:334)     at CategoryConsoleLoggerImpl.push../node_modules/typescript-logging/dist/commonjs/log/category/AbstractCategoryLogger.js.AbstractCategoryLogger._log (AbstractCategoryLogger.js:274)     at Object.ErrorStackParser$$parse [as parse] (error-stack-parser.js:74)     at Object.&lt;anonymous&gt; (stacktrace.js:106)     at new ZoneAwarePromise (zone.js:891)     at Object.StackTrace$$fromError [as fromError] (stacktrace.js:105)     at MessageUtils.js:168     at new ZoneAwarePromise (zone.js:891)     at Function.push../node_modules/typescript-logging/dist/commonjs/utils/MessageUtils.js.MessageFormatUtils.renderError (MessageUtils.js:166)     at _loop_1 (AbstractCategoryLogger.js:321)     at CategoryConsoleLoggerImpl.push../node_modules/typescript-logging/dist/commonjs/log/category/AbstractCategoryLogger.js.AbstractCategoryLogger._logInternal (AbstractCategoryLogger.js:334)     at CategoryConsoleLoggerImpl.push../node_modules/typescript-logging/dist/commonjs/log/category/AbstractCategoryLogger.js.AbstractCategoryLogger._log (AbstractCategoryLogger.js:274)     at resolvePromise (zone.js:814)     at resolvePromise (zone.js:771)     at zone.js:873     at ZoneDelegate.push../node_modules/zone.js/dist/zone.js.ZoneDelegate.invokeTask (zone.js:421)     at Object.onInvokeTask (core.js:3662)     at ZoneDelegate.push../node_modules/zone.js/dist/zone.js.ZoneDelegate.invokeTask (zone.js:420)     at Zone.push../node_modules/zone.js/dist/zone.js.Zone.runTask (zone.js:188)     at drainMicroTaskQueue (zone.js:595)     at ZoneTask.push../node_modules/zone.js/dist/zone.js.ZoneTask.invokeTask [as invoke] (zone.js:500)     at invokeTask (zone.js:1540) push../src/app/error-handler/exception-handler.service.ts.ExceptionHandlerService.log @ exception-handler.service.ts:19 push../src/app/error-handler/exception-handler.service.ts.ExceptionHandlerService.handleError @ exception-handler.service.ts:12 next @ core.js:4167 schedulerFn @ core.js:3403 push../node_modules/rxjs/_esm5/internal/Subscriber.js.SafeSubscriber.__tryOrUnsub @ Subscriber.js:253 push../node_modules/rxjs/_esm5/internal/Subscriber.js.SafeSubscriber.next @ Subscriber.js:191 push../node_modules/rxjs/_esm5/internal/Subscriber.js.Subscriber._next @ Subscriber.js:129 push../node_modules/rxjs/_esm5/internal/Subscriber.js.Subscriber.next @ Subscriber.js:93 push../node_modules/rxjs/_esm5/internal/Subject.js.Subject.next @ Subject.js:53 push../node_modules/@angular/core/fesm5/core.js.EventEmitter.emit @ core.js:3395 (anonymous) @ core.js:3693 push../node_modules/zone.js/dist/zone.js.ZoneDelegate.invoke @ zone.js:388 push../node_modules/zone.js/dist/zone.js.Zone.run @ zone.js:138 push../node_modules/@angular/core/fesm5/core.js.NgZone.runOutsideAngular @ core.js:3630 onHandleError @ core.js:3693 push../node_modules/zone.js/dist/zone.js.ZoneDelegate.handleError @ zone.js:392 push../node_modules/zone.js/dist/zone.js.Zone.runGuarded @ zone.js:154 _loop_1 @ zone.js:677 api.microtaskDrainDone @ zone.js:686 drainMicroTaskQueue @ zone.js:602 push../node_modules/zone.js/dist/zone.js.ZoneTask.invokeTask @ zone.js:500 invokeTask @ zone.js:1540 globalZoneAwareCallback @ zone.js:1566 core.js:1542 ERROR Error: Uncaught (in promise): Error: Cannot parse given Error object Error: Cannot parse given Error object     at Object.ErrorStackParser$$parse [as parse] (error-stack-parser.js:74)     at Object.&lt;anonymous&gt; (stacktrace.js:106)     at new ZoneAwarePromise (zone.js:891)     at Object.StackTrace$$fromError [as fromError] (stacktrace.js:105)     at MessageUtils.js:168     at new ZoneAwarePromise (zone.js:891)     at Function.push../node_modules/typescript-logging/dist/commonjs/utils/MessageUtils.js.MessageFormatUtils.renderError (MessageUtils.js:166)     at _loop_1 (AbstractCategoryLogger.js:321)     at CategoryConsoleLoggerImpl.push../node_modules/typescript-logging/dist/commonjs/log/category/AbstractCategoryLogger.js.AbstractCategoryLogger._logInternal (AbstractCategoryLogger.js:334)     at CategoryConsoleLoggerImpl.push../node_modules/typescript-logging/dist/commonjs/log/category/AbstractCategoryLogger.js.AbstractCategoryLogger._log (AbstractCategoryLogger.js:274)     at Object.ErrorStackParser$$parse [as parse] (error-stack-parser.js:74)     at Object.&lt;anonymous&gt; (stacktrace.js:106)     at new ZoneAwarePromise (zone.js:891)     at Object.StackTrace$$fromError [as fromError] (stacktrace.js:105)     at MessageUtils.js:168     at new ZoneAwarePromise (zone.js:891)     at Function.push../node_modules/typescript-logging/dist/commonjs/utils/MessageUtils.js.MessageFormatUtils.renderError (MessageUtils.js:166)     at _loop_1 (AbstractCategoryLogger.js:321)     at CategoryConsoleLoggerImpl.push../node_modules/typescript-logging/dist/commonjs/log/category/AbstractCategoryLogger.js.AbstractCategoryLogger._logInternal (AbstractCategoryLogger.js:334)     at CategoryConsoleLoggerImpl.push../node_modules/typescript-logging/dist/commonjs/log/category/AbstractCategoryLogger.js.AbstractCategoryLogger._log (AbstractCategoryLogger.js:274)     at resolvePromise (zone.js:814)     at resolvePromise (zone.js:771)     at zone.js:873     at ZoneDelegate.push../node_modules/zone.js/dist/zone.js.ZoneDelegate.invokeTask (zone.js:421)     at Object.onInvokeTask (core.js:3662)     at ZoneDelegate.push../node_modules/zone.js/dist/zone.js.ZoneDelegate.invokeTask (zone.js:420)     at Zone.push../node_modules/zone.js/dist/zone.js.Zone.runTask (zone.js:188)     at drainMicroTaskQueue (zone.js:595)     at ZoneTask.push../node_modules/zone.js/dist/zone.js.ZoneTask.invokeTask [as invoke] (zone.js:500)     at invokeTask (zone.js:1540) ```  ### Server log  This was only exception in server log (might be not related though): ``` 2018-08-27 23:48:55.673 ERROR [-,,,] 1 --- [ning]: pollPods] i.s.s.l.j.c.ActivityTrackingController   : Unexpected Error occurred.  io.fabric8.kubernetes.client.KubernetesClientException: Operation: [list]  for kind: [Pod]  with name: [null]  in namespace: [soak]  failed. at io.fabric8.kubernetes.client.KubernetesClientException.launderThrowable(KubernetesClientException.java:62) ~[kubernetes-client-3.1.4.fuse-710001.jar!/:na] at io.fabric8.kubernetes.client.KubernetesClientException.launderThrowable(KubernetesClientException.java:71) ~[kubernetes-client-3.1.4.fuse-710001.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.BaseOperation.list(BaseOperation.java:609) ~[kubernetes-client-3.1.4.fuse-710001.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.BaseOperation.list(BaseOperation.java:70) ~[kubernetes-client-3.1.4.fuse-710001.jar!/:na] at io.syndesis.server.logging.jsondb.controller.ActivityTrackingController.listPods(ActivityTrackingController.java:298) ~[server-logging-jsondb-1.4.7.jar!/:1.4.7] at io.syndesis.server.logging.jsondb.controller.ActivityTrackingController.pollPods(ActivityTrackingController.java:242) ~[server-logging-jsondb-1.4.7.jar!/:1.4.7] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_151] at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) ~[na:1.8.0_151] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) ~[na:1.8.0_151] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) ~[na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_151] at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_151] Caused by: java.net.SocketTimeoutException: timeout at okio.Okio$4.newTimeoutException(Okio.java:230) ~[okio-1.13.0.jar!/:na] at okio.AsyncTimeout.exit(AsyncTimeout.java:285) ~[okio-1.13.0.jar!/:na] at okio.AsyncTimeout$2.read(AsyncTimeout.java:241) ~[okio-1.13.0.jar!/:na] at okio.RealBufferedSource.indexOf(RealBufferedSource.java:345) ~[okio-1.13.0.jar!/:na] at okio.RealBufferedSource.readUtf8LineStrict(RealBufferedSource.java:217) ~[okio-1.13.0.jar!/:na] at okio.RealBufferedSource.readUtf8LineStrict(RealBufferedSource.java:211) ~[okio-1.13.0.jar!/:na] at okhttp3.internal.http1.Http1Codec.readResponseHeaders(Http1Codec.java:189) ~[okhttp-3.8.1.jar!/:na] at okhttp3.internal.http.CallServerInterceptor.intercept(CallServerInterceptor.java:75) ~[okhttp-3.8.1.jar!/:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92) ~[okhttp-3.8.1.jar!/:na] at okhttp3.internal.connection.ConnectInterceptor.intercept(ConnectInterceptor.java:45) ~[okhttp-3.8.1.jar!/:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92) ~[okhttp-3.8.1.jar!/:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:67) ~[okhttp-3.8.1.jar!/:na] at okhttp3.internal.cache.CacheInterceptor.intercept(CacheInterceptor.java:93) ~[okhttp-3.8.1.jar!/:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92) ~[okhttp-3.8.1.jar!/:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:67) ~[okhttp-3.8.1.jar!/:na] at okhttp3.internal.http.BridgeInterceptor.intercept(BridgeInterceptor.java:93) ~[okhttp-3.8.1.jar!/:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92) ~[okhttp-3.8.1.jar!/:na] at okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept(RetryAndFollowUpInterceptor.java:120) ~[okhttp-3.8.1.jar!/:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92) ~[okhttp-3.8.1.jar!/:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:67) ~[okhttp-3.8.1.jar!/:na] at io.fabric8.openshift.client.internal.OpenShiftOAuthInterceptor.intercept(OpenShiftOAuthInterceptor.java:66) ~[openshift-client-3.1.4.fuse-710001.jar!/:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92) ~[okhttp-3.8.1.jar!/:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:67) ~[okhttp-3.8.1.jar!/:na] at okhttp3.RealCall.getResponseWithInterceptorChain(RealCall.java:185) ~[okhttp-3.8.1.jar!/:na] at okhttp3.RealCall.execute(RealCall.java:69) ~[okhttp-3.8.1.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:377) ~[kubernetes-client-3.1.4.fuse-710001.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:343) ~[kubernetes-client-3.1.4.fuse-710001.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:327) ~[kubernetes-client-3.1.4.fuse-710001.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.BaseOperation.list(BaseOperation.java:605) ~[kubernetes-client-3.1.4.fuse-710001.jar!/:na] ... 10 common frames omitted Caused by: java.net.SocketException: Socket closed at java.net.SocketInputStream.read(SocketInputStream.java:204) ~[na:1.8.0_151] at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[na:1.8.0_151] at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_151] at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_151] at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:983) ~[na:1.8.0_151] at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:940) ~[na:1.8.0_151] at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_151] at okio.Okio$2.read(Okio.java:139) ~[okio-1.13.0.jar!/:na] at okio.AsyncTimeout$2.read(AsyncTimeout.java:237) ~[okio-1.13.0.jar!/:na] ... 36 common frames omitted ```  Oputput of [jstack 1](https://github.com/syndesisio/syndesis/files/2332396/jstack.txt)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; Unfortunately I can't reproduce consistently otherwise I'd mark it as a blocker.</body>
		<created>2018-08-29 14:05:06</created>
		<closed>2019-01-13 18:25:13</closed>
	</bug>
	<bug>
		<id>3497</id>
		<title>Apicurio GUI - info box not showed properly</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Scrolling to the end of the page when editing operation in apicurio studio and opening security tooltip does not show the whole help box.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Whole help box should be visible.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![screenshot_20180829_103107](https://user-images.githubusercontent.com/14313995/44775993-54628200-ab77-11e8-96e1-2109dd0a8c39.png)  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-08-29 08:38:51</created>
		<closed>2018-10-16 12:11:29</closed>
	</bug>
	<bug>
		<id>3496</id>
		<title>ApicurIO GUI - context menu disappearing </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Context menu keeps disappearing. I am not sure if it is expected or not, because if I hold right click it stays open. Creating this issue just to be sure to ask anyone who knows better.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Menu should be visible when opened until user clicks somewhere else or selects an option.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![out](https://user-images.githubusercontent.com/14313995/44775328-a6a2a380-ab75-11e8-824e-34649da558e5.gif)  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Open apicurio studio 2. Right click on any operation 3. 4. </body>
		<created>2018-08-29 08:27:36</created>
		<closed>2018-10-17 08:00:47</closed>
	</bug>
	<bug>
		<id>3486</id>
		<title>Incorrect path on DropBox file download does not throw error on the UI</title>
		<body>When an integration is created with the drop box connector and incorrect path is specified, throws an error saying path is invalid in the logs, but the Syndesis UI does not update the error count or the failed message exchange.  The error count should show the error that happens on file poll.  &lt;img width="1437" alt="activityview" src="https://user-images.githubusercontent.com/39506194/44739100-e3629200-aac4-11e8-8394-9c2b0cb042b8.png"&gt; &lt;img width="1422" alt="syndesis_error" src="https://user-images.githubusercontent.com/39506194/44739101-e3fb2880-aac4-11e8-975a-282d95b4ac18.png"&gt;   2018-08-28 00:21:32.371  WARN 1 --- [- dropbox://get] .c.d.i.c.DropboxScheduledPollGetConsumer : Consumer Consumer[dropbox://get?accessToken=xxxxxxx&amp;clientIdentifier=xxxxxx&amp;remotePath=syndesis] failed polling endpoint: dropbox://get?accessToken=xxxxx&amp;clientIdentifier=xxxx&amp;remotePath=syndesis. Will try again at next poll. Caused by: [java.lang.IllegalArgumentException - String 'path' does not match pattern] java.lang.IllegalArgumentException: String 'path' does not match pattern at com.dropbox.core.v2.files.ListFolderArg.&lt;init&gt;(ListFolderArg.java:74) ~[dropbox-core-sdk-3.0.6.jar!/:na] at com.dropbox.core.v2.files.ListFolderArg.&lt;init&gt;(ListFolderArg.java:107) ~[dropbox-core-sdk-3.0.6.jar!/:na] at com.dropbox.core.v2.files.DbxUserFilesRequests.listFolder(DbxUserFilesRequests.java:1465) ~[dropbox-core-sdk-3.0.6.jar!/:na] at org.apache.camel.component.dropbox.core.DropboxAPIFacade.downloadFilesInFolder(DropboxAPIFacade.java:336) ~[camel-dropbox-2.21.0.jar!/:2.21.0] at org.apache.camel.component.dropbox.core.DropboxAPIFacade.get(DropboxAPIFacade.java:331) ~[camel-dropbox-2.21.0.jar!/:2.21.0] at org.apache.camel.component.dropbox.integration.consumer.DropboxScheduledPollGetConsumer.poll(DropboxScheduledPollGetConsumer.java:44) ~[camel-dropbox-2.21.0.jar!/:2.21.0] at org.apache.camel.impl.ScheduledPollConsumer.doRun(ScheduledPollConsumer.java:174) [camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.impl.ScheduledPollConsumer.run(ScheduledPollConsumer.java:101) [camel-core-2.21.0.jar!/:2.21.0] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_151] at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [na:1.8.0_151] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [na:1.8.0_151] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_151] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_151] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_151]  1) Created a Drop Box connector and a slack connector. 2) Chose the action Download from Drop Box, but gave the folder name instead of the path (which is wrong) 3) Published the integration  I see that in the open shift console i see the poll failing, but i dont see any feedback on Syndesis UI. How would the user know something went wrong, unless i am monitoring logs continuously. </body>
		<created>2018-08-28 17:20:30</created>
		<closed>2018-10-29 14:01:52</closed>
	</bug>
	<bug>
		<id>3463</id>
		<title>[Upgrade] Syndesis operator uses hardcoded "latest" for upgrade pod tag</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Currently, by default, the syndesis specifies upgrade container tag "latest": https://github.com/syndesisio/syndesis/blob/master/install/syndesis.yml#L1635   But for the community version in the docker hub, there is no such tag: https://hub.docker.com/r/syndesis/syndesis-upgrade/tags/   Therefore it causes upgrade to fail because of missing image:   `Failed to pull image "docker.io/syndesis/syndesis-upgrade:latest": rpc error: code = Unknown desc = Tag latest not found in repository docker.io/syndesis/syndesis-upgrade`  I think the version should be changed from latest to &lt;operator_version&gt; somewhere in the process of building the operator image.  cc @rhuss   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-08-28 07:42:10</created>
		<closed>2018-11-13 09:03:31</closed>
	</bug>
	<bug>
		<id>3462</id>
		<title>Use of constants in the datamapper is broken</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [*] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem If constants are used in the datamapper step their value always ends up 'null'.  ## Expected behavior To use the value of the defined constant  ## Screenshot &lt;img width="955" alt="screen shot 2018-08-27 at 6 38 19 pm" src="https://user-images.githubusercontent.com/35576/44690343-74cff680-aa28-11e8-8229-6c47d2e28dab.png"&gt; &lt;img width="920" alt="screen shot 2018-08-27 at 6 38 35 pm" src="https://user-images.githubusercontent.com/35576/44690344-74cff680-aa28-11e8-9be1-ff770eaa62ec.png"&gt;  Note how 'first_name' is 'null' in the second screenshot.    </body>
		<created>2018-08-27 22:39:04</created>
		<closed>2018-09-19 16:31:55</closed>
	</bug>
	<bug>
		<id>3460</id>
		<title>'Unable to mount volumes for pod "syndesis-upgrade-1.4.7...' during upgrade from 1.4.6 to 1.4.7 on OSO pro</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please cho  ose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem I'm unable to upgrade syndesis on openshift pro:   3:31:18 PM | Warning | Failed Mount | Unable to mount volumes for pod "syndesis-upgrade-1.4.7_upgrade-project(ee1e559b-a9fb-11e8-937e-125b034d2f46)": timeout expired waiting for volumes to attach/mount for pod "upgrade-project"/"syndesis-upgrade-1.4.7". list of unattached/unmounted volumes=[backup-dir]5 times in the last10 minutes -- | -- | -- | -- 3:20:13 PM | Normal | Successful Mount Volume | MountVolume.SetUp succeeded for volume "syndesis-operator-token-jwf4x" 3:20:13 PM | Warning | Failed Attach Volume | Multi-Attach error for volume "pvc-655fe43a-a9fb-11e8-ba69-12b5519f9b58" Volume is already used by pod(s) syndesis-db-1-2m8n5 3:20:13 PM | Normal | Scheduled | Successfully assigned syndesis-upgrade-1.4.7 to ip-172-31-58-128.ec2.internal   ![screen shot 2018-08-27 at 15 26 39](https://user-images.githubusercontent.com/6814482/44662533-53faa780-aa0e-11e8-8bfa-5ec1fc60d752.png) &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. deploy syndesis 1.4.6 on OSO Pro using template 2. manually create operator service account  3. try to upgrade to 1.4.7 via template ("old way")  </body>
		<created>2018-08-27 13:45:29</created>
		<closed>2018-10-16 13:14:02</closed>
	</bug>
	<bug>
		<id>3459</id>
		<title>apicurio - warnings are not updated when changed via gui and saved</title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11443**  ## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When adding custom API connector and editing it in apicurio, operation numbers are refreshed, but warnings are not.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Warnings from apicur gui should be propagated out when saved  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![screenshot_20180827_125204](https://user-images.githubusercontent.com/14313995/44656331-bc3e8e80-a9f8-11e8-97f5-3d0800931ad6.png)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. From customization page update an OpenAPI file with warnings 2. Go next and click review/edit button to open apicurio gui 3. Solve at least one warning and save, you will be returned to overview page 4. Note that warnings number was not updated </body>
		<created>2018-08-27 13:12:49</created>
		<closed>2019-09-07 11:32:20</closed>
	</bug>
	<bug>
		<id>3457</id>
		<title>SAP Concur connector has no technology preview label</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Concur is marked as technology preview in documentation and release notes, we should add this label into UI. Its not really a blocker, but it is very easy to fix and has no regression threats.</body>
		<created>2018-08-27 10:37:05</created>
		<closed>2018-09-11 12:32:54</closed>
	</bug>
	<bug>
		<id>3443</id>
		<title>[Upgrade] Missing migration script for syndesis-db-conf</title>
		<body>According to the upgrade script (upgrade_40_update_resources) we should provide migration script for configmaps:  ``` This command first will call out to migration scripts for updating stateful resources (ConfigMap, Secrets, PersistentVolumeClaims) ```  because the configmaps are ignored later in the script:  ``` # Document which resource shouldn't be updated DONT_TOUCH_RESOURCES="ConfigMap Secret PersistentVolumeClaim RoleBinding" ```  This causes problems when upgrading 7.0.1 to 7.1, because there is a new config map syndesis-db-conf in 7.1 and the *syndesis-db does not start after upgrading* :  ``` Failed Mount MountVolume.SetUp failed for volume "syndesis-db-conf" : configmaps "syndesis-db-conf" not found ``` </body>
		<created>2018-08-24 10:21:47</created>
		<closed>2018-08-24 17:04:18</closed>
	</bug>
	<bug>
		<id>3436</id>
		<title>Can't edit API connector definition added using the URL</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  When creating new API connector, I can't edit the swagger.json file in the apicurio editor, if it was added using the "URL". The "review/edit" button is not clickable in this case, as can be seen in the screenshot. In case the same swagger.json was added using locally downloaded file, it can be edited. The adding using URL is also mentioned in the related "swagger editing user story": https://github.com/syndesisio/syndesis/issues/2750 so it should be possible.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  It should be possible to edit this API connector definition.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![screenshot from 2018-08-23 09-45-37](https://user-images.githubusercontent.com/4180208/44511940-5335de80-a6b9-11e8-9896-1c1a8afc4a78.png)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Go to "API connectors" 2. Add one using URL, you can use http://petstore.swagger.io/v2/swagger.json 3. The "review/edit"  </body>
		<created>2018-08-23 07:51:36</created>
		<closed>2018-09-11 07:43:35</closed>
	</bug>
	<bug>
		<id>3433</id>
		<title>Add possibility to create integration sequentionally </title>
		<body>See also **https://issues.jboss.org/browse/ENTESB-11453**  ## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ x] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem I feel creating "Start" then "Finish" and then "everything between" isn't very intuitive, especially when creating integrations with 4 and more elements.  Also adding "new finish" (for example some audit, log) during editing integration is complicated.  &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-08-22 15:55:59</created>
		<closed>2019-09-07 11:45:56</closed>
	</bug>
	<bug>
		<id>3424</id>
		<title>Build: specify --camel-snapshot without an explicit environment variable doesn't work</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## The problem If we use the --camel-snapshot option from build and we specify a version, this is not taken into account because of the code here: https://github.com/syndesisio/syndesis/blob/master/app/s2i/copy_mvn_repo.sh#L17  so we need to fix the documentation or find a way to pass the option to copy_mvn_repo.sh  ## Expected behavior camel-snapshot option should work also without an explicit env variable set </body>
		<created>2018-08-22 11:18:08</created>
		<closed>2019-04-19 08:48:45</closed>
	</bug>
	<bug>
		<id>3416</id>
		<title>Integration version is incremented during publishing yet deployment contains old version</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  1. Integration is created with a version of 1; 2. Integration is published:     - A copy of the integration is nested in the deployment;     - The draft integration version is incremented.  Equality comparison of the draft integration and the deployment's integration (_deployment.getSpec()_) is no longer possible since the versions are now different.  Should the version be incremented as a result of publishing rather than editing?</body>
		<created>2018-08-21 13:51:44</created>
		<closed>2018-12-12 16:28:52</closed>
	</bug>
	<bug>
		<id>3415</id>
		<title>Deployment of integration not using latest connection metadata if draft integration not edited first</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  1. Connection SqlConn1 is created with a username of "sampleDB"; 2. Integration IntegA is created depending on connection SqlConn1; 3. Connection SqlConn1 is modified (username amended to "AABB"); 4. IntegA is deployed.  - After step 3, the draft IntegA still contains a nested connection of SqlConn1 with a username of "sampleDB" NOT "AABB"; - At step 4, the deployment of IntegA uses the existing draft integration of IntegA hence the deployment is generated with SqlConn1 with a username of "sampleDB" NOT "AABB".  #### Note: Only when the integration is actually edited will it be updated with the latest connection metadata. Therefore, the workaround is to edit the integration between steps 3 and 4.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  - When a connection is modified, all associated draft integrations should be updated automatically to the latest connection metadata; - When an integration is deployed, it should be checked for the latest connection metadata and the deployment should deploy with that information;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt;  See above. </body>
		<created>2018-08-21 13:03:27</created>
		<closed>2018-12-12 16:28:52</closed>
	</bug>
	<bug>
		<id>3414</id>
		<title>Use webhook without any data shape</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; If I create an integration starting from the webhook I need to specify the data shape, if I don't by selecting _"Type specification not required"_ then the mapping step can't be added after the webhook. That is I get an error _"No supported source data type was found. Data type needs to be configured before Data Mapper step is added._".  I'd like to create integrations where I can go from a webhook to a connection needing some data by using the mapping step to provide data with constants or I would opt to provide a constant value for the connection after the webhook.  I think we either need to support `any` (`none` for timer?) data shape in the mapper, or we need a step to set the constant data.  Am I missing something? Kinda makes webhooks not like timers and timers not like webhooks.  ## Expected behaviour &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Create an integration that starts with webhook without providing any data and use connections that require some data.  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Try creating integration that starts with webhook without any data (Type specification not required) 2. Try adding any connection as end 3. Try adding mapper step in between 4. </body>
		<created>2018-08-21 09:06:45</created>
		<closed>2018-12-12 16:28:50</closed>
	</bug>
	<bug>
		<id>3412</id>
		<title>Embedded Apicur.io Editor Minor Issues</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; These issues are applicable to the apicur.io editor which is embedded in syndesis. Therefore, they will probably be fixed upstream?  - On first display of the editor, the save tooltip is displayed narrowly in a long vertical block with 1-2 words per line (see https://issues.jboss.org/secure/attachment/12439213/apicurio-save-button-tooltip.png);  - There is some odd behaviour with the 'Contact Info' controls:     - Enter name but leave other inputs blank;     - Dialog disappears but message 'None Found ..." message is redisplayed even though there is a name. Error is displayed indicating a valid email address must be provided;     - Fixing Contact Info by reopening and editing does not clear previous errors - only when clicking Save is the error removed;     - Enter all info so no errors then reopen and remove the email address;     - Clicking OK gives an error that "The "url" property must be a valid URL." rather than there being no email address;     - Clicking Save fixes this and displays the correct error, ie. no email address.  - Clicking Save   - Would be beneficial if errors were flagged up to user prior to returning to the Review Actions page, ie. "You are saving a spec with errors. Would you like to fix them first?" and focus returns to the editor.      ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; - Save Tooltip to display in an appropriately wide rectangle; - Contact Info controls to correctly handle all different combinations of inputs and display appropriate errors messages; - Save button to flag validation errors prior to exiting the editor.     ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-08-20 14:53:57</created>
		<closed>2019-01-01 16:11:57</closed>
	</bug>
	<bug>
		<id>3405</id>
		<title>Failed to stop integration Error stopping integration: [object Object] during publishing </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem Currently it's not possible to stop integration during publishing,  _Failed to stop integration Error stopping integration: [object Object]_ is displayed. I can delete integration though.   ## Expected behavior I should be able to stop integration during publishing. When I make some mistake I can't edit either so for fixing it I have to delete it and create new one.   ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-08-20 09:24:29</created>
		<closed>2018-10-17 14:51:42</closed>
	</bug>
	<bug>
		<id>3404</id>
		<title>Importing integration from another syndesis instance does not work</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Importing integration from another instance will import the integration, but the integration can not start and stays in "Assembling" state forever: ![screenshot_20180820_102837](https://user-images.githubusercontent.com/14313995/44329089-d231d980-a463-11e8-934e-eaccabb65ea4.png)  Syndesis version: 1.4.6   </body>
		<created>2018-08-20 08:48:21</created>
		<closed>2018-10-02 08:00:22</closed>
	</bug>
	<bug>
		<id>3400</id>
		<title>Deleting activity entries when the integration is deleted</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; We seem to keep the activity logs for deleted integrations. We should delete those when an integration is deleted. Also seems that the ActivityController is checking the status of deleted integrations, that should not be the case.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; No entries in activities for deleted integrations. Don't consider integrations that have been deleted.  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create integration, publish it and let it run to gather some activity entries 2. Delete the integrations 3. Notice the activity entries in the JSONDB 4. Notice that the ActivityTrackingController is logging `deleted X transactions for integration: id-of-the-deleted-integration` </body>
		<created>2018-08-17 14:19:27</created>
		<closed>2018-12-12 16:28:49</closed>
	</bug>
	<bug>
		<id>3399</id>
		<title>ServiceNow connector:  `Unexpected character (']' (code 93)):` when optional fields are empty </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem Currently _Retrieve Record_ action in serviceNow step has two optional parameters _The query used to filter the result set_ and _Limit of elements per page_.  When I try to retrieve records from Incident table (more that 20 000 incidents)with both empty I can see following exception in pod:  ```2018-08-17 12:06:28.116 ERROR 1 --- [r://integration] o.a.camel.processor.DefaultErrorHandler  : Failed delivery for (MessageId: i-LK6ltcDQuByAtpu6TsSz on ExchangeId: i-LK6ldyvQuByAtpu6TsRz). Exhausted after delivery attempt: 1 caught: javax.ws.rs.client.ResponseProcessingException: Problem with reading the data, class com.fasterxml.jackson.databind.JsonNode, ContentType: application/json;charset=UTF-8. --  | Message History  | ---------------------------------------------------------------------------------------------------------------------------------------  | RouteId              ProcessorId          Processor                                                                        Elapsed (ms)  | [-LK6usU0hqrFaHJ6Vc] [-LK6usU0hqrFaHJ6Vc] [timer://integration?period=60000                                              ] [     64086]  | [-LK6usU0hqrFaHJ6Vc] [to1               ] [servicenow-1                                                                  ] [     64073]  | Stacktrace  | ---------------------------------------------------------------------------------------------------------------------------------------  | javax.ws.rs.client.ResponseProcessingException: Problem with reading the data, class com.fasterxml.jackson.databind.JsonNode, ContentType: application/json;charset=UTF-8.  | at org.apache.cxf.jaxrs.impl.ResponseImpl.reportMessageHandlerProblem(ResponseImpl.java:446) ~[cxf-rt-frontend-jaxrs-3.1.11.fuse-000263.jar!/:3.1.11.fuse-000263]  | at org.apache.cxf.jaxrs.impl.ResponseImpl.doReadEntity(ResponseImpl.java:386) ~[cxf-rt-frontend-jaxrs-3.1.11.fuse-000263.jar!/:3.1.11.fuse-000263]  | at org.apache.cxf.jaxrs.impl.ResponseImpl.readEntity(ResponseImpl.java:321) ~[cxf-rt-frontend-jaxrs-3.1.11.fuse-000263.jar!/:3.1.11.fuse-000263]  | at org.apache.cxf.jaxrs.impl.ResponseImpl.readEntity(ResponseImpl.java:311) ~[cxf-rt-frontend-jaxrs-3.1.11.fuse-000263.jar!/:3.1.11.fuse-000263]  | at org.apache.camel.component.servicenow.AbstractServiceNowProcessor.setBody(AbstractServiceNowProcessor.java:110) ~[camel-servicenow-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.component.servicenow.AbstractServiceNowProcessor.setBodyAndHeaders(AbstractServiceNowProcessor.java:59) ~[camel-servicenow-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.component.servicenow.releases.helsinki.HelsinkiServiceNowTableProcessor.retrieveRecord(HelsinkiServiceNowTableProcessor.java:90) ~[camel-servicenow-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.component.servicenow.ServiceNowDispatcher.process(ServiceNowDispatcher.java:40) ~[camel-servicenow-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.component.servicenow.AbstractServiceNowProcessor.process(AbstractServiceNowProcessor.java:70) ~[camel-servicenow-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.impl.BaseSelectorProducer.process(BaseSelectorProducer.java:35) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at io.syndesis.integration.component.proxy.ComponentProxyProducer.process(ComponentProxyProducer.java:44) ~[integration-component-proxy-1.4.5.jar!/:1.4.5]  | at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at java.util.TimerThread.mainLoop(Timer.java:555) [na:1.8.0_151]  | at java.util.TimerThread.run(Timer.java:505) [na:1.8.0_151]  | Caused by: com.fasterxml.jackson.core.JsonParseException: Unexpected character (']' (code 93)): expected a value  | at [Source: sun.net.www.protocol.http.HttpURLConnection$HttpInputStream@701f452b; line: 1, column: 12706756]  | at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1702) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:558) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:456) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleUnexpectedValue(UTF8StreamJsonParser.java:2656) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:878) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:772) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.databind.deser.std.BaseNodeDeserializer.deserializeArray(JsonNodeDeserializer.java:269) ~[jackson-databind-2.8.11.1.jar!/:2.8.11.1]  | at com.fasterxml.jackson.databind.deser.std.BaseNodeDeserializer.deserializeObject(JsonNodeDeserializer.java:232) ~[jackson-databind-2.8.11.1.jar!/:2.8.11.1]  | at com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:69) ~[jackson-databind-2.8.11.1.jar!/:2.8.11.1]  | at com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:15) ~[jackson-databind-2.8.11.1.jar!/:2.8.11.1]  | at com.fasterxml.jackson.databind.ObjectReader._bind(ObjectReader.java:1583) ~[jackson-databind-2.8.11.1.jar!/:2.8.11.1]  | at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:964) ~[jackson-databind-2.8.11.1.jar!/:2.8.11.1]  | at com.fasterxml.jackson.jaxrs.base.ProviderBase.readFrom(ProviderBase.java:815) ~[jackson-jaxrs-base-2.8.11.jar!/:2.8.11]  | at org.apache.cxf.jaxrs.utils.JAXRSUtils.readFromMessageBodyReader(JAXRSUtils.java:1354) ~[cxf-rt-frontend-jaxrs-3.1.11.fuse-000263.jar!/:3.1.11.fuse-000263]  | at org.apache.cxf.jaxrs.impl.ResponseImpl.doReadEntity(ResponseImpl.java:377) ~[cxf-rt-frontend-jaxrs-3.1.11.fuse-000263.jar!/:3.1.11.fuse-000263]  | ... 23 common frames omitted  | {"exchange":"i-LK6ldyvQuByAtpu6TsRz","status":"done","failed":true}  | 2018-08-17 12:06:28.117  WARN 1 --- [r://integration] o.a.camel.component.timer.TimerConsumer  : Error processing exchange. Exchange[i-LK6ldyvQuByAtpu6TsRz]. Caused by: [javax.ws.rs.client.ResponseProcessingException - Problem with reading the data, class com.fasterxml.jackson.databind.JsonNode, ContentType: application/json;charset=UTF-8.]  | javax.ws.rs.client.ResponseProcessingException: Problem with reading the data, class com.fasterxml.jackson.databind.JsonNode, ContentType: application/json;charset=UTF-8.  | at org.apache.cxf.jaxrs.impl.ResponseImpl.reportMessageHandlerProblem(ResponseImpl.java:446) ~[cxf-rt-frontend-jaxrs-3.1.11.fuse-000263.jar!/:3.1.11.fuse-000263]  | at org.apache.cxf.jaxrs.impl.ResponseImpl.doReadEntity(ResponseImpl.java:386) ~[cxf-rt-frontend-jaxrs-3.1.11.fuse-000263.jar!/:3.1.11.fuse-000263]  | at org.apache.cxf.jaxrs.impl.ResponseImpl.readEntity(ResponseImpl.java:321) ~[cxf-rt-frontend-jaxrs-3.1.11.fuse-000263.jar!/:3.1.11.fuse-000263]  | at org.apache.cxf.jaxrs.impl.ResponseImpl.readEntity(ResponseImpl.java:311) ~[cxf-rt-frontend-jaxrs-3.1.11.fuse-000263.jar!/:3.1.11.fuse-000263]  | at org.apache.camel.component.servicenow.AbstractServiceNowProcessor.setBody(AbstractServiceNowProcessor.java:110) ~[camel-servicenow-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.component.servicenow.AbstractServiceNowProcessor.setBodyAndHeaders(AbstractServiceNowProcessor.java:59) ~[camel-servicenow-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.component.servicenow.releases.helsinki.HelsinkiServiceNowTableProcessor.retrieveRecord(HelsinkiServiceNowTableProcessor.java:90) ~[camel-servicenow-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.component.servicenow.ServiceNowDispatcher.process(ServiceNowDispatcher.java:40) ~[camel-servicenow-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.component.servicenow.AbstractServiceNowProcessor.process(AbstractServiceNowProcessor.java:70) ~[camel-servicenow-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.impl.BaseSelectorProducer.process(BaseSelectorProducer.java:35) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at io.syndesis.integration.component.proxy.ComponentProxyProducer.process(ComponentProxyProducer.java:44) ~[integration-component-proxy-1.4.5.jar!/:1.4.5]  | at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at java.util.TimerThread.mainLoop(Timer.java:555) [na:1.8.0_151]  | at java.util.TimerThread.run(Timer.java:505) [na:1.8.0_151]  | Caused by: com.fasterxml.jackson.core.JsonParseException: Unexpected character (']' (code 93)): expected a value  | at [Source: sun.net.www.protocol.http.HttpURLConnection$HttpInputStream@701f452b; line: 1, column: 12706756]  | at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1702) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:558) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:456) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleUnexpectedValue(UTF8StreamJsonParser.java:2656) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:878) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:772) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.databind.deser.std.BaseNodeDeserializer.deserializeArray(JsonNodeDeserializer.java:269) ~[jackson-databind-2.8.11.1.jar!/:2.8.11.1]  | at com.fasterxml.jackson.databind.deser.std.BaseNodeDeserializer.deserializeObject(JsonNodeDeserializer.java:232) ~[jackson-databind-2.8.11.1.jar!/:2.8.11.1]  | at com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:69) ~[jackson-databind-2.8.11.1.jar!/:2.8.11.1]  | at com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:15) ~[jackson-databind-2.8.11.1.jar!/:2.8.11.1]  | at com.fasterxml.jackson.databind.ObjectReader._bind(ObjectReader.java:1583) ~[jackson-databind-2.8.11.1.jar!/:2.8.11.1]  | at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:964) ~[jackson-databind-2.8.11.1.jar!/:2.8.11.1]  | at com.fasterxml.jackson.jaxrs.base.ProviderBase.readFrom(ProviderBase.java:815) ~[jackson-jaxrs-base-2.8.11.jar!/:2.8.11]  | at org.apache.cxf.jaxrs.utils.JAXRSUtils.readFromMessageBodyReader(JAXRSUtils.java:1354) ~[cxf-rt-frontend-jaxrs-3.1.11.fuse-000263.jar!/:3.1.11.fuse-000263]  | at org.apache.cxf.jaxrs.impl.ResponseImpl.doReadEntity(ResponseImpl.java:377) ~[cxf-rt-frontend-jaxrs-3.1.11.fuse-000263.jar!/:3.1.11.fuse-000263]  | ... 23 common frames omitted  | {"exchange":"i-LK6ltcLQuByAtpu6TsTz","status":"begin"} ``` &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  According documentation: _Limit of elements per page_ should have default value 1000 which is not true because if I set limit to 1000 manually, integration is working.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-08-17 13:21:53</created>
		<closed>2018-10-08 14:53:22</closed>
	</bug>
	<bug>
		<id>3390</id>
		<title>Have a canned error response in the webhook connector</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [x] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When the exception occurs in the webhook the body of the response contains the stack trace of the exception that occurs. This breaks the abstraction and leaks internal details of the integration. We should have a canned response with few details, perhaps similar to how we have REST errors for the UI.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Don't leak internal details, have an error that can be consumed by the webhook client.  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. We should define how this error looks like 2. Add Camel error handler to the route with the webhook 3. Think about Accept-header Content-Type for the return body (or just return JSON in all cases?) 4. </body>
		<created>2018-08-16 06:00:16</created>
		<closed>2018-12-12 16:28:46</closed>
	</bug>
	<bug>
		<id>3389</id>
		<title>Webhook support for GET methods requires HTTP body</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When specifying JSON schema for webhook, we need to specify the `body` parameter. When processing the GET request webhook connector tries to parse a empty stream and that results in: ``` com.fasterxml.jackson.databind.JsonMappingException: No content to map due to end-of-input  at [Source: org.apache.camel.converter.stream.InputStreamCache@a5362c9; line: 1, column: 0] ```  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Be able to specify body-less JSON schema and be able to use GET requests without issues.  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create integration with a webhook start 2. Specify this JSON schema for data shape: ```json {   "type": "object",   "definitions": {},   "$schema": "http://json-schema.org/draft-07/schema#",   "id": "io:syndesis:webhook",   "properties": {     "parameters": {       "type": "object",       "properties": {         "q": {           "type": "string"         }       }     }   } } ``` 3. Invoke the webhook via curl: ```shell $ curl 'https://webhook-hostname/webhook/webhook-token?q=42' ``` </body>
		<created>2018-08-15 13:39:19</created>
		<closed>2018-08-20 14:20:33</closed>
	</bug>
	<bug>
		<id>3388</id>
		<title>Custom API connector: Camel sends Accept: application/json for XML endpoints</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Having a custom API connector with a method that returns application/xml - the integration sends a request with Accept: application/json that results in HTTP 406 exception.    ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; To send Accept: application/xml when the endpoint specification says that it returns application/xml  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  This is the request from the integration: ``` GET /api/getXml HTTP/1.1 --  | Accept: application/json  | breadcrumbId: i-LJxezNjcn-m8cLrLkCuz  | firedTime: Wed Aug 15 13:00:04 UTC 2018  | Syndesis.STEP_ID: -LJxbTKc6sjAjo81pzTq  | Syndesis.STEP_TRACKER_ID: i-LJxezNncn-m8cLrLkCwz  | Host: http-svc:8080  | Connection: Keep-Alive  | User-Agent: Apache-HttpClient/4.5.5 (Java/1.8.0_151)  | Accept-Encoding: gzip,deflate ```  Exception: ``` org.apache.camel.http.common.HttpOperationFailedException: HTTP operation failed invoking http://http-svc:8080/api/getXml  with statusCode: 406 --  | at org.apache.camel.component.http4.HttpProducer.populateHttpOperationFailedException(HttpProducer.java:312) ~[camel-http4-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.component.http4.HttpProducer.process(HttpProducer.java:207) ~[camel-http4-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.component.rest.RestProducer.process(RestProducer.java:86) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.component.connector.ConnectorProducer.process(ConnectorProducer.java:45) ~[camel-connector-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) [integration-runtime-1.5-SNAPSHOT.jar!/:1.5-SNAPSHOT]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at java.util.TimerThread.mainLoop(Timer.java:555) [na:1.8.0_151]  | at java.util.TimerThread.run(Timer.java:505) [na:1.8.0_151] ```  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  Swagger: ``` {   "swagger": "2.0",   "info": {     "description": "Endpoints for custom connector tests",     "version": "1.0",     "title": "HTTP Endpoints",     "termsOfService": "https://www.google.com",     "contact": {       "name": "John Doe",       "url": "https://www.google.com",       "email": "johndoe@acme.com"     },     "license": {       "name": "Apache 2.0",       "url": "http://www.apache.org/licenses/LICENSE-2.0"     }   },   "host": "localhost:8080",   "basePath": "/",   "tags": [     {       "name": "HTTP Endpoints",       "description": "Endpoints for custom connector tests"     },     {       "name": "delete-json",       "description": "Delete Json"     },     {       "name": "delete-xml",       "description": "Delete Xml"     },     {       "name": "get-json",       "description": "Get Json"     },     {       "name": "get-xml",       "description": "Get Xml"     },     {       "name": "post-json",       "description": "Post Json"     },     {       "name": "post-xml",       "description": "Post Xml"     },     {       "name": "put-json",       "description": "Put Json"     },     {       "name": "put-xml",       "description": "Put Xml"     }   ],   "schemes": [     "http"   ],   "paths": {     "/api/deleteJson": {       "delete": {         "tags": [           "delete-json"         ],         "summary": "deleteJson",         "operationId": "deleteJsonUsingDELETE",         "produces": [           "application/json"         ],         "responses": {           "200": {             "description": "OK",             "schema": {               "type": "string"             }           },           "204": {             "description": "No Content"           },           "401": {             "description": "Unauthorized"           },           "403": {             "description": "Forbidden"           }         },         "deprecated": false       }     },     "/api/deleteXml": {       "delete": {         "tags": [           "delete-xml"         ],         "summary": "deleteXml",         "operationId": "deleteXmlUsingDELETE",         "produces": [           "application/xml"         ],         "responses": {           "200": {             "description": "OK",             "schema": {               "$ref": "#/definitions/XmlResponse"             }           },           "204": {             "description": "No Content"           },           "401": {             "description": "Unauthorized"           },           "403": {             "description": "Forbidden"           }         },         "deprecated": false       }     },     "/api/getJson": {       "get": {         "tags": [           "get-json"         ],         "summary": "getJson",         "operationId": "getJsonUsingGET",         "produces": [           "application/json"         ],         "responses": {           "200": {             "description": "OK",             "schema": {               "type": "string"             }           },           "401": {             "description": "Unauthorized"           },           "403": {             "description": "Forbidden"           },           "404": {             "description": "Not Found"           }         },         "deprecated": false       }     },     "/api/getXml": {       "get": {         "tags": [           "get-xml"         ],         "summary": "getXml",         "operationId": "getXmlUsingGET",         "produces": [           "application/xml"         ],         "responses": {           "200": {             "description": "OK",             "schema": {               "$ref": "#/definitions/XmlResponse"             }           },           "401": {             "description": "Unauthorized"           },           "403": {             "description": "Forbidden"           },           "404": {             "description": "Not Found"           }         },         "deprecated": false       }     },     "/api/postJson": {       "post": {         "tags": [           "post-json"         ],         "summary": "postJson",         "operationId": "postJsonUsingPOST",         "consumes": [           "application/json"         ],         "produces": [           "application/json"         ],         "responses": {           "200": {             "description": "OK",             "schema": {               "type": "string"             }           },           "201": {             "description": "Created"           },           "401": {             "description": "Unauthorized"           },           "403": {             "description": "Forbidden"           },           "404": {             "description": "Not Found"           }         },         "deprecated": false       }     },     "/api/postXml": {       "post": {         "tags": [           "post-xml"         ],         "summary": "postXml",         "operationId": "postXmlUsingPOST",         "consumes": [           "application/json"         ],         "produces": [           "application/xml"         ],         "responses": {           "200": {             "description": "OK",             "schema": {               "$ref": "#/definitions/XmlResponse"             }           },           "201": {             "description": "Created"           },           "401": {             "description": "Unauthorized"           },           "403": {             "description": "Forbidden"           },           "404": {             "description": "Not Found"           }         },         "deprecated": false       }     },     "/api/putJson": {       "put": {         "tags": [           "put-json"         ],         "summary": "putJson",         "operationId": "putJsonUsingPUT",         "consumes": [           "application/json"         ],         "produces": [           "application/json"         ],         "responses": {           "200": {             "description": "OK",             "schema": {               "type": "string"             }           },           "201": {             "description": "Created"           },           "401": {             "description": "Unauthorized"           },           "403": {             "description": "Forbidden"           },           "404": {             "description": "Not Found"           }         },         "deprecated": false       }     },     "/api/putXml": {       "put": {         "tags": [           "put-xml"         ],         "summary": "putXml",         "operationId": "putXmlUsingPUT",         "consumes": [           "application/json"         ],         "produces": [           "application/xml"         ],         "responses": {           "200": {             "description": "OK",             "schema": {               "$ref": "#/definitions/XmlResponse"             }           },           "201": {             "description": "Created"           },           "401": {             "description": "Unauthorized"           },           "403": {             "description": "Forbidden"           },           "404": {             "description": "Not Found"           }         },         "deprecated": false       }     }   },   "definitions": {     "XmlResponse": {       "type": "object",       "properties": {         "prop1": {           "type": "string",           "xml": {             "name": "first",             "attribute": false,             "wrapped": false           }         }       },       "title": "XmlResponse",       "xml": {         "name": "XmlResponse",         "attribute": false,         "wrapped": false       }     }   } } ```  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-08-15 13:06:32</created>
		<closed>2018-11-08 13:26:45</closed>
	</bug>
	<bug>
		<id>3384</id>
		<title>Fetching connections is broken when there is integration with datamapper deployed</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  First of all, this is on master only - therefore I introduced new label "master" (that can be removed after this one is solved), it is not an issue in 1.4.5  When the integration containing datamapper is successfully created and provisioned, fetching connections is broken, because of the change introduced in #3256 , in particular probably in this line: https://github.com/syndesisio/syndesis/pull/3256/files#diff-deb6adbcb1d4eb759e992784fa73c217R272 as the datamapper step does not have any connection.   See steps to reproduce  ```  java.util.NoSuchElementException: No value present --  | at java.util.Optional.get(Optional.java:135) ~[na:1.8.0_151]  | at io.syndesis.server.endpoint.v1.handler.connection.ConnectionHandler.lambda$augmentedWithUsage$2(ConnectionHandler.java:265) ~[server-endpoint-1.5-SNAPSHOT.jar!/:1.5-SNAPSHOT]  | at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[na:1.8.0_151]  | at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1380) ~[na:1.8.0_151]  | at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ~[na:1.8.0_151]  | at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ~[na:1.8.0_151]  | at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ~[na:1.8.0_151]  | at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[na:1.8.0_151]  | at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ~[na:1.8.0_151]  | at io.syndesis.server.endpoint.v1.handler.connection.ConnectionHandler.lambda$augmentedWithUsage$3(ConnectionHandler.java:266) ~[server-endpoint-1.5-SNAPSHOT.jar!/:1.5-SNAPSHOT]  | at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267) ~[na:1.8.0_151]  | at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ~[na:1.8.0_151]  | at java.util.Collections$2.tryAdvance(Collections.java:4717) ~[na:1.8.0_151]  | at java.util.Collections$2.forEachRemaining(Collections.java:4725) ~[na:1.8.0_151]  | at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ~[na:1.8.0_151]  | at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ~[na:1.8.0_151]  | at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ~[na:1.8.0_151]  | at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[na:1.8.0_151]  | at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ~[na:1.8.0_151]  | at io.syndesis.server.endpoint.v1.handler.connection.ConnectionHandler.augmentedWithUsage(ConnectionHandler.java:273) ~[server-endpoint-1.5-SNAPSHOT.jar!/:1.5-SNAPSHOT]  | at io.syndesis.server.endpoint.v1.handler.connection.ConnectionHandler.list(ConnectionHandler.java:111) ~[server-endpoint-1.5-SNAPSHOT.jar!/:1.5-SNAPSHOT]  | at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_151]  | at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_151]  | at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151]  | at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151]  | at org.jboss.resteasy.core.MethodInjectorImpl.invoke(MethodInjectorImpl.java:140) ~[resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.core.ResourceMethodInvoker.internalInvokeOnTarget(ResourceMethodInvoker.java:510) ~[resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTargetAfterFilter(ResourceMethodInvoker.java:401) ~[resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.core.ResourceMethodInvoker.lambda$invokeOnTarget$0(ResourceMethodInvoker.java:365) ~[resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:361) ~[resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTarget(ResourceMethodInvoker.java:367) ~[resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:339) ~[resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:312) ~[resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:441) [resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.core.SynchronousDispatcher.lambda$invoke$4(SynchronousDispatcher.java:231) [resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.core.SynchronousDispatcher.lambda$preprocess$0(SynchronousDispatcher.java:137) [resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:361) ~[resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.core.SynchronousDispatcher.preprocess(SynchronousDispatcher.java:140) [resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:217) [resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.plugins.server.servlet.ServletContainerDispatcher.service(ServletContainerDispatcher.java:227) ~[resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:56) ~[resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:51) ~[resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) ~[javax.servlet-api-3.1.0.jar!/:3.1.0]  | at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) ~[spring-boot-1.5.13.RELEASE.jar!/:1.5.13.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:111) ~[spring-boot-actuator-1.5.13.RELEASE.jar!/:1.5.13.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.security.web.authentication.preauth.AbstractPreAuthenticatedProcessingFilter.doFilter(AbstractPreAuthenticatedProcessingFilter.java:121) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.security.web.csrf.CsrfFilter.doFilterInternal(CsrfFilter.java:100) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:66) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) ~[spring-security-web-4.2.6.RELEASE.jar!/:4.2.6.RELEASE]  | at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at org.springframework.cloud.sleuth.instrument.web.TraceFilter.doFilter(TraceFilter.java:186) ~[spring-cloud-sleuth-core-1.2.6.RELEASE.jar!/:1.2.6.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:106) ~[spring-boot-actuator-1.5.13.RELEASE.jar!/:1.5.13.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:64) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:132) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.server.Connectors.executeRootHandler(Connectors.java:336) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final]  | at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_151]  | at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_151]  | at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_151]   ```  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. create an integration with datamapper step 2. wait for the provisioning of the integration 3. refresh(F5) the main page of syndesis and notice that the bottom part with connections is still loading 4. check server logs </body>
		<created>2018-08-15 08:15:52</created>
		<closed>2018-08-15 15:12:46</closed>
	</bug>
	<bug>
		<id>3382</id>
		<title>API Connector - Reponse mapping</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When trying to map an API Connector's output to another datashape with a DataMapper I get the following error in the log:  ``` {"exchange":"i-LJtjJ_t7gG7dxPzNpC1z","step":"-LJtGGNaGeegiSb7Dn6a","id":"i-LJtjJhW7gG7dxPzNpC5z","message":"Body: [{\"parameters\":{\"id\":\"quoting\"},\"body\":{\"lookup\":\"ksession\",\"commands\":[{\"insert\":{\"return-object\":true,\"out-identifier\":\"quote1\",\"object\":{\"com.redhat.insurancequoting.Quote\":{\"price\":0,\"driver\":{\"age\":20,\"fines\":2},\"vehicle\":{\"mileage\":500,\"modelYear\":2017}}}}}]}}] LOQUEMANDO:"} --  | 2018-08-14 18:40:31.585  INFO 1 --- [ Session Task-2] -LJtE092GeegiSb7Dn6_                     : Body: [{"parameters":{"id":"quoting"},"body":{"lookup":"ksession","commands":[{"insert":{"return-object":true,"out-identifier":"quote1","object":{"com.redhat.insurancequoting.Quote":{"price":0,"driver":{"age":20,"fines":2},"vehicle":{"mileage":500,"modelYear":2017}}}}}]}}] LOQUEMANDO:  | {"exchange":"i-LJtjJ_t7gG7dxPzNpC1z","step":"-LJtGGNaGeegiSb7Dn6a","id":"i-LJtjJhU7gG7dxPzNpC4z","duration":2347192}  | {"exchange":"i-LJtjJ_t7gG7dxPzNpC1z","step":"none","id":"i-LJtjJhX7gG7dxPzNpC6z","duration":408509716}  | {"exchange":"i-LJtjJ_t7gG7dxPzNpC1z","step":"-LJtEHtjGeegiSb7Dn6_","id":"i-LJtjJnv7gG7dxPzNpC7z","duration":119778385}  | {"exchange":"i-LJtjJ_t7gG7dxPzNpC1z","step":"-LJtiCAkGeegiSb7Dn6b","id":"i-LJtjJpn7gG7dxPzNpC9z","duration":349888}  | 2018-08-14 18:40:32.124 ERROR 1 --- [ Session Task-2] o.a.camel.processor.DefaultErrorHandler  : Failed delivery for (MessageId: i-LJtjJpn7gG7dxPzNpC8z on ExchangeId: i-LJtjJ_t7gG7dxPzNpC1z). Exhausted after delivery attempt: 1 caught: java.lang.NullPointerException  |   | Message History  | ---------------------------------------------------------------------------------------------------------------------------------------  | RouteId              ProcessorId          Processor                                                                        Elapsed (ms)  | [-LJtE092GeegiSb7Dn] [-LJtE092GeegiSb7Dn] [sjms-sjms-1://queue:cola1                                                     ] [      1016]  | [-LJtE092GeegiSb7Dn] [setHeader1        ] [setHeader[Syndesis.STEP_ID]                                                   ] [         5]  | [-LJtE092GeegiSb7Dn] [process1          ] [Processor@0x6aa63c8a                                                          ] [         2]  | [-LJtE092GeegiSb7Dn] [step:i-LJtjBLP7gG7] [pipeline                                                                      ] [       446]  | [-LJtE092GeegiSb7Dn] [setHeader2        ] [setHeader[Syndesis.STEP_ID]                                                   ] [         0]  | [-LJtE092GeegiSb7Dn] [to1               ] [atlas:mapping-step-2.json?sourceMapName=Syndesis.CAPTURED_OUT_MESSAGES_MAP    ] [       442]  | [-LJtE092GeegiSb7Dn] [process2          ] [Processor@0x6aa63c8a                                                          ] [         0]  | [-LJtE092GeegiSb7Dn] [step:-LJtGGNaGeegi] [pipeline                                                                      ] [         3]  | [-LJtE092GeegiSb7Dn] [setHeader3        ] [setHeader[Syndesis.STEP_ID]                                                   ] [         0]  | [-LJtE092GeegiSb7Dn] [log1              ] [log                                                                           ] [         2]  | [-LJtE092GeegiSb7Dn] [process3          ] [Processor@0x6aa63c8a                                                          ] [         0]  | [-LJtE092GeegiSb7Dn] [step:-LJtgB73Geegi] [pipeline                                                                      ] [       409]  | [-LJtE092GeegiSb7Dn] [setHeader4        ] [setHeader[Syndesis.STEP_ID]                                                   ] [         0]  | [-LJtE092GeegiSb7Dn] [process4          ] [Processor@0x6a9ab242                                                          ] [       407]  | [-LJtE092GeegiSb7Dn] [process5          ] [Processor@0x6aa63c8a                                                          ] [         0]  | [-LJtE092GeegiSb7Dn] [step:-LJtEHtjGeegi] [pipeline                                                                      ] [       120]  | [-LJtE092GeegiSb7Dn] [setHeader5        ] [setHeader[Syndesis.STEP_ID]                                                   ] [         0]  | [-LJtE092GeegiSb7Dn] [to2               ] [swagger-operation-5?operationId=manageContainer                               ] [       118]  | [-LJtE092GeegiSb7Dn] [process6          ] [Processor@0x6aa63c8a                                                          ] [         0]  | [-LJtE092GeegiSb7Dn] [step:-LJtiCAkGeegi] [pipeline                                                                      ] [         1]  | [-LJtE092GeegiSb7Dn] [setHeader6        ] [setHeader[Syndesis.STEP_ID]                                                   ] [         0]  | [-LJtE092GeegiSb7Dn] [to3               ] [mock-6                                                                        ] [         1]  | [-LJtE092GeegiSb7Dn] [process7          ] [Processor@0x6aa63c8a                                                          ] [         0]  | [-LJtE092GeegiSb7Dn] [step:-LJtiPSlGeegi] [pipeline                                                                      ] [         0]  | [-LJtE092GeegiSb7Dn] [setHeader7        ] [setHeader[Syndesis.STEP_ID]                                                   ] [         0]  | [-LJtE092GeegiSb7Dn] [to4               ] [atlas:mapping-step-7.json?sourceMapName=Syndesis.CAPTURED_OUT_MESSAGES_MAP    ] [         2]  |   | Stacktrace  | ---------------------------------------------------------------------------------------------------------------------------------------  |   | java.lang.NullPointerException: null  | at io.atlasmap.json.module.JsonModule.getCollectionSize(JsonModule.java:218) ~[atlas-json-module-1.34.5.fuse-000001-redhat-3.jar!/:1.34.5.fuse-000001-redhat-3]  | at io.atlasmap.core.DefaultAtlasContext.extractCollectionMappings(DefaultAtlasContext.java:333) ~[atlas-core-1.34.5.fuse-000001-redhat-3.jar!/:1.34.5.fuse-000001-redhat-3]  | at io.atlasmap.core.DefaultAtlasContext.process(DefaultAtlasContext.java:252) ~[atlas-core-1.34.5.fuse-000001-redhat-3.jar!/:1.34.5.fuse-000001-redhat-3]  | at org.apache.camel.component.atlasmap.AtlasEndpoint.onExchange(AtlasEndpoint.java:194) ~[camel-atlasmap-1.34.5.fuse-000001-redhat-3.jar!/:na]  | at org.apache.camel.impl.ProcessorEndpoint$1.process(ProcessorEndpoint.java:71) ~[camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3]  | at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3]  | at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) ~[camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3]  | at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3]  | at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:77) [integration-runtime-1.3.12.fuse-000001-redhat-2.jar!/:1.3.12.fuse-000001-redhat-2]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3]  | at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3]  | at org.apache.camel.util.AsyncProcessorHelper.process(AsyncProcessorHelper.java:109) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:80) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3]  | at org.apache.camel.component.sjms.consumer.InOnlyMessageHandler.handleMessage(InOnlyMessageHandler.java:65) [camel-sjms-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3]  | at org.apache.camel.component.sjms.consumer.AbstractMessageHandler.onMessage(AbstractMessageHandler.java:86) [camel-sjms-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3]  | at org.apache.activemq.ActiveMQMessageConsumer.dispatch(ActiveMQMessageConsumer.java:1401) [activemq-client-5.14.5.jar!/:5.14.5]  | at org.apache.activemq.ActiveMQSessionExecutor.dispatch(ActiveMQSessionExecutor.java:131) [activemq-client-5.14.5.jar!/:5.14.5]  | at org.apache.activemq.ActiveMQSessionExecutor.iterate(ActiveMQSessionExecutor.java:202) [activemq-client-5.14.5.jar!/:5.14.5]  | at org.apache.activemq.thread.PooledTaskRunner.runTask(PooledTaskRunner.java:133) [activemq-client-5.14.5.jar!/:5.14.5]  | at org.apache.activemq.thread.PooledTaskRunner$1.run(PooledTaskRunner.java:48) [activemq-client-5.14.5.jar!/:5.14.5]  | at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_171]  | at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_171]  | at java.lang.Thread.run(Thread.java:748) [na:1.8.0_171]  ```  Export of the integration: [amqToRHDMtoAmq-export.zip](https://github.com/syndesisio/syndesis/files/2288215/amqToRHDMtoAmq-export.zip)  Syndesis version: 1.3.12.fuse-000001-redhat-2  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Be able to map an API connector's output to another dataformat.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![image](https://user-images.githubusercontent.com/10658194/44111411-b38eab50-9fd8-11e8-9ce8-4fa174d8c17f.png)   ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1.Create connection to AMQ 2.Create connection to API [Insurance Quoting.json.txt](https://github.com/syndesisio/syndesis/files/2288224/Insurance.Quoting.json.txt) 3. Create integration from AMQ -&gt; DataMapper -&gt; API -&gt; DataMapper -&gt; AMQ </body>
		<created>2018-08-14 19:33:31</created>
		<closed>2018-08-20 09:58:20</closed>
	</bug>
	<bug>
		<id>3378</id>
		<title>Upgrade pod's version needs to be hardcoded in the productised template</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt; Currently the upgrade pod version is specified as a template parameter, but it should be hardcoded in  https://github.com/syndesisio/fuse-online-install/blob/6f24eb483f21d0b8b588794ffcc02491ba428974/resources/fuse-ignite-oso.yml#L1529  The reason is, that the version number used are Syndesis style minor versions (1.3 or 1.4), but the productised upgrade pod is picked from the Red Hat registry which has a different versioning scheme (e.g. 1.1-05). This version should be pinned when the template is created via the generator.  Also the operator needs to be fixed to not provide a SYNDESIS_VERSION anymore when instantiating the template.  Long term, the operator itself should be configured with the concrete version of the upgrade pod and should take it either from a config file or via a command line parameter.  </body>
		<created>2018-08-14 12:10:00</created>
		<closed>2018-08-23 14:57:24</closed>
	</bug>
	<bug>
		<id>3375</id>
		<title>minishift-restore.sh needs syndesis namespace</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; `minishift-restore.sh` utilised by `yarn minishift:restore` has a namespace defined for the `Endpoint` resource making it difficult to restore if the namespace application is installed in is not `syndesis`.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Don't specify namespace in OpenShift resources and use the currently used namespace.  </body>
		<created>2018-08-14 10:27:44</created>
		<closed>2018-08-15 08:20:09</closed>
	</bug>
	<bug>
		<id>3373</id>
		<title>Dodgy regexp to detect if OpenAPI specification is in JSON or YAML format</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; In custom API client connector we're trying to detect the format of the uploaded specification in order to parse it using JSON or YAML parser. The JSON detection is done via regex `\s+\{` and fails to detect OpenAPI specifications that do not start with a whitespace character.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Be better at detecting OpenAPI specification format. </body>
		<created>2018-08-14 10:22:45</created>
		<closed>2018-08-15 08:20:28</closed>
	</bug>
	<bug>
		<id>3371</id>
		<title>Import Integration Wizard: 'No file select' after file upload</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem This is a minor bug, but in the Integration Import wizard, if you drag and drop a valid zip file, it will tell you that the file was successfully imported or has failed, but the input field still reads 'No file chosen'. Do we want to hide that text or display something else? I recall having this conversation with UXD and there was mention of redundancy, because the success/failure message already displays the file name, but we still should do something about the 'No file chosen' text, whether we choose to display the file name or hide it.  The failure error could also use some work, as you just get back a `null`, but I suppose that's a separate issue.  ## Expected behavior No confusion as to whether or not the file was uploaded or not.  ## Screenshot  **Successful upload**  &lt;img width="1679" alt="screenshot 2018-08-13 12 18 41" src="https://user-images.githubusercontent.com/3844502/44044532-d51fe4cc-9ef3-11e8-80a1-49609ab75dbd.png"&gt;   **Failed upload**  &lt;img width="1680" alt="screenshot 2018-08-13 12 23 04" src="https://user-images.githubusercontent.com/3844502/44044537-d8c368ce-9ef3-11e8-8f1a-e603c7d28597.png"&gt;   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Navigate to Integrations in the vertical navigation/sidebar. 2. If you don't already have an exported Integration zip file, then get one by selecting 'Export' on the right-hand side dropdown of any existing integration. 3. Click on the 'Import' button at the top right-hand corner. You'll be redirected to the Import wizard. 4.  Try to upload a zip file (preferably a valid one). See above.  cc @elvisisking  </body>
		<created>2018-08-13 16:27:32</created>
		<closed>2018-11-25 19:26:23</closed>
	</bug>
	<bug>
		<id>3355</id>
		<title>Can't create Twitter connection via OAuth</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; I am not able to create twitter connection via OAuth. I end up with this: ![screenshot_20180808_164706](https://user-images.githubusercontent.com/14313995/43845718-e7c8094e-9b2c-11e8-9dce-c634dba1e3d8.png)  I checked my callback URL in twitter app and it is correct. Tested on clean syndesis master. @zregvart maybe my problem is connected with recent OAuth validation fix? But all other connectors using OAuth work so I am not sure what is wrong here :/</body>
		<created>2018-08-08 15:27:00</created>
		<closed>2018-08-10 12:05:07</closed>
	</bug>
	<bug>
		<id>3352</id>
		<title>ROUTE_HOST_NAME must not be required</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt; In the templates, otherwise, the upgrade won't start up. </body>
		<created>2018-08-08 11:57:02</created>
		<closed>2018-08-08 12:57:42</closed>
	</bug>
	<bug>
		<id>3350</id>
		<title>Activities stopped tracking after couple of hours </title>
		<body>This topic was discussed in comments of https://github.com/syndesisio/syndesis/issues/2607 so I created new issue because I can still hit this.  I have 6 integrations (&gt;= 3 steps) - 3 are processing message every second  - 3 every ~15-20s   After couple of hours activities stops tracking. Restart of integration or syndesis-server helps for another couple of hours (~8 hours ~100 000 messages).  &lt;img width="1206" alt="screen shot 2018-08-08 at 08 56 37" src="https://user-images.githubusercontent.com/6814482/43821315-2b385baa-9ae9-11e8-9d50-94d5413085e4.png"&gt;  I'm trying also simpler scenario with 6 integration: 3 integrations with timer -&gt; amq (message every 5s) 3 integration amq -&gt; log (every 5s) This is running fine for currently 47 hours with correct activities tracking. However activities are much smaller -- only one step. </body>
		<created>2018-08-08 07:01:52</created>
		<closed>2018-08-13 08:00:33</closed>
	</bug>
	<bug>
		<id>3342</id>
		<title>Route guard problem in create connection workflow</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem If you create a connection that skips step 2 (configure connection), and takes you straight to step 3 (name connection), when you click "back" (to take you back to step 1), the route guard is triggered.  This doesn't happen on connections that don't skip step 2 - you can go back from either step 2 or step 3, and the route guard isn't triggered.  ## Expected behavior Clicking back on these connections should just take you back to step 1 without triggering the route guard.  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create a webhook or IRC connection, and click "back" on step 3.</body>
		<created>2018-08-07 17:58:54</created>
		<closed>2018-08-10 11:37:46</closed>
	</bug>
	<bug>
		<id>3341</id>
		<title>UI updates to required form fields.</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem When all fields in a form are required * remove asterisks * helper text should read "All fields are required."  When some fields are required * helper text should read "The fields marked with * are required."  When all fields are optional * helper text should read "All fields are optional."  related - https://github.com/syndesisio/syndesis/issues/3319  PatternFly code for reference - https://rawgit.com/patternfly/patternfly/master-dist/dist/tests/forms.html  ## Screenshot  ### Examples  #### All fields required &lt;img width="1410" alt="screen shot 2018-08-07 at 12 19 20 pm" src="https://user-images.githubusercontent.com/35148959/43792623-ded7423a-9a3e-11e8-8193-0188ef0337e1.png"&gt;  #### Some fields required &lt;img width="1410" alt="screen shot 2018-08-07 at 12 29 36 pm" src="https://user-images.githubusercontent.com/35148959/43792617-dccd4c96-9a3e-11e8-86f1-634130db8598.png"&gt;  #### All fields optional &lt;img width="1418" alt="screen shot 2018-08-07 at 12 38 00 pm" src="https://user-images.githubusercontent.com/35148959/43792613-da86f270-9a3e-11e8-9151-1ace6d16fb4e.png"&gt;  cc @dongniwang </body>
		<created>2018-08-07 17:40:50</created>
		<closed>2019-02-04 00:01:29</closed>
	</bug>
	<bug>
		<id>3337</id>
		<title>Missing info in activities after running integration for couple of hours </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem I have scenario consist of 6 integration with 3messages/s in total. After couple of hours of running (~4 hours 60000 messages)  I'm missing steps infromations in activities: No steps: &lt;img width="1228" alt="screen shot 2018-08-07 at 16 39 02" src="https://user-images.githubusercontent.com/6814482/43782945-c7812eb2-9a60-11e8-994e-79722958f0b0.png"&gt; &lt;img width="1211" alt="screen shot 2018-08-07 at 16 42 34" src="https://user-images.githubusercontent.com/6814482/43783000-ecba83d6-9a60-11e8-828f-d64917ffe98d.png"&gt;    ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; always should be all steps visible:  &lt;img width="1176" alt="screen shot 2018-08-07 at 16 38 53" src="https://user-images.githubusercontent.com/6814482/43783032-011ab9f4-9a61-11e8-9ae0-2b7a77e373fb.png"&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.  + As you reproduce the issue, take note of any network requests that are made.  + Requests that result in an error will be highlighted red.  + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.  + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!! Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-08-07 14:50:26</created>
		<closed>2018-08-13 07:30:19</closed>
	</bug>
	<bug>
		<id>3335</id>
		<title>Connections missing from dashboard/home page</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Connections are not listed on the dashboard/home page like they should be  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![image](https://user-images.githubusercontent.com/351660/43779166-a94f2ad8-9a25-11e8-8ef1-a7ca87b67f11.png) </body>
		<created>2018-08-07 13:39:10</created>
		<closed>2018-08-07 17:37:33</closed>
	</bug>
	<bug>
		<id>3330</id>
		<title>syndesis install --help syntax error</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; &lt;!-- If possible, please choose the appropriate labels for your issue. You find a description of all labels used at https://doc.syndesis.io/#dev-labels --&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Running `tools/bin/syndesis install --help` prints this error, on Fedora and `bash` at least ``` Options for install: /data/repositories/work/syndesis/syndesis/tools/bin/commands/install: command substitution: line 8: syntax error near unexpected token `newline' /data/repositories/work/syndesis/syndesis/tools/bin/commands/install: command substitution: line 8: `--setup --grant &lt;user&gt;' -s  --setup                   Install CRDs clusterwide. Use --grant if you want a specific user to be  ```  </body>
		<created>2018-08-07 12:03:28</created>
		<closed>2018-08-07 12:59:21</closed>
	</bug>
	<bug>
		<id>3329</id>
		<title>Can't create concur connector via oauth</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  @zregvart  After successful callback, I am redirected here in syndesis with no way how to finish the connector: ![screenshot_20180807_132539](https://user-images.githubusercontent.com/14313995/43773291-8ce4757c-9a45-11e8-885b-5911211babc6.png) </body>
		<created>2018-08-07 11:33:15</created>
		<closed>2018-08-07 12:57:10</closed>
	</bug>
	<bug>
		<id>3328</id>
		<title>Flaky OutMessageCaptureProcessorTest</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  This error happens in ~ 10-20% of all test runs and indicates a flaky test ``` [INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.355 s - in io.syndesis.integration.runtime.handlers.SplitStepHandlerTest [INFO]  [INFO] Results: [INFO]  [ERROR] Errors:  [ERROR]   OutMessageCaptureProcessorTest.testCaptureWithSplitAndSchedule:291 NullPointer [INFO]  [ERROR] Tests run: 57, Failures: 0, Errors: 1, Skipped: 0 ```  @chirino as you was the author of the test, is this something you could fix quickly ? </body>
		<created>2018-08-07 10:03:13</created>
		<closed>2018-08-09 06:22:04</closed>
	</bug>
	<bug>
		<id>3319</id>
		<title>API client connector workflow - required fields should be indicated with a red asterisk (*)</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Required fields are not indicated on step 3 of API Client Connector creation workflow.   &lt;img width="806" alt="screen shot 2018-08-06 at 11 36 58 am" src="https://user-images.githubusercontent.com/24943812/43727148-2cd10f78-996f-11e8-8f7b-8766d3932a3b.png"&gt;   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Indicate required fields with a red asterisk (*) to the left of the filed label. Should also include the sentence "The fields marked with * are required."   See PatternFly field labeling for detailed instruction https://www.patternfly.org/pattern-library/forms-and-controls/field-labeling/  (The spacing in the following mock-up is not correct, please reference PF site for correct implmentation - FYI @michael-coker )  ![required_fields](https://user-images.githubusercontent.com/24943812/43727743-cd84b3f6-9970-11e8-8144-d3ad1257925c.png)  cc: @amysueg @michael-coker    </body>
		<created>2018-08-06 16:09:12</created>
		<closed>2018-10-19 18:28:57</closed>
	</bug>
	<bug>
		<id>3305</id>
		<title>Prometheus pod running out of disk space</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; On staging we have the Prometheus pod in Crash Loop and the log contains this error:  `level=error ts=2018-08-04T12:36:02.673472193Z caller=main.go:579 err="Opening storage failed open DB in data/: write /prometheus/data/104677851: no space left on device"`  Could be that the 1-sec-timer-to-log integration generated a lot metrics that we need additional storage.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Not run out of disk space.  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create 1-sec timer to log integration 2. Leave it running for a while 3. 4. </body>
		<created>2018-08-04 12:40:54</created>
		<closed>2019-08-09 10:09:19</closed>
	</bug>
	<bug>
		<id>3301</id>
		<title>If consoleUrl is not defined an invalid URL to the logs is rendered</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; In 7.0 the behaviour was that if the consoleUrl is not defined no link to the console was rendered. This was the compromise we came to after long discussion since it is not always easily possible to provide this information and we wanted to have a zero config setup  With 7.1 it seems that the URL to the pod event and pod logs into the console is unconditionally rendered, with an invalid URL like `/project/myproject/browse/pods/i-logtest-1-vcv7l?tab=logs` when no `consoleUrl` was configured. </body>
		<created>2018-08-03 19:10:45</created>
		<closed>2018-08-06 15:22:00</closed>
	</bug>
	<bug>
		<id>3293</id>
		<title>Concur oauth settings - no trimming of whitespace characters before credentials are used</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  When filling oauth details for SAP Concur, adding whitespace character to the end of the field "Authorization URL" will make it unusable. Creating concur connection will then ends with error: 400 Bad request. URI does not match any available uri-template.  This happens easily with copy-pasting credentials (as it was in my case :) ), maybe we should be more user friendly and trim those types of credentials before using them.</body>
		<created>2018-08-03 12:56:07</created>
		<closed>2018-12-24 19:30:12</closed>
	</bug>
	<bug>
		<id>3291</id>
		<title>Warnings are not updated after editing API definition </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem The "Warnings" section of the API connector review page does not appear to be updated after editing an API definition.  To reproduce ... 1. Create new API Client Connector 2. Import Todo API definition from file 3. Select Review/Edit 4. Delete the DELETE {id} operation 5. Save the API definition 6. Note that the warning "Operation DELETE /{id} does not provide a response schema for code 204" is still present even though that operation was deleted.   ## Expected behavior Warnings section is updated after editing API definition </body>
		<created>2018-08-03 12:06:36</created>
		<closed>2018-12-02 12:37:45</closed>
	</bug>
	<bug>
		<id>3286</id>
		<title>Successfully deleted integration not handled properly</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  After fixing https://github.com/syndesisio/syndesis/issues/3151 I noticed that even an integration is successfully deleted on back-end side, it is still shown in status Stopping in summary page  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  Once deleted the integration should disappear/chage status  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![peek 2018-08-03 08-22](https://user-images.githubusercontent.com/1868933/43627542-1deeef9a-96f7-11e8-919b-dfc0861ec34f.gif)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. create an integration 2. let it start 3. delete the integration </body>
		<created>2018-08-03 06:29:35</created>
		<closed>2018-08-03 14:14:22</closed>
	</bug>
	<bug>
		<id>3278</id>
		<title>Apicurio Editor: Re-validate edited API specification</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Step 2 shows the Review Actions template, with details about the specification, including warnings and errors. When the user makes changes to the specification via the Apicurio editor and presses Save, this Review step is not updated. This is not just a matter of updating the model--we need to make another request to the API for this, as this is done server-side.  ## Expected behavior User updates the specification via the Apicurio editor, is taken back to the Review Actions (Step 2) part of the wizard, and they see the updated overview of the edited spec.  ## Screenshot N/A  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1.  2. 3. 4. </body>
		<created>2018-08-02 14:44:02</created>
		<closed>2018-08-02 18:31:11</closed>
	</bug>
	<bug>
		<id>3271</id>
		<title>Operator - error entry in the logs </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Spotted an error log call in the startup logs of the Operator.  I'm not sure if this is just a transient error, or if this is a blocking one.  `level=error msg="error syncing key (myproject/app): service account token not found"`  If it turns out being a transient one, I'd suggest changing its level to info.  ```bash + syndesis-operator-1-k7bms  syndesis-operator syndesis-operator-1-k7bms syndesis-operator time="2018-08-02T07:56:30Z" level=info msg="Go Version: go1.10.3" syndesis-operator-1-k7bms syndesis-operator time="2018-08-02T07:56:30Z" level=info msg="Go OS/Arch: linux/amd64" syndesis-operator-1-k7bms syndesis-operator time="2018-08-02T07:56:30Z" level=info msg="operator-sdk Version: 0.0.5+git" syndesis-operator-1-k7bms syndesis-operator time="2018-08-02T07:56:30Z" level=info msg="Using template ./syndesis-template.yml" syndesis-operator-1-k7bms syndesis-operator time="2018-08-02T07:56:30Z" level=info msg="Watching syndesis.io/v1alpha1, Syndesis, myproject, 5" syndesis-operator-1-k7bms syndesis-operator time="2018-08-02T07:56:30Z" level=info msg="No legacy Syndesis installations detected in the myproject namespace" syndesis-operator-1-k7bms syndesis-operator time="2018-08-02T07:56:30Z" level=info msg="Syndesis legacy installations check completed" syndesis-operator-1-k7bms syndesis-operator time="2018-08-02T07:56:35Z" level=info msg="Syndesis resource app initialized: installing version latest" syndesis-operator-1-k7bms syndesis-operator time="2018-08-02T07:56:35Z" level=info msg="Installing Syndesis resource app" syndesis-operator-1-k7bms syndesis-operator time="2018-08-02T07:56:35Z" level=error msg="error syncing key (myproject/app): service account token not found" syndesis-operator-1-k7bms syndesis-operator time="2018-08-02T07:56:35Z" level=info msg="Installing Syndesis resource app" syndesis-operator-1-k7bms syndesis-operator time="2018-08-02T07:56:35Z" level=error msg="error syncing key (myproject/app): service account token not found" syndesis-operator-1-k7bms syndesis-operator time="2018-08-02T07:56:36Z" level=info msg="Installing Syndesis resource app" syndesis-operator-1-k7bms syndesis-operator time="2018-08-02T07:56:42Z" level=info msg="Syndesis resource app installed" syndesis-operator-1-k7bms syndesis-operator time="2018-08-02T07:56:42Z" level=info msg="Waiting for Syndesis resource app to startup"  ```</body>
		<created>2018-08-02 08:05:02</created>
		<closed>2018-11-07 11:41:00</closed>
	</bug>
	<bug>
		<id>3264</id>
		<title>Apicurio Editor: Steps not getting updated with edited changes</title>
		<body>## This is a... &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem When a specification is updated via the Apicurio editor, the subsequent steps are not getting updated. The final POST request to the API includes the correct, updated version.  ## Expected behavior The Review Actions, Authentication, and Review/Edit Connector Details steps should be using the latest changes for the specification.  ## Tasks involved / Steps to Reproduce 1. Customizations &gt; API Client Connector 2. Upload a Swagger/OpenAPI specification file. 3. Click Review/Edit in the Review step. 4. Make changes in the Apicurio editor. 5. Press 'Save'. See that changes are not reflected in the aforementioned steps. </body>
		<created>2018-08-01 16:37:28</created>
		<closed>2018-08-02 18:59:39</closed>
	</bug>
	<bug>
		<id>3260</id>
		<title>Cannot build Syndesis with Operator</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem `tools/bin/syndesis: line 95: cd: tools/bin: No such file or directory Creating syndesis-operator with syndesis/godev:1.10 /home/oscerd/workspace/jboss-fuse/syndesis/tools/bin/commands/util/operator_funcs: line 63: pushd: //install/operator: No such file or directory `  ## Expected behavior build operator and install </body>
		<created>2018-08-01 14:08:09</created>
		<closed>2018-08-02 12:50:13</closed>
	</bug>
	<bug>
		<id>3254</id>
		<title>HTTP Consumer fails to follow redirect.</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; This is actually borderline between a bug and a feature. Currently, HTTP Consumer, doesn't follow redirects. If you define a connection using the default value "www.redhat.com" and path "/", you hit an endpoint that forces a 302 redirect, and this fails this way:  &lt;details&gt;   &lt;summary&gt;&lt;b&gt;Click to expand&lt;/b&gt;&lt;/summary&gt; &lt;pre&gt;&lt;code&gt; i-paolo-1-dldhn i-paolo org.apache.camel.http.common.HttpOperationFailedException: HTTP operation failed invoking http://www.redhat.com/ with statusCode: 301, redirectLocation: https://www.redhat.com/ i-paolo-1-dldhn i-paolo at org.apache.camel.component.http4.HttpProducer.populateHttpOperationFailedException(HttpProducer.java:310) ~[camel-http4-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3] i-paolo-1-dldhn i-paolo at org.apache.camel.component.http4.HttpProducer.process(HttpProducer.java:207) ~[camel-http4-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3] i-paolo-1-dldhn i-paolo at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3] i-paolo-1-dldhn i-paolo at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3] i-paolo-1-dldhn i-paolo at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3] i-paolo-1-dldhn i-paolo at io.syndesis.integration.component.proxy.ComponentProxyProducer.process(ComponentProxyProducer.java:44) ~[integration-component-proxy-1.3.12.fuse-000001-redhat-2.jar!/:1.3.12.fuse-000001-redhat-2] i-paolo-1-dldhn i-paolo at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) ~[camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3] i-paolo-1-dldhn i-paolo at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3] i-paolo-1-dldhn i-paolo at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3] i-paolo-1-dldhn i-paolo at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3] i-paolo-1-dldhn i-paolo at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3] i-paolo-1-dldhn i-paolo at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3] i-paolo-1-dldhn i-paolo at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3] i-paolo-1-dldhn i-paolo at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:77) [integration-runtime-1.3.12.fuse-000001-redhat-2.jar!/:1.3.12.fuse-000001-redhat-2] i-paolo-1-dldhn i-paolo at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3] i-paolo-1-dldhn i-paolo at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3] i-paolo-1-dldhn i-paolo at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3] i-paolo-1-dldhn i-paolo at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3] i-paolo-1-dldhn i-paolo at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3] i-paolo-1-dldhn i-paolo at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3] i-paolo-1-dldhn i-paolo at org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3] i-paolo-1-dldhn i-paolo at org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79) [camel-core-2.21.0.fuse-000112-redhat-3.jar!/:2.21.0.fuse-000112-redhat-3] i-paolo-1-dldhn i-paolo at java.util.TimerThread.mainLoop(Timer.java:555) [na:1.8.0_171] i-paolo-1-dldhn i-paolo at java.util.TimerThread.run(Timer.java:505) [na:1.8.0_171] i-paolo-1-dldhn i-paolo {"exchange":"i-LIlirTmXESPE5W6P_Zpz","step":"-LIlhf8cWV3WrQkyc1aG","id":"i-LIlirt-XESPE5W6P_Zqz","duration":803113459,"failure":"org.apache.camel.http.common.HttpOperationFailedException: HTTP operation failed invoking http://www.redhat.com/ with statusCode: 301, redirectLocation: https://www.redhat.com/\n\tat org.apache.camel.component.http4.HttpProducer.populateHttpOperationFailedException(HttpProducer.java:310)\n\tat org.apache.camel.component.http4.HttpProducer.process(HttpProducer.java:207)\n\tat org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:138)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:101)\n\tat io.syndesis.integration.component.proxy.ComponentProxyProducer.process(ComponentProxyProducer.java:44)\n\tat org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148)\n\tat org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110)\n\tat org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548)\n\tat org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:138)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:101)\n\tat org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110)\n\tat io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:77)\n\tat org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110)\n\tat org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548)\n\tat org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:138)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:101)\n\tat org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201)\n\tat org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197)\n\tat org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79)\n\tat java.util.TimerThread.mainLoop(Timer.java:555)\n\tat java.util.TimerThread.run(Timer.java:505)\n"} i-paolo-1-dldhn i-paolo {"exchange":"i-LIlirTmXESPE5W6P_Zpz","status":"done","failed":true} i-paolo-1-dldhn i-paolo 2018-07-31 19:05:54.807  WARN 1 --- [r://integration] o.a.camel.component.timer.TimerConsumer  : Error processing exchange. Exchange[i-LIlirTmXESPE5W6P_Zpz]. Caused by: [org.apache.camel.http.common.HttpOperationFailedException - HTTP operation failed invoking http://www.redhat.com/ with statusCode: 301, redirectLocation: https://www.redhat.com/]  &lt;/code&gt;&lt;/pre&gt; &lt;/details&gt;  ## Expected behavior Either to support redirect by default, or to expose the configuration or to change the suggested example.  Tested on iPaaS 7.0.1</body>
		<created>2018-08-01 08:58:54</created>
		<closed>2018-10-10 15:05:32</closed>
	</bug>
	<bug>
		<id>3246</id>
		<title>Access syndesis server API using curl not working</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [*] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Using either firefox or chrome it is possible to directly enter an url pointing to a function in the server REST API and the correct json is returned. It should be possible to do the same on the command line (cli) using curl, eg.  `curl -vvv -X GET -H "Authorization: Bearer $(oc whoami -t)" https://$(oc get route syndesis  --template={{.spec.host}})/api/v1/connections`  This 'fails' (see [gist](https://gist.github.com/phantomjinx/4b12374f551a09e58b136d7bba746992)) due to a lack of redirecting from the oauth proxy. Is this expected behaviour? Can something be done to make it redirect?  Alternatively, the syndesis script provides a cookie which can be used instead of the bearer token, ie.  `curl -vvv -k --cookie $(syndesis dev --cookie --refresh)  "https://$(oc get route syndesis  --template={{.spec.host}})/api/v1/connections"`  This produces the same result as the previous command. The assumption here is this used to work but no longer works.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; curl is able to fetch the results of any part of the REST API as long as the correct authentication artifacts are provided to it.  </body>
		<created>2018-07-31 20:12:02</created>
		<closed>2019-02-12 22:24:20</closed>
	</bug>
	<bug>
		<id>3241</id>
		<title>Top 5 integrations is the same as Recent updates</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem What exactly suppose to show 'Top 5 integrations' tab ? Currently it looks like it shows only last updated integration.  &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  "Top 5 Integrations" should be sorted descending by messages processed and limited to 5 integrations.</body>
		<created>2018-07-31 14:36:51</created>
		<closed>2018-09-25 21:01:02</closed>
	</bug>
	<bug>
		<id>3224</id>
		<title>Settings page incorrectly displays that access to an application is not configured</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; In the Settings page, after I register my Syndesis environment with Salesforce, the contracted entry still displays "Access to application is not configured.":  ![image](https://user-images.githubusercontent.com/25067106/43401582-89e644a8-93de-11e8-9e0e-ba56896664a6.png)  But since registration was validated, this should no longer appear. If I open my Salesforce entry, the id and secret values are there. When I click Save, I get: ![image](https://user-images.githubusercontent.com/25067106/43401764-035b67a0-93df-11e8-80ea-0d2e7a552a8e.png) And then when I click OK,  "Access to this application is not configured." still appears.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  After I register with an application and Syndesis validates authorization then "Access to this application is not configured." should no longer appear.   </body>
		<created>2018-07-30 14:02:08</created>
		<closed>2018-07-30 16:54:23</closed>
	</bug>
	<bug>
		<id>3223</id>
		<title>Servicenow - can't retrieve data from custom table</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; If I create a custom table in Servicenow, I cant select it and therefore retrieve any data in an integration using Servicenow connection.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; I can select and retrieve the data from a custom table in **Table Name** selectbox.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![snrr](https://user-images.githubusercontent.com/8707251/43397601-b154155c-9405-11e8-8f2a-cde7d838bdfe.png)  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-07-30 12:36:43</created>
		<closed>2018-08-07 12:24:59</closed>
	</bug>
	<bug>
		<id>3208</id>
		<title>Wrong date format in recent tabs (Month instead of minutes)</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Recent updates tab displays Month instead of minutes  ![screen shot 2018-07-27 at 17 32 22](https://user-images.githubusercontent.com/6814482/43330414-6fe053ae-91c3-11e8-9e10-adb93daf8b81.png)  &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-07-27 15:35:53</created>
		<closed>2018-07-27 15:59:53</closed>
	</bug>
	<bug>
		<id>3207</id>
		<title>integration activity: step name is not shown for data mapper steps</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Step name is not shown for data mapper steps.  It appears that the data mapper step does not have an id thus the ui cannot correlate the information from the activity to the right step, below an extract fo the integration jsoin that gets copied over the integration pod:  ```json      {       "action": {         "descriptor": {           "inputDataShape": {             "name": "All preceding outputs",             "kind": "any"           },           "outputDataShape": {             "name": "Data Mapper (add_lead Parameter)",             "description": "Parameters of Stored Procedure 'add_lead'",             "kind": "json-schema",             "type": "add_lead_IN",             "specification": "..."           }         },         "actionType": "step"       },       "stepKind": "mapper",       "name": "Data Mapper",       "configuredProperties": {         "atlasmapping": "..."       }     }, ```  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  Each step should have a proper name  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![image](https://user-images.githubusercontent.com/1868933/43322645-872e9228-91af-11e8-9650-cf0ea1086767.png) </body>
		<created>2018-07-27 13:19:19</created>
		<closed>2018-07-31 14:56:21</closed>
	</bug>
	<bug>
		<id>3204</id>
		<title> "Create integration" button is not visible all the time</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  Create integration button on home page is not visible, when there is no integration. I understand that. But when I created an integration and saved it as draft, the button is still not there so there is no option to go straight to creating integration from home page. Only after refreshing the page with F5 the button suddenly appeared. </body>
		<created>2018-07-27 11:24:37</created>
		<closed>2018-07-27 13:14:48</closed>
	</bug>
	<bug>
		<id>3197</id>
		<title>Ability to change Host property of Concur connector</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [x] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; We ship the Concur connector with a set of predefined properties. Some of these, like OAuth settings, can be changed on the Settings / OAuth client page. Currently we have no way of changing the `Host` property, a property that is used to determine what environment should the integration be targeted at. So even if the user changes the Token/Authorization URLs to point to the implementation environment, the request at runtime would go to the production environment and error out as the OAuth token is not valid for it.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Have the ability to change the `Host` property of Concur connector.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![ezgif-3-94b5e009b0](https://user-images.githubusercontent.com/1306050/43264875-84d4558a-90e7-11e8-8959-c412e02bcfc5.gif)   </body>
		<created>2018-07-26 13:21:38</created>
		<closed>2018-08-02 18:30:11</closed>
	</bug>
	<bug>
		<id>3184</id>
		<title>Timer connector requires camel-quartz2 as runtime dependency</title>
		<body>## This is a... &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem The timer connector for the cron timer need camel-quartz2 as dependency, otherwise it won't find the scheme. </body>
		<created>2018-07-25 13:24:36</created>
		<closed>2018-07-25 14:00:59</closed>
	</bug>
	<bug>
		<id>3178</id>
		<title>Add `initialDelaySeconds` to prometheus liveness/readyness checks</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Prometheus deployment config does not specify `initialDelaySeconds` for liveness/readyness checks, on staging this causes premature termination of prometheus pod and it ends up in a crash loop back off.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Let prometheus startup before issuing readyness/liveness probes. </body>
		<created>2018-07-25 08:40:58</created>
		<closed>2018-07-25 09:08:24</closed>
	</bug>
	<bug>
		<id>3175</id>
		<title>[Create Connection] Wizard step mismatch when returns from OAuth  </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Noticed this when watching the Concur demo. During the create connection flow step 2 - user selects to connect via OAuth, the page redirects user to Concur and then comes back to syndesis. The screen then shows add connection details with the wizard step indicator is still on step 2.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  From the UX design, we suggested to return user to step 2 with a success confirmation message. Then user proceeds to step 3. See design [here](https://github.com/syndesisio/syndesis/blob/master/ux/designs/oauth/oauth.md).   Alternatively, we could just return user to step 3, but in this case the wizard should indicate user is on step 3.   ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![image](https://user-images.githubusercontent.com/24943812/43163110-132350c2-8f5b-11e8-91d6-19ff84033108.png)   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; @KurtStam mentioned this is nothing to with concur specifically but could be happening to all OAuth connectors.    cc:  @michael-coker @gashcrumb @sjcox-rh </body>
		<created>2018-07-24 20:13:00</created>
		<closed>2018-07-25 15:43:54</closed>
	</bug>
	<bug>
		<id>3174</id>
		<title>Apicurio Editor: URL-fetched specification not supported</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Specifications should be treated differently based on how they are obtained (e.g. URL fetch or file upload), due to the data structure. See [here](https://gist.github.com/kahboom/9f9e606df271b49973bf7337de3ed0d1) for reference. This is related to #3096.  When a URL is specified, the user can then proceed to Review/Edit from the Review Actions step (2), but the editor is blank, as if a blank specification had been provided.    ## Expected behavior User should be able to either upload a file or specify a URL for the Swagger/OpenAPI spec and see the details of it in the Review/Edit Apicurio editor.  ## Screenshot &lt;img width="1680" alt="screenshot 2018-08-01 12 38 31" src="https://user-images.githubusercontent.com/3844502/43535535-49e0c8f0-9588-11e8-905f-d8057605e591.png"&gt;    ## Request and Response Data See [here](https://gist.github.com/kahboom/9f9e606df271b49973bf7337de3ed0d1) for reference.   ## Tasks involved / Steps to Reproduce 1. Navigate to Customizations. 2. Proceed as if you were creating a custom API connector, except select the URL option. 3. Test with any valid Swagger/OpenAPI URL. 4. You should see an error. </body>
		<created>2018-07-24 19:55:33</created>
		<closed>2018-08-06 14:19:25</closed>
	</bug>
	<bug>
		<id>3168</id>
		<title>Telegram Receive Message action does not reflect chat Id property</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  Telegram does not listen and answer to correct chat Ids specified in the integration.   ## Reproducer:   Create integration: TELEGRAM receive ==&gt; DATA MAPPER (map text to text) ==&gt; TELEGRAM send Specify different chat Id's for receive and send telegram actions.  ### problem 1 Send a message to the chat you used in receive action. The integration will respond to the same chat instead of the chat you specified in telegram send action.  ### problem 2 Send a message to the chat you used in send action. The integration will also respond to this chat even though it should not even listen to this chat.   ### note 1 The telegram send action works as expected when tested separately.  @nicolaferraro </body>
		<created>2018-07-24 14:50:56</created>
		<closed>2018-08-24 11:50:29</closed>
	</bug>
	<bug>
		<id>3165</id>
		<title>Cleanup Timer connector's Cron Expression action</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Timer connector's Cron Expression action should be cleaned up to:  - Cron Expression propery description should contain an example of a cron expression  - Cron Expression should be required  - Cron Expression should have a default of 1 minute  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Be in line with what we have done for other connectors.  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. edit `app/connector/timer/src/main/resources/META-INF/syndesis/connector/timer.json` to reflect the above </body>
		<created>2018-07-24 12:13:29</created>
		<closed>2018-07-25 13:59:54</closed>
	</bug>
	<bug>
		<id>3164</id>
		<title>Cleanup Timer connector's Simple Timer action</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Timer connector's `Simple Timer` action should be cleaned up to:  - have nicer labels: currently `period`, should be `Period`  - to have default period of 1 min (same as DB connector)  - no description (same as DB connector)  - label hint of `Delay between scheduling (executing).` (same as DB connector)  - period should be required  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Be in line with what we have done for other connectors, namely the DB connector.  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. edit `app/connector/timer/src/main/resources/META-INF/syndesis/connector/timer.json` to reflect the above </body>
		<created>2018-07-24 11:52:04</created>
		<closed>2018-07-25 13:59:54</closed>
	</bug>
	<bug>
		<id>3162</id>
		<title>`syndesis release` error with two digit latest tags</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When we use `syndesis release --snapshot-release` and the latest tag has a two-digit release version two errors are printed:  ``` tools/bin/commands/release: line 175: 1.4: syntax error: invalid arithmetic operator (error token is ".4") tools/bin/commands/release: line 413: $1: unbound variable ```  Oddly, this does not error out and exit.  Here is the debug output of the relevant section: ``` ++++ calc_timestamp_version /.../syndesis ++++ local topdir=/.../syndesis ++++ cd /.../syndesis/app +++++ ./mvnw -N help:evaluate -Dexpression=project.version +++++ grep '^[0-9]' +++++ sed -e 's/\([0-9]*\.[0-9]*\).*/\1/' ++++ local pom_version=1.4 ++++ '[' -z 1.4 ']' +++++ git tag +++++ grep '^1.4' +++++ sed -e s/1.4.// +++++ head -1 +++++ sort -n -r +++++ grep -v - ++++ local patch_level=1.4 /.../syndesis/tools/bin/commands/release: line 176: 1.4: syntax error: invalid arithmetic operator (error token is ".4") ``` At this point we had a number of 1.4.1 snapshot releases (e.g. 1.4.1-20180711) I wonder if we should order tags by time not numerically.  Or we should make sure to have 1.4.1 before snapshot releases.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; 1. Calculate snapshot release version with two-digit versions (1.4 -&gt; 1.4.0) 2. Handle errors better </body>
		<created>2018-07-24 10:40:46</created>
		<closed>2018-07-30 21:37:19</closed>
	</bug>
	<bug>
		<id>3151</id>
		<title>Error 500 when deleting integrations</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Deleting integration yields an error. Oddly this is not the case when the integration is stopped, so trying to delete second time in a row succeeds.  ``` 2018-07-23 10:26:53.114 ERROR [-,40eef3b7be856afd,40eef3b7be856afd,false] 1 --- [  XNIO-3 task-2] .s.e.v.h.e.SyndesisServerExceptionMapper : Internal Server Exception. Failure executing: PATCH at: https://openshift.default.svc/api/v1/namespaces/syndesis/replicationcontrollers/i-salesforce-5 . Message: Forbidden!Configured service account doesn't have access. Service account may have been revoked. replicationcontrollers "i-salesforce-5" is forbidden: cannot set blockOwnerDeletion if an ownerReference refers to a resource you can't set finalizers on: User "system:serviceaccount:syndesis:syndesis-server" cannot update deploymentconfigs/finalizers.apps.openshift.io in project "syndesis", &lt;nil&gt;. io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: PATCH at: https://openshift.default.svc/api/v1/namespaces/syndesis/replicationcontrollers/i-salesforce-5 . Message: Forbidden!Configured service account doesn't have access. Service account may have been revoked. replicationcontrollers "i-salesforce-5" is forbidden: cannot set blockOwnerDeletion if an ownerReference refers to a resource you can't set finalizers on: User "system:serviceaccount:syndesis:syndesis-server" cannot update deploymentconfigs/finalizers.apps.openshift.io in project "syndesis", &lt;nil&gt;. at io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:470) ~[kubernetes-client-3.1.4.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:407) ~[kubernetes-client-3.1.4.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:379) ~[kubernetes-client-3.1.4.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:343) ~[kubernetes-client-3.1.4.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handlePatch(OperationSupport.java:279) ~[kubernetes-client-3.1.4.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.BaseOperation.handlePatch(BaseOperation.java:783) ~[kubernetes-client-3.1.4.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.HasMetadataOperation$3.apply(HasMetadataOperation.java:156) ~[kubernetes-client-3.1.4.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.HasMetadataOperation$3.apply(HasMetadataOperation.java:152) ~[kubernetes-client-3.1.4.jar!/:na] at io.fabric8.kubernetes.api.model.DoneableReplicationController.done(DoneableReplicationController.java:26) ~[kubernetes-model-2.0.10.jar!/:2.0.10] at io.fabric8.kubernetes.api.model.DoneableReplicationController.done(DoneableReplicationController.java:5) ~[kubernetes-model-2.0.10.jar!/:2.0.10] at io.fabric8.kubernetes.client.dsl.base.HasMetadataOperation.patch(HasMetadataOperation.java:163) ~[kubernetes-client-3.1.4.jar!/:na] at io.fabric8.kubernetes.client.dsl.internal.RollableScalableResourceOperation.patch(RollableScalableResourceOperation.java:185) ~[kubernetes-client-3.1.4.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.HasMetadataOperation$1.apply(HasMetadataOperation.java:60) ~[kubernetes-client-3.1.4.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.HasMetadataOperation$1.apply(HasMetadataOperation.java:50) ~[kubernetes-client-3.1.4.jar!/:na] at io.fabric8.kubernetes.api.model.DoneableReplicationController.done(DoneableReplicationController.java:26) ~[kubernetes-model-2.0.10.jar!/:2.0.10] at io.fabric8.kubernetes.client.dsl.internal.ReplicationControllerOperationsImpl.withReplicas(ReplicationControllerOperationsImpl.java:85) ~[kubernetes-client-3.1.4.jar!/:na] at io.fabric8.kubernetes.client.dsl.internal.ReplicationControllerOperationsImpl.withReplicas(ReplicationControllerOperationsImpl.java:42) ~[kubernetes-client-3.1.4.jar!/:na] at io.fabric8.kubernetes.client.dsl.internal.RollableScalableResourceOperation.scale(RollableScalableResourceOperation.java:77) ~[kubernetes-client-3.1.4.jar!/:na] at io.fabric8.kubernetes.client.dsl.internal.RollableScalableResourceOperation.scale(RollableScalableResourceOperation.java:45) ~[kubernetes-client-3.1.4.jar!/:na] at io.fabric8.kubernetes.client.dsl.internal.ScalableReaper.reap(ScalableReaper.java:30) ~[kubernetes-client-3.1.4.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.BaseOperation.delete(BaseOperation.java:621) ~[kubernetes-client-3.1.4.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.BaseOperation.delete(BaseOperation.java:70) ~[kubernetes-client-3.1.4.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.BaseOperation.delete(BaseOperation.java:662) ~[kubernetes-client-3.1.4.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.BaseOperation.deleteList(BaseOperation.java:696) ~[kubernetes-client-3.1.4.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.BaseOperation.delete(BaseOperation.java:636) ~[kubernetes-client-3.1.4.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.BaseOperation.delete(BaseOperation.java:70) ~[kubernetes-client-3.1.4.jar!/:na] at io.fabric8.openshift.client.dsl.internal.DeploymentConfigOperationsImpl$DeploymentConfigReaper.reap(DeploymentConfigOperationsImpl.java:129) ~[openshift-client-3.1.4.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.BaseOperation.delete(BaseOperation.java:621) ~[kubernetes-client-3.1.4.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.BaseOperation.delete(BaseOperation.java:70) ~[kubernetes-client-3.1.4.jar!/:na] at io.syndesis.server.openshift.OpenShiftServiceImpl.removeDeploymentConfig(OpenShiftServiceImpl.java:279) ~[server-openshift-1.4-SNAPSHOT.jar!/:1.4-SNAPSHOT] at io.syndesis.server.openshift.OpenShiftServiceImpl.delete(OpenShiftServiceImpl.java:110) ~[server-openshift-1.4-SNAPSHOT.jar!/:1.4-SNAPSHOT] at io.syndesis.server.endpoint.v1.handler.integration.IntegrationHandler.delete(IntegrationHandler.java:237) ~[server-endpoint-1.4-SNAPSHOT.jar!/:1.4-SNAPSHOT] ```  Are we missing a permission?  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Delete integrations without errors.  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create integration and publish 2. Delete it, notice the error 3. Delete again (while it's stopped), great success </body>
		<created>2018-07-23 10:33:19</created>
		<closed>2018-08-03 09:17:36</closed>
	</bug>
	<bug>
		<id>3150</id>
		<title>Activity shows 'No Errors' even if there are exceptions in pod's log</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem I have no errors in activity when I have exeptions in logs:  ![screen shot 2018-07-23 at 11 53 24](https://user-images.githubusercontent.com/6814482/43070090-27634d18-8e6f-11e8-8cdb-4b0da2e55d9a.png) ```  {"exchange":"i-LI5UK7y2B2_hQp5ECQsz","step":"-LHs62QN3UerPfOI7WY5","id":"i-LI5ULMF2B2_hQp5ECQyz","duration":5742271} --  | {"exchange":"i-LI5UK7y2B2_hQp5ECQsz","step":"-LHs62QN3UerPfOI7WY5","id":"i-LI5UK832B2_hQp5ECQvz","duration":5010080407}  | {"exchange":"i-LI5UK7y2B2_hQp5ECQsz","status":"done","failed":false}  | {"exchange":"i-LI5ULMd2B2_hQp5ECQzz","status":"begin"}  | {"exchange":"i-LI5ULMd2B2_hQp5ECQzz","step":"-LHs6Abi3UerPfOI7WY5","id":"i-LI5ULMe2B2_hQp5ECR-z","duration":5323750}  | {"exchange":"i-LI5ULMd2B2_hQp5ECQzz","step":"-LHs5Slz3UerPfOI7WY4","id":"i-LI5UM_s2B2_hQp5ECR2z","duration":8553316}  | {"exchange":"i-LI5ULMd2B2_hQp5ECQzz","step":"-LHs7t9A3UerPfOI7WY7","id":"i-LI5UMa02B2_hQp5ECR3z","message":"Body: [bigger] Log zo syndesisu"}  | 2018-07-23 09:34:29.249  INFO 1 --- [ Session Task-2] -LHs5Eft3UerPfOI7WY4                     : Body: [bigger] Log zo syndesisu  | {"exchange":"i-LI5ULMd2B2_hQp5ECQzz","step":"-LHs7t9A3UerPfOI7WY7","id":"i-LI5UMa02B2_hQp5ECR3z","duration":392309}  | 2018-07-23 09:34:29.250  WARN 1 --- [ Session Task-2] i.s.i.runtime.util.JsonSimplePredicate   : Unable to apply simple filter to the given payload  | 2018-07-23 09:34:29.250 DEBUG 1 --- [ Session Task-2] i.s.i.runtime.util.JsonSimplePredicate   : Unable to parse incoming message body as JSON needed for simple filtering  | com.fasterxml.jackson.core.JsonParseException: Unrecognized token 'bigger': was expecting ('true', 'false' or 'null')  | at [Source: org.apache.camel.converter.stream.InputStreamCache@1cec5123; line: 1, column: 13]  | at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1702) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:558) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._reportInvalidToken(UTF8StreamJsonParser.java:3528) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleUnexpectedValue(UTF8StreamJsonParser.java:2686) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:878) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:772) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:3850) ~[jackson-databind-2.8.11.1.jar!/:2.8.11.1]  | at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3799) ~[jackson-databind-2.8.11.1.jar!/:2.8.11.1]  | at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2938) ~[jackson-databind-2.8.11.1.jar!/:2.8.11.1]  | at io.syndesis.integration.runtime.util.JsonSimplePredicate.matches(JsonSimplePredicate.java:91) ~[integration-runtime-1.4-SNAPSHOT.jar!/:1.4-SNAPSHOT]  | at org.apache.camel.processor.FilterProcessor.matches(FilterProcessor.java:65) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.FilterProcessor.process(FilterProcessor.java:51) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) [integration-runtime-1.4-SNAPSHOT.jar!/:1.4-SNAPSHOT]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.DelayProcessorSupport.processDelay(DelayProcessorSupport.java:100) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.DelayProcessorSupport.process(DelayProcessorSupport.java:168) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) [integration-runtime-1.4-SNAPSHOT.jar!/:1.4-SNAPSHOT]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.util.AsyncProcessorHelper.process(AsyncProcessorHelper.java:109) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:80) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.component.sjms.consumer.InOnlyMessageHandler.handleMessage(InOnlyMessageHandler.java:65) [camel-sjms-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.component.sjms.consumer.AbstractMessageHandler.onMessage(AbstractMessageHandler.java:86) [camel-sjms-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.activemq.ActiveMQMessageConsumer.dispatch(ActiveMQMessageConsumer.java:1401) [activemq-client-5.14.5.jar!/:5.14.5]  | at org.apache.activemq.ActiveMQSessionExecutor.dispatch(ActiveMQSessionExecutor.java:131) [activemq-client-5.14.5.jar!/:5.14.5]  | at org.apache.activemq.ActiveMQSessionExecutor.iterate(ActiveMQSessionExecutor.java:202) [activemq-client-5.14.5.jar!/:5.14.5]  | at org.apache.activemq.thread.PooledTaskRunner.runTask(PooledTaskRunner.java:133) [activemq-client-5.14.5.jar!/:5.14.5]  | at org.apache.activemq.thread.PooledTaskRunner$1.run(PooledTaskRunner.java:48) [activemq-client-5.14.5.jar!/:5.14.5]  | at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_151]  | at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_151]  | at java.lang.Thread.run(Thread.java:748) [na:1.8.0_151]  ``` `  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-07-23 09:56:06</created>
		<closed>2018-07-25 12:36:39</closed>
	</bug>
	<bug>
		<id>3149</id>
		<title>Advanced filter throws exception when message body is plaintext </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem  I have integration consists of http4 connection (which produces plaintext), AMQ connection: ![screen shot 2018-07-23 at 11 27 08](https://user-images.githubusercontent.com/6814482/43069501-8ae6cbe6-8e6d-11e8-9b83-8a340e47e4a6.png)   and advanced filter with `${body} contains 'number'` expression. I'm getting following exeption in integrations pod: ```   | {"exchange":"i-LI5UBV62B2_hQp5ECQ6z","step":"-LHs62QN3UerPfOI7WY5","id":"i-LI5UBVH2B2_hQp5ECQ9z","duration":5050540952}  | {"exchange":"i-LI5UBV62B2_hQp5ECQ6z","status":"done","failed":false}  | {"exchange":"i-LI5UCjx2B2_hQp5ECQDz","status":"begin"}  | {"exchange":"i-LI5UCjx2B2_hQp5ECQDz","step":"-LHs6Abi3UerPfOI7WY5","id":"i-LI5UCk32B2_hQp5ECQEz","duration":8870706}  | {"exchange":"i-LI5UCjx2B2_hQp5ECQDz","step":"-LHs5Slz3UerPfOI7WY4","id":"i-LI5UDyM2B2_hQp5ECQHz","duration":8723435}  | {"exchange":"i-LI5UCjx2B2_hQp5ECQDz","step":"-LHs7t9A3UerPfOI7WY7","id":"i-LI5UDyV2B2_hQp5ECQIz","message":"Body: [number:9436] Log zo syndesisu"}  | 2018-07-23 09:33:53.952  INFO 1 --- [ Session Task-2] -LHs5Eft3UerPfOI7WY4                     : Body: [number:9436] Log zo syndesisu  | {"exchange":"i-LI5UCjx2B2_hQp5ECQDz","step":"-LHs7t9A3UerPfOI7WY7","id":"i-LI5UDyV2B2_hQp5ECQIz","duration":350469}  | 2018-07-23 09:33:53.953  WARN 1 --- [ Session Task-2] i.s.i.runtime.util.JsonSimplePredicate   : Unable to apply simple filter to the given payload  | 2018-07-23 09:33:53.959 DEBUG 1 --- [ Session Task-2] i.s.i.runtime.util.JsonSimplePredicate   : Unable to parse incoming message body as JSON needed for simple filtering  | com.fasterxml.jackson.core.JsonParseException: Unrecognized token 'number': was expecting 'null', 'true', 'false' or NaN  | at [Source: org.apache.camel.converter.stream.InputStreamCache@2779bdba; line: 1, column: 8]  | at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1702) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:558) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._reportInvalidToken(UTF8StreamJsonParser.java:3528) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._reportInvalidToken(UTF8StreamJsonParser.java:3502) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._matchToken(UTF8StreamJsonParser.java:2824) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:858) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:772) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:3850) ~[jackson-databind-2.8.11.1.jar!/:2.8.11.1]  | at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3799) ~[jackson-databind-2.8.11.1.jar!/:2.8.11.1]  | at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2938) ~[jackson-databind-2.8.11.1.jar!/:2.8.11.1]  | at io.syndesis.integration.runtime.util.JsonSimplePredicate.matches(JsonSimplePredicate.java:91) ~[integration-runtime-1.4-SNAPSHOT.jar!/:1.4-SNAPSHOT]  | at org.apache.camel.processor.FilterProcessor.matches(FilterProcessor.java:65) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.FilterProcessor.process(FilterProcessor.java:51) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) [integration-runtime-1.4-SNAPSHOT.jar!/:1.4-SNAPSHOT]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.DelayProcessorSupport.processDelay(DelayProcessorSupport.java:100) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.DelayProcessorSupport.process(DelayProcessorSupport.java:168) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) [integration-runtime-1.4-SNAPSHOT.jar!/:1.4-SNAPSHOT]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.util.AsyncProcessorHelper.process(AsyncProcessorHelper.java:109) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:80) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.component.sjms.consumer.InOnlyMessageHandler.handleMessage(InOnlyMessageHandler.java:65) [camel-sjms-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.component.sjms.consumer.AbstractMessageHandler.onMessage(AbstractMessageHandler.java:86) [camel-sjms-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.activemq.ActiveMQMessageConsumer.dispatch(ActiveMQMessageConsumer.java:1401) [activemq-client-5.14.5.jar!/:5.14.5]  | at org.apache.activemq.ActiveMQSessionExecutor.dispatch(ActiveMQSessionExecutor.java:131) [activemq-client-5.14.5.jar!/:5.14.5]  | at org.apache.activemq.ActiveMQSessionExecutor.iterate(ActiveMQSessionExecutor.java:202) [activemq-client-5.14.5.jar!/:5.14.5]  | at org.apache.activemq.thread.PooledTaskRunner.runTask(PooledTaskRunner.java:133) [activemq-client-5.14.5.jar!/:5.14.5]  | at org.apache.activemq.thread.PooledTaskRunner$1.run(PooledTaskRunner.java:48) [activemq-client-5.14.5.jar!/:5.14.5]  | at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_151]  | at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_151]  | at java.lang.Thread.run(Thread.java:748) [na:1.8.0_151]  | {"exchange":"i-LI5UCjx2B2_hQp5ECQDz","step":"-LHs62QN3UerPfOI7WY5","id":"i-LI5UDyW2B2_hQp5ECQJz","duration":24378220}  | {"exchange":"i-LI5UCjx2B2_hQp5ECQDz","step":"-LHs62QN3UerPfOI7WY5","id":"i-LI5UCkC2B2_hQp5ECQGz","duration":5035848330}  | {"exchange":"i-LI5UCjx2B2_hQp5ECQDz","status":"done","failed":false}  | {"exchange":"i-LI5UDyw2B2_hQp5ECQKz","status":"begin"}  | {"exchange":"i-LI5UDyw2B2_hQp5ECQKz","step":"-LHs6Abi3UerPfOI7WY5","id":"i-LI5UDyx2B2_hQp5ECQLz","duration":10538289}  | {"exchange":"i-LI5UDyw2B2_hQp5ECQKz","step":"-LHs5Slz3UerPfOI7WY4","id":"i-LI5UFCF2B2_hQp5ECQOz","duration":4500632}  | {"exchange":"i-LI5UDyw2B2_hQp5ECQKz","step":"-LHs7t9A3UerPfOI7WY7","id":"i-LI5UFCK2B2_hQp5ECQPz","message":"Body: [smaller] Log zo syndesisu"}  | 2018-07-23 09:33:58.997  INFO 1 --- [ Session Task-2] -LHs5Eft3UerPfOI7WY4                     : Body: [smaller] Log zo syndesisu  | {"exchange":"i-LI5UDyw2B2_hQp5ECQKz","step":"-LHs7t9A3UerPfOI7WY7","id":"i-LI5UFCK2B2_hQp5ECQPz","duration":334694}  | 2018-07-23 09:33:58.997  WARN 1 --- [ Session Task-2] i.s.i.runtime.util.JsonSimplePredicate   : Unable to apply simple filter to the given payload  | 2018-07-23 09:33:58.998 DEBUG 1 --- [ Session Task-2] i.s.i.runtime.util.JsonSimplePredicate   : Unable to parse incoming message body as JSON needed for simple filtering  | com.fasterxml.jackson.core.JsonParseException: Unrecognized token 'smaller': was expecting ('true', 'false' or 'null')  | at [Source: org.apache.camel.converter.stream.InputStreamCache@23d2cc50; line: 1, column: 15]  | at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1702) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:558) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._reportInvalidToken(UTF8StreamJsonParser.java:3528) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleUnexpectedValue(UTF8StreamJsonParser.java:2686) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:878) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:772) ~[jackson-core-2.8.11.jar!/:2.8.11]  | at com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:3850) ~[jackson-databind-2.8.11.1.jar!/:2.8.11.1]  | at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3799) ~[jackson-databind-2.8.11.1.jar!/:2.8.11.1]  | at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2938) ~[jackson-databind-2.8.11.1.jar!/:2.8.11.1]  | at io.syndesis.integration.runtime.util.JsonSimplePredicate.matches(JsonSimplePredicate.java:91) ~[integration-runtime-1.4-SNAPSHOT.jar!/:1.4-SNAPSHOT]  | at org.apache.camel.processor.FilterProcessor.matches(FilterProcessor.java:65) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.FilterProcessor.process(FilterProcessor.java:51) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) [integration-runtime-1.4-SNAPSHOT.jar!/:1.4-SNAPSHOT]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.DelayProcessorSupport.processDelay(DelayProcessorSupport.java:100) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.DelayProcessorSupport.process(DelayProcessorSupport.java:168) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:79) [integration-runtime-1.4-SNAPSHOT.jar!/:1.4-SNAPSHOT]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.util.AsyncProcessorHelper.process(AsyncProcessorHelper.java:109) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:80) [camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.component.sjms.consumer.InOnlyMessageHandler.handleMessage(InOnlyMessageHandler.java:65) [camel-sjms-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.camel.component.sjms.consumer.AbstractMessageHandler.onMessage(AbstractMessageHandler.java:86) [camel-sjms-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094]  | at org.apache.activemq.ActiveMQMessageConsumer.dispatch(ActiveMQMessageConsumer.java:1401) [activemq-client-5.14.5.jar!/:5.14.5]  | at org.apache.activemq.ActiveMQSessionExecutor.dispatch(ActiveMQSessionExecutor.java:131) [activemq-client-5.14.5.jar!/:5.14.5]  | at org.apache.activemq.ActiveMQSessionExecutor.iterate(ActiveMQSessionExecutor.java:202) [activemq-client-5.14.5.jar!/:5.14.5]  | at org.apache.activemq.thread.PooledTaskRunner.runTask(PooledTaskRunner.java:133) [activemq-client-5.14.5.jar!/:5.14.5]  | at org.apache.activemq.thread.PooledTaskRunner$1.run(PooledTaskRunner.java:48) [activemq-client-5.14.5.jar!/:5.14.5]  | at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_151]  | at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_151]  | at java.lang.Thread.run(Thread.java:748) [na:1.8.0_151]    ```  </body>
		<created>2018-07-23 09:48:37</created>
		<closed>2018-07-25 08:48:00</closed>
	</bug>
	<bug>
		<id>3147</id>
		<title>'Recent Updates' displays only first 5 created integrations </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem 'Recent Updates' displays only first 5 created integrations. If any other is updated or new integration is created it doesn't show up in recent upgrades card.  &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-07-23 08:40:16</created>
		<closed>2018-07-24 14:18:53</closed>
	</bug>
	<bug>
		<id>3137</id>
		<title>Generic http error handler error shown instead of proper error</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  ![capture](https://user-images.githubusercontent.com/351660/43006332-6cd1d89c-8c03-11e8-83d1-f6a8e6de3a1c.PNG)  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  vs. the contents of the actual response:  ""You must specify parameters aligned with one of the supported authentication methods: for username and password authentication: userName, password, clientSecret; for refresh token authentication: refreshToken, clientSecret; for JWT: userName, keystore. And for every one of those loginUrl and clientId must be specified also." t"  Which actually isn't helpful still to the user, but at least it should wind up on the page vs this generic HTTP error handler text. </body>
		<created>2018-07-20 14:00:12</created>
		<closed>2018-07-20 14:42:36</closed>
	</bug>
	<bug>
		<id>3135</id>
		<title>Limit list fetching to just an initial fetch and then just updates</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Currently the UI *always* does a full list fetch of objects at certain times, but it's not really needed, for example if you go to the connection list page, there's always a fetch, same on the integration list page etc.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  Ideally the list would be fetched on-demand and then whenever there's a change server-side. </body>
		<created>2018-07-20 13:04:28</created>
		<closed>2018-07-20 14:17:51</closed>
	</bug>
	<bug>
		<id>3131</id>
		<title>View Log link not working</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; The "View Logs" link on the publishing page does not work for me.   ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![screenshot from 2018-07-20 10-12-18](https://user-images.githubusercontent.com/1520602/42991882-44d8f2ea-8c07-11e8-93d3-515d07b6e260.png)   ## Details This is where the link point.  https://syndesis.192.168.42.6.nip.io/project/syndesis/browse/pods/i-paolo-3-build?tab=logs  If I click there, I'm redirected to https://syndesis.192.168.42.6.nip.io/  That doesn't display anything  ![screenshot from 2018-07-20 10-27-40](https://user-images.githubusercontent.com/1520602/42991985-8e845c2c-8c07-11e8-8b33-806b427d7cac.png)   If I check with CLI tools I can see this, that might indeed explain the issue, since the log entry is waiting and doesn't have anything to update  ``` 10:19 $ stern paolo + i-paolo-2-build  sti-build i-paolo-2-build sti-build Image "docker.io/syndesis/syndesis-s2i@sha256:8aed68b4d29..." not available locally, pulling ... - i-paolo-2-build + i-paolo-3-build  sti-build i-paolo-3-build sti-build Image "docker.io/syndesis/syndesis-s2i@sha256:8aed68b4d29..." not available locally, pulling ... ```  but anyhow, I wonder if we should show something in that log destination page</body>
		<created>2018-07-20 08:29:52</created>
		<closed>2018-07-20 08:34:02</closed>
	</bug>
	<bug>
		<id>3130</id>
		<title>UX - Publish button visible even while publishing an integration - design v1.1</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem While an Integration is in "Publishing" state, it still shows a "Publish button". This sounds a surprising option, that in my view, could lead an impatient user to keep pressing the button if things are just slightly slow  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![screenshot from 2018-07-20 10-12-18](https://user-images.githubusercontent.com/1520602/42991405-abf78b96-8c05-11e8-95e8-a204a2e93ba2.png)  </body>
		<created>2018-07-20 08:14:58</created>
		<closed>2018-07-25 11:06:31</closed>
	</bug>
	<bug>
		<id>3129</id>
		<title>Logger connector doesn't have an icon</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![screenshot from 2018-07-20 10-11-08](https://user-images.githubusercontent.com/1520602/42991227-4466ad04-8c05-11e8-9b0d-47eeb6e62298.png)   </body>
		<created>2018-07-20 08:11:58</created>
		<closed>2018-07-20 10:02:17</closed>
	</bug>
	<bug>
		<id>3125</id>
		<title>integration import - summary doesn't always show up after a successful import</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  The first time an integration is imported the summary view may not show up, as there's some time between when the upload finishes and when the integration is listed in a GET request.  This means when you drag/drop a .zip onto the import page it'll show that the .zip was successfully imported, however no summary is shown.  Clicking on the 'Done' button at the top-right takes you back to the integration list page, where you can see the newly imported integration.  This is maybe due to the fact that the import upload API only returns back an ID of the imported integration, so the UI has to go and fetch the integration out of band to show any of the information for the summary.  Ideally when the upload API completes, it should return what's required by the design, i.e. the name for each integration imported, any connections that were imported and if those connections require user attention.</body>
		<created>2018-07-19 17:21:35</created>
		<closed>2019-01-28 17:40:11</closed>
	</bug>
	<bug>
		<id>3121</id>
		<title>The View/Edit/Start/Stop dropdown menu of syndesis integration is disappearing on integration start</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ x ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  There is a problem with the syndesis integration dropdown menu, which offers the user operations: View/Edit/Start/Stop/Delete/Export.  When the integration is starting, the menu tends to disappear approx. every 3 seconds.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; The menu should be in its place until the user selects one of the offered operations or clicks somewhere else on the page.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![out](https://user-images.githubusercontent.com/4180208/42941633-aa90d648-8b5d-11e8-920d-7dbbee49e1db.gif)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create some integration 2. While the integration is starting - go to the integrations list page 3. Click on the three vertical dots in the right - the menu appears 4. Observe how it disappears without any action after 3 seconds (can be observed only when the integration is starting) </body>
		<created>2018-07-19 12:14:41</created>
		<closed>2018-08-10 11:58:11</closed>
	</bug>
	<bug>
		<id>3120</id>
		<title>'View Log in Openshift' link doesn't work</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem After clicking on 'View Log in Openshift' I'm getting blank syndesis page instead of openshift log.  Looks like it's trying to redirect to wrong link: Minishift url: https://192.168.64.12:8443/ Syndesis url: https://stability.192.168.64.12.nip.io/ 'View Log in Openshift' url : https://stability.192.168.64.12.nip.io/project/stability/browse/pods/i-guessing-number-6-c2cdq?tab=logs &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-07-19 11:16:47</created>
		<closed>2018-07-19 11:26:21</closed>
	</bug>
	<bug>
		<id>3116</id>
		<title>Prometheus deployment failing</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; The Prometheus pod is constantly crashing due to not being able to write to /data.  This was solved by adding the following to the DeploymentConfig:  securityContext:   fsGroup: 2000   runAsNonRoot: true   runAsUser: 1000  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Prometheus starts up fine.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Deploy syndesis master 2. 3. 4. </body>
		<created>2018-07-18 20:03:33</created>
		<closed>2018-10-22 12:30:45</closed>
	</bug>
	<bug>
		<id>3108</id>
		<title>Apicurio editor - Save button missing</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; I can't find any Save button whatever I change in the swagger specs. The editor can be only cancelled.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![apicuriosavemissing](https://user-images.githubusercontent.com/8707251/42885159-8ab5ed94-8aa0-11e8-8d04-067d4e70a455.png) ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-07-18 13:39:17</created>
		<closed>2018-08-01 14:19:25</closed>
	</bug>
	<bug>
		<id>3099</id>
		<title>Update the informational text when an oauth app isn't configured</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Currently when an oauth application is unconfigured, the list item contains the text "Client ID and secret not configured."  With the changes to the oauth app page where a given app can have more than those two settings or use different terms, this string isn't applicable, for example:  ![capture](https://user-images.githubusercontent.com/351660/42823851-97646196-89ac-11e8-9df4-e95d55d357cc.PNG)  So the message says "Client I and client secret not configured" but the SAP concur connector has an ID, secret, URLs etc.  For twitter it uses different terms for the ID/secret:  ![capture](https://user-images.githubusercontent.com/351660/42823924-c9ce92f0-89ac-11e8-91fa-9037270bb434.PNG)  We should update this text to be more open-ended/generic.</body>
		<created>2018-07-17 14:33:22</created>
		<closed>2018-07-17 15:03:31</closed>
	</bug>
	<bug>
		<id>3096</id>
		<title>API connector - Next button does nothing after specifying a swagger file</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  API Client Connector - After specifying a swagger file to load, clicking **Next** button does nothing. I'm unable to proceed further.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![apiconnnext](https://user-images.githubusercontent.com/8707251/42819367-a183012e-89d3-11e8-9085-b24835a66f42.png)  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-07-17 13:13:30</created>
		<closed>2018-07-30 20:56:28</closed>
	</bug>
	<bug>
		<id>3095</id>
		<title>Unexpected behavior when editing an integration while in building process</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; If you edit integration when its in building state and delete any step, it will reappear again.  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create an integration (I tested it with database --&gt; log --&gt; database) 2. Click on publish 3. Edit the integration while its building 4. Delete one step 5. The step will reappear after few seconds  ![out](https://user-images.githubusercontent.com/14313995/42817802-8149e124-89cf-11e8-8e5d-a937b7736145.gif)     Sometimes it breaks in different way and this happens: ![out](https://user-images.githubusercontent.com/14313995/42817739-491518f0-89cf-11e8-862a-53adbdc2988a.gif)   </body>
		<created>2018-07-17 12:43:12</created>
		<closed>2018-07-26 12:24:29</closed>
	</bug>
	<bug>
		<id>3093</id>
		<title>Failure while installing Syndesis without routeHostname</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Installing Syndesis via operator without a route hostname cause errors in the process. This should be handled differently, i.e. validate the custom resource to avoid accepting something without route hostname, or better auto-generating the route hostname if that is missing from the CR config.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  If a CR is submitted without routeHostname, it should be refused or the operator should generate one.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; N/A  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt; N/A  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt; N/A  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Install the operator and the Syndesis CRD in a namespace 2. Create a Syndesis CR without .spec.routeHostname 3. Observe the error in the operator logs and partial resources created </body>
		<created>2018-07-17 10:55:57</created>
		<closed>2018-07-20 13:18:33</closed>
	</bug>
	<bug>
		<id>3092</id>
		<title>Syndesis resources are not owned by the CR after upgrade</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  After installing syndesis version `x` and upgrading to version `y`, all Syndesis resources are no more owned by the syndesis CR: i.e. `meta/ownerReferences` do not contain the CR. As consequence, when deleting the CR, Syndesis is not deleted (different behaviour).  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  After upgrade, all resources should belong to the Syndesis CR, so that when it is deleted, everything else is deleted.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; N/A  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt; N/A  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt; N/A  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Install syndesis version `x` with a operator and CR 2. Upgrade to syndesis version `y` by updating the operator image 3. Delete the syndesis CR 4. Check the namespace: resources are still there </body>
		<created>2018-07-17 10:35:13</created>
		<closed>2018-07-24 10:48:51</closed>
	</bug>
	<bug>
		<id>3090</id>
		<title>When creating integration, connector icons are not clickable</title>
		<body>I think that those icons should be clickable and should show step details like when you expand integration flow and click on the names of those steps.  ![screenshot_20180716_183350](https://user-images.githubusercontent.com/14313995/42771283-f8cd5ae0-8926-11e8-92b5-5af36d98fb7e.png) </body>
		<created>2018-07-16 16:37:18</created>
		<closed>2018-07-17 13:18:54</closed>
	</bug>
	<bug>
		<id>3088</id>
		<title>Syndesis version contains special characters after upgrade</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  After running a upgrade pod to update syndesis from to a specific version, the upgrade pod updates the `syndesis` property into the `syndesis-global-config` secret, but it adds a `&lt;newline&gt;` character at the end of the version.  @rhuss   E.g. version `1.4.12` is represented in base64 as `MS40LjEyCg==`, not as `MS40LjEy`.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  No new-line characters appended in the syndesis version (or other fields updated by the upgrade pod).  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  N/A  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  N/A  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Upgrade syndesis using a upgrade pod 2. Check and decode the syndesis property in the syndesis-global-config secret </body>
		<created>2018-07-16 14:53:34</created>
		<closed>2018-07-20 11:18:35</closed>
	</bug>
	<bug>
		<id>3087</id>
		<title>Basic filter form - path autocomplete</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; A follow up from https://github.com/syndesisio/syndesis/pull/3059, wanted to create a dedicated issue for adding back the autocomplete functionality for the path field in the basic filter form array.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; When typing into the path (Property Name) field, typeahead options are shown making it easier for users to select which value they want to enter.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; &lt;img width="938" alt="screen shot 2018-07-13 at 2 11 27 pm" src="https://user-images.githubusercontent.com/5942899/42763346-bf2a1d6e-88e0-11e8-8ed1-0b6af91e8123.png"&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create simple integration, choose "basic filter" as one of the steps 2. Place focus in the "Property Name" field, and start typing 3. Notice the autocomplete values do not appear </body>
		<created>2018-07-16 14:13:50</created>
		<closed>2018-07-26 12:41:06</closed>
	</bug>
	<bug>
		<id>3073</id>
		<title>Basic filter form default state</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; The predicate select control doesn't reflect its default value on load, also the "Done" button should initially be disabled, as no rule has yet been defined.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; When the basic filter form loads in an empty state, or with a previously saved ruleset array, the predicate select control should reflect the default value. Also, user shouldn't be able to select the "Done" button until they've entered a well formed ruleset.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; &lt;img width="938" alt="screen shot 2018-07-13 at 2 11 27 pm" src="https://user-images.githubusercontent.com/5942899/42707157-46224134-86a7-11e8-8a7e-954f5359aad5.png"&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create a simple integration 2. Add a step, basic filter 3. Notice the initial state of the form illustrates the aforementioned issues</body>
		<created>2018-07-13 18:18:03</created>
		<closed>2018-07-25 16:49:14</closed>
	</bug>
	<bug>
		<id>3071</id>
		<title>Unecessary requests to `/api/v1/integrations`</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; It seems that we're hitting the `/api/v1/integrations` endpoint multiple times. This really hurts the backend (~10sec responses).  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Load only when needed, probably only when update is received via socket?  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; On staging: ![peek 2018-07-13 16-54](https://user-images.githubusercontent.com/1306050/42698380-059a3c22-86be-11e8-9059-ab0edf9ee079.gif)  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt; `GET /api/v1/integrations`  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Open Syndesis 2. Wait on the dashboard screen doing nothing 3. Notice the requests going to `/api/v1/integrations` </body>
		<created>2018-07-13 15:00:40</created>
		<closed>2018-07-18 14:05:47</closed>
	</bug>
	<bug>
		<id>3063</id>
		<title>Incorrect hostname in publishing state monitoring response</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Event and logs url from monitoring api contain a generic hostname instead of the actual cluster host name.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Event and logs url should have correct hostname obtained from openshift client API.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt; GET calls to `https://syndesis.192.168.64.36.nip.io/api/v1/monitoring/integrations` returns incorrect logsUrl and eventsURl of the form `"logsUrl":"https://openshift.default.svc/api/v1/namespaces/syndesis/pods/i-amqp-integration-21-build/logs"` ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create and Publish an integration 2. Open a browser tab with the URL `https://&lt;cluster-host&gt;/api/v1/monitoring/integrations` 3. Check the logs/events url hostname.</body>
		<created>2018-07-13 06:31:48</created>
		<closed>2018-07-13 21:02:05</closed>
	</bug>
	<bug>
		<id>3042</id>
		<title>Console error in API connector auth step</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem When there is an OAuth option in the connector auth type, you get the following error  `ExpressionChangedAfterItHasBeenCheckedError: Expression has changed after it was checked. Previous value: 'ngIf: false'. Current value: 'ngIf: true'.`  Here is the offending line https://github.com/syndesisio/syndesis/blob/master/app/ui/src/app/customizations/api-connector/api-connector-create/api-connector-auth/api-connector-auth.component.html#L29  ## Screenshot ![screen shot 2018-07-11 at 12 23 15 pm](https://user-images.githubusercontent.com/35148959/42589263-06d12f10-8506-11e8-9cfe-ddb10c71c166.png)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. I use this swagger file to create a connector - https://drive.google.com/file/d/1Qr37rHhLd0xtc72loucQ_Va5GVfEy3UQ/view?usp=sharing 2. Open the console and navigate to the authentication type in the connector setup workflow  </body>
		<created>2018-07-11 17:30:21</created>
		<closed>2018-07-30 17:20:53</closed>
	</bug>
	<bug>
		<id>3041</id>
		<title>Concur connector has incorrect data shapes</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Swagger file we created Concur connector from has little to do with reality. I just checked with [List Items API Swagger](https://developer.concur.com/api-explorer/v3-0/ListItems.swagger2.json) and the `GET /common/listitems` operation's response is defined as:  ```json     "ListItemGetCollection": {       "properties": {         "Items": {           "$ref": "#/definitions/ListItemGet"         },         "NextPage": {           "type": "string",           "description": "The URI of the next page of results, if any."         }       } ```  And based on the response we receive it should be defined as:  ```json     "ListItemGetCollection": {       "properties": {         "Items": {           "type": "array",           "items": {             "$ref": "#/definitions/ListItemGet"           }         },         "NextPage": {           "type": "string",           "description": "The URI of the next page of results, if any."         }       } ```  One can only safely assume that this mistake was made on all of 30 other Swagger specifications provided and merged into the Concur connector.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Data shapes of the connector should converge with reality.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![ezgif-4-914a9cb720](https://user-images.githubusercontent.com/1306050/42581578-5e5a18d8-852d-11e8-893c-10ca7a5525c9.gif) </body>
		<created>2018-07-11 15:11:26</created>
		<closed>2018-07-27 07:23:42</closed>
	</bug>
	<bug>
		<id>3040</id>
		<title>Whitespace characters not preserved after Angular upgrade</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Since Angular 6.0.0-beta.6 the white space optimization option is activated by default. That means that spacing between `inline` and `inline-block` elements isn't preserved, causing elements to be up against one another.  ## Expected behavior There should be a space between adjacent inline and inline-block elements.  ## Screenshot ![screen shot 2018-07-11 at 10 03 28 am](https://user-images.githubusercontent.com/35148959/42581125-aef2c718-84f1-11e8-8feb-93b5e6ff6bd2.png) ![screen shot 2018-07-11 at 10 03 12 am](https://user-images.githubusercontent.com/35148959/42581126-af1365ae-84f1-11e8-8ae4-d403fc69c35f.png) ![screen shot 2018-07-11 at 10 03 00 am](https://user-images.githubusercontent.com/35148959/42581127-af2abeb6-84f1-11e8-84fc-4c329d1100d2.png) ![screen shot 2018-07-11 at 10 07 28 am](https://user-images.githubusercontent.com/35148959/42581386-4054898a-84f2-11e8-91fd-1fb4c6f67ab3.png) </body>
		<created>2018-07-11 15:05:35</created>
		<closed>2018-07-18 16:51:23</closed>
	</bug>
	<bug>
		<id>3033</id>
		<title>New Connection wizard shows step 2 instead of 3 for Timer connector</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When creating new Connection for the Timer connector the wizard progress highlights step 2 instead of step 3.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; For connections without configuration we should either show two steps (Select Connector, Name Connection) or we should skip and mark as disabled the unnecessary middle step (Configure Connection).  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![screenshot_2018-07-11 syndesis 2](https://user-images.githubusercontent.com/1306050/42566630-7236e410-8507-11e8-96ca-e668910269ba.png)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create new Connection for Timer connector 2. Notice the step presented 3. 4. </body>
		<created>2018-07-11 10:40:25</created>
		<closed>2018-07-11 12:56:42</closed>
	</bug>
	<bug>
		<id>3025</id>
		<title>isDraft toggles to true when stopping an integration</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  While working on the detailed status stuff I've noticed that when you click 'Stop' on a running integration the `isDraft` flag seems to get set to `true` always.  This causes the 'draft' area on the integration detail page to show up, which seems kinda weird since I think this is supposed to only appear when there's been edits to the integration flow.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  Stopping/starting an integration shouldn't affect the `isDraft` flag and the 'draft' area shouldn't appear unless actual edits have been made to the integration in the editor. </body>
		<created>2018-07-10 16:33:45</created>
		<closed>2018-11-15 04:03:36</closed>
	</bug>
	<bug>
		<id>3022</id>
		<title>Twice tooltips for copy components</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When using the copy to clipboard components, I noticed that when a tooltip input is used, the tooltip is rendered twice, once attached to the appropriate element, but then it's duplicated again on the parent container.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; When a tooltip is used, it's not duplicated.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; &lt;img width="447" alt="screen shot 2018-07-09 at 10 42 14 am" src="https://user-images.githubusercontent.com/5942899/42522437-1920e368-8439-11e8-9d14-51bc64f46db0.png"&gt;   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Add a [tooltip] input property to the copy component on settings page 2. Hover over the copy to clipboard component 3. Notice the tooltip is rendered twice, once for the entire component and once for the appropriate element </body>
		<created>2018-07-10 16:04:01</created>
		<closed>2018-08-13 17:28:05</closed>
	</bug>
	<bug>
		<id>3017</id>
		<title>Integration doesn't start at all</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem An integration doesn't start, no errors, no exceptions in log. Just nothing happens. The integration is listed in the integrations list but that's pretty much all that happens.  ## Expected behavior An integration starts  ## Tasks involved / Steps to Reproduce 1. Create an integration and click Publish Or click Start on already created integration </body>
		<created>2018-07-10 09:08:45</created>
		<closed>2018-07-11 12:12:41</closed>
	</bug>
	<bug>
		<id>3016</id>
		<title>Logout on firefox does not work correctly</title>
		<body>I tried new logout endpoint on firefox from anonymous window and it does not work.  After I log out, I am on logout page. Then when I click on Login button, this happens: ![logout_error_firefox](https://user-images.githubusercontent.com/14313995/42498786-6bf51318-842d-11e8-950a-62c475d3d856.png)  Console looked like this: ![logout_error_console](https://user-images.githubusercontent.com/14313995/42498806-76af477e-842d-11e8-80fe-1b8a28213d8e.png)  @zregvart</body>
		<created>2018-07-10 08:42:47</created>
		<closed>2018-10-22 13:23:15</closed>
	</bug>
	<bug>
		<id>3014</id>
		<title>Tabs overlay the integration detail page title area</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  The tabs can float over the integration name area:  ![capture](https://user-images.githubusercontent.com/351660/42479881-eeaef25e-83a8-11e8-8494-4c0f21e99a91.PNG)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 3 different ways:  * make the window small. * open the developer console, position it at the bottom of the window and increase the vertical height. * have a lot of deployments.</body>
		<created>2018-07-09 22:53:12</created>
		<closed>2018-07-11 17:59:37</closed>
	</bug>
	<bug>
		<id>3006</id>
		<title>Error when downloading specific diagnostics from support page</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  Downloading specific integration diagnostics from support page does not work:  ![diagnostics_fail](https://user-images.githubusercontent.com/14313995/42443100-d908f116-836c-11e8-9cc8-c0d18b71d0fe.png)   </body>
		<created>2018-07-09 09:48:00</created>
		<closed>2018-07-30 13:16:10</closed>
	</bug>
	<bug>
		<id>2978</id>
		<title>Polyfills and shims needed for Angular 6 upgrade</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem After rebasing and using the latest changes with Angular 6.0.4 I started to get the following error coming from the yamljs package when I'd try to rebuild with `yarn ng build --aot=false --vendor-chunk=true --source-map=true` or even just `syndesis build --clean`, which uses the same command.  ## Screenshot   ``` ERROR in ./node_modules/yamljs/lib/Utils.js Module not found: Error: Can't resolve 'fs' in '/Users/kahboom/Projects/syndesis/app/ui/node_modules/yamljs/lib' ```  &lt;img width="835" alt="screenshot 2018-07-04 23 19 44" src="https://user-images.githubusercontent.com/3844502/42300994-19fb0568-7fe1-11e8-9460-acb753462dca.png"&gt;    See my comment [here](https://github.com/angular/angular-cli/issues/10681#issuecomment-402594619) for more details.  I also got a few other weird things related to SASS:  ``` Module build failed: Error: Node Sass does not yet support your current environment: OS X 64-bit with Unsupported runtime (64) ```  &lt;img width="1673" alt="screenshot 2018-07-04 22 02 51" src="https://user-images.githubusercontent.com/3844502/42300965-ea7fe75e-7fe0-11e8-8685-ef5659c2d859.png"&gt;   EDIT: This should be resolved with this PR #2886 .</body>
		<created>2018-07-05 03:21:59</created>
		<closed>2018-07-19 02:15:34</closed>
	</bug>
	<bug>
		<id>2976</id>
		<title>unable to add log step</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Log step does not appear to work anymore, the integration runtime throws this error:  ``` org.apache.camel.RuntimeCamelException: org.apache.camel.FailedToCreateRouteException: Failed to create route ... because of message must be specified and not empty on: Log[] ```  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ``` i-webh1-11-rbxcv i-webh1 org.apache.camel.RuntimeCamelException: org.apache.camel.FailedToCreateRouteException: Failed to create route -LGa5pFqdfn87sTtbaNV at: &gt;&gt;&gt; pipeline -&gt; [[SetHeader[Syndesis.STEP_ID, constant{-LGa7_9Bdfn87sTtbaNX}], Log[], process[Processor@0x40faff12]]] &lt;&lt;&lt; in route: Route(-LGa5pFqdfn87sTtbaNV)[[From[servlet-1]] -&gt; [SetHeader[... because of message must be specified and not empty on: Log[] i-webh1-11-rbxcv i-webh1 at org.apache.camel.util.ObjectHelper.wrapRuntimeCamelException(ObjectHelper.java:1830) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.apache.camel.spring.SpringCamelContext.start(SpringCamelContext.java:136) ~[camel-spring-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.apache.camel.spring.SpringCamelContext.onApplicationEvent(SpringCamelContext.java:174) ~[camel-spring-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172) ~[spring-context-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] i-webh1-11-rbxcv i-webh1 at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165) ~[spring-context-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] i-webh1-11-rbxcv i-webh1 at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139) ~[spring-context-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] i-webh1-11-rbxcv i-webh1 at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:393) ~[spring-context-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] i-webh1-11-rbxcv i-webh1 at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:347) ~[spring-context-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] i-webh1-11-rbxcv i-webh1 at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:883) ~[spring-context-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] i-webh1-11-rbxcv i-webh1 at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.finishRefresh(EmbeddedWebApplicationContext.java:144) ~[spring-boot-1.5.13.RELEASE.jar!/:1.5.13.RELEASE] i-webh1-11-rbxcv i-webh1 at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546) ~[spring-context-4.3.17.RELEASE.jar!/:4.3.17.RELEASE] i-webh1-11-rbxcv i-webh1 at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) ~[spring-boot-1.5.13.RELEASE.jar!/:1.5.13.RELEASE] i-webh1-11-rbxcv i-webh1 at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.13.RELEASE.jar!/:1.5.13.RELEASE] i-webh1-11-rbxcv i-webh1 at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.13.RELEASE.jar!/:1.5.13.RELEASE] i-webh1-11-rbxcv i-webh1 at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.13.RELEASE.jar!/:1.5.13.RELEASE] i-webh1-11-rbxcv i-webh1 at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.13.RELEASE.jar!/:1.5.13.RELEASE] i-webh1-11-rbxcv i-webh1 at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.13.RELEASE.jar!/:1.5.13.RELEASE] i-webh1-11-rbxcv i-webh1 at io.syndesis.example.Application.main(Application.java:13) [classes!/:na] i-webh1-11-rbxcv i-webh1 at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_151] i-webh1-11-rbxcv i-webh1 at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_151] i-webh1-11-rbxcv i-webh1 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151] i-webh1-11-rbxcv i-webh1 at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151] i-webh1-11-rbxcv i-webh1 at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48) [project-0.1-SNAPSHOT.jar:na] i-webh1-11-rbxcv i-webh1 at org.springframework.boot.loader.Launcher.launch(Launcher.java:87) [project-0.1-SNAPSHOT.jar:na] i-webh1-11-rbxcv i-webh1 at org.springframework.boot.loader.Launcher.launch(Launcher.java:50) [project-0.1-SNAPSHOT.jar:na] i-webh1-11-rbxcv i-webh1 at org.springframework.boot.loader.PropertiesLauncher.main(PropertiesLauncher.java:595) [project-0.1-SNAPSHOT.jar:na] i-webh1-11-rbxcv i-webh1 Caused by: org.apache.camel.FailedToCreateRouteException: Failed to create route -LGa5pFqdfn87sTtbaNV at: &gt;&gt;&gt; pipeline -&gt; [[SetHeader[Syndesis.STEP_ID, constant{-LGa7_9Bdfn87sTtbaNX}], Log[], process[Processor@0x40faff12]]] &lt;&lt;&lt; in route: Route(-LGa5pFqdfn87sTtbaNV)[[From[servlet-1]] -&gt; [SetHeader[... because of message must be specified and not empty on: Log[] i-webh1-11-rbxcv i-webh1 at org.apache.camel.model.RouteDefinition.addRoutes(RouteDefinition.java:1303) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.apache.camel.model.RouteDefinition.addRoutes(RouteDefinition.java:204) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.apache.camel.impl.DefaultCamelContext.startRoute(DefaultCamelContext.java:1143) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.apache.camel.impl.DefaultCamelContext.startRouteDefinitions(DefaultCamelContext.java:3729) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.apache.camel.impl.DefaultCamelContext.doStartCamel(DefaultCamelContext.java:3443) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.apache.camel.impl.DefaultCamelContext.access$000(DefaultCamelContext.java:209) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.apache.camel.impl.DefaultCamelContext$2.call(DefaultCamelContext.java:3251) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.apache.camel.impl.DefaultCamelContext$2.call(DefaultCamelContext.java:3247) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.apache.camel.impl.DefaultCamelContext.doWithDefinedClassLoader(DefaultCamelContext.java:3270) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.apache.camel.impl.DefaultCamelContext.doStart(DefaultCamelContext.java:3247) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.apache.camel.impl.DefaultCamelContext.start(DefaultCamelContext.java:3163) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.apache.camel.spring.SpringCamelContext.start(SpringCamelContext.java:133) ~[camel-spring-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 ... 24 common frames omitted i-webh1-11-rbxcv i-webh1 Caused by: java.lang.IllegalArgumentException: message must be specified and not empty on: Log[] i-webh1-11-rbxcv i-webh1 at org.apache.camel.util.StringHelper.notEmpty(StringHelper.java:339) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.apache.camel.util.ObjectHelper.notEmpty(ObjectHelper.java:376) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.apache.camel.model.LogDefinition.createProcessor(LogDefinition.java:85) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.apache.camel.model.ProcessorDefinition.createProcessor(ProcessorDefinition.java:511) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.apache.camel.model.ProcessorDefinition.createOutputsProcessorImpl(ProcessorDefinition.java:474) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.apache.camel.model.ProcessorDefinition.createOutputsProcessor(ProcessorDefinition.java:441) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.apache.camel.model.ProcessorDefinition.createOutputsProcessor(ProcessorDefinition.java:185) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.apache.camel.model.ProcessorDefinition.createChildProcessor(ProcessorDefinition.java:204) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.apache.camel.model.PipelineDefinition.createProcessor(PipelineDefinition.java:46) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.apache.camel.model.ProcessorDefinition.makeProcessorImpl(ProcessorDefinition.java:562) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.apache.camel.model.ProcessorDefinition.makeProcessor(ProcessorDefinition.java:523) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.apache.camel.model.ProcessorDefinition.addRoutes(ProcessorDefinition.java:239) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 at org.apache.camel.model.RouteDefinition.addRoutes(RouteDefinition.java:1300) ~[camel-core-2.21.0.fuse-000094.jar!/:2.21.0.fuse-000094] i-webh1-11-rbxcv i-webh1 ... 36 common frames omitted  ``` </body>
		<created>2018-07-04 16:37:06</created>
		<closed>2018-07-05 15:08:43</closed>
	</bug>
	<bug>
		<id>2974</id>
		<title>step properties not persisted</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  When switching back and fort between steps, some configuration are lost  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  Configurations should be kept  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;   ![jdbc-issue](https://user-images.githubusercontent.com/1868933/42282440-cd2a183a-7fa6-11e8-95ac-343e29b7f6df.gif) </body>
		<created>2018-07-04 14:25:53</created>
		<closed>2018-07-05 14:35:14</closed>
	</bug>
	<bug>
		<id>2971</id>
		<title>[Meta] No suitable driver found for jdbc:postgresql://syndesis-db:5432/sampledb. Unable to fetch and process metadata </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  When creating integration with postgres default connection, this is logged in meta:  ```  2018-07-04 11:47:35.399 ERROR 1 --- [  XNIO-3 task-4] i.s.connector.meta.v1.VerifierEndpoint   : Unable to fetch and process metadata for connector: sql, action: sql-start-connector --  | 2018-07-04 11:47:35.406 ERROR 1 --- [  XNIO-3 task-4] i.s.c.meta.VerifierExceptionMapper       : Exception while handling request: POST /api/v1/connectors/sql/actions/sql-start-connector  |   | io.syndesis.common.util.SyndesisServerException: No suitable driver found for jdbc:postgresql://syndesis-db:5432/sampledb. Unable to fetch and process metadata  | at io.syndesis.connector.support.verifier.api.MetadataRetrieval.handle(MetadataRetrieval.java:42) ~[connector-support-verifier-1.4-SNAPSHOT.jar!/:1.4-SNAPSHOT]  | at io.syndesis.connector.meta.v1.ConnectorEndpoint.actions(ConnectorEndpoint.java:87) ~[classes!/:1.4-SNAPSHOT]  | at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_151]  | at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_151]  | at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151]  | at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151]  | at org.jboss.resteasy.core.MethodInjectorImpl.invoke(MethodInjectorImpl.java:140) ~[resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.core.ResourceMethodInvoker.internalInvokeOnTarget(ResourceMethodInvoker.java:510) ~[resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTargetAfterFilter(ResourceMethodInvoker.java:401) ~[resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.core.ResourceMethodInvoker.lambda$invokeOnTarget$0(ResourceMethodInvoker.java:365) ~[resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:361) ~[resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTarget(ResourceMethodInvoker.java:367) ~[resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:339) ~[resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:312) ~[resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:441) [resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.core.SynchronousDispatcher.lambda$invoke$4(SynchronousDispatcher.java:231) [resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.core.SynchronousDispatcher.lambda$preprocess$0(SynchronousDispatcher.java:137) [resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.core.interception.PreMatchContainerRequestContext.filter(PreMatchContainerRequestContext.java:361) ~[resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.core.SynchronousDispatcher.preprocess(SynchronousDispatcher.java:140) [resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:217) [resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.plugins.server.servlet.ServletContainerDispatcher.service(ServletContainerDispatcher.java:227) ~[resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:56) ~[resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:51) ~[resteasy-jaxrs-3.5.1.Final.jar!/:3.5.1.Final]  | at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) ~[javax.servlet-api-3.1.0.jar!/:3.1.0]  | at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) ~[spring-boot-1.5.13.RELEASE.jar!/:1.5.13.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at org.springframework.web.filter.AbstractRequestLoggingFilter.doFilterInternal(AbstractRequestLoggingFilter.java:244) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:111) ~[spring-boot-actuator-1.5.13.RELEASE.jar!/:1.5.13.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:106) ~[spring-boot-actuator-1.5.13.RELEASE.jar!/:1.5.13.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.17.RELEASE.jar!/:4.3.17.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:64) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:132) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) ~[undertow-servlet-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.server.Connectors.executeRootHandler(Connectors.java:336) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final]  | at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) ~[undertow-core-1.4.25.Final.jar!/:1.4.25.Final]  | at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_151]  | at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_151]  | at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_151]  | Caused by: io.syndesis.common.util.SyndesisServerException: No suitable driver found for jdbc:postgresql://syndesis-db:5432/sampledb  | at io.syndesis.connector.sql.SqlConnectorMetaDataExtension.meta(SqlConnectorMetaDataExtension.java:55) ~[connector-sql-1.4-SNAPSHOT.jar!/:1.4-SNAPSHOT]  | at io.syndesis.connector.support.verifier.api.ComponentMetadataRetrieval.fetchMetaData(ComponentMetadataRetrieval.java:54) ~[connector-support-verifier-1.4-SNAPSHOT.jar!/:1.4-SNAPSHOT]  | at io.syndesis.connector.support.verifier.api.ComponentMetadataRetrieval.fetch(ComponentMetadataRetrieval.java:48) ~[connector-support-verifier-1.4-SNAPSHOT.jar!/:1.4-SNAPSHOT]  | at io.syndesis.connector.meta.v1.ConnectorEndpoint.actions(ConnectorEndpoint.java:81) ~[classes!/:1.4-SNAPSHOT]  | ... 84 common frames omitted  | Caused by: java.sql.SQLException: No suitable driver found for jdbc:postgresql://syndesis-db:5432/sampledb  | at java.sql.DriverManager.getConnection(DriverManager.java:689) ~[na:1.8.0_151]  | at java.sql.DriverManager.getConnection(DriverManager.java:247) ~[na:1.8.0_151]  | at io.syndesis.connector.sql.SqlSupport.createConnection(SqlSupport.java:40) ~[connector-sql-1.4-SNAPSHOT.jar!/:1.4-SNAPSHOT]  | at io.syndesis.connector.sql.SqlConnectorMetaDataExtension.meta(SqlConnectorMetaDataExtension.java:46) ~[connector-sql-1.4-SNAPSHOT.jar!/:1.4-SNAPSHOT]  | ... 87 common frames omitted   ```  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. select start connection postgres 2. write some SQL, for example "SELECT 1" 3. Hit done 4. Check exceptions in meta pod and UI </body>
		<created>2018-07-04 11:49:17</created>
		<closed>2018-07-04 16:04:29</closed>
	</bug>
	<bug>
		<id>2969</id>
		<title>Filter in settings page is broken</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  The filter works, but when you add some filter and then click on clear all, you are redirected to new empty tab. The same happens when you select the filter from dropdown and click on the only member - Name:  ![out](https://user-images.githubusercontent.com/14313995/42260542-24b80c66-7f65-11e8-97bd-5b47f235e029.gif)    </body>
		<created>2018-07-04 06:36:14</created>
		<closed>2018-07-05 18:04:07</closed>
	</bug>
	<bug>
		<id>2968</id>
		<title>Buttons when creating connection are broken</title>
		<body>**[x] Regression**  Instead of next/back buttons there are just question marks.  ![malformedbuttons](https://user-images.githubusercontent.com/14313995/42260186-be0187c8-7f63-11e8-8325-e233805d566c.png)    </body>
		<created>2018-07-04 06:28:47</created>
		<closed>2018-07-05 13:25:07</closed>
	</bug>
	<bug>
		<id>2967</id>
		<title>Meta pod doesn't start because "Cannot determine embedded database driver class for database type NONE"</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  With the latest version of images, the meta pod fails to start with: Cannot determine embedded database driver class for database type NONE . It was working yesterday (3rd july) in the morning  ```  No extensions found --  | No extensions found  | exec java -Djava.net.preferIPv4Stack=true -Duser.home=/tmp -javaagent:/opt/agent-bond/agent-bond.jar=jolokia{{host=0.0.0.0}},jmx_exporter{{9779:/opt/agent-bond/jmx_exporter_config.yml}} -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005 -Xmx256m -XX:+UseParallelGC -XX:GCTimeRatio=4 -XX:AdaptiveSizePolicyWeight=90 -XX:MinHeapFreeRatio=20 -XX:MaxHeapFreeRatio=40 -XX:+ExitOnOutOfMemoryError -cp . -jar /deployments/meta-1.4-SNAPSHOT.jar  | I&gt; No access restrictor found, access to any MBean is allowed  | Jolokia: Agent started with URL http://172.17.0.13:8778/jolokia/  | Listening for transport dt_socket at address: 5005  | _______.                 _               _  | /       \|                 \| \|             (_)  | \|   (----`_   _  ____    _ \| \|  ____   ___  _   ___  | \   \   \| \| \| \|\|  _ \  / \|\| \| / _  ) /___)\| \| /___)  | .----)   \|  \| \|_\| \|\| \| \| \|( (_\| \|( (/ / \|___ \|\| \|\|___ \|  | \|_______/    \__  \|\|_\| \|_\| \____\| \____)(___/ \|_\|(___/  | ============ (____/ ===================================  | :: Meta :: v1.4-SNAPSHOT  |   |   | 2018-07-04 06:08:36.741  INFO 1 --- [           main] io.syndesis.connector.meta.Application   : Starting Application v1.4-SNAPSHOT on syndesis-meta-1-kzk5n with PID 1 (/deployments/meta-1.4-SNAPSHOT.jar started by ? in /deployments)  | 2018-07-04 06:08:36.759  INFO 1 --- [           main] io.syndesis.connector.meta.Application   : No active profile set, falling back to default profiles: default  | 2018-07-04 06:08:36.879  INFO 1 --- [           main] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@73e9cf30: startup date [Wed Jul 04 06:08:36 UTC 2018]; root of context hierarchy  | 2018-07-04 06:08:40.412  INFO 1 --- [           main] p.s.r.ResteasyEmbeddedServletInitializer : Finding JAX-RS Application classes  | 2018-07-04 06:08:40.414  INFO 1 --- [           main] p.s.r.ResteasyEmbeddedServletInitializer : Property resteasy.jaxrs.app.registration has not been set, JAX-RS Application classes registration is being set to AUTO  | 2018-07-04 06:08:40.416  INFO 1 --- [           main] p.s.r.ResteasyEmbeddedServletInitializer : Searching for JAX-RS Application Spring beans  | 2018-07-04 06:08:40.541  INFO 1 --- [           main] org.reflections.Reflections              : Reflections took 64 ms to scan 1 urls, producing 20 keys and 28 values  | 2018-07-04 06:08:40.585  INFO 1 --- [           main] p.s.r.ResteasyEmbeddedServletInitializer : JAX-RS Application class found: io.syndesis.connector.meta.v1.V1  | 2018-07-04 06:08:40.602  INFO 1 --- [           main] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring  | 2018-07-04 06:08:41.651  INFO 1 --- [           main] org.xnio                                 : XNIO version 3.3.8.Final  | 2018-07-04 06:08:41.764  INFO 1 --- [           main] org.xnio.nio                             : XNIO NIO Implementation Version 3.3.8.Final  | 2018-07-04 06:08:41.950  WARN 1 --- [           main] io.undertow.websockets.jsr               : UT026009: XNIO worker was not set on WebSocketDeploymentInfo, the default worker will be used  | 2018-07-04 06:08:41.951  WARN 1 --- [           main] io.undertow.websockets.jsr               : UT026010: Buffer pool was not set on WebSocketDeploymentInfo, the default pool will be used  | 2018-07-04 06:08:42.072  INFO 1 --- [           main] io.undertow.servlet                      : Initializing Spring embedded WebApplicationContext  | 2018-07-04 06:08:42.072  INFO 1 --- [           main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 5195 ms  | 2018-07-04 06:08:42.713  INFO 1 --- [           main] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/]  | 2018-07-04 06:08:42.720  INFO 1 --- [           main] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'io.syndesis.connector.meta.v1.V1' to [/api/v1/*]  | 2018-07-04 06:08:42.728  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'metricsFilter' to: [/*]  | 2018-07-04 06:08:42.731  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]  | 2018-07-04 06:08:42.731  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]  | 2018-07-04 06:08:42.732  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]  | 2018-07-04 06:08:42.732  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]  | 2018-07-04 06:08:42.733  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'webRequestLoggingFilter' to: [/*]  | 2018-07-04 06:08:42.734  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestLoggingFilter' to: [/*]  | 2018-07-04 06:08:42.734  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'applicationContextIdFilter' to: [/*]  | 2018-07-04 06:08:43.769  INFO 1 --- [           main] o.apache.camel.impl.DefaultCamelContext  : Apache Camel 2.21.0.fuse-000094 (CamelContext: verifier-context) is starting  | 2018-07-04 06:08:43.778  INFO 1 --- [           main] o.a.c.m.DefaultManagementStrategy        : JMX is disabled  | 2018-07-04 06:08:43.949  INFO 1 --- [           main] o.a.c.i.converter.DefaultTypeConverter   : Type converters loaded (core: 194, classpath: 19)  | 2018-07-04 06:08:43.972  INFO 1 --- [           main] o.apache.camel.impl.DefaultCamelContext  : StreamCaching is not in use. If using streams then its recommended to enable stream caching. See more details at http://camel.apache.org/stream-caching.html  | 2018-07-04 06:08:43.977  INFO 1 --- [           main] o.apache.camel.impl.DefaultCamelContext  : Total 0 routes, of which 0 are started  | 2018-07-04 06:08:43.979  INFO 1 --- [           main] o.apache.camel.impl.DefaultCamelContext  : Apache Camel 2.21.0.fuse-000094 (CamelContext: verifier-context) started in 0.211 seconds  | 2018-07-04 06:08:45.226  INFO 1 --- [           main] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@73e9cf30: startup date [Wed Jul 04 06:08:36 UTC 2018]; root of context hierarchy  | 2018-07-04 06:08:45.444  INFO 1 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)  | 2018-07-04 06:08:45.448  INFO 1 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity&lt;java.util.Map&lt;java.lang.String, java.lang.Object&gt;&gt; org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)  | 2018-07-04 06:08:45.574  INFO 1 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]  | 2018-07-04 06:08:45.575  INFO 1 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]  | 2018-07-04 06:08:45.807  INFO 1 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]  | 2018-07-04 06:08:46.553  WARN 1 --- [           main] ationConfigEmbeddedWebApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource [org/springframework/boot/autoconfigure/jdbc/DataSourceConfiguration$Dbcp.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.commons.dbcp.BasicDataSource]: Factory method 'dataSource' threw exception; nested exception is org.springframework.boot.autoconfigure.jdbc.DataSourceProperties$DataSourceBeanCreationException: Cannot determine embedded database driver class for database type NONE. If you want an embedded database please put a supported one on the classpath. If you have database settings to be loaded from a particular profile you may need to active it (no profiles are currently active).  | 2018-07-04 06:08:46.554  INFO 1 --- [           main] o.apache.camel.impl.DefaultCamelContext  : Apache Camel 2.21.0.fuse-000094 (CamelContext: verifier-context) is shutting down  | 2018-07-04 06:08:46.587  INFO 1 --- [           main] o.apache.camel.impl.DefaultCamelContext  : Apache Camel 2.21.0.fuse-000094 (CamelContext: verifier-context) uptime 2.820 seconds  | 2018-07-04 06:08:46.587  INFO 1 --- [           main] o.apache.camel.impl.DefaultCamelContext  : Apache Camel 2.21.0.fuse-000094 (CamelContext: verifier-context) is shutdown in 0.033 seconds  | 2018-07-04 06:08:46.605  INFO 1 --- [           main] utoConfigurationReportLoggingInitializer :  |   | Error starting ApplicationContext. To display the auto-configuration report re-run your application with 'debug' enabled.  | 2018-07-04 06:08:46.623 ERROR 1 --- [           main] o.s.b.d.LoggingFailureAnalysisReporter   :  |   | ***************************  | APPLICATION FAILED TO START  | ***************************  |   | Description:  |   | Cannot determine embedded database driver class for database type NONE  |   | Action:  |   | If you want an embedded database please put a supported one on the classpath. If you have database settings to be loaded from a particular profile you may need to active it (no profiles are currently active).   ```  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Meta pod to start  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-07-04 06:14:58</created>
		<closed>2018-07-04 08:19:12</closed>
	</bug>
	<bug>
		<id>2956</id>
		<title>[Integration Deployment] Sometimes the integration deployment is being recreated indefinitely</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Current integration deployment behavior is that a "deployment 1" is created, but it is terminated and "deployment 2" is started and then the integration is deployed.  In rare cases (which I can't reliably reproduce), the "deployment 2" is terminated for unknown reasons and the whole "deployment" process is started again. So "deployment 3" is started and terminated and "deployment 4" is started and should deploy the integration. And this over and over again and the integration is never deployed successfully.  I saw this problem both on minishift and deployed openshift instance.  According to server log, it is doing the reprovision:  ```  2018-07-03 12:06:16.441  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.i.IntegrationController          : Integration i-LGV1IwetePgfhzupC2oz:1 : Desired status "Published" != current status "Unpublished" --&gt; calling status change handler --  | 2018-07-03 12:06:16.442  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.i.IntegrationController          : Integration i-LGV1IwetePgfhzupC2oz : Start processing integration: i-LGV1IwetePgfhzupC2oz, version: 1 with handler:PublishHandler  | 2018-07-03 12:06:17.051  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Build started: false, isRunning: false, Deployment ready: true  | 2018-07-03 12:06:17.052  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Steps performed so far: {}  | 2018-07-03 12:06:17.348  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Created project files and starting build  | 2018-07-03 12:06:21.603  INFO [-,,,] 1 --- [ool-12-thread-1] i.s.i.p.generator.ProjectGenerator       : Integration [sf-kafka]: Project files written to output stream  | 2018-07-03 12:07:12.399  INFO [-,,,] 1 --- [oller Scheduler] i.s.s.c.i.IntegrationController          : Checking integrations for their status.  | 2018-07-03 12:08:12.427  INFO [-,,,] 1 --- [oller Scheduler] i.s.s.c.i.IntegrationController          : Checking integrations for their status.  | 2018-07-03 12:09:12.398  INFO [-,,,] 1 --- [oller Scheduler] i.s.s.c.i.IntegrationController          : Checking integrations for their status.  | 2018-07-03 12:09:13.875  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Starting deployment  | 2018-07-03 12:09:16.799  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Deployment done  | 2018-07-03 12:09:16.822  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Build started: false, isRunning: false, Deployment ready: false  | 2018-07-03 12:09:16.822  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: [PENDING] [{buildv1=172.30.1.1:5000/myproject/i-sf-kafka:1, deploy=1}]  | 2018-07-03 12:09:16.823  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.i.IntegrationController          : Integration i-LGV1IwetePgfhzupC2oz : Setting status to Pending  | 2018-07-03 12:10:12.399  INFO [-,,,] 1 --- [oller Scheduler] i.s.s.c.i.IntegrationController          : Checking integrations for their status.  | 2018-07-03 12:10:16.926  INFO [-,,,] 1 --- [oller Scheduler] i.s.s.c.i.IntegrationController          : Integration i-LGV1IwetePgfhzupC2oz:1 : Desired status "Published" != current status "Unpublished" --&gt; calling status change handler  | 2018-07-03 12:10:16.926  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.i.IntegrationController          : Integration i-LGV1IwetePgfhzupC2oz : Start processing integration: i-LGV1IwetePgfhzupC2oz, version: 1 with handler:PublishHandler  | 2018-07-03 12:10:16.964  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Build started: false, isRunning: false, Deployment ready: false  | 2018-07-03 12:10:16.964  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Steps performed so far: {buildv1=172.30.1.1:5000/myproject/i-sf-kafka:1}  | 2018-07-03 12:10:17.054  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Skipped step buildv1 because already performed  | 2018-07-03 12:10:17.057  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Starting deployment  | 2018-07-03 12:10:19.797  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Deployment done  | 2018-07-03 12:10:19.810  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Build started: false, isRunning: false, Deployment ready: false  | 2018-07-03 12:10:19.810  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: [PENDING] [{buildv1=172.30.1.1:5000/myproject/i-sf-kafka:1, deploy=3}]  | 2018-07-03 12:10:19.810  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.i.IntegrationController          : Integration i-LGV1IwetePgfhzupC2oz : Setting status to Pending  | 2018-07-03 12:11:12.405  INFO [-,,,] 1 --- [oller Scheduler] i.s.s.c.i.IntegrationController          : Checking integrations for their status.  | 2018-07-03 12:11:19.950  INFO [-,,,] 1 --- [oller Scheduler] i.s.s.c.i.IntegrationController          : Integration i-LGV1IwetePgfhzupC2oz:1 : Desired status "Published" != current status "Unpublished" --&gt; calling status change handler  | 2018-07-03 12:11:19.951  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.i.IntegrationController          : Integration i-LGV1IwetePgfhzupC2oz : Start processing integration: i-LGV1IwetePgfhzupC2oz, version: 1 with handler:PublishHandler  | 2018-07-03 12:11:19.997  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Build started: false, isRunning: false, Deployment ready: false  | 2018-07-03 12:11:19.997  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Steps performed so far: {buildv1=172.30.1.1:5000/myproject/i-sf-kafka:1}  | 2018-07-03 12:11:20.093  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Skipped step buildv1 because already performed  | 2018-07-03 12:11:20.099  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Starting deployment  | 2018-07-03 12:11:22.656  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Deployment done  | 2018-07-03 12:11:22.684  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Build started: false, isRunning: false, Deployment ready: false  | 2018-07-03 12:11:22.684  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: [PENDING] [{buildv1=172.30.1.1:5000/myproject/i-sf-kafka:1, deploy=4}]  | 2018-07-03 12:11:22.684  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.i.IntegrationController          : Integration i-LGV1IwetePgfhzupC2oz : Setting status to Pending  | 2018-07-03 12:12:12.398  INFO [-,,,] 1 --- [oller Scheduler] i.s.s.c.i.IntegrationController          : Checking integrations for their status.  | 2018-07-03 12:12:22.749  INFO [-,,,] 1 --- [oller Scheduler] i.s.s.c.i.IntegrationController          : Integration i-LGV1IwetePgfhzupC2oz:1 : Desired status "Published" != current status "Unpublished" --&gt; calling status change handler  | 2018-07-03 12:12:22.749  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.i.IntegrationController          : Integration i-LGV1IwetePgfhzupC2oz : Start processing integration: i-LGV1IwetePgfhzupC2oz, version: 1 with handler:PublishHandler  | 2018-07-03 12:12:22.781  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Build started: false, isRunning: false, Deployment ready: false  | 2018-07-03 12:12:22.781  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Steps performed so far: {buildv1=172.30.1.1:5000/myproject/i-sf-kafka:1}  | 2018-07-03 12:12:22.865  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Skipped step buildv1 because already performed  | 2018-07-03 12:12:22.870  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Starting deployment  | 2018-07-03 12:12:25.680  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Deployment done  | 2018-07-03 12:12:25.698  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Build started: false, isRunning: false, Deployment ready: false  | 2018-07-03 12:12:25.699  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: [PENDING] [{buildv1=172.30.1.1:5000/myproject/i-sf-kafka:1, deploy=6}]  | 2018-07-03 12:12:25.701  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.i.IntegrationController          : Integration i-LGV1IwetePgfhzupC2oz : Setting status to Pending  | 2018-07-03 12:13:12.399  INFO [-,,,] 1 --- [oller Scheduler] i.s.s.c.i.IntegrationController          : Checking integrations for their status.  | 2018-07-03 12:13:25.836  INFO [-,,,] 1 --- [oller Scheduler] i.s.s.c.i.IntegrationController          : Integration i-LGV1IwetePgfhzupC2oz:1 : Desired status "Published" != current status "Unpublished" --&gt; calling status change handler  | 2018-07-03 12:13:25.837  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.i.IntegrationController          : Integration i-LGV1IwetePgfhzupC2oz : Start processing integration: i-LGV1IwetePgfhzupC2oz, version: 1 with handler:PublishHandler  | 2018-07-03 12:13:25.884  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Build started: false, isRunning: false, Deployment ready: false  | 2018-07-03 12:13:25.884  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Steps performed so far: {buildv1=172.30.1.1:5000/myproject/i-sf-kafka:1}  | 2018-07-03 12:13:25.957  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Skipped step buildv1 because already performed  | 2018-07-03 12:13:25.960  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Starting deployment  | 2018-07-03 12:13:28.539  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Deployment done  | 2018-07-03 12:13:28.551  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Build started: false, isRunning: false, Deployment ready: false  | 2018-07-03 12:13:28.551  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: [PENDING] [{buildv1=172.30.1.1:5000/myproject/i-sf-kafka:1, deploy=8}]  | 2018-07-03 12:13:28.551  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.i.IntegrationController          : Integration i-LGV1IwetePgfhzupC2oz : Setting status to Pending  | 2018-07-03 12:14:12.398  INFO [-,,,] 1 --- [oller Scheduler] i.s.s.c.i.IntegrationController          : Checking integrations for their status.  | 2018-07-03 12:14:28.636  INFO [-,,,] 1 --- [oller Scheduler] i.s.s.c.i.IntegrationController          : Integration i-LGV1IwetePgfhzupC2oz:1 : Desired status "Published" != current status "Unpublished" --&gt; calling status change handler  | 2018-07-03 12:14:28.636  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.i.IntegrationController          : Integration i-LGV1IwetePgfhzupC2oz : Start processing integration: i-LGV1IwetePgfhzupC2oz, version: 1 with handler:PublishHandler  | 2018-07-03 12:14:28.662  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Build started: false, isRunning: false, Deployment ready: false  | 2018-07-03 12:14:28.662  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Steps performed so far: {buildv1=172.30.1.1:5000/myproject/i-sf-kafka:1}  | 2018-07-03 12:14:28.715  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Skipped step buildv1 because already performed  | 2018-07-03 12:14:28.718  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Starting deployment  | 2018-07-03 12:14:30.809  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Deployment done  | 2018-07-03 12:14:30.835  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Build started: false, isRunning: false, Deployment ready: false  | 2018-07-03 12:14:30.835  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: [PENDING] [{buildv1=172.30.1.1:5000/myproject/i-sf-kafka:1, deploy=9}]  | 2018-07-03 12:14:30.835  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.i.IntegrationController          : Integration i-LGV1IwetePgfhzupC2oz : Setting status to Pending  | 2018-07-03 12:15:12.399  INFO [-,,,] 1 --- [oller Scheduler] i.s.s.c.i.IntegrationController          : Checking integrations for their status.  | 2018-07-03 12:15:31.066  INFO [-,,,] 1 --- [oller Scheduler] i.s.s.c.i.IntegrationController          : Integration i-LGV1IwetePgfhzupC2oz:1 : Desired status "Published" != current status "Unpublished" --&gt; calling status change handler  | 2018-07-03 12:15:31.070  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.i.IntegrationController          : Integration i-LGV1IwetePgfhzupC2oz : Start processing integration: i-LGV1IwetePgfhzupC2oz, version: 1 with handler:PublishHandler  | 2018-07-03 12:15:31.103  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Build started: false, isRunning: false, Deployment ready: false  | 2018-07-03 12:15:31.104  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Steps performed so far: {buildv1=172.30.1.1:5000/myproject/i-sf-kafka:1}  | 2018-07-03 12:15:31.193  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Skipped step buildv1 because already performed  | 2018-07-03 12:15:31.198  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Starting deployment  | 2018-07-03 12:15:33.326  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Deployment done  | 2018-07-03 12:15:33.358  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Build started: false, isRunning: false, Deployment ready: false  | 2018-07-03 12:15:33.358  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: [PENDING] [{buildv1=172.30.1.1:5000/myproject/i-sf-kafka:1, deploy=10}]  | 2018-07-03 12:15:33.359  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.i.IntegrationController          : Integration i-LGV1IwetePgfhzupC2oz : Setting status to Pending  | 2018-07-03 12:16:12.402  INFO [-,,,] 1 --- [oller Scheduler] i.s.s.c.i.IntegrationController          : Checking integrations for their status.  | 2018-07-03 12:16:29.965  INFO [-,,,] 1 --- [oller Scheduler] i.s.s.l.j.c.ActivityTrackingController   : Purging old controller  | 2018-07-03 12:16:33.444  INFO [-,,,] 1 --- [oller Scheduler] i.s.s.c.i.IntegrationController          : Integration i-LGV1IwetePgfhzupC2oz:1 : Desired status "Published" != current status "Unpublished" --&gt; calling status change handler  | 2018-07-03 12:16:33.445  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.i.IntegrationController          : Integration i-LGV1IwetePgfhzupC2oz : Start processing integration: i-LGV1IwetePgfhzupC2oz, version: 1 with handler:PublishHandler  | 2018-07-03 12:16:33.467  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Build started: false, isRunning: false, Deployment ready: false  | 2018-07-03 12:16:33.468  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Steps performed so far: {buildv1=172.30.1.1:5000/myproject/i-sf-kafka:1}  | 2018-07-03 12:16:33.533  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Skipped step buildv1 because already performed  | 2018-07-03 12:16:33.537  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Starting deployment  | 2018-07-03 12:16:35.821  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Deployment done  | 2018-07-03 12:16:35.839  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: Build started: false, isRunning: false, Deployment ready: false  | 2018-07-03 12:16:35.839  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-kafka]: [PENDING] [{buildv1=172.30.1.1:5000/myproject/i-sf-kafka:1, deploy=12}]  | 2018-07-03 12:16:35.839  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.i.IntegrationController          : Integration i-LGV1IwetePgfhzupC2oz : Setting status to Pending  | 2018-07-03 12:17:12.399  INFO [-,,,] 1 --- [oller Scheduler] i.s.s.c.i.IntegrationController          : Checking integrations for their status.  ... and so on :-) ```     ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Successful deployment of the integration  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![s5mu](https://user-images.githubusercontent.com/7081216/42220038-22a67080-7ece-11e8-9050-3fdb52df64c0.png)  22 deployments in 17 minutes and still counting...  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-07-03 12:35:12</created>
		<closed>2018-08-07 12:10:37</closed>
	</bug>
	<bug>
		<id>2955</id>
		<title>Basic filter step broken</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  The basic filter step can't be used properly. I can't add any rules.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![out](https://user-images.githubusercontent.com/4180208/42216649-de4fc392-7ec2-11e8-8a8d-eaa94951dea8.gif)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Syndesis from master running 2. Add new integration, specify some start/stop end connection 3. Specify the "Basic filter step" 4. Observe, that there is no possibility to specify options for basic filter step </body>
		<created>2018-07-03 11:16:08</created>
		<closed>2018-07-13 10:40:17</closed>
	</bug>
	<bug>
		<id>2949</id>
		<title>Empty cancel modal</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  When creating a connection, when I try to switch back to connections overview, empty modal with cancel button appears.  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![out](https://user-images.githubusercontent.com/4180208/42206515-a60f6f66-7ea7-11e8-8c09-a2ce076fc4c6.gif)   ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Syndesis from master running 2. Select some of the connections - start create new connection process 3. Press the Home &gt; Connections option, observe the modal with cancel button </body>
		<created>2018-07-03 08:00:02</created>
		<closed>2018-07-03 10:05:56</closed>
	</bug>
	<bug>
		<id>2948</id>
		<title>Connection creation is broken</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  The fields for filling connection properties are not showing.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![out](https://user-images.githubusercontent.com/4180208/42206066-66a34240-7ea6-11e8-9c7b-599c19da2dfe.gif)   ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Start syndesis from master 2. Try to create some of the connections 3. It can't be done </body>
		<created>2018-07-03 07:50:12</created>
		<closed>2018-07-03 09:15:18</closed>
	</bug>
	<bug>
		<id>2942</id>
		<title>config.json file isn't served by yarn start:minishift</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  We've merged the angular 6 upgrade which is awesome but brings this issue.  Basically the development server doesn't serve the config.json file, likely because I had to pull it from the `angular.json` file so that we could run tests correctly on CI.  Need to figure out how to have this file served properly but not be required for the build, as it's not supposed to be part of the repo.  @seanforyou23 FYI</body>
		<created>2018-07-02 10:37:46</created>
		<closed>2018-07-02 13:12:13</closed>
	</bug>
	<bug>
		<id>2941</id>
		<title>Syndesis UI not displaying integrations/connections</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  There seems to be an issue when I try to display "integrations" and "connections" page.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![syndesis_not_working](https://user-images.githubusercontent.com/4180208/42159042-b649a3c0-7df2-11e8-89fb-dce4875cb396.png)   ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. syndesis from master is running 2. try to access integrations/connections page </body>
		<created>2018-07-02 10:22:31</created>
		<closed>2018-07-02 21:50:55</closed>
	</bug>
	<bug>
		<id>2931</id>
		<title>Todo app connection requires empty Base Path but it cannot be set empty</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem If I create custom api connector to TODO app, the app requires BASE PATH attribute to be set empty to work properly. But this property must be set to be allowed to create a connector (empty value is not accepted when creating the connector). If I create a connection from this connector then, I can edit BASE PATH property and set it empty.  But an integration using TODO connection doesn't start failing with the following error:  &gt; org.apache.camel.RuntimeCamelException: java.lang.IllegalArgumentException: Could not find a suitable setter for property: basePath as there isn't a setter method with same type: java.lang.String nor type conversion possible: basePath must be specified and not empty  It's blocking some UI tests that use TODO app connection in an integration.   ## Expected behavior TODO app should require non-empty BASE PATH property. There was "/api" required recently and everything worked nicely.</body>
		<created>2018-06-29 13:39:14</created>
		<closed>2018-10-10 09:41:56</closed>
	</bug>
	<bug>
		<id>2929</id>
		<title>When reseting DB using testsupport, sometimes older deployment is started immediately</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Sometimes after reseting the DB using the testsupport endpoint, older deployment is started immediately: ![1](https://user-images.githubusercontent.com/7081216/42080480-18852ef0-7b83-11e8-832c-08735d9db061.png)  This deployment eventually fails because it can't find the image:  ![2](https://user-images.githubusercontent.com/7081216/42080522-4244dbfa-7b83-11e8-9271-19a3bcbb7ad1.png)  This is causing problem when deploying next integration (different than the previous one), as it fails with this error:  ``` 2018-06-28 19:10:05.318  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-update-to-db-rest-test]: Deployment done 2018-06-28 19:10:05.332  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-update-to-db-rest-test]: Build started: false, isRunning: false, Deployment ready: false 2018-06-28 19:10:05.332  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [sf-update-to-db-rest-test]: [PENDING] [{buildv1=docker-registry.default.svc:5000/syndesis/i-sf-update-to-db-rest-test:1, deploy=1}] 2018-06-28 19:10:05.332  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.i.IntegrationController          : Integration i-LG6mKOKLX1oMKobeQLqz : Setting status to Pending 2018-06-28 19:10:05.337 ERROR [-,,,] 1 --- [tion Controller] i.s.s.c.i.IntegrationController          : Error while processing integration status for integration i-LG6mKOKLX1oMKobeQLqz:1   java.lang.NullPointerException: null         at io.syndesis.server.controller.integration.IntegrationController.lambda$callStateChangeHandler$10(IntegrationController.java:207) ~[server-controller-1.4.1-20180628.jar!/:1.4.1-20180628]         at io.syndesis.server.controller.StateChangeHandler.execute(StateChangeHandler.java:35) ~[server-controller-1.4.1-20180628.jar!/:1.4.1-20180628]         at io.syndesis.server.controller.integration.IntegrationController.lambda$callStateChangeHandler$11(IntegrationController.java:196) ~[server-controller-1.4.1-20180628.jar!/:1.4.1-20180628]         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_151]         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_151]         at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_151]   Exception in thread "Integration Controller" java.lang.NullPointerException: instance         at java.util.Objects.requireNonNull(Objects.java:228)         at io.syndesis.common.model.integration.ImmutableIntegrationDeployment$Builder.createFrom(ImmutableIntegrationDeployment.java:989)         at io.syndesis.server.controller.integration.IntegrationController.lambda$callStateChangeHandler$11(IntegrationController.java:219)         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)         at java.lang.Thread.run(Thread.java:748) ```  It is hard to reproduce as it quite random, so I currently don't know if it is just a test support endpoint problem or if it can be reproduced from the UI as well.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; deployment 1 not be started when terminating deployment 2  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. deploy integration 2. clean db using testsupport endpoint 3. observe pods in openshift 4. if not reproduced, go to 1 </body>
		<created>2018-06-29 08:08:17</created>
		<closed>2018-07-02 08:28:02</closed>
	</bug>
	<bug>
		<id>2925</id>
		<title>Only 20 connectors are returned at most when creating a connection</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  When you install a few extensions that add connectors you'll quickly find that some connectors vanish from the list of available connectors when you go to create a connection.  With a bit of testing by slowly adding connector extensions I found that the API response for /connectors appears to have a maximum limit of 20.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  All connectors should be returned as the 1st page of the create connection wizard doesn't do pagination.  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Open up the browser developer console and look at the network tab, check the "Preview" tab for the HTTP request to /connectors 2. Add a connector extension, note how the `totalCount` in the response increases by 1 3. Add more connector extensions so that you have more than 20 connectors 4. Note that `totalCount` stops at 20, and some connectors that were available are now missing. </body>
		<created>2018-06-28 11:24:37</created>
		<closed>2018-07-18 17:07:43</closed>
	</bug>
	<bug>
		<id>2922</id>
		<title>URL and scope fields aren't saved when clicking Save</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  These three fields were added, however they don't appear to save values properly:  ![capture](https://user-images.githubusercontent.com/351660/42026770-080c45ce-7a96-11e8-9111-ef47eaac21c8.PNG)  after a refresh:  ![capture](https://user-images.githubusercontent.com/351660/42026853-316a758a-7a96-11e8-9de4-108bd7dd5ad4.PNG)  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlisting the acceptance criteria. --&gt;  I should be able to populate these fields and save the values.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt; Data being posted:  ```json {   "clientId": "",   "clientSecret": "",   "icon": "data:image\/svg+xml;base64,PHN2ZyBpZD0iTGF5ZXJfMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2aWV3Qm94PSIwIDAgMzAwIDI0My44Ij48c3R5bGU+PC9zdHlsZT48cGF0aCBkPSJNOTQuMyAyNDMuOGMxMTMuMiAwIDE3NS4xLTkzLjggMTc1LjEtMTc1LjEgMC0yLjctLjEtNS4zLS4yLTggMTItOC43IDIyLjUtMTkuNSAzMC43LTMxLjktMTEgNC45LTIyLjkgOC4yLTM1LjMgOS43IDEyLjctNy42IDIyLjUtMTkuNyAyNy4xLTM0LTExLjkgNy4xLTI1LjEgMTIuMi0zOS4xIDE0LjlDMjQxLjQgNy41IDIyNS40IDAgMjA3LjcgMGMtMzQgMC02MS42IDI3LjYtNjEuNiA2MS41IDAgNC44LjUgOS41IDEuNiAxNC01MS4xLTIuNS05Ni41LTI3LTEyNi44LTY0LjItNS4zIDkuMS04LjMgMTkuNy04LjMgMzAuOSAwIDIxLjQgMTAuOSA0MC4yIDI3LjQgNTEuMi0xMC4xLS4zLTE5LjYtMy4xLTI3LjktNy43di44YzAgMjkuOCAyMS4yIDU0LjcgNDkuNCA2MC4zLTUuMiAxLjQtMTAuNiAyLjItMTYuMiAyLjItNCAwLTcuOC0uNC0xMS42LTEuMSA3LjggMjQuNSAzMC42IDQyLjIgNTcuNSA0Mi43QzcwLjEgMjA3LjIgNDMuNSAyMTcgMTQuNyAyMTdjLTUgMC05LjktLjMtMTQuNy0uOSAyNy4yIDE3LjUgNTkuNiAyNy43IDk0LjMgMjcuNyIgZmlsbD0iIzFkYTFmMiIvPjwvc3ZnPg==",   "id": "twitter",   "name": "Twitter",   "authorizationUrl": "asdfasdf",   "tokenUrl": "asdfasdf" }  ```</body>
		<created>2018-06-28 09:43:57</created>
		<closed>2018-07-12 12:20:51</closed>
	</bug>
	<bug>
		<id>2920</id>
		<title>Update message dialog modals</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem This is a follow up from [updating the delete modal message dialogs](https://github.com/syndesisio/syndesis/issues/2879) to the new [PatternFly pattern for message dialogs](https://rawgit.com/patternfly/patternfly/master-dist/dist/tests/message-dialogs.html).  It looks like the wording between message dialogs is inconsistent (title, content, button text, etc), and we might be able to take advantage of the new styles for message dialogs for some of our modal actions.  ### Delete OAuth ![screen shot 2018-06-27 at 3 49 15 pm](https://user-images.githubusercontent.com/35148959/41998979-bcc73c82-7a21-11e8-980c-1da4af4d7c05.png)  ### Delete extension ![screen shot 2018-06-27 at 3 49 08 pm](https://user-images.githubusercontent.com/35148959/41998984-c34978e0-7a21-11e8-87a7-4d6561d6c94b.png)  ### Delete extension in use with integration(s) ![screen shot 2018-06-27 at 3 53 16 pm](https://user-images.githubusercontent.com/35148959/41999137-4abdaeea-7a22-11e8-950f-9e5f40340843.png)   ### Delete API client connector ![screen shot 2018-06-27 at 3 48 55 pm](https://user-images.githubusercontent.com/35148959/41998999-cc98f1d2-7a21-11e8-81ae-555e5093093c.png)  ### Delete connection ![screen shot 2018-06-27 at 3 48 49 pm](https://user-images.githubusercontent.com/35148959/41999006-d3243cb4-7a21-11e8-8c99-69c38653b11b.png)  ### Delete step from integration ![screen shot 2018-06-27 at 3 52 05 pm](https://user-images.githubusercontent.com/35148959/41999067-11a13df2-7a22-11e8-85b6-b69e1bf6e6d0.png)  ### Delete integration ![screen shot 2018-06-27 at 3 48 42 pm](https://user-images.githubusercontent.com/35148959/41999038-f32b6c1c-7a21-11e8-9ad6-5d56b7ebe622.png)  ### Start integration ![screen shot 2018-06-27 at 3 45 22 pm](https://user-images.githubusercontent.com/35148959/41998828-4fa39bfa-7a21-11e8-8abc-515fa51ac33a.png)  ### Stop integration ![screen shot 2018-06-27 at 3 45 28 pm](https://user-images.githubusercontent.com/35148959/41998835-5471fa0a-7a21-11e8-911e-ee5df0c3036a.png)  cc @sjcox-rh @dongniwang @amysueg </body>
		<created>2018-06-27 20:47:46</created>
		<closed>2018-07-05 13:52:00</closed>
	</bug>
	<bug>
		<id>2915</id>
		<title>Integration using Telegram Connections fails on ClientErrorException: HTTP 409 Conflict</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Integration using Telegram connections (from syndesis-extensions/syndesis-connector-telegram) fails on javax.ws.rs.ClientErrorException: HTTP 409 Conflict error.  I was not sure whether to use '@' before chatId or not so I tried both options (according to logs with @ option seems to be correct. i.e '@from_channel').  here are integration logs. [integraion_tel_with@.log](https://github.com/syndesisio/syndesis/files/2141714/integraion_tel_with.log) [integration_tel_no@.log](https://github.com/syndesisio/syndesis/files/2141715/integration_tel_no.log)   ## Expected behavior integration works.  ## Screenshot  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. on Telegram create 2 public chat channels (e.g. 'from_channel' and 'to_channel') and set your bot (related to API token in telegram connector) as their administrator. 2. create Telegram to Telegram integration ('from_channel' -&gt; 'to_channel' channel),  3. in Telegram send message to 'from' channel 4. </body>
		<created>2018-06-27 14:57:35</created>
		<closed>2018-08-02 08:26:49</closed>
	</bug>
	<bug>
		<id>2912</id>
		<title>Optimize metrics retrieval</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When we present the dashboard (first screen), we have a number of request for `/api/v1/metrics/integrations`. I counted 6 on our staging environment, this uses connections to the database and prevents requests to `/api/v1/integrations` from completing: we get a 504.  This is then perceived as slowness of the UI.  I think we either need to reduce the rate of fetching metrics, prioritize fetching other data or push metrics from the server to the UI.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; We need to serve the data for the most compelling parts of the UI first and reduce the load on the database.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![screenshot from 2018-06-27 15-14-31](https://user-images.githubusercontent.com/1306050/41976583-c8ad65e8-7a1d-11e8-80e2-8a091ea69cce.png) ![screenshot from 2018-06-27 15-17-56](https://user-images.githubusercontent.com/1306050/41976595-cf242b1e-7a1d-11e8-8c74-1acb941fa9d1.png)  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt; `/api/v1/metrics/integrations` `/api/v1/integrations`  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Reload the dashboard on staging site 2. Observe the numerous requests to metrics and errors while fetching integrations in the UI and in the network inspector 3. 4. </body>
		<created>2018-06-27 13:23:47</created>
		<closed>2018-07-13 13:17:54</closed>
	</bug>
	<bug>
		<id>2898</id>
		<title>AWS S3 connection configuration not editable</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [V ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem  After creating a AWS S3 connection,  I wanted to change the regions, but was not able to do it.  Unable to edit configurations (Region) with AWS S3 connections.   ## Expected behavior The region should be updated after saving the configuration.  ## Screenshot ![screen shot 2018-06-26 at 1 49 36 pm](https://user-images.githubusercontent.com/2534483/41891693-113b9d1a-7948-11e8-9795-2b506142c0d4.png)   </body>
		<created>2018-06-26 05:53:32</created>
		<closed>2018-10-02 18:39:49</closed>
	</bug>
	<bug>
		<id>2880</id>
		<title>Publishing integration fails as k8s secret cannot be created</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Creating a k8s secret can fail if the secret is larger in file size than 1MB. This can happen if the `specification` property of the API connector containing the Swagger specification is oversized. This can be noticed when using the new Concur connector.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Secret can be created, integration is published. </body>
		<created>2018-06-25 11:51:08</created>
		<closed>2018-06-25 12:23:09</closed>
	</bug>
	<bug>
		<id>2861</id>
		<title>Remove the Id field from the identifier field when performing upsert</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Using the `Id` field doesn't make sense with Salesforce upsert, as upsert supports only external identifiers (`Id` being an internal one).  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; No `Id` field being offered when configuring Salesforce create or update action. </body>
		<created>2018-06-20 15:33:03</created>
		<closed>2018-12-24 19:30:13</closed>
	</bug>
	<bug>
		<id>2859</id>
		<title>Add guard to API connector route</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem If you try to refresh or navigate to a URL like `https://syndesis.&lt;url&gt;.nip.io/customizations/api-connector/create/swagger-connector`, you will get an error related to the API Connector Detail component and having a `filter` method that does not exist for `undefined` (or similar). The page will not load properly.  ## Expected behavior This should not be loading anything from the API Connector Detail component. I believe the problem comes down to the routes. Angular thinks you are trying to load an API Connector, and is looking for an `:id` in the path, which it believes it finds and attempts to load nonexistent information about it. There should be a guard for it.  ## Screenshot &lt;img width="1360" alt="screenshot 2018-06-20 12 38 25" src="https://user-images.githubusercontent.com/3844502/41659882-c638e37e-749a-11e8-9bf8-828a42dd5426.png"&gt;  </body>
		<created>2018-06-20 13:01:42</created>
		<closed>2018-09-21 12:33:44</closed>
	</bug>
	<bug>
		<id>2858</id>
		<title>[UX][DataMapper] Remove transformation button help causes page flickering</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  When hovering mouse on "Remove transformation" button in datamapper step, the whole page will start "flickering", because of the help message is prolonging the page in horizontal direction for a while  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot ![removetransform](https://user-images.githubusercontent.com/7081216/41657317-42876ee4-7493-11e8-9e69-970d11f1a0a9.gif)  In reality the flicker is much faster, the framerate of the gif is low :-)  Happens to me on chrome on linux, 1920x1080 screen ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. see linked gif 2. 3. 4. </body>
		<created>2018-06-20 12:10:17</created>
		<closed>2018-07-24 20:49:37</closed>
	</bug>
	<bug>
		<id>2854</id>
		<title>Users should not be able to delete SAP Concur connector</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; As it's based on the API connector it's possible to delete the SAP Concur connector.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Not being able to delete the connector.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![screenshot-2018-6-19 syndesis](https://user-images.githubusercontent.com/1306050/41602959-3bb4a15c-73dc-11e8-9eb4-6a32087ac898.png)   ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-06-19 14:17:30</created>
		<closed>2018-06-19 15:02:12</closed>
	</bug>
	<bug>
		<id>2853</id>
		<title>[SalesForce connector] CreateSObjectResult not returned</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; I have an integration: AMQ(consume) -&gt; SF(createSObject) -&gt; LOG(just to see the exchange) -&gt; AMQ(produce)  According to the output datashape definitions, some of the methods of salesforce connector should return org.apache.camel.component.salesforce.api.dto.CreateSObjectResult - for example salesforce-create-sobject.  However as you can see here, the exchange after salesforce step in the integration has empty body:  ``` Exchange[Id: i-LFNIOhmVXttg2QfXepBz, ExchangePattern: InOnly, Properties: {CamelCreatedTimestamp=Tue Jun 19 13:48:16 UTC 2018, CamelExternalRedelivered=false, CamelMessageHistory=[DefaultMessageHistory[routeId=-LFNAqX5_n9PP0kYpVxn, node=setHeader1], DefaultMessageHistory[routeId=-LFNAqX5_n9PP0kYpVxn, node=process1], DefaultMessageHistory[routeId=-LFNAqX5_n9PP0kYpVxn, node=step:-LFNG_CY_n9PP0kYpVxo], DefaultMessageHistory[routeId=-LFNAqX5_n9PP0kYpVxn, node=setHeader2], DefaultMessageHistory[routeId=-LFNAqX5_n9PP0kYpVxn, node=to1], DefaultMessageHistory[routeId=-LFNAqX5_n9PP0kYpVxn, node=process2], DefaultMessageHistory[routeId=-LFNAqX5_n9PP0kYpVxn, node=step:-LFNBJiC_n9PP0kYpVxo], DefaultMessageHistory[routeId=-LFNAqX5_n9PP0kYpVxn, node=setHeader3], DefaultMessageHistory[routeId=-LFNAqX5_n9PP0kYpVxn, node=to2]], CamelToEndpoint=log-3, Syndesis.ACTIVITY_ID=i-LFNIOhmVXttg2QfXepBz, Syndesis.CAPTURED_OUT_MESSAGES_MAP={-LFNAqX5_n9PP0kYpVxn=SjmsMessage[JmsMessageID: ID:fakefrog-35334-1529416096234-1:1:1:1:1]}}, Headers: {Syndesis.STEP_ID=-LFNBJiC_n9PP0kYpVxo, Syndesis.STEP_TRACKER_ID=i-LFNIOsPVXttg2QfXepDz}, BodyType: null, Body: [Body is null], Out: null: ] ```  And therefore you don't have the ID that was generated in salesforce. In plain camel, the response looks like this:  ``` Exchange[ExchangePattern: InOnly, BodyType: org.apache.camel.component.salesforce.api.dto.CreateSObjectResult, Body: {"id":"00Q0Y00000FrOU8UAN","errors":[],"success":true}] ```  To reproduce, I just used this json: {"FirstName":"Joe", "LastName":"Doe","Email":"joedoe@acme.com","Company":"XYZ"} that I posted to the queue.  To reproduce with standalone spring boot camel, I used this route: ```         from("activemq:queue:sf-producers-input")                 .to("log:?level=INFO&amp;showBody=true")                 .to("salesforce:createSObject?sObjectName=Lead")                 .to("log:?level=INFO&amp;showBody=true"); ```  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-06-19 13:59:49</created>
		<closed>2018-07-23 14:31:49</closed>
	</bug>
	<bug>
		<id>2850</id>
		<title>Enable drag/drop UI for API connector upload</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem API client connector upload should have the same drag/drop interface as the tech extension and integration upload UI's.  Part of https://github.com/syndesisio/syndesis/issues/2798  ping @gashcrumb @kahboom </body>
		<created>2018-06-18 20:39:54</created>
		<closed>2018-10-19 18:23:09</closed>
	</bug>
	<bug>
		<id>2839</id>
		<title>DataManagerITCase::createDuplicateConnection test is flaky</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Seems that DataManagerITCase::createDuplicateConnection test fails on and off, which makes it a flaky test.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; The test should work consistently.  </body>
		<created>2018-06-16 11:49:38</created>
		<closed>2018-09-21 12:33:43</closed>
	</bug>
	<bug>
		<id>2835</id>
		<title>HTTP Connector method not honored</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When trying to use the HTTP connector as finish connection with METHOD=PUT, the integration actually uses POST (there is no &lt;setHeader&gt; to define method before the &lt;to uri="http4"&gt;)  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; I would have expected to honour PUT HTTP method ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![image](https://user-images.githubusercontent.com/10658194/41484964-0b47076e-70b5-11e8-904f-bf2dd0c056a0.png)   ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1.Create HTTP connection number 1 2.Create HTTP connection number 2 3.Create Integration using connection number 1 as starter 4.Use connection number 2 as finish connection 5. Set Method to PUT 6. Publish integration </body>
		<created>2018-06-15 19:00:23</created>
		<closed>2018-07-03 13:32:10</closed>
	</bug>
	<bug>
		<id>2824</id>
		<title>Importing integration twice causes UI to fail</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  From what I understand - importing integration twice should just replace the previous one.  Expected: ![import_success](https://user-images.githubusercontent.com/14313995/41464479-c1b785ca-709a-11e8-8559-e29fbcc0470d.png)   But cancel and done buttons look like this:  ![import_fail](https://user-images.githubusercontent.com/14313995/41464300-1a4de8e2-709a-11e8-9f70-7b4ad294e536.png)  Note that those buttons have no functionality as the integration is already imported when those buttons appear. Maybe remove them and just put there OK button?  Also note that information about imported integration is not complete - there is no name of integration and info about salesforce connection is also missing.   I used this integration for reproducing  [Integration_import_export_test-export.zip](https://github.com/syndesisio/syndesis/files/2105773/Integration_import_export_test-export.zip)  Import the integration. Then import the same integration again.  </body>
		<created>2018-06-15 10:56:52</created>
		<closed>2018-07-18 14:49:05</closed>
	</bug>
	<bug>
		<id>2823</id>
		<title>Error when putting incorrect sql statement in database connection</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ![out](https://user-images.githubusercontent.com/14313995/41463653-7d4f2080-7097-11e8-81fb-479a65dccc6c.gif)   We should inform user that SQL is wrong and allow him to change it back. </body>
		<created>2018-06-15 10:33:12</created>
		<closed>2018-06-26 08:20:42</closed>
	</bug>
	<bug>
		<id>2815</id>
		<title>Upgrading to Yarn v1.7.0 causes failure for new installs</title>
		<body> **NOTE: The following only applies if you are using Node 10 (not LTS) + Yarn v1.7.0. The second error will also occur if `upath` is somewhere in the dependency tree.**   ## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Was just minding my business, installing some new packages with my legacy Yarn, and got prompted by Yarn to upgrade to `v1.7.0`. I usually hesitate, but said, hey, why not, life's too short..  Suddenly, `yarn install` started failing any time you add a new package to `package.json`, which was sad for me because that's exactly what I needed to do.  &lt;img width="831" alt="screenshot 2018-06-14 12 23 14" src="https://user-images.githubusercontent.com/3844502/41416744-7544045a-6fe3-11e8-981a-671274f9cc7e.png"&gt;  The errors/warnings:  ``` (node:20616) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead. ```  ``` error upath@1.0.4: The engine "node" is incompatible with this module. Expected version "&gt;=4 &lt;=9". error Found incompatible module. ```  Huh? I don't know even this module, and it's already telling me what Node engine version I need to use, so much that it is telling Yarn not to install anything until I do what it says.   ## Expected behavior No errors on `yarn install`? The first was just a deprecation warning and likely wasn't failing the install, but was still driving me crazy. The second one, well,`yarn install` should install npm packages without failing, despite whatever engine version is specified.   As Jan says in this issue https://github.com/anodynos/upath/issues/14#issuecomment-384893717: &gt;Also please never ever purposefully break forward compatibility by enforcing something like node &lt;= X.  Just stop it, people.   ## Tasks involved / Steps to Reproduce Test with v.1.2.0 or whatever I was using before, and see no problems.  1. Upgrade to Yarn v.1.7.0, the latest and greatest. 2. Pretend to add a new package to `package.json`. Okay, actually add it. 3. Run `yarn install`.   ## Solutions/Workarounds  ### First Error: No idea, but using yarn from npm seemed to fix it completely: `npm i -g yarn &amp;&amp; yarn install`  &lt;img width="843" alt="screenshot 2018-06-14 15 14 20" src="https://user-images.githubusercontent.com/3844502/41417564-a6e7bfe0-6fe5-11e8-8f38-c74d4ead0fae.png"&gt;  Btw, this error wasn't even super obvious that it was related to Webpack until I did `NODE_OPTIONS=--trace-warnings yarn outdated`.  ### Second Error: 1. Downgrade to v1.6.0 or whatever version you were using that worked.   - If you use Homebrew, you need to look at the commit history for the Ruby file for the formula if you don't already have that version installed (my most "recent" was v1.2.0, so was looking for something more.. modern). Also, not every formula supports multiple versions. AND you may need to unlink to then be able to switch symlinks using `brew switch yarn@&lt;version&gt;`. Anyway, nty.. 2. Nuke everything. `rm yarn.lock &amp;&amp; rm -rf node_modules &amp;&amp; yarn cache clean`, then `yarn install` and pray to Lady Gaga that it all works.. 3. Directly edit the `yarn.lock` file by removing the portion that references `upath` if you are not really using the module. But then again, why are we editing `yarn.lock` manually? 3. Tell Yarn globally that it should know better: `yarn config set ignore-engines true -g` 4. Tell Yarn locally that it should know better.  The third one seems to work fine, but I'm testing out the 4th option, which may involve adding a `.yarnrc` to the UI root.  ### tl;dr So, for now, 1) install using yarn from npm to get rid of the deprecation warning, 2) set Yarn global configuration setting to ignore engines, then you can `yarn install` like normal again.</body>
		<created>2018-06-14 14:23:20</created>
		<closed>2018-08-09 16:08:17</closed>
	</bug>
	<bug>
		<id>2811</id>
		<title>Basic filter does not work when using Salesforce connectur</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ V] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Video showing how it happens: https://vimeo.com/274944607/7230f19bf7 So the problem is that I was trying to capture all the changes made to the opportunity in SF. So I did a basic filter on the isWon value.   Although in the log it says isWon has returned false, but system still throws null exception, saying isWon is Null in the Body  ``` org.apache.camel.language.bean.RuntimeBeanExpressionException: Failed to invoke method: IsWon on null due to: org.apache.camel.component.bean.MethodNotFoundException: Method with name: IsWon not found on bean: org.apache.camel.converter.stream.ByteArrayInputStreamCache@448242a0 of type: org.apache.camel.converter.stream.ByteArrayInputStreamCache. Exchange[i-LEuVHiKc4drEGRxqyC5z] at org.apache.camel.language.bean.BeanExpression.invokeOgnlMethod(BeanExpression.java:302) ~[camel-core-2.21.0.fuse-000077-redhat-1.jar!/:2.21.0.fuse-000077-redhat-1] at org.apache.camel.language.bean.BeanExpression.evaluate(BeanExpression.java:114) ~[camel-core-2.21.0.fuse-000077-redhat-1.jar!/:2.21.0.fuse-000077-redhat-1] at org.apache.camel.language.bean.BeanExpression.evaluate(BeanExpression.java:135) ~[camel-core-2.21.0.fuse-000077-redhat-1.jar!/:2.21.0.fuse-000077-redhat-1] at org.apache.camel.model.language.ExpressionDefinition.evaluate(ExpressionDefinition.java:127) ~[camel-core-2.21.0.fuse-000077-redhat-1.jar!/:2.21.0.fuse-000077-redhat-1] at org.apache.camel.model.language.ExpressionDefinition.evaluate(ExpressionDefinition.java:119) ~[camel-core-2.21.0.fuse-000077-redhat-1.jar!/:2.21.0.fuse-000077-redhat-1] at org.apache.camel.builder.ExpressionBuilder$40.evaluate(ExpressionBuilder.java:1004) ~[camel-core-2.21.0.fuse-000077-redhat-1.jar!/:2.21.0.fuse-000077-redhat-1] at org.apache.camel.support.ExpressionAdapter.evaluate(ExpressionAdapter.java:36) ~[camel-core-2.21.0.fuse-000077-redhat-1.jar!/:2.21.0.fuse-000077-redhat-1] at org.apache.camel.builder.BinaryPredicateSupport.matchesReturningFailureMessage(BinaryPredicateSupport.java:60) ~[camel-core-2.21.0.fuse-000077-redhat-1.jar!/:2.21.0.fuse-000077-redhat-1]  ```   ## Tasks involved / Steps to Reproduce See Video </body>
		<created>2018-06-13 19:19:20</created>
		<closed>2018-06-20 13:43:16</closed>
	</bug>
	<bug>
		<id>2805</id>
		<title>Disable name check in errorprone</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; We seem to be hitting https://github.com/google/error-prone/issues/780, let's disable the name check and re-enable it when this gets resolved in errorprone.  </body>
		<created>2018-06-13 07:10:19</created>
		<closed>2018-06-13 18:24:15</closed>
	</bug>
	<bug>
		<id>2778</id>
		<title>Tokenize Syndesis references in UI</title>
		<body>## This is a... &lt;pre&gt;&lt;code&gt; [X] Task &lt;/code&gt;&lt;/pre&gt;   ## The problem There are a number of spots in productized builds of the UI where the term 'Syndesis' still appears.  Two examples would be on the connection configuration pages for Salesforce and Twitter:  &gt; Log into your Twitter account to grant authorization for Syndesis to act on your behalf.  Probably need to scan the UI code for any other hard-coded references as well.  ## Expected behavior Either tokenize the references to Syndesis so they can be replaced in prod builds or generify the language.  In the above example, we could just say something like:  &gt; Log into your Twitter account to grant authorization for the system to act on your behalf.  </body>
		<created>2018-06-07 16:18:26</created>
		<closed>2018-06-11 15:54:14</closed>
	</bug>
	<bug>
		<id>2767</id>
		<title>Error in console when using delete REST API</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When the `delete` method is invoked on `AbstractStore` the logic subscribes to the result of a `Observable` of the `RESTService`, that `Observable` resolves as `null` which is in turn is passed to `AbstractStore::plain` resulting in: ``` TypeError: right-hand side of 'in' should be an object, got null ```  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; I don't understand what should the `AbstractStore::delete` resolve as, we don't seem to receive a value from `RESTService::delete`.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![screenshot from 2018-06-06 16-03-35](https://user-images.githubusercontent.com/1306050/41043076-668a6904-69a3-11e8-9069-2b6ecd99dd93.png)  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ```http DELETE /api/v1/connections/i-L9ebOic2DLRU1XmzMLuz HTTP/1.1 Accept: application/json, text/plain, */* ```  ```http HTTP/1.1 204 No Content ```  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt; Any HTTP endpoint using DELETE.  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Try deleting a connection from UI 2. 3. 4. </body>
		<created>2018-06-06 14:07:09</created>
		<closed>2018-06-07 13:18:35</closed>
	</bug>
	<bug>
		<id>2764</id>
		<title>Possible resources leak</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  The javadoc related to javax.ws.rs.client.Client states:  ``` Clients are heavy-weight objects that manage the client-side communication infrastructure. Initialization as well as disposal of a {@code Client} instance may be a rather expensive operation. It is therefore advised to construct only a small number of {@code Client} instances in the application. Client instances must be {@link #close() properly closed} before being disposed to avoid leaking resources. ```  But the pattern we are using in syndesis does not follow that rule, see:  - https://github.com/syndesisio/syndesis/blob/master/app/server/verifier/src/main/java/io/syndesis/server/verifier/ExternalVerifierService.java - https://github.com/syndesisio/syndesis/blob/master/app/server/metrics/prometheus/src/main/java/io/syndesis/server/metrics/prometheus/HttpClient.java - https://github.com/syndesisio/syndesis/blob/master/app/server/endpoint/src/main/java/io/syndesis/server/endpoint/v1/handler/connection/MetadataCommand.java  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  1. we should not create a new client for each request  2. we should close it when it is not needed anymore  </body>
		<created>2018-06-06 11:36:33</created>
		<closed>2018-06-07 09:20:32</closed>
	</bug>
	<bug>
		<id>2759</id>
		<title>[datamapper] Field search from Mapping Details pane doesn't work</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Once you select multiple fields at source or target, the active mapping transitions to Combine/Separate, then you can add more source/target fields from Mapping Details pane by pushing "Add Source" or "Add Target" button. Then you get the search box immediately, but the search is not somehow working within Syndesis.  ## Expected behavior Show field search results and allow selecting one of them. </body>
		<created>2018-06-05 17:38:57</created>
		<closed>2018-07-10 07:52:02</closed>
	</bug>
	<bug>
		<id>2755</id>
		<title>Activity Monitoring: empty response from backend</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem I've tried to rerun the soak test scenario on today's tag `1.4.1-20180605`. However, I can't see any Activity displayed on a page. Backend's response is empty, even for the straight request to server.  ## Expected behavior Activities over time are visibile  ## Screenshot &lt;img width="981" alt="screen shot 2018-06-05 at 16 01 46" src="https://user-images.githubusercontent.com/5637792/40980873-c9bce51c-68d9-11e8-98ab-a624a7b6d36b.png"&gt;   ## Request and Response Data ``` GET /api/v1/activity/integrations/i-LEFAjpOhQlZNq3ZGF-7z HTTP/1.1 Host: syndesis.apps.perf2.xpaas Connection: keep-alive Pragma: no-cache Cache-Control: no-cache Accept: application/json, text/plain, */* SYNDESIS-XSRF-TOKEN: awesome User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.183 Safari/537.36 Vivaldi/1.96.1147.42 DNT: 1 Referer: https://syndesis.apps.perf2.xpaas/integrations/i-LEFAjpOhQlZNq3ZGF-7z?view=activity Accept-Encoding: gzip, deflate, br Accept-Language: en-GB,en-US;q=0.9,en;q=0.8 Cookie: b2a2e2613ad00502bbe3dae4fed6f03a=46f39228ecc2cd9481e1508468b70f1a; _oauth_proxy=eHBhYXNxZUBjbHVzdGVyLmxvY2FsfGlyaXFEdW90UUNBdExzYk5kME5DR3ZiQk5rcnlwdlozRldLMHhDNk5EZDJKMkpxdmovelB1QXo1V3dsMTQwbGNLQU1NanNZTFpkY3ZBWm89fC02MjEzNTU5NjgwMHw=|1528204485|BBjMAmtlhA04gLmf1bEnV6g5hCk= ``` Response ``` HTTP/1.1 200 OK Cache-Control: no-cache, no-store, max-age=0, must-revalidate, proxy-revalidate, s-maxage=0 Content-Length: 2 Content-Type: application/json Date: Tue, 05 Jun 2018 14:03:07 GMT Expires: 0 Gap-Auth: xpaasqe@cluster.local Gap-Upstream-Address: syndesis-server Pragma: no-cache Strict-Transport-Security: max-age=31536000 ; includeSubDomains Syndesis-Xsrf-Token: awesome X-Application-Context: application X-Content-Type-Options: nosniff X-Frame-Options: DENY X-Xss-Protection: 1; mode=block ```   ``` syndesis=# select * from pg_stat_activity;  datid | datname  |  pid  | usesysid | usename  | application_name | client_addr | client_hostname | client_port |         backend_start         |          xact_start           |          query_start          |         state_change          | waiting |        state    | backend_xid | backend_xmin |                                                                                                                                                                                                                     query  -------+----------+-------+----------+----------+------------------+-------------+-----------------+-------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------+---------+------------------ ---+-------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  16385 | syndesis |  1819 |    16384 | syndesis |                  | 10.129.0.1  |                 |       39722 | 2018-06-05 13:34:32.642486+00 | 2018-06-05 13:54:52.01888+00  | 2018-06-05 13:54:52.019304+00 | 2018-06-05 13:54:52.021046+00 | f       | idle in transacti on |             |         1082 | select path,value,ovalue from jsondb where path LIKE $1 and path &gt;= $2 and path &lt; $3 order by path ASC  16385 | syndesis |  1820 |    16384 | syndesis |                  | 10.129.0.1  |                 |       39724 | 2018-06-05 13:34:32.70542+00  |                               | 2018-06-05 13:48:51.312603+00 | 2018-06-05 13:48:51.312611+00 | f       | idle    |             |              | COMMIT  16385 | syndesis |  1821 |    16384 | syndesis |                  | 10.129.0.1  |                 |       39726 | 2018-06-05 13:34:32.712346+00 | 2018-06-05 13:47:59.174423+00 | 2018-06-05 13:47:59.174448+00 | 2018-06-05 13:47:59.175183+00 | f       | idle in transacti on |             |         1015 | SELECT data FROM filestore WHERE path=$1  16385 | syndesis |  1822 |    16384 | syndesis |                  | 10.129.0.1  |                 |       39728 | 2018-06-05 13:34:32.719077+00 | 2018-06-05 13:44:33.068511+00 | 2018-06-05 13:44:33.068636+00 | 2018-06-05 13:44:33.069414+00 | f       | idle in transacti on |             |          938 | SELECT data FROM filestore WHERE path=$1  16385 | syndesis |  1823 |    16384 | syndesis |                  | 10.129.0.1  |                 |       39730 | 2018-06-05 13:34:32.725039+00 | 2018-06-11 05:54:29.199144+00 | 2018-06-11 05:54:29.199516+00 | 2018-06-11 05:54:29.200688+00 | f       | idle in transacti on |             |        73863 | select path,value,ovalue from jsondb where path LIKE $1 and path &gt;= $2 and path &lt; $3 order by path ASC  16385 | syndesis |  1824 |    16384 | syndesis |                  | 10.129.0.1  |                 |       39732 | 2018-06-05 13:34:32.731351+00 | 2018-06-05 13:42:16.933953+00 | 2018-06-05 13:42:16.934602+00 | 2018-06-05 13:42:16.936566+00 | f       | idle in transacti on |             |          907 | SELECT data FROM filestore WHERE path=$1  16385 | syndesis |  1825 |    16384 | syndesis |                  | 10.129.0.1  |                 |       39734 | 2018-06-05 13:34:32.737416+00 | 2018-06-05 13:35:23.349052+00 | 2018-06-05 13:35:23.349185+00 | 2018-06-05 13:35:23.357102+00 | f       | idle in transacti on |             |          818 | SELECT data FROM filestore WHERE path=$1  16385 | syndesis |  1826 |    16384 | syndesis |                  | 10.129.0.1  |                 |       39736 | 2018-06-05 13:34:32.743253+00 | 2018-06-05 13:43:24.64441+00  | 2018-06-05 13:43:24.644435+00 | 2018-06-05 13:43:24.645302+00 | f       | idle in transacti on |             |          920 | SELECT data FROM filestore WHERE path=$1  16385 | syndesis |  1827 |    16384 | syndesis |                  | 10.129.0.1  |                 |       39738 | 2018-06-05 13:34:32.749213+00 | 2018-06-05 13:45:41.182523+00 | 2018-06-05 13:45:41.182548+00 | 2018-06-05 13:45:41.183351+00 | f       | idle in transacti on |             |          958 | SELECT data FROM filestore WHERE path=$1  16385 | syndesis |  1828 |    16384 | syndesis |                  | 10.129.0.1  |                 |       39740 | 2018-06-05 13:34:32.755448+00 | 2018-06-05 13:34:43.451718+00 | 2018-06-05 13:34:43.462198+00 | 2018-06-05 13:34:43.484651+00 | f       | idle in transacti on |             |          805 | SELECT p.proname,p.oid  FROM pg_catalog.pg_proc p, pg_catalog.pg_namespace n  WHERE p.pronamespace=n.oid AND n.nspname='pg_catalog' AND ( proname = 'lo_open' or proname = 'lo_close' or proname = 'lo_creat' or proname = 'lo_unlink' or pr oname = 'lo_lseek' or proname = 'lo_lseek64' or proname = 'lo_tell' or proname = 'lo_tell64' or proname = 'loread' or proname = 'lowrite' or proname = 'lo_truncate' or proname = 'lo_truncate64')  16385 | syndesis |  2679 |    16384 | syndesis |                  | 10.129.0.1  |                 |       41190 | 2018-06-05 13:46:50.462334+00 | 2018-06-05 13:46:51.067104+00 | 2018-06-05 13:46:51.070437+00 | 2018-06-05 13:46:51.071236+00 | f       | idle in transacti on |             |          989 | SELECT p.proname,p.oid  FROM pg_catalog.pg_proc p, pg_catalog.pg_namespace n  WHERE p.pronamespace=n.oid AND n.nspname='pg_catalog' AND ( proname = 'lo_open' or proname = 'lo_close' or proname = 'lo_creat' or proname = 'lo_unlink' or pr oname = 'lo_lseek' or proname = 'lo_lseek64' or proname = 'lo_tell' or proname = 'lo_tell64' or proname = 'loread' or proname = 'lowrite' or proname = 'lo_truncate' or proname = 'lo_truncate64')  16385 | syndesis |  2749 |    16384 | syndesis |                  | 10.129.0.1  |                 |       41448 | 2018-06-05 13:47:53.57209+00  | 2018-06-05 13:48:51.226192+00 | 2018-06-05 13:48:51.226505+00 | 2018-06-05 13:48:51.232158+00 | f       | idle in transacti on |             |         1027 | select path,value,ovalue from jsondb where path LIKE $1 order by path ASC  16385 | syndesis |  2750 |    16384 | syndesis |                  | 10.129.0.1  |                 |       41450 | 2018-06-05 13:47:53.575772+00 | 2018-06-11 06:00:31.250189+00 | 2018-06-11 06:00:31.250458+00 | 2018-06-11 06:00:31.250471+00 | f       | idle in transacti on |             |        73917 | select path,value,ovalue from jsondb where path LIKE $1 order by path ASC  16385 | syndesis |  2820 |    16384 | syndesis |                  | 10.129.0.1  |                 |       41568 | 2018-06-05 13:48:51.245227+00 |                               | 2018-06-05 13:48:51.338238+00 | 2018-06-05 13:48:51.338246+00 | f       | idle    |             |              | COMMIT  16385 | syndesis |  2821 |    16384 | syndesis |                  | 10.129.0.1  |                 |       41570 | 2018-06-05 13:48:51.24925+00  |                               | 2018-06-05 13:48:51.332999+00 | 2018-06-05 13:48:51.334084+00 | f       | idle    |             |              | select path,value,ovalue from jsondb where path LIKE $1 and path &gt;= $2 and path &lt; $3 order by path ASC  16385 | syndesis |  2823 |    16384 | syndesis |                  | 10.129.0.1  |                 |       41574 | 2018-06-05 13:48:51.250309+00 |                               | 2018-06-05 13:50:50.657709+00 | 2018-06-05 13:50:50.659322+00 | f       | idle    |             |              | select path,value,ovalue from jsondb where path LIKE $1 and path &gt;= $2 and path &lt; $3 order by path ASC  16385 | syndesis |  2822 |    16384 | syndesis |                  | 10.129.0.1  |                 |       41572 | 2018-06-05 13:48:51.250937+00 | 2018-06-11 06:00:06.158511+00 | 2018-06-11 06:00:06.164551+00 | 2018-06-11 06:00:06.164563+00 | f       | idle in transacti on |             |        73911 | select path,value,ovalue from jsondb where path LIKE $1 order by path ASC  16385 | syndesis |  2824 |    16384 | syndesis |                  | 10.129.0.1  |                 |       41576 | 2018-06-05 13:48:51.253989+00 |                               | 2018-06-05 13:48:51.335479+00 | 2018-06-05 13:48:51.337027+00 | f       | idle    |             |              | select path,value,ovalue from jsondb where path LIKE $1 and path &gt;= $2 and path &lt; $3 order by path ASC  16385 | syndesis | 44760 |       10 | postgres | psql             |             |                 |          -1 | 2018-06-11 05:59:47.419084+00 | 2018-06-11 06:00:31.38028+00  | 2018-06-11 06:00:31.38028+00  | 2018-06-11 06:00:31.380286+00 | f       | active    |             |        73917 | select * from pg_stat_activity;  16385 | syndesis | 44795 |       10 | postgres |                  |             |                 |             | 2018-06-11 06:00:24.603251+00 | 2018-06-11 06:00:24.630976+00 | 2018-06-11 06:00:24.630976+00 | 2018-06-11 06:00:24.630978+00 | f       | active    |             |        73917 | autovacuum: VACUUM public.jsondb (20 rows) ```  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Deploy integration 2. Navigate to activity tracking </body>
		<created>2018-06-05 14:05:20</created>
		<closed>2018-06-12 08:55:16</closed>
	</bug>
	<bug>
		<id>2741</id>
		<title>Connector AWS S3: deleteAfterRead option is useless in get Object action</title>
		<body>## This is a... &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem The deleteAfterRead option in the get object action is useless, because this option provides the functionality only when you poll a bucket and process a batch of S3 Objects.   ## Expected behavior No presence of deleteAfterRead in case of get Object action </body>
		<created>2018-06-04 14:22:40</created>
		<closed>2018-06-05 10:24:03</closed>
	</bug>
	<bug>
		<id>2726</id>
		<title>Activities entries inconsistent</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   Sorry for not searching whether this has been already reported, but a I'm rolling out iPaaS for production right now and a simple Twitter Mention to DB Update I recognized again in the final version there is an inconsistency in the Activity logs:  ![image](https://user-images.githubusercontent.com/99080/40811033-023d7396-6530-11e8-9562-a934b9df5416.png)  ![image](https://user-images.githubusercontent.com/99080/40811035-079fe468-6530-11e8-9d10-ca86e0ae1cd6.png)  ![image](https://user-images.githubusercontent.com/99080/40811044-0e3b9fba-6530-11e8-998e-fb3d63d6cf6c.png)  ![image](https://user-images.githubusercontent.com/99080/40811052-159b7596-6530-11e8-8758-e558aaf0331f.png)  I would expect the datamapper log entry in every activity which also resulted in stored procedure update.</body>
		<created>2018-05-31 22:10:14</created>
		<closed>2018-07-04 11:29:55</closed>
	</bug>
	<bug>
		<id>2721</id>
		<title>The build generates changed *.json files</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  After running a full build (`syndesis build -f -c`) some connector json files are changed:  ![capture](https://user-images.githubusercontent.com/351660/40790775-c91c89a6-64c3-11e8-8883-d9c4f3cc3fa9.PNG)  Now I gotta go and uncommit these files. </body>
		<created>2018-05-31 15:15:44</created>
		<closed>2018-10-09 18:34:32</closed>
	</bug>
	<bug>
		<id>2720</id>
		<title>AMQ connection check certificates select doesn't show the value properly</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Regardless of what "Check Certificates" is set to, it always shows "Enable", as the actual configured value isn't given to the form config.  The value is actually stored properly just not displayed properly.  @kcbabo FYI </body>
		<created>2018-05-31 15:11:40</created>
		<closed>2018-06-04 15:27:16</closed>
	</bug>
	<bug>
		<id>2716</id>
		<title>syndesis-extension-definition-schema.json is invalid</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem the syndesis-extension-definition-schema.json is invalid. https://github.com/syndesisio/syndesis/blob/master/app/extension/api/src/main/resources/syndesis/syndesis-extension-definition-schema.json  it is using some references which doesn't exists/are not provided.  Vs Code Json schema valitor is reporting: Invalid schema: dereference error - Error: Error opening file "urn:jsonschema\:io:syndesis:model:connection:ConfigurationProperty" ENOENT: no such file or directory, open 'C:\Program Files (x86)\Microsoft VS Code\urn:jsonschema\:io:syndesis:model:connection:ConfigurationProperty'  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-05-31 13:21:11</created>
		<closed>2018-10-09 18:34:33</closed>
	</bug>
	<bug>
		<id>2709</id>
		<title>License check is not working for (some?) XML files</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Seems that we have several `logback-test.xml` files that have different license headers in them and the license check is not catching those.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Have uniformed license headers   </body>
		<created>2018-05-24 15:55:39</created>
		<closed>2018-10-09 18:34:30</closed>
	</bug>
	<bug>
		<id>2706</id>
		<title>SQL Connector should not parse body when no parameters are set</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When inserting data into a DB, if the insert query has no parameters, the SQL connector should not parse the body and not expect it to be present or to be JSON data.  I've a integration from webhook to SQL with query: `INSERT INTO TODO (TASK) VALUES (1)`. On invocation I get: ``` java.lang.IllegalArgumentException: Unable to parse given JSON at io.syndesis.connector.sql.common.JSONBeanUtil.parseSqlParametersFromJSONBean(JSONBeanUtil.java:80) at io.syndesis.connector.sql.customizer.SqlConnectorCustomizer.doBeforeProducer(SqlConnectorCustomizer.java:56) at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at io.syndesis.integration.component.proxy.ComponentProxyProducer.process(ComponentProxyProducer.java:44) at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:77) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.util.AsyncProcessorHelper.process(AsyncProcessorHelper.java:109) at org.apache.camel.processor.Pipeline.process(Pipeline.java:80) at org.apache.camel.http.common.CamelServlet.doService(CamelServlet.java:208) at org.apache.camel.http.common.CamelServlet.service(CamelServlet.java:78) at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:85) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:106) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:64) at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:131) at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292) at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) at io.undertow.server.Connectors.executeRootHandler(Connectors.java:332) at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:812) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Caused by: com.fasterxml.jackson.databind.JsonMappingException: No content to map due to end-of-input  at [Source: ; line: 1, column: 0] at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:270) at com.fasterxml.jackson.databind.DeserializationContext.reportMissingContent(DeserializationContext.java:1248) at com.fasterxml.jackson.databind.ObjectReader._initForReading(ObjectReader.java:358) at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:1611) at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1220) at io.syndesis.connector.sql.common.JSONBeanUtil.parseSqlParametersFromJSONBean(JSONBeanUtil.java:78) ... 84 more ```  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; The connector should not parse the body if there are no parameters in the query.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; N/A  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt; N/A  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt; N/A  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Add webhooks e.g. from the extension repo if the new webhook feature is not yet merged 2. Create a route from webhook to sampledb with query: `INSERT INTO TODO (TASK) VALUES (1)` 3. Don't add anything else 4. Publish 5. Invoke webhook URL with a HTTP request having a empty body </body>
		<created>2018-05-24 08:47:03</created>
		<closed>2018-07-27 07:02:14</closed>
	</bug>
	<bug>
		<id>2694</id>
		<title>Import and publish of integration with same name is possible</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  It is possible to import integration with the same name as has the already running integration in syndesis. If the imported integration is published, the running pod in syndesis is rewritten with the newly published integration, both then end up in inconsistent "Published" state.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; The user should not be allowed to import integration with the same name, or the one integration should be rewritten (the user should be notified about this).  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![out](https://user-images.githubusercontent.com/4180208/40348371-d99baad6-5da3-11e8-9b61-1a25bf61b739.gif)  ![same_name_integration](https://user-images.githubusercontent.com/4180208/40348397-eb5e9526-5da3-11e8-8fbd-007a6a08c141.png)  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create integration with "name" 2. Import an integration with the same "name" - previously created and exported  3. Publish the integration with the same name 4. Observe the build and deployment on openshift </body>
		<created>2018-05-22 07:40:26</created>
		<closed>2018-08-06 12:38:22</closed>
	</bug>
	<bug>
		<id>2693</id>
		<title>Integration with same name - cumbersome change of specified name</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  I noticed, that on creation of the integration, the name of the integration is saved in UI even in case, it is not unique. This causes quite unpleasant user experience, when the user has to change the integration name in the upper left corner, where the integration name, which can't be used is displayed.  His other option is to cancel the whole not yet saved integration and go through the creation process again. I think this could be prevented, if the integration name, which can't be used was removed and the user would be able to start with the naming process again from scratch.    ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; This naming process in case the first name of the integration was not unique should be improved.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![out](https://user-images.githubusercontent.com/4180208/40346828-4efce58e-5d9e-11e8-9976-a7fba25cd7ea.gif)   ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create integration with "name" 2. Create second integration, when naming it, select the same "name" 3. Notice the error, the "Publish" button spins without stopping 4. The name can't be easily changed through the name input field </body>
		<created>2018-05-22 07:01:42</created>
		<closed>2018-07-17 19:43:47</closed>
	</bug>
	<bug>
		<id>2692</id>
		<title>Zero/negative/not integer value for time interval is allowed</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  User is able to set negative (also not-integer) value for Period.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; There could be some sort of validation to prevent this behavior.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![negative_int_time](https://user-images.githubusercontent.com/4180208/40310309-9e5837b0-5d0c-11e8-9a5c-df6af67f5f55.gif)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create new Integration 2. Select DB connection as input 3. Set the time period to whatever you want 4. Go on with creating integration </body>
		<created>2018-05-21 13:37:50</created>
		<closed>2018-05-24 09:14:49</closed>
	</bug>
	<bug>
		<id>2687</id>
		<title>Update Maven repos list for productized images</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [X] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt; Currently the productised templates contains these list of repos: ```  maven:         repositories:           01_maven_central: https://repo1.maven.org/maven2           02_redhat_ea_repository: https://maven.repository.redhat.com/earlyaccess/all           03_jboss_ea: https://repository.jboss.org/nexus/content/groups/ea ```  But in fuse-ignite-we replace 02 and 03 with:  ``` maven_repo_redhat="https://maven.repository.redhat.com/ga/" maven_repo_jboss="https://repository.jboss.org/" ```  So, my question is, whether we shouldn't just put these two repos into the original above ?  @dsimansk @paoloantinori any thoughts on this ?</body>
		<created>2018-05-18 17:53:32</created>
		<closed>2018-07-18 13:13:23</closed>
	</bug>
	<bug>
		<id>2680</id>
		<title>Custom API connector refused with "URISyntaxException: Malformed IPv6 address"</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When I try to create custom API connector using URL: http://54.152.43.92:8080/v2/swagger.json I get this error:  ```java.lang.IllegalArgumentException: java.net.URISyntaxException: Malformed IPv6 address at index 8: http://[54.152.43.92:8080]```  When I copy the swagger.json into a file, I am able to use it to create a custom API connector.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; The API connector should be created.  ## Screenshot ![screenshot from 2018-05-18 14-17-38](https://user-images.githubusercontent.com/4180208/40234229-5422a7e2-5aa6-11e8-8dcb-f8d93bbe170e.png)  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt; [server.txt](https://github.com/syndesisio/syndesis/files/2016710/server.txt)   ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-05-18 11:53:08</created>
		<closed>2018-05-24 07:41:17</closed>
	</bug>
	<bug>
		<id>2675</id>
		<title>extension : extension's default in/out kind should be 'none'</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  Set the default input/out data shape kind to "none"  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  The default  input/out data shape kind is set as "any" which leads the UI to display a warning for incompatible data between steps.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  Warning should not be shown.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![image](https://user-images.githubusercontent.com/1868933/40185048-fcb50c3e-59f1-11e8-9f24-32e955c021e5.png) </body>
		<created>2018-05-17 14:50:37</created>
		<closed>2018-05-24 07:42:48</closed>
	</bug>
	<bug>
		<id>2658</id>
		<title>Fix issue related to unstable test OutMessageCaptureProcessorTest.testCaptureWithSplitAndSchedule</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem a build has failed due a failing test, following builds were fine without any code modification. The product/test is not stable  see https://circleci.com/gh/syndesisio/syndesis/31464 https://ci.fabric8.io/view/release%20builds/job/syndesis-release/113  18:22:26  [ERROR] Errors:  18:22:26  [ERROR]   OutMessageCaptureProcessorTest.testCaptureWithSplitAndSchedule:291 NullPointer 18:22:26  [INFO]  18:22:26  [ERROR] Tests run: 41, Failures: 0, Errors: 1, Skipped: 0   ## Expected behavior reliable behavior  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-05-15 12:07:45</created>
		<closed>2018-10-09 18:34:21</closed>
	</bug>
	<bug>
		<id>2656</id>
		<title>"Sample Integrations Tutorials" and "User guide" documentation pointing to wrong location</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  The URL for "Sample Integrations Tutorials" and "User guide" is probably not correct. It redirects to 404 page.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  When choosing the first two options from these:  ![screenshot from 2018-05-15 10-23-47](https://user-images.githubusercontent.com/4180208/40045276-2546ab5e-582a-11e8-9b41-42a33d7708c8.png)  I get: ![404_user_guide_sample_integrations_tutorial](https://user-images.githubusercontent.com/4180208/40045224-03606700-582a-11e8-876d-135b0af39543.png) </body>
		<created>2018-05-15 08:24:59</created>
		<closed>2018-05-15 09:08:48</closed>
	</bug>
	<bug>
		<id>2653</id>
		<title>Ignite "Contact Us" address is "fuse-online-tech-preview@redhat.com"</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; The "Contact Us" address in the latest GA candidate is pointing to "mailto:fuse-online-tech-preview@redhat.com".   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; It should be probably some address which would not contain "tech-preview", or get rid of the "Contact Us" altogether.   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Click the "Contact Us"  2. Observe the email address</body>
		<created>2018-05-15 06:58:38</created>
		<closed>2018-05-15 13:49:30</closed>
	</bug>
	<bug>
		<id>2611</id>
		<title>Syndesis lifecycle - issue with renaming of integrations and older versions</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  It seems like there is an issue in current lifecycle design:  I created an integration with name "test". I then published the integration and then renamed it to "test_updated". Then I edited the integration and deployed the newer version of this integration (this starts the pod with the name "i-test-updated"). Then I revert the integration to the older "version 1" - this will start a pod with name "i-test", the integration name stays however "test_updated". The issue is now, when I start a new integration "test", this will recreate the running pod "i-test", which is now dedicated to the "test_updated" integration and this will break both my old and new integration, because the "i-test" pod will try to recreate endlessly.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; There could be some mechanism, which would prevent from creating the integration, which starts the pod with the same name as the running one, or some other solution.   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create integration, run it 2. Rename the integration  3. Edit the integration - run the new version 4. Revert to older version 1 of the integration 5. Create a new integration, with the original name of the integration, that is already running 6. Observe in OpenShift the incorrect behavior </body>
		<created>2018-05-14 13:56:11</created>
		<closed>2018-08-01 22:06:24</closed>
	</bug>
	<bug>
		<id>2607</id>
		<title>syndesis-db out of available connections after ~week of uptime</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  After about a week of uptime, with ~2M messages, the syndesis-db starts to log the following errors  FATAL:  remaining connection slots are reserved for non-replication superuser connections  and any request to the backend fails, e.g.:  ``` 2018-05-14 07:20:49.847 ERROR [-,0bae21f38eea0c62,0bae21f38eea0c62,false] 1 --- [  XNIO-3 task-5] .s.e.v.h.e.SyndesisServerExceptionMapper : Internal Server Exception. org.postgresql.util.PSQLException: The connection attempt failed.  org.skife.jdbi.v2.exceptions.UnableToObtainConnectionException: org.postgresql.util.PSQLException: The connection attempt failed. at org.skife.jdbi.v2.DBI.open(DBI.java:229) ~[jdbi-2.78.jar!/:2.78] at io.syndesis.server.jsondb.impl.SqlJsonDB.getAsStreamingOutput(SqlJsonDB.java:184) ~[server-jsondb-1.3.5.fuse-000002-redhat-1.jar!/:1.3.5.fuse-000002-redhat-1] at io.syndesis.server.jsondb.JsonDB.getAsStream(JsonDB.java:160) ~[server-jsondb-1.3.5.fuse-000002-redhat-1.jar!/:1.3.5.fuse-000002-redhat-1] at io.syndesis.server.jsondb.JsonDB.getAsByteArray(JsonDB.java:130) ~[server-jsondb-1.3.5.fuse-000002-redhat-1.jar!/:1.3.5.fuse-000002-redhat-1] at io.syndesis.server.jsondb.dao.JsonDbDao.fetchAll(JsonDbDao.java:96) ~[server-jsondb-1.3.5.fuse-000002-redhat-1.jar!/:1.3.5.fuse-000002-redhat-1] at io.syndesis.server.dao.manager.DataManager.lambda$fetchAll$0(DataManager.java:211) ~[server-dao-1.3.5.fuse-000002-redhat-1.jar!/:1.3.5.fuse-000002-redhat-1] at io.syndesis.server.dao.manager.DataManager.doWithDataAccessObject(DataManager.java:430) ~[server-dao-1.3.5.fuse-000002-redhat-1.jar!/:1.3.5.fuse-000002-redhat-1] at io.syndesis.server.dao.manager.DataManager.fetchAll(DataManager.java:211) ~[server-dao-1.3.5.fuse-000002-redhat-1.jar!/:1.3.5.fuse-000002-redhat-1] at io.syndesis.server.endpoint.v1.handler.BaseHandler.fetchAll(BaseHandler.java:46) ~[server-endpoint-1.3.5.fuse-000002-redhat-1.jar!/:1.3.5.fuse-000002-redhat-1] at io.syndesis.server.endpoint.v1.handler.connection.ConnectionHandler.list(ConnectionHandler.java:106) ~[server-endpoint-1.3.5.fuse-000002-redhat-1.jar!/:1.3.5.fuse-000002-redhat-1] at sun.reflect.GeneratedMethodAccessor942.invoke(Unknown Source) ~[na:na] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_171] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_171] at org.jboss.resteasy.core.MethodInjectorImpl.invoke(MethodInjectorImpl.java:140) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTarget(ResourceMethodInvoker.java:294) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:248) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:235) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:402) [resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:209) [resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.plugins.server.servlet.ServletContainerDispatcher.service(ServletContainerDispatcher.java:227) [resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:56) [resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:51) [resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) [javax.servlet-api-3.1.0.jar!/:3.1.0] at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:85) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) [spring-boot-1.5.8.RELEASE.jar!/:1.5.8.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110) [spring-boot-actuator-1.5.8.RELEASE.jar!/:1.5.8.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.authentication.preauth.AbstractPreAuthenticatedProcessingFilter.doFilter(AbstractPreAuthenticatedProcessingFilter.java:121) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.csrf.CsrfFilter.doFilterInternal(CsrfFilter.java:100) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:64) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at org.springframework.cloud.sleuth.instrument.web.TraceFilter.doFilter(TraceFilter.java:186) [spring-cloud-sleuth-core-1.2.5.RELEASE.jar!/:1.2.5.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:106) [spring-boot-actuator-1.5.8.RELEASE.jar!/:1.5.8.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:64) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:131) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) [undertow-core-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) [undertow-core-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) [undertow-core-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) [undertow-core-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) [undertow-core-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) [undertow-core-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.server.Connectors.executeRootHandler(Connectors.java:332) [undertow-core-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) [undertow-core-1.4.21.Final.jar!/:1.4.21.Final] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_171] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_171] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_171] Caused by: org.postgresql.util.PSQLException: The connection attempt failed. at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:272) ~[postgresql-9.4.1212.jre7.jar!/:9.4.1212.jre7] at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51) ~[postgresql-9.4.1212.jre7.jar!/:9.4.1212.jre7] at org.postgresql.jdbc.PgConnection.&lt;init&gt;(PgConnection.java:215) ~[postgresql-9.4.1212.jre7.jar!/:9.4.1212.jre7] at org.postgresql.Driver.makeConnection(Driver.java:404) ~[postgresql-9.4.1212.jre7.jar!/:9.4.1212.jre7] at org.postgresql.Driver.connect(Driver.java:272) ~[postgresql-9.4.1212.jre7.jar!/:9.4.1212.jre7] at org.apache.tomcat.jdbc.pool.PooledConnection.connectUsingDriver(PooledConnection.java:310) ~[tomcat-jdbc-8.5.23.jar!/:na] at org.apache.tomcat.jdbc.pool.PooledConnection.connect(PooledConnection.java:203) ~[tomcat-jdbc-8.5.23.jar!/:na] at org.apache.tomcat.jdbc.pool.ConnectionPool.createConnection(ConnectionPool.java:735) ~[tomcat-jdbc-8.5.23.jar!/:na] at org.apache.tomcat.jdbc.pool.ConnectionPool.borrowConnection(ConnectionPool.java:667) ~[tomcat-jdbc-8.5.23.jar!/:na] at org.apache.tomcat.jdbc.pool.ConnectionPool.getConnection(ConnectionPool.java:198) ~[tomcat-jdbc-8.5.23.jar!/:na] at org.apache.tomcat.jdbc.pool.DataSourceProxy.getConnection(DataSourceProxy.java:132) ~[tomcat-jdbc-8.5.23.jar!/:na] at org.skife.jdbi.v2.DataSourceConnectionFactory.openConnection(DataSourceConnectionFactory.java:34) ~[jdbi-2.78.jar!/:2.78] at org.skife.jdbi.v2.DBI.open(DBI.java:211) ~[jdbi-2.78.jar!/:2.78] ... 124 common frames omitted Caused by: java.net.NoRouteToHostException: No route to host (Host unreachable) at java.net.PlainSocketImpl.socketConnect(Native Method) ~[na:1.8.0_171] at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[na:1.8.0_171] at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[na:1.8.0_171] at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[na:1.8.0_171] at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[na:1.8.0_171] at java.net.Socket.connect(Socket.java:589) ~[na:1.8.0_171] at org.postgresql.core.PGStream.&lt;init&gt;(PGStream.java:61) ~[postgresql-9.4.1212.jre7.jar!/:9.4.1212.jre7] at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:144) ~[postgresql-9.4.1212.jre7.jar!/:9.4.1212.jre7] ... 136 common frames omitted ```  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;    ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-05-14 07:23:06</created>
		<closed>2018-07-09 12:31:01</closed>
	</bug>
	<bug>
		<id>2604</id>
		<title>Use `Accept: application/json` for `/api/v1/version` endpoint</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; We're parsing the response as JSON from `/api/v1/version` endpoint, we should indicate that our preference is for `application/json` response in the `Accept` header.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; When interacting with `/api/v1/version` endpoint `Accept: application/json` header is set without any other mime type.   ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  See https://github.com/syndesisio/syndesis/issues/2576#issuecomment-387749480  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt; `GET /api/v1/version`  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Access the support page 2. In undetermined number of cases there will be an error reported as in #2583, #2576 or #2423  </body>
		<created>2018-05-12 16:46:44</created>
		<closed>2018-05-15 13:50:20</closed>
	</bug>
	<bug>
		<id>2603</id>
		<title>After importing integration - Unable to decrypt key error appears</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Unable to decrypt key error appears attempting to publish an integration that was reimported. All this even after changing the password in the FTP connection and passing validation test.  ## Request and Response Data Error in log file: https://gist.github.com/honghuac/d7bd4d01a0e7562ad4a0bfcfddd9f7b8  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Export integration containing FTP connection 2. Import integration to different Fuse Ignite instance 3. Change FTP connection password 4. Publish integration  </body>
		<created>2018-05-12 13:14:36</created>
		<closed>2018-07-27 06:59:29</closed>
	</bug>
	<bug>
		<id>2602</id>
		<title>Import of zipped Integration - password for FTP connection needs to be reprovided</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; An existing integration that uses a FTP connection was exported. When reimported to another Fuse Ignite instance, the FTP connection of this integration has to be reprovided with the FTP server password, as the password that was exported fails the validation. </body>
		<created>2018-05-12 12:42:27</created>
		<closed>2018-11-15 04:03:35</closed>
	</bug>
	<bug>
		<id>2601</id>
		<title>Import of zipped Integration - fails to recreate API Client Connector in Customization screen</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; A backed up integration with API Client Connector, when reimported to Fuse Ignite, fails to display/recreate API Client Connector in Customization screen   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Export existing Integration with API Client Connector 2. Reimport it to a new Fuse Ignite instance 3. Check for API Client Connector </body>
		<created>2018-05-12 12:37:23</created>
		<closed>2018-07-12 17:28:39</closed>
	</bug>
	<bug>
		<id>2600</id>
		<title>Integration export fails with HTTP error 406</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem There's an regression between tags `1.3.6` and `1.3.7`. When I try to export an integration zip, there's an error notification. I suspect that enforcing `Accept:` header to be `application/json` is causing it. See the details of request below.  Browser console show error code 406: ``` {"errorCode":406,"userMsg":"Given request is not acceptable","developerMsg":"RESTEASY003635: No match for accept header"} ```  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;   ## Request and Response Data 1.3.7. request headers ``` GET /api/v1/integration-support/export.zip?id=i-LCJ51QuINcd-_bOOHXcz HTTP/1.1 Host: proj263404.6a63.fuse-ignite.openshiftapps.com Connection: keep-alive Pragma: no-cache Cache-Control: no-cache Accept: application/json SYNDESIS-XSRF-TOKEN: awesome User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36 Referer: https://proj263404.6a63.fuse-ignite.openshiftapps.com/integrations Accept-Encoding: gzip, deflate, br Accept-Language: en-GB,en;q=0.9,en-US;q=0.8,cs;q=0.7 Cookie: 9df916a3f797bf6405ce6f4582ab073b=e5825fdce7aea16e2165f1935a40ae1a; _oauth_proxy=ZHNpbWFuc2tAcmVkaGF0LmNvbXxtWnZUS3FaSklaZ2VoTDg1T21uNUxFR3RvbE5pZkJoTCtVVHc2RTliR1BtNHBMTi93dkIzR3J2dU5lRnB6Wm96Y3lRTUJSb1hIR2NONDNFPXwtNjIxMzU1OTY4MDB8|1526124216|Ta9JymWwtV3rYjdUnZxLY3NzZDk= ```  1.3.6 ``` GET /api/v1/integration-support/export.zip?id=i-LCJ2Llvxjr5CayesGuEz HTTP/1.1 Host: proj260415.6a63.fuse-ignite.openshiftapps.com Connection: keep-alive Pragma: no-cache Cache-Control: no-cache Accept: application/json, text/plain, */* SYNDESIS-XSRF-TOKEN: awesome User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.183 Safari/537.36 Vivaldi/1.96.1147.36 DNT: 1 Referer: https://proj260415.6a63.fuse-ignite.openshiftapps.com/ Accept-Encoding: gzip, deflate, br Accept-Language: en-GB,en-US;q=0.9,en;q=0.8 Cookie: 53c273361e89a86a0b0f8598671baf50=a3241a426e3de21a127f7ee362be3228; _oauth_proxy=cWUtMUBjbHVzdGVyLmxvY2FsfEVqblNuNXlQVEh6OWFJVnFmc25FYTVWZ3VRSEpteUk1Z1Y5QzU1VlFCMllDdVkyeW5WMlpSOVl6bVdDeE9iN0NDbytHeHIvZ3krV1lNYnc9fC02MjEzNTU5NjgwMHw=|1526123502|_w_b7dDfRFQEFTIb_pPEMy7SPgA=; _oauth_proxy_csrf=086ede1af26f484fcb4c2a9231a073e4 ``` ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-05-12 11:45:10</created>
		<closed>2018-05-12 12:23:42</closed>
	</bug>
	<bug>
		<id>2598</id>
		<title>activity view does not show recent activity after ~day of uptime </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  The activity log seems to stop at some point and does not show any of the recent entries. I have an integration that starts with a 1s timer, and after a day of runtime, the last activity shown is May 10, 2018, 7:01:44 PM  , while the current time is    May 11, 2018 17:52:13 PM  watching the actual pod log shows that the integration is still running correctly and reports logs every seconds as expected.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  activity log should show recent entries even after days of uptime  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![Activity log view stopped at 7:01:44 PM](http://xtf.cz/syndesis-activity-log-stopped.png)   ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-05-11 16:02:27</created>
		<closed>2018-08-06 09:42:49</closed>
	</bug>
	<bug>
		<id>2597</id>
		<title>Canceling "Update extension" redirects to "Import extension" page</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  When I'm on "Update extension" page, then select a new version of the extension I want to update and then press "Cancel" button, I'm redirected to the "Import extension" page.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; I would like to be redirected to the "Upgrade extension" page.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![out](https://user-images.githubusercontent.com/4180208/39921459-3bf68bc4-551b-11e8-95c8-826dafe89b34.gif)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create an extension  2. Import it to syndesis 3. Go to the update extension page 4. Select new version of extension you want to update 5. Press "Cancel" button in the bottom of the update dialog 6. Observe wrong redirect </body>
		<created>2018-05-11 11:01:52</created>
		<closed>2018-06-08 16:25:02</closed>
	</bug>
	<bug>
		<id>2594</id>
		<title>Correct message displayed upon connector deletion</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Upon deletion of a connector the wrong message is displayed  ## Expected behavior Display this message:  ``` Deleting this connector does not affect running integrations.  Are you sure you want to delete the "XXXXXXX" connector?  ```</body>
		<created>2018-05-11 09:24:58</created>
		<closed>2018-05-11 09:56:49</closed>
	</bug>
	<bug>
		<id>2587</id>
		<title>Import integration, when I press "cancel" integration get's imported</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; There is a "Cancel" button, for integration import. When I press it, the integration get's imported.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; I think it would be nice, if the integration was not imported when I press the "Cancel" button. For the confirmation of import, there is the "Done" button.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![out](https://user-images.githubusercontent.com/4180208/39861173-0fe40696-5440-11e8-9b63-17374c99b2e0.gif)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Press "import integration" 2. Select integration to import 3. Press "Cancel" button 4. </body>
		<created>2018-05-10 08:52:46</created>
		<closed>2018-07-17 18:44:39</closed>
	</bug>
	<bug>
		<id>2586</id>
		<title>Custom API connector Delete behavior - new changes in CR1</title>
		<body>## This is a... &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem There was a discussion about Deleting Custom API connector that haven't lead to any solution. https://github.com/syndesisio/syndesis/issues/2124, https://github.com/syndesisio/syndesis/issues/1827  Meanwhile, a side effect of an other fix (probably https://github.com/syndesisio/syndesis/issues/2524)  caused change in that behavior, which is:  1. connector can be deleted if there is or isn't a connection created from the connector. THe connection is still editable. It wasn't before. 2. connector can't be deleted (Delete button inactive) if a connection created from the connector is being used in an integration 3. If the connector has been deleted and you want to use a connection created from the connector in a new integration, There is an error when selecting the connection in the integration. ![connectionclicked](https://user-images.githubusercontent.com/8707251/39859067-e443df18-5438-11e8-86c4-300c98dab658.png) [server_pod.log](https://github.com/syndesisio/syndesis/files/1990798/server_pod.log)  There is also a warning when deleting a connector that says:  &gt;You can no longer edit a connection that was created from this connector. **(not true)** You can still add connections created from this connector to integrations. **(not true)** Deleting this connector does not affect running integrations. **(true, because you can't Delete it when a connection created from the connector is being used in an integration)**  &gt;Are you sure you want to delete the "Todo App API" connector?  Please do something with that inconsistency. Whichever it is of an easiest way of changing the warning or getting things working properly. Thanks.</body>
		<created>2018-05-10 08:13:46</created>
		<closed>2018-05-24 07:54:46</closed>
	</bug>
	<bug>
		<id>2585</id>
		<title>When transfering integration between two syndesis instances: Unable to decrypt key:accessToken</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; I'm unable to transfer integration from one syndesis instance to another. The connections (twitter and salesforce in my case) used by the integration use the "basic connection configuration" I don't use the "OAuth Application Management".  After I updated both connections (Orange triangle "Configuration required"), I tried to publish the integration. The server log provides following error:  ``` 2018-05-10 07:52:42.744 ERROR [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [twitter-salesforce]: [ERROR] Activation failure  java.lang.IllegalArgumentException: Unable to decrypt key:accessToken at io.syndesis.integration.project.generator.ProjectGeneratorHelper.mandatoryDecrypt(ProjectGeneratorHelper.java:133) ~[integration-project-generator-1.3.5.fuse-000002-redhat-1.jar!/:1.3.5.fuse-000002-redhat-1] at io.syndesis.integration.project.generator.ProjectGenerator.addDecryptedKeyProperty(ProjectGenerator.java:223) ~[integration-project-generator-1.3.5.fuse-000002-redhat-1.jar!/:1.3.5.fuse-000002-redhat-1] at io.syndesis.integration.project.generator.ProjectGenerator.generateApplicationProperties(ProjectGenerator.java:151) ~[integration-project-generator-1.3.5.fuse-000002-redhat-1.jar!/:1.3.5.fuse-000002-redhat-1] at io.syndesis.server.controller.integration.online.PublishHandler.createDeploymentData(PublishHandler.java:131) ~[server-controller-1.3.5.fuse-000002-redhat-1.jar!/:1.3.5.fuse-000002-redhat-1] at io.syndesis.server.controller.integration.online.PublishHandler.execute(PublishHandler.java:100) ~[server-controller-1.3.5.fuse-000002-redhat-1.jar!/:1.3.5.fuse-000002-redhat-1] at io.syndesis.server.controller.StateChangeHandler.execute(StateChangeHandler.java:33) [server-controller-1.3.5.fuse-000002-redhat-1.jar!/:1.3.5.fuse-000002-redhat-1] at io.syndesis.server.controller.integration.IntegrationController.lambda$callStateChangeHandler$11(IntegrationController.java:196) [server-controller-1.3.5.fuse-000002-redhat-1.jar!/:1.3.5.fuse-000002-redhat-1] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_171] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_171] at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_171]  2018-05-10 07:52:42.744 INFO [-,,,] 1 --- [tion Controller] i.s.s.c.i.IntegrationController : Integration i-LC7vFY2P96ad_t7Pzytz : Setting status to Pending (Unable to decrypt key:accessToken) ```  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; The integration should get published after user updates the connections.  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt; Attached the exported integration (created on CR1):  [twitter_salesforce-export.zip](https://github.com/syndesisio/syndesis/files/1990811/twitter_salesforce-export.zip)  Server log: [server_log.txt](https://github.com/syndesisio/syndesis/files/1990818/server_log.txt)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Start two syndesis instances (or you can simply use the attached integration) 2. Create integration TW-&gt;SF on one instance, export it 3. Import to second instance, update the connections 4. Publish integration 5. observe errors in server log, the integration will stay in "Publishing" state indefinitely </body>
		<created>2018-05-10 08:07:36</created>
		<closed>2018-07-26 11:55:00</closed>
	</bug>
	<bug>
		<id>2584</id>
		<title>Only one name of connection when importing integrations</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  When I import integration into syndesis, the list of "connections" that this specific imported integration uses is not complete. There is only one connection listed, even though every integration uses at least two connections.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; The "Connection name" list should contain a complete list of connections, the imported integration uses.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; This integration has two connections, "twitter" and "salesforce" as you can see on second screenshot. ![import_integration](https://user-images.githubusercontent.com/4180208/39858257-471f4ddc-5436-11e8-8f6e-8d10e856805a.png)  ![integration_import](https://user-images.githubusercontent.com/4180208/39858261-4b0c81d0-5436-11e8-88e4-8b18b3f408c1.png)   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Export an integration 2. Import it into syndesis 3. Observe, that the "Connection name" list contains always only one connection name</body>
		<created>2018-05-10 07:41:34</created>
		<closed>2018-10-03 10:41:07</closed>
	</bug>
	<bug>
		<id>2583</id>
		<title>Error on support page for version 1.3.5</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  When going to the support in 1.3.5 the following errors appears:  &lt;img width="637" alt="screen shot 2018-05-09 at 14 27 51" src="https://user-images.githubusercontent.com/99080/39840746-4eb5e9a8-5395-11e8-974c-867dcd69d65f.png"&gt; </body>
		<created>2018-05-09 21:29:27</created>
		<closed>2018-05-10 20:52:36</closed>
	</bug>
	<bug>
		<id>2579</id>
		<title>Activity Log is inconsistent</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  I'm using  simple twitter mention connector with a log step afterwards where I select the "log body" option.  In the activity logs there are entries with missing body, but also an entry missing (see the log in the next comment)  &lt;img width="1230" alt="image" src="https://user-images.githubusercontent.com/99080/39828418-c77df8f6-536f-11e8-92dc-dbc9b0e28fd3.png"&gt; </body>
		<created>2018-05-09 17:00:51</created>
		<closed>2018-07-24 12:22:50</closed>
	</bug>
	<bug>
		<id>2578</id>
		<title>Ignite-upgrade CR container using old 'oc' binary</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  @paoloantinori @dsimansk for tracking purposes. https://issues.jboss.org/browse/ENTESB-8124  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-05-09 14:05:17</created>
		<closed>2018-05-11 16:59:35</closed>
	</bug>
	<bug>
		<id>2577</id>
		<title>[Upgrade] Not possible to upgrade to prod version using docker img</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Currently it is not possible to upgrade to newer version using docker container, because of preflight check failing. The version defined the template in prod version upgrade container specifies syndesis: "1.3" version.  The upgrade script then fails here:  ```     if [ -n "${SYNDESIS_VERSION:-}" ]; then         if [ "$SYNDESIS_VERSION" != "${target_version}" ]; then             echo "Internal error: Container template's version is not the same as upgrade container tag"             echo "- Container version:               $SYNDESIS_VERSION"             echo "- Version extracted from template: $target_version"             exit 1         fi     fi  ```  Because the container variable SYNDESIS_VERSION is set to "1.3.5.fuse-000002-redhat-1" and the "target_version" is parsed from the template and therefore resolves to "1.3" and the if shuts everything down  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-05-09 13:41:43</created>
		<closed>2018-07-04 09:25:49</closed>
	</bug>
	<bug>
		<id>2575</id>
		<title>Templates of fuse-ignite-* flavour should point to GA maven repo</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Since we're goint toward GA release, Maven artifacts will end up in  `https://maven.repository.redhat.com/ga/`  https://github.com/syndesisio/fuse-ignite-install/blob/d6a78cc0beb410c93386af2a6b46bdfc271ae8d0/resources/fuse-ignite-ocp.yml#L1094  </body>
		<created>2018-05-09 11:59:47</created>
		<closed>2018-07-18 13:31:35</closed>
	</bug>
	<bug>
		<id>2574</id>
		<title>Upgrade template of fuse-ignite flavour should point to productized image version</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem When templates are released to `fuse-ignite-install` repository. Coordinates to `fuse-ignite-upgrade` should be also changed accordingly from Dockerhub to RH registry.  https://github.com/syndesisio/fuse-ignite-install/blob/master/resources/fuse-ignite-ocp.yml#L1522   ## Expected behavior Fuse Ignite template points only to product versions  Cc @paoloantinori @rhuss. If you prefer to have the issue created in the other repository, just let me know.</body>
		<created>2018-05-09 10:56:26</created>
		<closed>2018-05-17 18:49:30</closed>
	</bug>
	<bug>
		<id>2573</id>
		<title>Ignite-upgrade CR container using outdated upgrade scripts</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  @paoloantinori @dsimansk just for tracking purposes, description is here: https://issues.jboss.org/browse/ENTESB-8117  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-05-09 10:40:45</created>
		<closed>2018-05-10 12:27:50</closed>
	</bug>
	<bug>
		<id>2569</id>
		<title>Extension Import screen is a bit confusing</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [X] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  In the top box it says in the green box "Sucessfully imported", but there is still an active "Import" button. Actually, at that stage the extension has *not* been imported, but _uploaded_ and checked. Maybe the green label should be changed to *Sucessfully uploaded* ?  &lt;img width="986" alt="image" src="https://user-images.githubusercontent.com/99080/39788356-f4d5ec14-52de-11e8-90aa-8a68575c5278.png"&gt; </body>
		<created>2018-05-08 23:45:07</created>
		<closed>2018-06-08 16:25:02</closed>
	</bug>
	<bug>
		<id>2563</id>
		<title>Product logo is too small to be readable</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem In TP4 the styling of top bar looked like: ![35691695-763ba200-0779-11e8-91b0-f1ea577ee158](https://user-images.githubusercontent.com/5637792/39749193-548d6862-52b2-11e8-94ce-0b17bd5ccf5d.png)  The logo is the same but the space left for the logo seems too small. In a current release candidate: &lt;img width="538" alt="screen shot 2018-05-08 at 11 21 12" src="https://user-images.githubusercontent.com/5637792/39749225-6a323bd4-52b2-11e8-8262-457456a0460a.png"&gt;   ## Expected behavior All words from logo are readable and have appropriate size.  Cc @paoloantinori @aileenc @kcbabo @rhuss  </body>
		<created>2018-05-08 09:29:28</created>
		<closed>2018-05-08 13:23:57</closed>
	</bug>
	<bug>
		<id>2555</id>
		<title>Max integrations per user vs per installation. </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [X] Thought Exercise &lt;/code&gt;&lt;/pre&gt;  ## The problem Right now we can configure a max integrations allowed per user.  Should that be max integrations allowed per installation? Seems per installation would make more sense since that kinda knows how much capacity is available to run integrations.  If multiple users share a single installation, they would be able to exceed the capacity of the install easily.   </body>
		<created>2018-05-04 15:15:55</created>
		<closed>2019-01-08 15:09:17</closed>
	</bug>
	<bug>
		<id>2553</id>
		<title>ENTESB-6910 Add licenses.xml to iPaaS</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Comply with licenses checks for productization. </body>
		<created>2018-05-04 12:34:06</created>
		<closed>2018-05-04 16:50:49</closed>
	</bug>
	<bug>
		<id>2547</id>
		<title>Prometheus - OOM</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Continuation of #2155 `syndesis-prometheus` have issues to scale, after an busy setup is running for a couple of days. We probably need to allocate more resource/limits to the corresponding pod. &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  </body>
		<created>2018-05-03 14:44:01</created>
		<closed>2018-08-21 14:20:59</closed>
	</bug>
	<bug>
		<id>2543</id>
		<title>Incorrect step highlighted in the new connection wizard for OAuth based connections</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; The new connection wizard for OAuth based connection flow creation as the last step after OAuth service provider invokes the callback displays step 2 (Configure Connection) instead of step 3 (Name Connection).  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; We should highlight step 3 -- Name Connection.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![screenshot-2018-5-3 syndesis - development](https://user-images.githubusercontent.com/1306050/39573976-a3c07ac2-4ed5-11e8-8fd5-45d29a1bf419.png)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create OAuth based connection with OAuth settings set 2. After callback notice the 2nd wizard step being highlighted (see screenshot) </body>
		<created>2018-05-03 11:27:54</created>
		<closed>2018-05-03 13:06:14</closed>
	</bug>
	<bug>
		<id>2540</id>
		<title>"Replace draft" when hit, it does basically nothing</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  This is a small issue, however I don't know whether it somehow isn't related to this issue https://github.com/syndesisio/syndesis/issues/2539. Basically the "Replace draft" option for various integration versions does nothing.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; It could do something?  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![screenshot from 2018-05-03 10-22-08](https://user-images.githubusercontent.com/4180208/39566864-4e630ddc-4ebd-11e8-966e-b189177123d4.png)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create iintegration, edit it so there are at least v1 and v2 2. You can invoke dropdown menu with options "Replace draft" and "Publish" tight next to the integration version.  3. The "Replace draft" does nothing </body>
		<created>2018-05-03 08:35:49</created>
		<closed>2018-05-04 16:14:39</closed>
	</bug>
	<bug>
		<id>2539</id>
		<title>When previous version is published, UI showing newest integration detail (also in edit mode)</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; The lifecycle got fixed (https://github.com/syndesisio/syndesis/issues/2432), so the user is now able to publish older version of integration. The integration detail and edit page however is not consistent with the currently deployed integration version.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; When there are for instance two versions (v1, v2), and the older v1 is published, the integration detail and edit page should provide the user the view and edit possibility of the currently running v1 integration, not the newest v2.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  As you can see, the integration in V1 doesn't contain any log steps: ![tw_db_version1](https://user-images.githubusercontent.com/4180208/39564759-ce7b77dc-4eb5-11e8-8c3c-1f8734ad4112.png)  The log steps are added in V2: ![tw_db_version2](https://user-images.githubusercontent.com/4180208/39564789-e03ba58c-4eb5-11e8-8918-023f98dd0a68.png)  When I return to the previous V1 (you can see, that the curent version is "version 1"), I however still see the V2 detail page.   ![tw_db_back_to_v1](https://user-images.githubusercontent.com/4180208/39564835-0f2fc7c4-4eb6-11e8-9861-8de4b7a877e7.png)  The "Edit" page also provides the possibility to edit not the V1, but the V2 integration: ![tw_db_edit_page_when_v1_deployed](https://user-images.githubusercontent.com/4180208/39564871-2eeaf368-4eb6-11e8-8d93-9d4b2c23ada6.png)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create integration, edit it, so you get at least 2 versions of this integration 2. Revert the integration to the previous version 3. Observe, that the detail page doesn't reflect currently running integration </body>
		<created>2018-05-03 07:45:10</created>
		<closed>2018-05-04 16:15:25</closed>
	</bug>
	<bug>
		<id>2524</id>
		<title>Deleting a connection which is used by an integration leads to inconsistent state</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  After an import of integration with a broken connection (because of missing OAuth dance, see #2522), deleting the connection is possible without warning (e.g. "is used in an existing integration"). After the deletion, the following error happens on the integration overview:  ![image](https://user-images.githubusercontent.com/99080/39515763-55e79360-4dfb-11e8-8a85-a67e92da40d7.png)  and in the server logs there's a NPE:  ``` 2018-05-02 09:24:07.765  INFO [-,,,] 1 --- [oller Scheduler] i.s.s.c.i.IntegrationController          : Checking integrations for their status. 2018-05-02 09:24:23.529 ERROR [-,bbc75ec8b624358d,bbc75ec8b624358d,false] 1 --- [  XNIO-3 task-8] .s.e.v.h.e.SyndesisServerExceptionMapper : Internal Server Exception. null  java.lang.NullPointerException: null at io.syndesis.server.endpoint.v1.handler.integration.IntegrationHandler.toCurrentConnection(IntegrationHandler.java:352) ~[server-endpoint-1.3.5-20180502.jar!/:1.3.5-20180502] at java.util.Optional.map(Optional.java:215) ~[na:1.8.0_151] at io.syndesis.server.endpoint.v1.handler.integration.IntegrationHandler.toCurrentSteps(IntegrationHandler.java:371) ~[server-endpoint-1.3.5-20180502.jar!/:1.3.5-20180502] at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[na:1.8.0_151] at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1380) ~[na:1.8.0_151] at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ~[na:1.8.0_151] at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ~[na:1.8.0_151] at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ~[na:1.8.0_151] at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[na:1.8.0_151] at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ~[na:1.8.0_151] at io.syndesis.server.endpoint.v1.handler.integration.IntegrationHandler.toCurrentIntegrationOverview(IntegrationHandler.java:333) ~[server-endpoint-1.3.5-20180502.jar!/:1.3.5-20180502] at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[na:1.8.0_151] at java.util.Collections$2.tryAdvance(Collections.java:4717) ~[na:1.8.0_151] at java.util.Collections$2.forEachRemaining(Collections.java:4725) ~[na:1.8.0_151] at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ~[na:1.8.0_151] at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ~[na:1.8.0_151] at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ~[na:1.8.0_151] at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[na:1.8.0_151] at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ~[na:1.8.0_151] at io.syndesis.server.endpoint.v1.handler.integration.IntegrationHandler.list(IntegrationHandler.java:149) ~[server-endpoint-1.3.5-20180502.jar!/:1.3.5-20180502] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_151] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_151] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151] ```</body>
		<created>2018-05-02 09:25:43</created>
		<closed>2018-05-09 12:31:28</closed>
	</bug>
	<bug>
		<id>2522</id>
		<title>Setting up secrets for imported OAuth based connections is broken</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   When importing an integration with a Twitter connection, after the import I get  ![image](https://user-images.githubusercontent.com/99080/39515300-fb67b506-4df9-11e8-8f9e-2874d3e0fd2a.png)  That's correct, but editing this connection via  ![image](https://user-images.githubusercontent.com/99080/39515332-0c81acfc-4dfa-11e8-90b7-634eeb3153bd.png)  leads to  ![image](https://user-images.githubusercontent.com/99080/39515343-19e71102-4dfa-11e8-8f04-239a6d167788.png)  There is no way to instantiate the OAuth dance again (the consumer secret and key has been setup in the global section).  Also, pushing the "Validate" button is a no-op here (no error indicated). IMO the button should be disabled in this case. </body>
		<created>2018-05-02 09:17:22</created>
		<closed>2018-09-20 10:23:43</closed>
	</bug>
	<bug>
		<id>2518</id>
		<title>UI gotchas when doing an import</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  These extra lines after an import look bogus:  ![image](https://user-images.githubusercontent.com/99080/39513701-84af13b8-4df5-11e8-8b8c-63efbfb4f777.png) </body>
		<created>2018-05-02 08:42:54</created>
		<closed>2018-10-03 12:44:55</closed>
	</bug>
	<bug>
		<id>2517</id>
		<title>No activity log shown</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When using a simple twitter-slack integration with a log step, the following output happens in the integration pod:  ``` {"exchange":"i-LBUt610F_AdqWHq8As5z","status":"begin"} {"exchange":"i-LBUt610F_AdqWHq8As5z","status":"begin"} {"exchange":"i-LBUt610F_AdqWHq8As5z","status":"begin"} {"exchange":"i-LBUt610F_AdqWHq8As5z","status":"begin"} {"exchange":"i-LBUt610F_AdqWHq8As5z","step":"-LBUoJgJqHvZKe2iX3I2","id":"i-LBUt611F_AdqWHq8As7z","message":"Twitter Message: @syndesis_d_test no matter how great and destructive your problems may seem now, remember, you've probably only seen the tip of them."} 2018-05-02 08:07:34.786  INFO 1 --- [line://MENTIONS] -LBUnwF1qHvZKe2iX3I0                     : Twitter Message: @syndesis_d_test no matter how great and destructive your problems may seem now, remember, you've probably only seen the tip of them. {"exchange":"i-LBUt610F_AdqWHq8As5z","step":"-LBUnxbiqHvZKe2iX3I0","id":"i-LBUt613F_AdqWHq8As9z","duration":75799708} {"exchange":"i-LBUt610F_AdqWHq8As5z","status":"done","failed":false} {"exchange":"i-LBUt610F_AdqWHq8As5z","status":"done","failed":false} {"exchange":"i-LBUt610F_AdqWHq8As5z","status":"done","failed":false} {"exchange":"i-LBUt610F_AdqWHq8As5z","status":"done","failed":false} ```  @chirino Is it correct that the duplicated log entries here ? (like multiple "begin" and "done" entries ?)  However, the activity screen looks like:  &lt;img width="762" alt="image" src="https://user-images.githubusercontent.com/99080/39512526-96ad6262-4df1-11e8-89ce-d27f1c0b31eb.png"&gt;  The server answer is   ![image](https://user-images.githubusercontent.com/99080/39512563-b98d42d4-4df1-11e8-9676-f83d80754c1c.png)  No special output in the server log.  &lt;details&gt; &lt;summary&gt;Full integration log&lt;/summary&gt;  ``` Starting the Java application using /opt/run-java/run-java.sh ... exec java -javaagent:/opt/jolokia/jolokia.jar=config=/opt/jolokia/etc/jolokia.properties -javaagent:/opt/prometheus/jmx_prometheus_javaagent.jar=9779:/tmp/src/prometheus-config.yml -Xmx256m -XX:ParallelGCThreads=1 -XX:ConcGCThreads=1 -Djava.util.concurrent.ForkJoinPool.common.parallelism=1 -XX:CICompilerCount=2 -XX:+UseParallelGC -XX:GCTimeRatio=4 -XX:AdaptiveSizePolicyWeight=90 -XX:MinHeapFreeRatio=20 -XX:MaxHeapFreeRatio=40 -XX:+ExitOnOutOfMemoryError -cp . -jar /deployments/project-0.1-SNAPSHOT.jar I&gt; No access restrictor found, access to any MBean is allowed Jolokia: Agent started with URL https://10.130.34.51:8778/jolokia/       _______.                 _               _     /       |                 | |             (_)    |   (----`_   _  ____    _ | |  ____   ___  _   ___     \   \   | | | ||  _ \  / || | / _  ) /___)| | /___) .----)   |  | |_| || | | |( (_| |( (/ / |___ || ||___ | |_______/    \__  ||_| |_| \____| \____)(___/ |_|(___/ ============ (____/ =================================== :: Integration ::  :: v   2018-05-02 08:07:16.492  INFO 1 --- [           main] io.syndesis.example.Application          : Starting Application on i-twitter-slack-2-7x9zf with PID 1 (/deployments/project-0.1-SNAPSHOT.jar started by ? in /deployments) 2018-05-02 08:07:16.497 DEBUG 1 --- [           main] io.syndesis.example.Application          : Running with Spring Boot v1.5.8.RELEASE, Spring v4.3.12.RELEASE 2018-05-02 08:07:16.497  INFO 1 --- [           main] io.syndesis.example.Application          : No active profile set, falling back to default profiles: default 2018-05-02 08:07:16.986  INFO 1 --- [           main] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@1b083826: startup date [Wed May 02 08:07:16 UTC 2018]; root of context hierarchy 2018-05-02 08:07:21.502  INFO 1 --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.apache.camel.spring.boot.CamelAutoConfiguration' of type [org.apache.camel.spring.boot.CamelAutoConfiguration$$EnhancerBySpringCGLIB$$f2ecbcbf] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2018-05-02 08:07:22.217  INFO 1 --- [           main] org.xnio                                 : XNIO version 3.3.8.Final 2018-05-02 08:07:22.289  INFO 1 --- [           main] org.xnio.nio                             : XNIO NIO Implementation Version 3.3.8.Final 2018-05-02 08:07:22.390  WARN 1 --- [           main] io.undertow.websockets.jsr               : UT026009: XNIO worker was not set on WebSocketDeploymentInfo, the default worker will be used 2018-05-02 08:07:22.390  WARN 1 --- [           main] io.undertow.websockets.jsr               : UT026010: Buffer pool was not set on WebSocketDeploymentInfo, the default pool will be used 2018-05-02 08:07:22.421  INFO 1 --- [           main] io.undertow.servlet                      : Initializing Spring embedded WebApplicationContext 2018-05-02 08:07:22.421  INFO 1 --- [           main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 5506 ms 2018-05-02 08:07:22.915  INFO 1 --- [           main] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/] 2018-05-02 08:07:22.920  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'metricsFilter' to: [/*] 2018-05-02 08:07:22.921  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*] 2018-05-02 08:07:22.922  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*] 2018-05-02 08:07:22.922  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*] 2018-05-02 08:07:22.922  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*] 2018-05-02 08:07:22.922  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'webRequestLoggingFilter' to: [/*] 2018-05-02 08:07:22.922  INFO 1 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'applicationContextIdFilter' to: [/*] 2018-05-02 08:07:23.825  INFO 1 --- [           main] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@1b083826: startup date [Wed May 02 08:07:16 UTC 2018]; root of context hierarchy 2018-05-02 08:07:24.022  INFO 1 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) 2018-05-02 08:07:24.023  INFO 1 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity&lt;java.util.Map&lt;java.lang.String, java.lang.Object&gt;&gt; org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest) 2018-05-02 08:07:24.116  INFO 1 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler] 2018-05-02 08:07:24.116  INFO 1 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler] 2018-05-02 08:07:24.222  INFO 1 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler] 2018-05-02 08:07:24.891  INFO 1 --- [           main] o.a.c.s.boot.CamelAutoConfiguration      : Using custom InterceptStrategy with id: integrationLoggingInterceptStrategy and implementation: io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy@f667fe 2018-05-02 08:07:25.096  INFO 1 --- [           main] o.a.c.i.converter.DefaultTypeConverter   : Type converters loaded (core: 193, classpath: 6) 2018-05-02 08:07:27.086  INFO 1 --- [           main] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/health || /health.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,java.security.Principal) 2018-05-02 08:07:27.426  INFO 1 --- [           main] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup 2018-05-02 08:07:27.491  INFO 1 --- [           main] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 0 2018-05-02 08:07:27.529 DEBUG 1 --- [           main] o.a.camel.spring.boot.RoutesCollector    : Post-processing CamelContext bean: twitter-slack 2018-05-02 08:07:27.585 DEBUG 1 --- [           main] o.a.camel.spring.boot.RoutesCollector    : CamelContextConfiguration found. Invoking beforeApplicationStart: io.syndesis.integration.runtime.IntegrationRuntimeAutoConfiguration$1@49ff7d8c 2018-05-02 08:07:27.597  INFO 1 --- [           main] i.s.i.runtime.IntegrationRouteBuilder    : Loading integration from: classpath:syndesis/integration/integration.json 2018-05-02 08:07:28.618 DEBUG 1 --- [           main] i.s.i.runtime.IntegrationRouteBuilder    : Step kind: endpoint, handler: io.syndesis.integration.runtime.handlers.ConnectorStepHandler 2018-05-02 08:07:28.792 DEBUG 1 --- [           main] i.s.i.c.proxy.ComponentProxyComponent    : Starting connector: twitter-timeline-1 2018-05-02 08:07:28.830 DEBUG 1 --- [           main] i.s.i.runtime.IntegrationRouteBuilder    : Step kind: log, handler: io.syndesis.integration.runtime.handlers.LogStepHandler 2018-05-02 08:07:28.831 DEBUG 1 --- [           main] i.s.i.runtime.IntegrationRouteBuilder    : Step kind: mapper, handler: io.syndesis.integration.runtime.handlers.DataMapperStepHandler 2018-05-02 08:07:28.831 DEBUG 1 --- [           main] i.s.i.runtime.IntegrationRouteBuilder    : Step kind: endpoint, handler: io.syndesis.integration.runtime.handlers.ConnectorStepHandler 2018-05-02 08:07:28.894 DEBUG 1 --- [           main] i.s.i.c.proxy.ComponentProxyComponent    : Starting connector: slack-4 2018-05-02 08:07:28.895 DEBUG 1 --- [           main] o.a.camel.spring.boot.RoutesCollector    : CamelContextConfiguration found. Invoking beforeApplicationStart: io.syndesis.integration.runtime.jmx.IntegrationMetadataAutoConfiguration$1@1b065145 2018-05-02 08:07:28.896  INFO 1 --- [           main] r.j.IntegrationMetadataAutoConfiguration : Added Syndesis MBean Service 2018-05-02 08:07:28.896 DEBUG 1 --- [           main] o.a.camel.spring.boot.RoutesCollector    : CamelContextConfiguration found. Invoking beforeApplicationStart: io.syndesis.integration.runtime.logging.IntegrationLoggingAutoConfiguration$1@62dae540 2018-05-02 08:07:28.914  INFO 1 --- [           main] o.a.camel.spring.SpringCamelContext      : Apache Camel 2.21.0 (CamelContext: twitter-slack) is starting 2018-05-02 08:07:28.915  INFO 1 --- [           main] o.a.camel.spring.SpringCamelContext      : StreamCaching is enabled on CamelContext: twitter-slack 2018-05-02 08:07:28.915  INFO 1 --- [           main] o.a.c.m.ManagedManagementStrategy        : JMX is enabled 2018-05-02 08:07:29.386  INFO 1 --- [           main] i.s.i.c.proxy.ComponentProxyComponent    : Connector resolved: twitter-timeline-1 -&gt; twitter-timeline://MENTIONS?accessToken=890116203867406336-GaXZhE2Zc1kePsI630O9AcdZp2LBKGR&amp;accessTokenSecret=5Gv6qKeC7ghNkM0kyLARwqMObbv4xFTpRaKCsBGIgQNk8&amp;consumerKey=oQJdK7ew5OfFSmEmlAwTi5jUZ&amp;consumerSecret=OBxMEUVk9zoExyh3b2XNAhSSduPNzQLGqKCinIBmRrHrfpfC4W&amp;delay=30000 2018-05-02 08:07:29.599  INFO 1 --- [           main] i.s.i.c.proxy.ComponentProxyComponent    : Connector resolved: slack-4 -&gt; slack://%23rh-summit?iconEmoji=%3Acamel%3A&amp;username=RH+Summit+Demo&amp;webhookUrl=https%3A%2F%2Fhooks.slack.com%2Fservices%2F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 2018-05-02 08:07:29.621  INFO 1 --- [           main] o.a.c.impl.DefaultStreamCachingStrategy  : StreamCaching in use with spool directory: /tmp/camel/camel-tmp-b138761b-bb94-4574-ac88-c7d7cc0a6c8d and rules: [Spool &gt; 128K body size] 2018-05-02 08:07:29.793  INFO 1 --- [           main] i.s.i.r.jmx.CamelContextMetadataMBean    : Registered mbean io.syndesis.camel:context=twitter-slack,type=context,name="twitter-slack" 2018-05-02 08:07:29.801  INFO 1 --- [           main] o.a.camel.spring.SpringCamelContext      : Route: -LBUnwF1qHvZKe2iX3I0 started and consuming from: twitter-timeline://MENTIONS?accessToken=890116203867406336-GaXZhE2Zc1kePsI630O9AcdZp2LBKGR&amp;accessTokenSecret=5Gv6qKeC7ghNkM0kyLARwqMObbv4xFTpRaKCsBGIgQNk8&amp;consumerKey=oQJdK7ew5OfFSmEmlAwTi5jUZ&amp;consumerSecret=OBxMEUVk9zoExyh3b2XNAhSSduPNzQLGqKCinIBmRrHrfpfC4W&amp;delay=30000 2018-05-02 08:07:29.802  INFO 1 --- [           main] o.a.camel.spring.SpringCamelContext      : Total 1 routes, of which 1 are started 2018-05-02 08:07:29.802  INFO 1 --- [           main] o.a.camel.spring.SpringCamelContext      : Apache Camel 2.21.0 (CamelContext: twitter-slack) started in 0.888 seconds 2018-05-02 08:07:29.803 DEBUG 1 --- [           main] o.a.camel.spring.boot.RoutesCollector    : CamelContextConfiguration found. Invoking afterApplicationStart: io.syndesis.integration.runtime.IntegrationRuntimeAutoConfiguration$1@49ff7d8c 2018-05-02 08:07:31.296 DEBUG 1 --- [           main] .i.r.IntegrationRuntimeAutoConfiguration : Routes:  &lt;?xml version="1.0" encoding="UTF-8" standalone="yes"?&gt; &lt;routes xmlns="http://camel.apache.org/schema/spring"&gt;     &lt;route customId="true" id="-LBUnwF1qHvZKe2iX3I0"&gt;         &lt;from customId="true" id="-LBUnxbiqHvZKe2iX3I0" uri="twitter-timeline-1"/&gt;         &lt;setHeader headerName="Syndesis.STEP_ID" id="setHeader1"&gt;             &lt;constant&gt;-LBUnwF1qHvZKe2iX3I0&lt;/constant&gt;         &lt;/setHeader&gt;         &lt;process customId="true" id="-LBUoJgJqHvZKe2iX3I2"/&gt;         &lt;pipeline customId="true" id="-LBUo2O3qHvZKe2iX3I1"&gt;             &lt;setHeader headerName="Syndesis.STEP_ID" id="setHeader2"&gt;                 &lt;constant&gt;-LBUoJgJqHvZKe2iX3I2&lt;/constant&gt;             &lt;/setHeader&gt;             &lt;log id="log1" loggingLevel="INFO" marker="-LBUoJgJqHvZKe2iX3I2" message="Twitter Message: ${body.text}"/&gt;             &lt;process id="process1"/&gt;         &lt;/pipeline&gt;         &lt;pipeline customId="true" id="-LBUnxbiqHvZKe2iX3I0"&gt;             &lt;setHeader headerName="Syndesis.STEP_ID" id="setHeader3"&gt;                 &lt;constant&gt;-LBUo2O3qHvZKe2iX3I1&lt;/constant&gt;             &lt;/setHeader&gt;             &lt;to id="to1" uri="atlas:mapping-step-3.json?sourceMapName=Syndesis.CAPTURED_OUT_MESSAGES_MAP"/&gt;             &lt;process id="process2"/&gt;         &lt;/pipeline&gt;         &lt;pipeline customId="true" id="step:-LBUnxbiqHvZKe2iX3I0"&gt;             &lt;setHeader headerName="Syndesis.STEP_ID" id="setHeader4"&gt;                 &lt;constant&gt;-LBUnxbiqHvZKe2iX3I0&lt;/constant&gt;             &lt;/setHeader&gt;             &lt;to id="to2" uri="slack-4"/&gt;             &lt;process id="process3"/&gt;         &lt;/pipeline&gt;     &lt;/route&gt; &lt;/routes&gt;  2018-05-02 08:07:31.296 DEBUG 1 --- [           main] o.a.camel.spring.boot.RoutesCollector    : CamelContextConfiguration found. Invoking afterApplicationStart: io.syndesis.integration.runtime.jmx.IntegrationMetadataAutoConfiguration$1@1b065145 2018-05-02 08:07:31.296 DEBUG 1 --- [           main] o.a.camel.spring.boot.RoutesCollector    : CamelContextConfiguration found. Invoking afterApplicationStart: io.syndesis.integration.runtime.logging.IntegrationLoggingAutoConfiguration$1@62dae540 2018-05-02 08:07:31.398  INFO 1 --- [           main] b.c.e.u.UndertowEmbeddedServletContainer : Undertow started on port(s) 8080 (http) 2018-05-02 08:07:31.404  INFO 1 --- [           main] io.syndesis.example.Application          : Started Application in 16.215 seconds (JVM running for 19.034) {"exchange":"i-LBUt5QMF_AdqWHq8ArEz","status":"begin"} {"exchange":"i-LBUt5QMF_AdqWHq8ArEz","status":"begin"} {"exchange":"i-LBUt5QMF_AdqWHq8ArEz","status":"begin"} {"exchange":"i-LBUt5QMF_AdqWHq8ArEz","status":"begin"} {"exchange":"i-LBUt5QMF_AdqWHq8ArEz","step":"-LBUoJgJqHvZKe2iX3I2","id":"i-LBUt5TIF_AdqWHq8ArGz","message":"Twitter Message: @syndesis_d_test Gruesse aus Pegnitz !"} 2018-05-02 08:07:32.500  INFO 1 --- [line://MENTIONS] -LBUnwF1qHvZKe2iX3I0                     : Twitter Message: @syndesis_d_test Gruesse aus Pegnitz ! 2018-05-02 08:07:32.602  WARN 1 --- [line://MENTIONS] i.a.core.DefaultAtlasConversionService   : Converter between java.util.Date and java.time.ZonedDateTime aleady exists. 2018-05-02 08:07:32.609  WARN 1 --- [line://MENTIONS] i.a.core.DefaultAtlasConversionService   : Converter between java.time.LocalDate and java.time.ZonedDateTime aleady exists. 2018-05-02 08:07:32.610  WARN 1 --- [line://MENTIONS] i.a.core.DefaultAtlasConversionService   : Converter between java.time.LocalDateTime and java.time.ZonedDateTime aleady exists. 2018-05-02 08:07:32.611  WARN 1 --- [line://MENTIONS] i.a.core.DefaultAtlasConversionService   : Converter between java.time.LocalTime and java.time.ZonedDateTime aleady exists. {"exchange":"i-LBUt5QMF_AdqWHq8ArEz","step":"-LBUnxbiqHvZKe2iX3I0","id":"i-LBUt5fCF_AdqWHq8ArIz","duration":427541142} {"exchange":"i-LBUt5QMF_AdqWHq8ArEz","status":"done","failed":false} {"exchange":"i-LBUt5QMF_AdqWHq8ArEz","status":"done","failed":false} {"exchange":"i-LBUt5QMF_AdqWHq8ArEz","status":"done","failed":false} {"exchange":"i-LBUt5QMF_AdqWHq8ArEz","status":"done","failed":false} {"exchange":"i-LBUt5lvF_AdqWHq8ArJz","status":"begin"} {"exchange":"i-LBUt5lvF_AdqWHq8ArJz","status":"begin"} {"exchange":"i-LBUt5lvF_AdqWHq8ArJz","status":"begin"} {"exchange":"i-LBUt5lvF_AdqWHq8ArJz","status":"begin"} {"exchange":"i-LBUt5lvF_AdqWHq8ArJz","step":"-LBUoJgJqHvZKe2iX3I2","id":"i-LBUt5lxF_AdqWHq8ArLz","message":"Twitter Message: @syndesis_d_test Gruesse aus Pegnitz !"} 2018-05-02 08:07:33.757  INFO 1 --- [line://MENTIONS] -LBUnwF1qHvZKe2iX3I0                     : Twitter Message: @syndesis_d_test Gruesse aus Pegnitz ! {"exchange":"i-LBUt5lvF_AdqWHq8ArJz","step":"-LBUnxbiqHvZKe2iX3I0","id":"i-LBUt5m-F_AdqWHq8ArNz","duration":75949534} {"exchange":"i-LBUt5lvF_AdqWHq8ArJz","status":"done","failed":false} {"exchange":"i-LBUt5lvF_AdqWHq8ArJz","status":"done","failed":false} {"exchange":"i-LBUt5lvF_AdqWHq8ArJz","status":"done","failed":false} {"exchange":"i-LBUt5lvF_AdqWHq8ArJz","status":"done","failed":false} {"exchange":"i-LBUt5nBF_AdqWHq8ArOz","status":"begin"} {"exchange":"i-LBUt5nBF_AdqWHq8ArOz","status":"begin"} {"exchange":"i-LBUt5nBF_AdqWHq8ArOz","status":"begin"} {"exchange":"i-LBUt5nBF_AdqWHq8ArOz","status":"begin"} {"exchange":"i-LBUt5nBF_AdqWHq8ArOz","step":"-LBUoJgJqHvZKe2iX3I2","id":"i-LBUt5nDF_AdqWHq8ArQz","message":"Twitter Message: @syndesis_d_test How are you ? 'hope Sprint 16 worked well .."} 2018-05-02 08:07:33.838  INFO 1 --- [line://MENTIONS] -LBUnwF1qHvZKe2iX3I0                     : Twitter Message: @syndesis_d_test How are you ? 'hope Sprint 16 worked well .. {"exchange":"i-LBUt5nBF_AdqWHq8ArOz","step":"-LBUnxbiqHvZKe2iX3I0","id":"i-LBUt5nGF_AdqWHq8ArSz","duration":111573904} {"exchange":"i-LBUt5nBF_AdqWHq8ArOz","status":"done","failed":false} {"exchange":"i-LBUt5nBF_AdqWHq8ArOz","status":"done","failed":false} {"exchange":"i-LBUt5nBF_AdqWHq8ArOz","status":"done","failed":false} {"exchange":"i-LBUt5nBF_AdqWHq8ArOz","status":"done","failed":false} {"exchange":"i-LBUt5p0F_AdqWHq8ArTz","status":"begin"} {"exchange":"i-LBUt5p0F_AdqWHq8ArTz","status":"begin"} {"exchange":"i-LBUt5p0F_AdqWHq8ArTz","status":"begin"} {"exchange":"i-LBUt5p0F_AdqWHq8ArTz","status":"begin"} {"exchange":"i-LBUt5p0F_AdqWHq8ArTz","step":"-LBUoJgJqHvZKe2iX3I2","id":"i-LBUt5p2F_AdqWHq8ArVz","message":"Twitter Message: @syndesis_d_test Looking forward to Sprint 17"} 2018-05-02 08:07:33.955  INFO 1 --- [line://MENTIONS] -LBUnwF1qHvZKe2iX3I0                     : Twitter Message: @syndesis_d_test Looking forward to Sprint 17 {"exchange":"i-LBUt5p0F_AdqWHq8ArTz","step":"-LBUnxbiqHvZKe2iX3I0","id":"i-LBUt5p5F_AdqWHq8ArXz","duration":106703522} {"exchange":"i-LBUt5p0F_AdqWHq8ArTz","status":"done","failed":false} {"exchange":"i-LBUt5p0F_AdqWHq8ArTz","status":"done","failed":false} {"exchange":"i-LBUt5p0F_AdqWHq8ArTz","status":"done","failed":false} {"exchange":"i-LBUt5p0F_AdqWHq8ArTz","status":"done","failed":false} {"exchange":"i-LBUt5qlF_AdqWHq8ArYz","status":"begin"} {"exchange":"i-LBUt5qlF_AdqWHq8ArYz","status":"begin"} {"exchange":"i-LBUt5qlF_AdqWHq8ArYz","status":"begin"} {"exchange":"i-LBUt5qlF_AdqWHq8ArYz","status":"begin"} {"exchange":"i-LBUt5qlF_AdqWHq8ArYz","step":"-LBUoJgJqHvZKe2iX3I2","id":"i-LBUt5r5F_AdqWHq8Ar_z","message":"Twitter Message: @syndesis_d_test Sprint 16 is over now"} 2018-05-02 08:07:34.086  INFO 1 --- [line://MENTIONS] -LBUnwF1qHvZKe2iX3I0                     : Twitter Message: @syndesis_d_test Sprint 16 is over now {"exchange":"i-LBUt5qlF_AdqWHq8ArYz","step":"-LBUnxbiqHvZKe2iX3I0","id":"i-LBUt5r7F_AdqWHq8Arbz","duration":68154196} {"exchange":"i-LBUt5qlF_AdqWHq8ArYz","status":"done","failed":false} {"exchange":"i-LBUt5qlF_AdqWHq8ArYz","status":"done","failed":false} {"exchange":"i-LBUt5qlF_AdqWHq8ArYz","status":"done","failed":false} {"exchange":"i-LBUt5qlF_AdqWHq8ArYz","status":"done","failed":false} {"exchange":"i-LBUt5sBF_AdqWHq8Arcz","status":"begin"} {"exchange":"i-LBUt5sBF_AdqWHq8Arcz","status":"begin"} {"exchange":"i-LBUt5sBF_AdqWHq8Arcz","status":"begin"} {"exchange":"i-LBUt5sBF_AdqWHq8Arcz","status":"begin"} {"exchange":"i-LBUt5sBF_AdqWHq8Arcz","step":"-LBUoJgJqHvZKe2iX3I2","id":"i-LBUt5seF_AdqWHq8Arez","message":"Twitter Message: @syndesis_d_test Hi Roland!"} 2018-05-02 08:07:34.186  INFO 1 --- [line://MENTIONS] -LBUnwF1qHvZKe2iX3I0                     : Twitter Message: @syndesis_d_test Hi Roland! {"exchange":"i-LBUt5sBF_AdqWHq8Arcz","step":"-LBUnxbiqHvZKe2iX3I0","id":"i-LBUt5sgF_AdqWHq8Argz","duration":65627977} {"exchange":"i-LBUt5sBF_AdqWHq8Arcz","status":"done","failed":false} {"exchange":"i-LBUt5sBF_AdqWHq8Arcz","status":"done","failed":false} {"exchange":"i-LBUt5sBF_AdqWHq8Arcz","status":"done","failed":false} {"exchange":"i-LBUt5sBF_AdqWHq8Arcz","status":"done","failed":false} {"exchange":"i-LBUt5tiF_AdqWHq8Arhz","status":"begin"} {"exchange":"i-LBUt5tiF_AdqWHq8Arhz","status":"begin"} {"exchange":"i-LBUt5tiF_AdqWHq8Arhz","status":"begin"} {"exchange":"i-LBUt5tiF_AdqWHq8Arhz","status":"begin"} {"exchange":"i-LBUt5tiF_AdqWHq8Arhz","step":"-LBUoJgJqHvZKe2iX3I2","id":"i-LBUt5uCF_AdqWHq8Arjz","message":"Twitter Message: @syndesis_d_test Awesome demo!"} 2018-05-02 08:07:34.285  INFO 1 --- [line://MENTIONS] -LBUnwF1qHvZKe2iX3I0                     : Twitter Message: @syndesis_d_test Awesome demo! {"exchange":"i-LBUt5tiF_AdqWHq8Arhz","step":"-LBUnxbiqHvZKe2iX3I0","id":"i-LBUt5uEF_AdqWHq8Arlz","duration":69377367} {"exchange":"i-LBUt5tiF_AdqWHq8Arhz","status":"done","failed":false} {"exchange":"i-LBUt5tiF_AdqWHq8Arhz","status":"done","failed":false} {"exchange":"i-LBUt5tiF_AdqWHq8Arhz","status":"done","failed":false} {"exchange":"i-LBUt5tiF_AdqWHq8Arhz","status":"done","failed":false} {"exchange":"i-LBUt5vKF_AdqWHq8Armz","status":"begin"} {"exchange":"i-LBUt5vKF_AdqWHq8Armz","status":"begin"} {"exchange":"i-LBUt5vKF_AdqWHq8Armz","status":"begin"} {"exchange":"i-LBUt5vKF_AdqWHq8Armz","status":"begin"} {"exchange":"i-LBUt5vKF_AdqWHq8Armz","step":"-LBUoJgJqHvZKe2iX3I2","id":"i-LBUt5vlF_AdqWHq8Aroz","message":"Twitter Message: @syndesis_d_test Hello ! Touch down ?"} 2018-05-02 08:07:34.385  INFO 1 --- [line://MENTIONS] -LBUnwF1qHvZKe2iX3I0                     : Twitter Message: @syndesis_d_test Hello ! Touch down ? {"exchange":"i-LBUt5vKF_AdqWHq8Armz","step":"-LBUnxbiqHvZKe2iX3I0","id":"i-LBUt5vnF_AdqWHq8Arqz","duration":72663950} {"exchange":"i-LBUt5vKF_AdqWHq8Armz","status":"done","failed":false} {"exchange":"i-LBUt5vKF_AdqWHq8Armz","status":"done","failed":false} {"exchange":"i-LBUt5vKF_AdqWHq8Armz","status":"done","failed":false} {"exchange":"i-LBUt5vKF_AdqWHq8Armz","status":"done","failed":false} {"exchange":"i-LBUt5xKF_AdqWHq8Arrz","status":"begin"} {"exchange":"i-LBUt5xKF_AdqWHq8Arrz","status":"begin"} {"exchange":"i-LBUt5xKF_AdqWHq8Arrz","status":"begin"} {"exchange":"i-LBUt5xKF_AdqWHq8Arrz","status":"begin"} {"exchange":"i-LBUt5xKF_AdqWHq8Arrz","step":"-LBUoJgJqHvZKe2iX3I2","id":"i-LBUt5xLF_AdqWHq8Artz","message":"Twitter Message: @syndesis_d_test TP2 is coming !"} 2018-05-02 08:07:34.486  INFO 1 --- [line://MENTIONS] -LBUnwF1qHvZKe2iX3I0                     : Twitter Message: @syndesis_d_test TP2 is coming ! {"exchange":"i-LBUt5xKF_AdqWHq8Arrz","step":"-LBUnxbiqHvZKe2iX3I0","id":"i-LBUt5xNF_AdqWHq8Arvz","duration":75938998} {"exchange":"i-LBUt5xKF_AdqWHq8Arrz","status":"done","failed":false} {"exchange":"i-LBUt5xKF_AdqWHq8Arrz","status":"done","failed":false} {"exchange":"i-LBUt5xKF_AdqWHq8Arrz","status":"done","failed":false} {"exchange":"i-LBUt5xKF_AdqWHq8Arrz","status":"done","failed":false} {"exchange":"i-LBUt5ytF_AdqWHq8Arwz","status":"begin"} {"exchange":"i-LBUt5ytF_AdqWHq8Arwz","status":"begin"} {"exchange":"i-LBUt5ytF_AdqWHq8Arwz","status":"begin"} {"exchange":"i-LBUt5ytF_AdqWHq8Arwz","status":"begin"} {"exchange":"i-LBUt5ytF_AdqWHq8Arwz","step":"-LBUoJgJqHvZKe2iX3I2","id":"i-LBUt5yuF_AdqWHq8Aryz","message":"Twitter Message: @syndesis_d_test It's getting cold these days ..."} 2018-05-02 08:07:34.586  INFO 1 --- [line://MENTIONS] -LBUnwF1qHvZKe2iX3I0                     : Twitter Message: @syndesis_d_test It's getting cold these days ... {"exchange":"i-LBUt5ytF_AdqWHq8Arwz","step":"-LBUnxbiqHvZKe2iX3I0","id":"i-LBUt5ywF_AdqWHq8As-z","duration":74478666} {"exchange":"i-LBUt5ytF_AdqWHq8Arwz","status":"done","failed":false} {"exchange":"i-LBUt5ytF_AdqWHq8Arwz","status":"done","failed":false} {"exchange":"i-LBUt5ytF_AdqWHq8Arwz","status":"done","failed":false} {"exchange":"i-LBUt5ytF_AdqWHq8Arwz","status":"done","failed":false} {"exchange":"i-LBUt6-SF_AdqWHq8As0z","status":"begin"} {"exchange":"i-LBUt6-SF_AdqWHq8As0z","status":"begin"} {"exchange":"i-LBUt6-SF_AdqWHq8As0z","status":"begin"} {"exchange":"i-LBUt6-SF_AdqWHq8As0z","status":"begin"} {"exchange":"i-LBUt6-SF_AdqWHq8As0z","step":"-LBUoJgJqHvZKe2iX3I2","id":"i-LBUt6-TF_AdqWHq8As2z","message":"Twitter Message: @syndesis_d_test It's getting cold these days ..."} 2018-05-02 08:07:34.686  INFO 1 --- [line://MENTIONS] -LBUnwF1qHvZKe2iX3I0                     : Twitter Message: @syndesis_d_test It's getting cold these days ... {"exchange":"i-LBUt6-SF_AdqWHq8As0z","step":"-LBUnxbiqHvZKe2iX3I0","id":"i-LBUt6-WF_AdqWHq8As4z","duration":72682634} {"exchange":"i-LBUt6-SF_AdqWHq8As0z","status":"done","failed":false} {"exchange":"i-LBUt6-SF_AdqWHq8As0z","status":"done","failed":false} {"exchange":"i-LBUt6-SF_AdqWHq8As0z","status":"done","failed":false} {"exchange":"i-LBUt6-SF_AdqWHq8As0z","status":"done","failed":false} {"exchange":"i-LBUt610F_AdqWHq8As5z","status":"begin"} {"exchange":"i-LBUt610F_AdqWHq8As5z","status":"begin"} {"exchange":"i-LBUt610F_AdqWHq8As5z","status":"begin"} {"exchange":"i-LBUt610F_AdqWHq8As5z","status":"begin"} {"exchange":"i-LBUt610F_AdqWHq8As5z","step":"-LBUoJgJqHvZKe2iX3I2","id":"i-LBUt611F_AdqWHq8As7z","message":"Twitter Message: @syndesis_d_test no matter how great and destructive your problems may seem now, remember, you've probably only seen the tip of them."} 2018-05-02 08:07:34.786  INFO 1 --- [line://MENTIONS] -LBUnwF1qHvZKe2iX3I0                     : Twitter Message: @syndesis_d_test no matter how great and destructive your problems may seem now, remember, you've probably only seen the tip of them. {"exchange":"i-LBUt610F_AdqWHq8As5z","step":"-LBUnxbiqHvZKe2iX3I0","id":"i-LBUt613F_AdqWHq8As9z","duration":75799708} {"exchange":"i-LBUt610F_AdqWHq8As5z","status":"done","failed":false} {"exchange":"i-LBUt610F_AdqWHq8As5z","status":"done","failed":false} {"exchange":"i-LBUt610F_AdqWHq8As5z","status":"done","failed":false} {"exchange":"i-LBUt610F_AdqWHq8As5z","status":"done","failed":false} ```   &lt;/details&gt;  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; The activity screen should show the log step and other information </body>
		<created>2018-05-02 08:18:05</created>
		<closed>2018-05-02 13:13:15</closed>
	</bug>
	<bug>
		<id>2509</id>
		<title>Slack connection can not be mapped</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  Using a Slack connection currently is not possible at it declares a `java.lang.String` as inputDataShape, but the mapper cannot deal with this yet (see atlasmap/atlasmap#9)  So we have to either  (a) remove the Slack connector from the list of connectors, or (b) fix this by introducing a Wrapper object as data input shape (with a single String property "message")  @igarashitm fancy to try this (similar to the SalesforceIdentifiere conversion in the salesforce connector in https://github.com/syndesisio/syndesis/blob/master/app/connector/salesforce/src/main/resources/META-INF/syndesis/connector/salesforce.json#L220 ?)</body>
		<created>2018-04-30 13:16:25</created>
		<closed>2018-04-30 16:36:59</closed>
	</bug>
	<bug>
		<id>2501</id>
		<title>Import/Export: Existing Integration Notification</title>
		<body>## This is a... &lt;pre&gt;&lt;code&gt; [ ] Feature request [ x ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem It used to be that importing an integration, whether it already existed or not would result in basic details of that integration appearing in the "Import Results" section. It appears that a change has been made, such that the integration details only appear in the API response of an import if it's a newly created/imported integration, but no details are returned if it already exists.  ## Expected behavior The API response should be the same data structure regardless of whether the integration was created or not. The ID is used to retrieve the integration details on import, so it is possible that the ID for an existing integration no longer falls under the same data structure. Will need to investigate further.  ## Screenshot  The following illustrates an integration that already exists and has been imported:  &lt;img width="1680" alt="screenshot 2018-04-27 11 55 46" src="https://user-images.githubusercontent.com/3844502/39372287-f1dba164-4a11-11e8-841a-2fb40f8382c7.png"&gt;  When I delete it and re-import it, I get the following:  &lt;img width="1676" alt="screenshot 2018-04-27 11 56 46" src="https://user-images.githubusercontent.com/3844502/39372346-131ab784-4a12-11e8-9bab-6c05c433bc40.png"&gt;   ## Request and Response Data May or may not be relevant; will be investigating further and adding details here.  ## API Endpoints and Schemas `POST` to `/api/v1/integrations`  ## Tasks involved / Steps to Reproduce 1. Import an integration that does not exist. 2. Import works as expected. 3. Attempt to import again, no details appear for it. This is the unexpected behavior. 4. Delete the integration. 5. Import again. 6. Import works as expected. </body>
		<created>2018-04-27 15:59:23</created>
		<closed>2019-02-05 17:29:09</closed>
	</bug>
	<bug>
		<id>2500</id>
		<title>Wrong time format in metrics view</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ![image](https://user-images.githubusercontent.com/99080/39368012-c19aa44c-4a38-11e8-891e-9884b3b6b9ae.png)  Should be "16:32" or "4:32 pm" ....</body>
		<created>2018-04-27 14:34:13</created>
		<closed>2018-10-24 12:36:50</closed>
	</bug>
	<bug>
		<id>2499</id>
		<title>[Upgrade] After performing a rollback, upgraded (and rolled back) deployments don't start</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  I'm performing the rollback in upgrade_50_replace_template, where I'm appending `exit 1` after `update_version $tag` in `replace_template::run()`.  After everything is rolled back, the deployments are scaled back to 1, but only those, that are not affected by upgrade (prometheus, oauthproxy, db [i'm not doing db migration for now]) are started back.  This is how it looks like after rollback:  ![uz3h](https://user-images.githubusercontent.com/7081216/39362867-492daf14-4a28-11e8-89b6-63815367170c.png)  The completed deployments in my case can't be scaled up - when I scale them via oc or via web, it goes back to 0 after few seconds.  cc @rhuss @paoloantinori @dsimansk   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-04-27 12:38:17</created>
		<closed>2018-05-02 22:14:09</closed>
	</bug>
	<bug>
		<id>2494</id>
		<title>Dynamic forms show hidden secret property</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; If a property is `type: hidden` and `secret: true` it will be shown in the UI.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; We should not show any hidden properties. </body>
		<created>2018-04-27 12:03:29</created>
		<closed>2018-04-30 08:33:03</closed>
	</bug>
	<bug>
		<id>2489</id>
		<title>Integration data buckets are not working</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Integration with with more data buckets does not work and throws error:  ``` 2018-04-27 09:24:44.615  WARN 1 --- [r://integration] o.a.camel.component.timer.TimerConsumer  : Error processing exchange. Exchange[i-LB5PoTP8--C4zmSirFYz]. Caused by: [io.atlasmap.api.AtlasException - Errors: [Source document '-LB5Ox45jJWJ_mHtrd3E' doesn't exist: docId='-LB5Ox45jJWJ_mHtrd3E', path='/first_name'], ]  io.atlasmap.api.AtlasException: Errors: [Source document '-LB5Ox45jJWJ_mHtrd3E' doesn't exist: docId='-LB5Ox45jJWJ_mHtrd3E', path='/first_name'],  at org.apache.camel.component.atlasmap.AtlasEndpoint.onExchange(AtlasEndpoint.java:213) ~[camel-atlasmap-1.34.2.jar!/:na] at org.apache.camel.impl.ProcessorEndpoint$1.process(ProcessorEndpoint.java:71) ~[camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) ~[camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) ~[camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ~[camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) ~[camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) ~[camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) ~[camel-core-2.21.0.jar!/:2.21.0] at io.syndesis.integration.runtime.logging.ActivityTrackingInterceptStrategy$EventProcessor.process(ActivityTrackingInterceptStrategy.java:77) ~[integration-runtime-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) ~[camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ~[camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) ~[camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) ~[camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ~[camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.processor.MulticastProcessor.doProcessSequential(MulticastProcessor.java:711) ~[camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.processor.MulticastProcessor.doProcessSequential(MulticastProcessor.java:634) ~[camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.processor.MulticastProcessor.process(MulticastProcessor.java:248) ~[camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.processor.Splitter.process(Splitter.java:114) ~[camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) ~[camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ~[camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) ~[camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) ~[camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197) [camel-core-2.21.0.jar!/:2.21.0] at org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79) [camel-core-2.21.0.jar!/:2.21.0] at java.util.TimerThread.mainLoop(Timer.java:555) [na:1.8.0_151] at java.util.TimerThread.run(Timer.java:505) [na:1.8.0_151]  ```  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Integration should work as expected, all previous data buckets should be available and functional from each data mapper step.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create integration as follows:  start:    PostgreDB (periodicSQL): _select * from contact limit 1_             PostgreDB (invokeSQL) : _select * from contact limit 1_             Data Mapper: map field company **from the first** data bucket to COMPANY finish:   PostgreDB: _select * from contact where company = :#COMPANY_  2. Publish the integration. Check openshift logs for this integration pod, there you can see mentioned error. </body>
		<created>2018-04-27 09:43:04</created>
		<closed>2018-04-30 07:08:59</closed>
	</bug>
	<bug>
		<id>2487</id>
		<title>Monitoring - Activity: intermittently missing step</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Sometimes the activities listing is missing step, but it's logged properly in the integration. The fail rate is around 1/5 for periodic integration.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot ![screen shot 2018-04-27 at 08 57 23](https://user-images.githubusercontent.com/5637792/39353823-2283bbac-4a09-11e8-8606-68fbe86a6eb9.png)  ![screen shot 2018-04-27 at 08 57 09](https://user-images.githubusercontent.com/5637792/39353825-229d5134-4a09-11e8-91fc-c6b66dca06e8.png)   ## Request and Response Data  https://gist.github.com/dsimansk/c9b56466113f4d30b294a1f21989114c  ``` {     "id": "i-LB4yU5pYtNTanACihbwz",     "logts": "2018-04-27T07:20:56.502385645Z",     "at": 1524813656501,     "pod": "i-www-2-t5lb4",     "ver": "1",     "status": "done",     "failed": false,     "steps": [       {         "id": "-LB4kmy-98xgmeFboo4R",         "at": 1524813656504,         "duration": 1057626       }     ]   } ```  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create simple DB -&gt; Datamapper -&gt; DB 2. Wath incoming Activity for missing steps </body>
		<created>2018-04-27 08:58:31</created>
		<closed>2018-07-27 15:22:42</closed>
	</bug>
	<bug>
		<id>2485</id>
		<title>Help icon URL for GA user guide is wrong and doc link from Settings page is wrong</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem In the staging site, when I click the Help icon and then click User Guide, there are two problems with the link target:  - The URL should point to the beginning of the user guide and instead it points to the section about registering applications that use OAuth.  - The help icon URL is also wrong because it points to the TP version of the doc when it should point to the GA version of the doc.  ## Expected behavior When you select the help icon and then click "User Guide" the target URL should be: https://access.redhat.com/documentation/en-us/red_hat_fuse/7.0/html-single/integrating_applications_with_ignite  In the Settings page, where it says "See the documentation for help." the link from "documentation" should be: https://access.redhat.com/documentation/en-us/red_hat_fuse/7.0/html-single/integrating_applications_with_ignite/#obtaining-authorization-to-access-applications  The dictionary file at app/ui/src/assets/dictionary/en-GB.json incorrectly defines **links.userguide** as   //access.redhat.com/documentation/en-us/red_hat_jboss_fuse/7.0-tp/html-single/integrating_applications_with_ignite/#obtaining-authorization-to-access-applications"  This is wrong because it points to a specific section when it should point to the beginning of the guide. This is also wrong because it points to the **7.0-tp** version when it should just point to the **7.0** version.   Later in the dictionary, under **settings.oauth-apps.documentation-link**, that link is defined as "**links.userguide**".  This is wrong. The Settings page should have its own URL because it goes to a specific section of the user guide.   </body>
		<created>2018-04-26 20:28:04</created>
		<closed>2018-05-08 19:23:32</closed>
	</bug>
	<bug>
		<id>2482</id>
		<title>On MySQL - Table name pattern can not be NULL or empty</title>
		<body>[ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request   ## The problem when I'm trying to create integration with MySQL DB connection (Validation = OK) during start action if I refer to existing table, there is a warning: "Table name pattern can not be NULL or empty.. Unable to fetch and process metadata" With Postgres DB it is ok.  ## Expected behavior No warning.  ## Screenshot ![mysql_console](https://user-images.githubusercontent.com/2714974/39317425-d91ef61c-497b-11e8-9539-2e61dd8e7f60.png)  meta pod log: file:///home/sveres/Documents/18_SYNDESIO/0_ISSUES/DB_mysql/meta.log  ## Request and Response Data Request URL: https://syndesis-project-r.192.168.99.100.nip.io/api/v1/connections/i-LB12Pg6skxtetMNA40Fz/actions/sql-start-connector Request Method: POST Status Code: 400 Bad Request Request Payload:  ``` {query: "SELECT * FROM CONTACT", schedulerExpression: "60000"} ``` Response: ``` {   "componentScheme": "sql",   "connectorCustomizers": [     "io.syndesis.connector.sql.customizer.SqlStartConnectorCustomizer"   ],   "inputDataShape": {     "kind": "none"   },   "outputDataShape": {     "kind": "any"   },   "propertyDefinitionSteps": [     {       "description": "Enter a SQL statement that starts with SELECT.",       "name": "SQL statement",       "properties": {         "query": {           "deprecated": false,           "labelHint": "SQL SELECT statement to be executed.",           "displayName": "SQL statement",           "group": "common",           "javaType": "java.lang.String",           "kind": "path",           "required": true,           "secret": false,           "type": "string"         },         "schedulerExpression": {           "defaultValue": "60000",           "deprecated": false,           "labelHint": "Delay between scheduling (executing).",           "displayName": "Period",           "group": "consumer",           "javaType": "long",           "kind": "parameter",           "required": false,           "secret": false,           "type": "duration"         }       }     }   ],   "split": {},   "_meta": {     "message": "Table name pattern can not be NULL or empty.. Unable to fetch and process metadata",     "type": "DANGER"   } } ```  ## Tasks involved / Steps to Reproduce 1. In OpenShift create MySQL DB. 2. In the database create some DB tables. 3. In Syndesis create relevant MySQL connection. 4.  In Syndesis try to create integration using MySQL connection.  </body>
		<created>2018-04-26 16:13:46</created>
		<closed>2018-04-27 09:51:58</closed>
	</bug>
	<bug>
		<id>2480</id>
		<title>Space out items in integration activity rows</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem re: https://github.com/syndesisio/syndesis/issues/1597#issuecomment-375700097  &gt; is there any way to move the version number to the left a bit so that all the elements in the main row are about equidistant apart?  Also, the divider after the open shift log link isn't spaced well.  ## Expected behavior row items should be spaced more evenly. divider after open shift log link should be spaced evenly.  ## Screenshot ![screen shot 2018-04-26 at 9 44 02 am](https://user-images.githubusercontent.com/35148959/39314781-aba9a876-493a-11e8-9491-1e52ca14ac1a.png)  ## Tasks involved / Steps to Reproduce 1. Go to integrations 1. Click on an integration to see details 1. Click on activity tab</body>
		<created>2018-04-26 15:16:33</created>
		<closed>2018-04-30 13:09:47</closed>
	</bug>
	<bug>
		<id>2476</id>
		<title>MQTT connector - should DataShape.kind be `any`?</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem MQTT connector specifies `java.lang.String` as a `DataShape.type` with `DataShape.kind=java` https://github.com/syndesisio/syndesis/blob/5e0192eb898232b487d767a04d1a59459ae2be94/app/connector/mqtt/src/main/resources/META-INF/syndesis/connector/mqtt.json#L86 https://github.com/syndesisio/syndesis/blob/5e0192eb898232b487d767a04d1a59459ae2be94/app/connector/mqtt/src/main/resources/META-INF/syndesis/connector/mqtt.json#L126  This causes an error with datamapper step as primitive types are not supported as a Document root (atlasmap/atlasmap#9).  ## Expected behavior Not sure, do we really want a plain single text as a DataShape for MQTT (which requires atlasmap/atlasmap#9 to be implemented ahead)? or want to have `DataShape.kind=any` so user can specify custom schema for JSON/XML via "Describe Data Type" scenario?  </body>
		<created>2018-04-26 14:08:16</created>
		<closed>2018-04-27 11:54:45</closed>
	</bug>
	<bug>
		<id>2465</id>
		<title>an openshift user with no access to the syndesis namespace can, too, login to syndesis</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  With syndesis 1.3.5-20180424  a user that does not have any access to the namespace of the syndesis application can login to syndesis and do anything there.  deployed on OCP v3.9.14 via   oc create -f install/support/serviceaccount-as-oauthclient-restricted.yml oc create -f install/syndesis.yml oc new-app --template=syndesis \     -p ROUTE_HOSTNAME=ignite.apps.perf2.xpaas \     -p OPENSHIFT_MASTER=$(oc whoami --show-server) \     -p OPENSHIFT_PROJECT=$(oc project -q) \     -p OPENSHIFT_OAUTH_CLIENT_SECRET=$(oc sa get-token syndesis-oauth-client)    ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  User with no access to the syndesis namespace should not be able to view any syndesis state or do any modifications.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create several users on OpenShift 2. Create a project and deploy syndesis  3. Verify the other users don't have access to the namespace of the syndesis application  (oc login , oc get projects) 3. Try to access the project on a clean browser profile, login as a different openshift user 4. Notice the user that does not have access to the syndesis namespace can still use syndesis and access all its integrations. </body>
		<created>2018-04-24 15:57:06</created>
		<closed>2018-04-25 10:33:18</closed>
	</bug>
	<bug>
		<id>2463</id>
		<title>Unable to download system diagnostics if there is no integration present</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Downloading diagnostics for all integrations from support page works only if you have at least one integration, otherwise downloaded zip is empty.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; There used to be some diagnostic files even if you had no integration in the system. I am sure that there are logs which are not connected to integrations and are shared amongst all of them so you should be able to get them even without having an integration.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Navigate to support page 2. Download diagnostics for all integrations 3. Note that zip has no entries if you have no integration </body>
		<created>2018-04-24 12:46:25</created>
		<closed>2018-04-24 16:15:00</closed>
	</bug>
	<bug>
		<id>2454</id>
		<title>extensions: dependencies with system scope are not included in step/connector extensions jar</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  If a step/connector extension needs a local library (system scope), then the dependency is not included in the generated extension jar.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  System lib should be included in extension jar regardless of the extension type.   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create an step extension with system libs 2. Generate the extension jar 3. check the content of the generated jar </body>
		<created>2018-04-20 15:06:55</created>
		<closed>2019-02-05 17:29:10</closed>
	</bug>
	<bug>
		<id>2447</id>
		<title>Error with upgrade procedure</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When running the upgrade procedure for the second time, the process fails leaving the system in an unconsistent state  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. `cd tools/upgrade  &amp;&amp; bash upgrade.sh --backup /tmp/backup --migration $(realpath migration) --template ../../install/syndesis.yml` 2.`cd tools/upgrade  &amp;&amp; bash upgrade.sh --backup /tmp/backup --migration $(realpath migration) --template ../../install/syndesis.yml` 3. 4.   ##### Logs:  &lt;details&gt;   &lt;summary&gt;&lt;b&gt;Click to expand&lt;/b&gt;&lt;/summary&gt; &lt;pre&gt;&lt;code&gt;  /data/repositories/work/syndesis/syndesis/tools/upgrade [upgrade_db L| 10]  16:47 $ bash upgrade.sh --backup /tmp/backup --migration $(realpath migration) --template ../../install/syndesis.yml ### ----------------------------------------- ### PREFLIGHT CHECK ### Upgrade from latest (latest) --&gt; latest ### ### --&gt; OK ### -----------------------------------------  ============================================= === STARTING UPGRADE TO SYNDESIS latest  =============================================  === * Stopping syndesis-server (prep_10_stop) deploymentconfig "syndesis-server" scaled deploymentconfig "syndesis-meta" scaled Waiting for syndesis-server to be scaled to 0 Waiting for syndesis-meta to be scaled to 0 NAME                          READY     STATUS        RESTARTS   AGE syndesis-db-2-phdxf           1/1       Running       0          1m syndesis-meta-2-v6s2r         1/1       Terminating   0          2m syndesis-oauthproxy-2-l94rw   1/1       Running       0          2m syndesis-prometheus-2-jvhrg   1/1       Running       0          2m syndesis-server-2-d5f6h       1/1       Terminating   0          2m syndesis-ui-2-dmxhw           1/1       Running       0          2m todo-2-lqkd8                  1/1       Running       0          1m syndesis-server-2-d5f6h   0/1       Terminating   0         2m === * Backup database (prep_20_backup_db) === * Backup Resource objects (prep_30_backup_resources)       - ConfigMap         * syndesis-meta-config         * syndesis-prometheus-config         * syndesis-sampledb-config         * syndesis-server-config         * syndesis-ui-config       - Secret         * syndesis-global-config         * syndesis-oauth-proxy-cookie-secret         * syndesis-server-secret       - DeploymentConfig         * syndesis-db         * syndesis-meta         * syndesis-oauthproxy         * syndesis-prometheus         * syndesis-server         * syndesis-ui       - Service         * syndesis-db         * syndesis-meta         * syndesis-oauthproxy         * syndesis-prometheus         * syndesis-server         * syndesis-ui       - Route         * syndesis       - RoleBinding         * syndesis:editors         * syndesis:viewers       - ServiceAccount         * syndesis-integration         * syndesis-prometheus         * syndesis-server       - Template         * syndesis         * syndesis-dev         * syndesis-upgrade       - PersistentVolumeClaim         * syndesis-meta         * syndesis-prometheus       - BuildConfig === * Process new template to extract update resources (prep_40_process_template)       - Current Syndesis version "latest"       - Not updating syndesis-server-config === * Migrate database (upgrade_10_migrate_db)     - TODO: Call out to syndesis-server and start the migration CLI       there with local miration scripts === * Stop all deployments (upgrade_20_stop_all)       - Stopping deployments syndesis-meta syndesis-oauthproxy syndesis-prometheus syndesis-server syndesis-ui deploymentconfig "syndesis-meta" scaled deploymentconfig "syndesis-oauthproxy" scaled deploymentconfig "syndesis-prometheus" scaled deploymentconfig "syndesis-server" scaled deploymentconfig "syndesis-ui" scaled Waiting for syndesis-meta to be scaled to 0 Waiting for syndesis-oauthproxy to be scaled to 0 NAME                          READY     STATUS        RESTARTS   AGE syndesis-db-2-phdxf           1/1       Running       0          2m syndesis-oauthproxy-2-l94rw   0/1       Terminating   0          2m syndesis-prometheus-2-jvhrg   0/1       Terminating   0          2m syndesis-ui-2-dmxhw           1/1       Terminating   0          2m todo-2-lqkd8                  1/1       Running       0          2m Waiting for syndesis-prometheus to be scaled to 0 Waiting for syndesis-server to be scaled to 0 Waiting for syndesis-ui to be scaled to 0 === * Update resources (upgrade_40_update_resources)       - No dynamic update scripts found for latest in /data/repositories/work/syndesis/syndesis/tools/upgrade/migration/resource       - BuildConfig: update (replace)         * todo       - ConfigMap: skipped       - DeploymentConfig: force update (delete/create)         * syndesis-db         * syndesis-meta         * syndesis-oauthproxy         * syndesis-prometheus         * syndesis-server         * syndesis-ui         * todo       - ImageStream: update (replace)         * oauth-proxy         * prometheus         * syndesis-meta         * syndesis-s2i         * syndesis-server         * syndesis-ui         * todo       - PersistentVolumeClaim: skipped       - RoleBinding: update (replace)         * syndesis:editors         * syndesis:viewers       - Route: force update (delete/create)         * syndesis         * todo       - Secret: skipped       - Service: force update (delete/create)         * syndesis-db         * syndesis-meta         * syndesis-oauthproxy         * syndesis-prometheus         * syndesis-server         * syndesis-ui         * todo       - ServiceAccount: force update (delete/create)         * syndesis-integration         * syndesis-prometheus         * syndesis-server       - Template: update (replace)         * syndesis-upgrade === * Replace template (upgrade_50_replace_template)       * Replacing template 'syndesis' template "syndesis" deleted template "syndesis" replaced       * Updating version to latest secret "syndesis-global-config" not patched ====&gt; Error ==&gt; Rollback   ----- Rollback --- * Rolling back 'Replace template'       * Restoring syndesis from /tmp/backup/2018-04-19-1524149276/backup/resources/Template/syndesis.json template "syndesis" deleted template "syndesis" replaced       * Restoring old version latest secret "syndesis-global-config" not patched ====&gt; Rollback Error ==&gt; Exit Backup directory *not* deleted: /tmp/backup/2018-04-19-1524149276/backup  &lt;/code&gt;&lt;/pre&gt; &lt;/details&gt;</body>
		<created>2018-04-19 14:53:52</created>
		<closed>2018-04-23 09:26:15</closed>
	</bug>
	<bug>
		<id>2444</id>
		<title>No metrics are collected and displayed</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem For a running integration I don't see metrics numbers to be updated periodically as exchanges are flowing through. My suspicion is that `app=syndesis` label is blocking the scraping or any other from https://github.com/syndesisio/syndesis/commit/476d1eac4e0720ce456c8ef0879ca7ddb357a714.  @dhirajsb wdyt?  Prometheus log from TP4 that grows steadily: ``` evel=info ts=2018-04-05T19:03:16.725499527Z caller=main.go:225 msg="Starting Prometheus" version="(version=2.1.0, branch=HEAD, revision=85f23d82a045d103ea7f3c89a91fba4a93e6367a)" --  | level=info ts=2018-04-05T19:03:16.725570503Z caller=main.go:226 build_context="(go=go1.9.2, user=root@6e784304d3ff, date=20180119-12:01:23)"  | level=info ts=2018-04-05T19:03:16.725599655Z caller=main.go:227 host_details="(Linux 3.10.0-693.11.6.el7.x86_64 #1 SMP Thu Dec 28 14:23:39 EST 2017 x86_64 syndesis-prometheus-1-9j2b2 (none))"  | level=info ts=2018-04-05T19:03:16.725614443Z caller=main.go:228 fd_limits="(soft=1048576, hard=1048576)"  | level=info ts=2018-04-05T19:03:16.728775656Z caller=web.go:383 component=web msg="Start listening for connections" address=0.0.0.0:9090  | level=info ts=2018-04-05T19:03:16.728482177Z caller=main.go:499 msg="Starting TSDB ..."  | level=info ts=2018-04-05T19:03:16.737321148Z caller=main.go:509 msg="TSDB started"  | level=info ts=2018-04-05T19:03:16.737362408Z caller=main.go:585 msg="Loading configuration file" filename=/etc/prometheus/prometheus.yml  | level=info ts=2018-04-05T19:03:16.738717738Z caller=kubernetes.go:191 component="discovery manager scrape" discovery=k8s msg="Using pod service account via in-cluster config"  | level=info ts=2018-04-05T19:03:16.739448018Z caller=main.go:486 msg="Server is ready to receive web requests."  | level=info ts=2018-04-05T19:03:16.739487149Z caller=manager.go:59 component="scrape manager" msg="Starting scrape manager..."  | level=info ts=2018-04-05T21:00:04.606894795Z caller=compact.go:387 component=tsdb msg="compact blocks" count=1 mint=1522951200000 maxt=1522958400000  | level=info ts=2018-04-05T21:00:04.633718044Z caller=head.go:348 component=tsdb msg="head GC completed" duration=1.681352ms  | level=info ts=2018-04-05T21:00:04.633768839Z caller=head.go:357 component=tsdb msg="WAL truncation completed" duration=2.066s  | level=info ts=2018-04-05T23:00:04.607313596Z caller=compact.go:387 component=tsdb msg="compact blocks" count=1 mint=1522958400000 maxt=1522965600000  | level=info ts=2018-04-05T23:00:04.637361545Z caller=head.go:348 component=tsdb msg="head GC completed" duration=895.659s  | level=info ts=2018-04-05T23:00:04.6374084Z caller=head.go:357 component=tsdb msg="WAL truncation completed" duration=2.17s  | level=info ts=2018-04-06T01:00:04.60717232Z caller=compact.go:387 component=tsdb msg="compact blocks" count=1 mint=1522965600000 maxt=1522972800000  | level=info ts=2018-04-06T01:00:04.637237103Z caller=head.go:348 component=tsdb msg="head GC completed" duration=884.222s  | level=info ts=2018-04-06T01:00:04.637289182Z caller=head.go:357 component=tsdb msg="WAL truncation completed" duration=2.691s  | level=info ts=2018-04-06T01:00:04.639691404Z caller=compact.go:387 component=tsdb msg="compact blocks" count=3 mint=1522951200000 maxt=1522972800000  | level=info ts=2018-04-06T03:00:04.607060672Z caller=compact.go:387 component=tsdb msg="compact blocks" count=1 mint=1522972800000 maxt=1522980000000  | level=info ts=2018-04-06T03:00:04.639141136Z caller=head.go:348 component=tsdb msg="head GC completed" duration=884.451s  | level=info ts=2018-04-06T03:00:04.639191633Z caller=head.go:357 component=tsdb msg="WAL truncation completed" duration=2.978s ```  Prometheus from current master that is stalled (on same integration): ``` level=info ts=2018-04-19T06:30:49.062743732Z caller=main.go:225 msg="Starting Prometheus" version="(version=2.1.0, branch=HEAD, revision=85f23d82a045d103ea7f3c89a91fba4a93e6367a)" level=info ts=2018-04-19T06:30:49.062819245Z caller=main.go:226 build_context="(go=go1.9.2, user=root@6e784304d3ff, date=20180119-12:01:23)" level=info ts=2018-04-19T06:30:49.062843215Z caller=main.go:227 host_details="(Linux 4.4.41-boot2docker #1 SMP Wed Jan 11 03:05:24 UTC 2017 x86_64 syndesis-prometheus-1-p8x6w (none))" level=info ts=2018-04-19T06:30:49.06287353Z caller=main.go:228 fd_limits="(soft=1048576, hard=1048576)" level=info ts=2018-04-19T06:30:49.102895289Z caller=web.go:383 component=web msg="Start listening for connections" address=0.0.0.0:9090 level=info ts=2018-04-19T06:30:49.102861984Z caller=main.go:499 msg="Starting TSDB ..." level=info ts=2018-04-19T06:30:49.211129501Z caller=main.go:509 msg="TSDB started" level=info ts=2018-04-19T06:30:49.211215373Z caller=main.go:585 msg="Loading configuration file" filename=/etc/prometheus/prometheus.yml level=info ts=2018-04-19T06:30:49.22330559Z caller=kubernetes.go:191 component="discovery manager scrape" discovery=k8s msg="Using pod service account via in-cluster config" level=info ts=2018-04-19T06:30:49.234368418Z caller=main.go:486 msg="Server is ready to receive web requests." level=info ts=2018-04-19T06:30:49.234790986Z caller=manager.go:59 component="scrape manager" msg="Starting scrape manager..." level=info ts=2018-04-19T09:00:04.638008531Z caller=compact.go:387 component=tsdb msg="compact blocks" count=1 mint=1524117600000 maxt=1524124800000 level=info ts=2018-04-19T09:00:04.829312216Z caller=head.go:348 component=tsdb msg="head GC completed" duration=4.862997ms level=info ts=2018-04-19T09:00:04.829396435Z caller=head.go:357 component=tsdb msg="WAL truncation completed" duration=1.966s ```  ## Expected behavior Numbers are increasing per exchange.  </body>
		<created>2018-04-19 10:59:18</created>
		<closed>2018-04-24 10:44:50</closed>
	</bug>
	<bug>
		<id>2443</id>
		<title>Client side state cookies not removed</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Seems that the code to remove client side state cookies is not functioning properly. The cookies are still there after the connection is created. At that point those should be removed. Having them there we end up having really long `Cookie` headers and that ends up with `400 Bad Request: Request Header Or Cookie Too Large` on ngnix.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Remove the client state cookie when it's no longer needed.  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create a OAuth based connection several times, I've counted 9 client side cookies and 18 oauth-proxy cookies </body>
		<created>2018-04-19 10:26:10</created>
		<closed>2018-05-24 07:50:30</closed>
	</bug>
	<bug>
		<id>2441</id>
		<title>Secret configuredProperties of a connector are not encrypted</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Connector properties that are marked as `secret=true` are not encrypted. They should be encrypted if present on a Connector or on a Connection.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Encrypt all secrets!  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create API connector with OAuth declared 2. Setup client id and secret 3. See that the connection's connector has clientSecret set as plain text on the connector's configuredProperties 4. If a connection is created, see that the accessToken is set as plain text on the connector's configuredProperties </body>
		<created>2018-04-19 09:52:56</created>
		<closed>2018-04-25 13:58:18</closed>
	</bug>
	<bug>
		<id>2439</id>
		<title>Missing step indicator in connection wizard</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; The active step of the connection wizard is not highlighted.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; The active step of the connection wizard is highlighted.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![screenshot-2018-4-19 syndesis 1](https://user-images.githubusercontent.com/1306050/38984325-ada6342e-43c6-11e8-8ef2-ad47d96b15a1.png) ![screenshot-2018-4-19 syndesis 2](https://user-images.githubusercontent.com/1306050/38984332-b00ae818-43c6-11e8-8bc8-dcce06ffc09b.png)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Try creating a connection (in my case an API connector connection) 2. Go through the steps 3. Notice no active step highlight is present </body>
		<created>2018-04-19 09:43:17</created>
		<closed>2018-04-22 10:34:15</closed>
	</bug>
	<bug>
		<id>2432</id>
		<title>Not able to start integration from older than current version</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; It is not possible to publish older than current version of integration. There is no integration build from older version in the OS, it simply deploys the current built version of integration. The UI looks as if the integration was published from the older version, this is however not true, it still runs the current version.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; When I hit publish on older version - for instance I have "version 1" and "version 2" and I hit "publish" on "version 1", I want the "version 1" to be running  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; There is a screenshot of the activity log. The "version 1" I created had no logging. I added this only for the "version 2", which means, there is still "version 2" running.  ![version_issue](https://user-images.githubusercontent.com/4180208/38976044-49749ace-43b0-11e8-837a-e9c7abd02482.png)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create integration (and publish) -&gt; this starts as "version 1" 2. Edit the integration (and publish) - e.g. you can simply add logger -&gt; this starts as "version 2" 3. Unpublish the integration using "unpublish" button 4. Publish the "version 1" integration 5. Wait for it to get deployed - in the UI it looks almost as if "version 1" was deployed, but on OS - "version 2" is running, as there was no rebuild</body>
		<created>2018-04-19 07:07:07</created>
		<closed>2018-05-02 11:06:19</closed>
	</bug>
	<bug>
		<id>2428</id>
		<title>SIGSEGV on redeploy</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Sometimes the integration pod crashes while editing and redeploying an integration:  ``` i-db2db2-5-9prjm i-db2db2 Starting the Java application using /opt/run-java/run-java.sh ... i-db2db2-5-9prjm i-db2db2 exec java -javaagent:/opt/jolokia/jolokia.jar=config=/opt/jolokia/etc/jolokia.properties -javaagent:/opt/prometheus/jmx_prometheus_javaagent.jar=9779:/tmp/src/prometheus-config.yml -XX:+UseParallelGC -XX:GCTimeRatio=4 -XX:AdaptiveSizePolicyWeight=90 -XX:MinHeapFreeRatio=20 -XX:MaxHeapFreeRatio=40 -XX:+ExitOnOutOfMemoryError -cp . -jar /deployments/project-0.1-SNAPSHOT.jar i-db2db2-5-9prjm i-db2db2 FATAL ERROR in native method: processing of -javaagent failed i-db2db2-5-9prjm i-db2db2 # i-db2db2-5-9prjm i-db2db2 # A fatal error has been detected by the Java Runtime Environment: i-db2db2-5-9prjm i-db2db2 # i-db2db2-5-9prjm i-db2db2 #  SIGSEGV (0xb) at pc=0x00007f2a6e433a37, pid=1, tid=0x00007f2a6f21b700 i-db2db2-5-9prjm i-db2db2 # i-db2db2-5-9prjm i-db2db2 # JRE version: OpenJDK Runtime Environment (8.0_151-b12) (build 1.8.0_151-b12) i-db2db2-5-9prjm i-db2db2 # Java VM: OpenJDK 64-Bit Server VM (25.151-b12 mixed mode linux-amd64 compressed oops) i-db2db2-5-9prjm i-db2db2 # Problematic frame: i-db2db2-5-9prjm i-db2db2 # C  [libc.so.6+0x36a37]  abort+0x297 i-db2db2-5-9prjm i-db2db2 # i-db2db2-5-9prjm i-db2db2 # Core dump written. Default location: /deployments/core or core.1 i-db2db2-5-9prjm i-db2db2 # i-db2db2-5-9prjm i-db2db2 # An error report file with more information is saved as: i-db2db2-5-9prjm i-db2db2 # /deployments/hs_err_pid1.log i-db2db2-5-9prjm i-db2db2 # i-db2db2-5-9prjm i-db2db2 # If you would like to submit a bug report, please visit: i-db2db2-5-9prjm i-db2db2 #   http://bugreport.java.com/bugreport/crash.jsp i-db2db2-5-9prjm i-db2db2 # i-db2db2-5-9prjm i-db2db2 [error occurred during error reporting , id 0xb] ... i-db2db2-5-9prjm i-db2db2 [error occurred during error reporting , id 0xb] i-db2db2-5-9prjm i-db2db2 [Too many errors, abort] ... i-db2db2-5-9prjm i-db2db2 [Too many errors, abort] i-db2db2-5-9prjm i-db2db2 at sun.instrument.InstrumentationImpl.loadClassAndStartAgent(InstrumentationImpl.java:386) i-db2db2-5-9prjm i-db2db2 at sun.instrument.InstrumentationImpl.loadClassAndCallPremain(InstrumentationImpl.java:401) i-db2db2-5-9prjm i-db2db2 Caused by: java.io.FileNotFoundException: /tmp/src/prometheus-config.yml (No such file or directory) i-db2db2-5-9prjm i-db2db2 at java.io.FileInputStream.open0(Native Method) i-db2db2-5-9prjm i-db2db2 at java.io.FileInputStream.open(FileInputStream.java:195) i-db2db2-5-9prjm i-db2db2 at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:138) i-db2db2-5-9prjm i-db2db2 at java.io.FileReader.&lt;init&gt;(FileReader.java:72) i-db2db2-5-9prjm i-db2db2 at io.prometheus.jmx.shaded.io.prometheus.jmx.JmxCollector.&lt;init&gt;(JmxCollector.java:74) i-db2db2-5-9prjm i-db2db2 at io.prometheus.jmx.shaded.io.prometheus.jmx.JavaAgent.premain(JavaAgent.java:36) i-db2db2-5-9prjm i-db2db2 ... 6 more ```  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  It should not crash :)  ## Env - minishift v1.16.0+8abe845 - openshift v3.7.1+a8deba5-34 - iso centos </body>
		<created>2018-04-18 14:05:21</created>
		<closed>2019-06-11 06:46:48</closed>
	</bug>
	<bug>
		<id>2420</id>
		<title>AWS connector sticks with US-East-1</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## The problem You can't change AWS zone  ## Expected behavior You can configure the AWS zone.  </body>
		<created>2018-04-17 21:19:28</created>
		<closed>2018-06-05 13:38:01</closed>
	</bug>
	<bug>
		<id>2419</id>
		<title>data mapper .toolbar css is affecting other .toolbar elements in the app</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## The problem If you go to the data mapper, it has styles for `.toolbar` and the `ViewEncapsulation` is set to `None`, so if you go anywhere else in the app with a `.toolbar` class after going to the data mapper, those other `.toolbar`'s will get styles set from the data mapper.  ## Expected behavior The `.toolbar` styles on the data mapper shouldn't affect other parts of the app.  ## Screenshot ![screen shot 2018-04-17 at 2 58 41 pm](https://user-images.githubusercontent.com/35148959/38893583-4ec95958-4250-11e8-8ea7-03c2142a5eb6.png)  ## Tasks involved / Steps to Reproduce 1. Edit an integration and bring up the data mapper. You just need to load the data mapper in the browser. 1. Go to "connections" and click "create connection" 1. See the broken toolbar</body>
		<created>2018-04-17 20:10:25</created>
		<closed>2018-04-18 14:40:51</closed>
	</bug>
	<bug>
		<id>2406</id>
		<title>Monitoring - Activity: Twitter mention activity is not logged</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem ``` Twitter Mention -&gt; Advanced Filter -&gt; Basic Filter -&gt; Salesforce Create or Update ```  Apart from Datamapper warnings ```  {"exchange":"i-LAHvdsdeh6MWSA3gsg6z","status":"begin"} {"exchange":"i-LAHvdsdeh6MWSA3gsg6z","step":"-LAH_OT3yIroXzXd1V8P","id":"i-LAHvdsfeh6MWSA3gsg8z","duration":1814005} {"exchange":"i-LAHvdsdeh6MWSA3gsg6z","step":"-LAH_GpoyIroXzXd1V8O","id":"i-LAHvdsheh6MWSA3gsg9z","duration":1103794} 2018-04-17 09:27:56.249  WARN 1 --- [line://MENTIONS] i.a.core.DefaultAtlasConversionService   : Converter between java.util.Date and java.time.ZonedDateTime aleady exists. 2018-04-17 09:27:56.262  WARN 1 --- [line://MENTIONS] i.a.core.DefaultAtlasConversionService   : Converter between java.time.LocalDate and java.time.ZonedDateTime aleady exists. 2018-04-17 09:27:56.264  WARN 1 --- [line://MENTIONS] i.a.core.DefaultAtlasConversionService   : Converter between java.time.LocalDateTime and java.time.ZonedDateTime aleady exists. 2018-04-17 09:27:56.267  WARN 1 --- [line://MENTIONS] i.a.core.DefaultAtlasConversionService   : Converter between java.time.LocalTime and java.time.ZonedDateTime aleady exists. {"exchange":"i-LAHvdsdeh6MWSA3gsg6z","step":"-LAH_7Y5yIroXzXd1V8N","id":"i-LAHvdsjeh6MWSA3gsgAz","duration":771709951} {"exchange":"i-LAHvdsdeh6MWSA3gsg6z","step":"-LAH_5InyIroXzXd1V8M","id":"i-LAHve3oeh6MWSA3gsgCz","duration":634184791} {"exchange":"i-LAHvdsdeh6MWSA3gsg6z","status":"done","failed":false}   ```  There seems to be mismatch between actual logging  The first step is logging id `-LAH_OT3yIroXzXd1V8P`, but in my integration  ``` "stepKind": "endpoint",       "id": "-LAH_4weyIroXzXd1V8M" ```  [Twitter to Salesforce E2E-export (1).zip](https://github.com/syndesisio/syndesis/files/1919081/Twitter.to.Salesforce.E2E-export.1.zip)   ## Expected behavior All steps are logged and visible.  ## Screenshot ![screen shot 2018-04-17 at 11 38 26](https://user-images.githubusercontent.com/5637792/38861882-e0298d7c-4233-11e8-876a-23776570d579.png)    ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create Twitter Mention -&gt; Salesforce or any other endpoint 2. Check Activity </body>
		<created>2018-04-17 09:40:06</created>
		<closed>2018-07-27 15:24:24</closed>
	</bug>
	<bug>
		<id>2393</id>
		<title>Log step - "null" in "custom text" field when not edited</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When I add a log step to integration, and I don't edit the "custom text" field, it shows "null" value when I click it again.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; The field should probably stay empty instead.   ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![log_null_field](https://user-images.githubusercontent.com/4180208/38809910-75f96e94-4185-11e8-9816-44de2e1abdb9.gif)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create integration 2. In integration add log step, leave the "custom text" field blank 3. Hit "Done" button in the log step definition 4. Hit again the declared log step - observe the "null" text in the field. </body>
		<created>2018-04-16 12:52:48</created>
		<closed>2018-04-17 18:12:36</closed>
	</bug>
	<bug>
		<id>2390</id>
		<title>Version history sort order is alphabetical</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; If you have more then 10 versions, 9 will be listed at the top and 10 at the bottom.    ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; The newest should be listed first.   ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4. </body>
		<created>2018-04-13 20:22:04</created>
		<closed>2018-04-17 18:12:48</closed>
	</bug>
	<bug>
		<id>2384</id>
		<title>please fix version information in the support button so it is accurate</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem  When you click on the support button, the version is hardcoded to 1.0. We need this to be correct for GA.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  The correct version is displayed.  </body>
		<created>2018-04-13 20:08:14</created>
		<closed>2018-04-17 17:44:51</closed>
	</bug>
	<bug>
		<id>2383</id>
		<title>Stale cookies prohibited connector creation</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Stale cookie impeded ability to create  new sales force connection. (https://github.com/syndesisio/syndesis/issues/2320 - tracks that specific error and will improve bubbling up/reporting issues.   This issue is to resolve the fact we had as stale cookie. Hiram seems to be aware of the original issue around this.   </body>
		<created>2018-04-13 20:06:43</created>
		<closed>2018-04-16 14:33:02</closed>
	</bug>
	<bug>
		<id>2378</id>
		<title>Integration state tracking doesn't seem to be working properly</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Trying to get an integration running this morning on a fresh build but finding that the state tracking seems all off.  I basically created an integration, clicked "Publish" and it was working.  Realized that I needed to change the settings for my start connection, so did that from the editor and clicked "Publish" again.  Now I'm in this weird state where there's a pod running with my integration *but* the state coming back isn't right:  ![integration](https://user-images.githubusercontent.com/351660/38738829-24e5378a-3f01-11e8-9449-2b798a046918.png)  Actually it looks like the server is trying to deploy it, but it was deployed :-/  Here's the server log:  [syndesis-server-2-ckkn7.log](https://github.com/syndesisio/syndesis/files/1907589/syndesis-server-2-ckkn7.log)  I'm noticing that the state fields aren't as I'd expect, the `currentState` is `Unpublished` and the `targetState` is `Published`.  But `currentState` should be `Pending` at this point if the server is trying to start the integration, at least that's what the UI is expecting it to be at this point since there's a `Pending` state.  Also selecting `Unpublish` from the menu doesn't appear to actually unpublish the integration, at least from the openshift console I still see a pod running.  It seems like the syndesis server has completely lost track of the pod perhaps?  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlisting the acceptance criteria. --&gt;  Ideally clicking publish should start or restart the integration.  When we're in a state transition, the `currentState` in the integration view object should be `Pending`.  Or we should decide that any discrepencies between the two states means that really the `currentState` should be `Pending` and that the UI should also reset this field as needed.  If the user clicks `Unpublish` then the server should pretty much halt any outstanding builds/deployments and ensure that there's no pod running for that integration.  ## Steps to reproduce  1.  Create a valid integration 1.  Publish it via the editor's 'Publish' button 1.  From the integration detail page, go back into the editor 1.  Change something, use the editor's 'Publish' button again to save the changes 1.  Enjoy  At this point I kinda tried using publish/unpublish from various spots on the detail page and integration list page to see if I could get the integration running again, but no joy.  It'd be awesome if someone could verify.</body>
		<created>2018-04-13 14:06:19</created>
		<closed>2018-04-18 16:54:18</closed>
	</bug>
	<bug>
		<id>2374</id>
		<title>Going into the Integration Editor and back to home page breaks the Integration Board card </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Going into the Integration Editor then coming back out to the Home Page breaks the Integration Board card (with a bottom scroll bar added...)   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  No scroll bar on the Integration Board card.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![screen shot 2018-04-12 at 3 00 49 pm](https://user-images.githubusercontent.com/24943812/38700106-fc963d0e-3e67-11e8-8023-78dca75b8af3.png)   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Click an integration on the Integration List View  2. Click "Edit Integration"  3. Click logo area of the top masthead    Could be related to https://github.com/syndesisio/syndesis/issues/2294  cc: @michael-coker </body>
		<created>2018-04-12 19:48:57</created>
		<closed>2018-04-16 16:00:54</closed>
	</bug>
	<bug>
		<id>2373</id>
		<title>Integration activity is loading from a different integration</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Loading the integration activity from an integration on staging shows one thing, then going to another integration's activity, and back to the first integration's activity loads the second integration's activity in the first.  ## Expected behavior An integration's activity should only list the activity of that integration.  ## Screenshot Actual activity &lt;img width="1397" alt="screen shot 2018-04-12 at 2 05 16 pm" src="https://user-images.githubusercontent.com/35148959/38698422-929502bc-3e5a-11e8-9339-da8c32db9a47.png"&gt;  Activity after going to another integration and back to this one &lt;img width="1397" alt="screen shot 2018-04-12 at 2 05 26 pm" src="https://user-images.githubusercontent.com/35148959/38698421-9280fa06-3e5a-11e8-85d1-088a811a0652.png"&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Go to [staging](https://syndesis-staging.b6ff.rh-idev.openshiftapps.com/) and click on "Integrations" 1. Click on the "Salesforce to Database April 8" integration 1. Click on the "Activity" tab and note that it's empty 1. Click on the "Integration" link in the breadcrumb 1. Click on the "Sample Integration" integration 1. Click on the "Activity" tab and note that it loads a bunch of activity 1. Click on the "Integration" link in the breadcrumb 1. Click on the "Salesforce to Database April 8" integration 1. Click on the "Activity" tab and note that it loads the "Sample Integration"'s activity  I'm curious if it's related to https://github.com/syndesisio/syndesis/issues/2294</body>
		<created>2018-04-12 19:10:13</created>
		<closed>2018-04-13 20:01:19</closed>
	</bug>
	<bug>
		<id>2365</id>
		<title>Activity Log Errors not showing up in the right step.</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Successful processing flow: ![syndesis](https://user-images.githubusercontent.com/103255/38676274-781e5a00-3e28-11e8-8d58-fe8bea50a071.jpg)  Processing flow where the Random Error step throws an exception: ![syndesis](https://user-images.githubusercontent.com/103255/38676293-8affc47e-3e28-11e8-8a9b-ab1c58d7268d.jpg)  Notice that the Random Error step is not listed and the error is shown in 'Periodic SQL Invocation' step.  ## Expected behavior Random Error step should show up and have the exception on that step entry.  ## Screenshot  </body>
		<created>2018-04-12 12:10:03</created>
		<closed>2018-04-26 12:56:18</closed>
	</bug>
	<bug>
		<id>2364</id>
		<title>NPE when accessing `/api/v1/integrations`</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; I'm seeing a NullPointerException when switching from any tab to Integrations tab in the UI.  ``` java.lang.NullPointerException: null at io.syndesis.server.endpoint.v1.handler.integration.IntegrationHandler.toCurrentConnection(IntegrationHandler.java:352) ~[server-endpoint-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT] at java.util.Optional.map(Optional.java:215) ~[na:1.8.0_151] at io.syndesis.server.endpoint.v1.handler.integration.IntegrationHandler.toCurrentSteps(IntegrationHandler.java:371) ~[server-endpoint-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT] at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[na:1.8.0_151] at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1380) ~[na:1.8.0_151] at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ~[na:1.8.0_151] at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ~[na:1.8.0_151] at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ~[na:1.8.0_151] at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[na:1.8.0_151] at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ~[na:1.8.0_151] at io.syndesis.server.endpoint.v1.handler.integration.IntegrationHandler.toCurrentIntegrationOverview(IntegrationHandler.java:333) ~[server-endpoint-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT] at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[na:1.8.0_151] at java.util.Collections$2.tryAdvance(Collections.java:4717) ~[na:1.8.0_151] at java.util.Collections$2.forEachRemaining(Collections.java:4725) ~[na:1.8.0_151] at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ~[na:1.8.0_151] at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ~[na:1.8.0_151] at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ~[na:1.8.0_151] at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[na:1.8.0_151] at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ~[na:1.8.0_151] at io.syndesis.server.endpoint.v1.handler.integration.IntegrationHandler.list(IntegrationHandler.java:149) ~[server-endpoint-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT] ```  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; No exceptions.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![screenshot from 2018-04-12 12-35-20](https://user-images.githubusercontent.com/1306050/38672320-1bf4feca-3e4e-11e8-96e7-527b8cdba8df.png)  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ```http GET /api/v1/integrations HTTP/1.1 Accept: application/json, text/plain, */* ```  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt; `GET /api/v1/integrations`  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Click to Integrations tab, I think also clicking to Home tab that displays integration summary 2. 3. 4. </body>
		<created>2018-04-12 10:37:53</created>
		<closed>2018-04-12 10:49:28</closed>
	</bug>
	<bug>
		<id>2362</id>
		<title>SYNDESIS006 is generated for properties that are configured at connector level</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When generating connection bulletin board properties that are configured at the connector level of that connection are not taken under consideration. This makes the computation return SYNDESIS006 warning for properties that are configured.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; If the property is configured at connection or connector level SYNDESIS006 should not be raised.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![screenshot-2018-4-12 syndesis](https://user-images.githubusercontent.com/1306050/38669116-d3184eee-3e45-11e8-88ea-f5320dfc0bcc.png)  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ```http GET /api/v1/connections/i-L9srbleHru4SWE28qhlz HTTP/1.1 Accept: application/json, text/plain, */* ```  ```http HTTP/1.1 200 OK Cache-Control: no-cache, no-store, max-age=0, must-revalidate, proxy-revalidate, s-maxage=0 Content-Type: application/json Date: Thu, 12 Apr 2018 09:37:23 GMT Expires: 0 Pragma: no-cache Strict-Transport-Security: max-age=31536000 ; includeSubDomains X-Application-Context: application X-Content-Type-Options: nosniff X-Frame-Options: DENY X-Xss-Protection: 1; mode=block Transfer-Encoding: chunked  {   "board": {     "id": "i-L9srbnFHru4SWE28qhmz",     "targetResourceId": "i-L9srbleHru4SWE28qhlz",     "notices": 0,     "warnings": 1,     "errors": 0,     "metadata": {       "connector-id": "i-L9srD9OHru4SWE28qhkz",       "connector-version-latest": "2",       "connector-version-connection": "2"     },     "messages": [       {         "level": "WARN",         "code": "SYNDESIS006"       }     ],     "createdAt": 1523520011472,     "updatedAt": 1523525787266   },   "id": "i-L9srbleHru4SWE28qhlz",   "connector": {     "connectorGroup": {       "id": "swagger-connector-template"     },     "connectorGroupId": "swagger-connector-template",     "description": "...",     "icon": "data:image/svg+xml,%3Csvg%20xmlns%3Asvg...",     "id": "i-L9srD9OHru4SWE28qhkz",     "version": 2,     "actions": [       {         "id": "io.syndesis.connector:connector-rest-swagger:1.3-SNAPSHOT:i-L9srD9OHru4SWE28qhkz:operation-1",         "name": "Create a new listitem",         "description": "Create a new listitem",         "descriptor": {           "connectorId": "i-L9srD9OHru4SWE28qhkz",           "camelConnectorGAV": "io.syndesis.connector:connector-rest-swagger:1.3-SNAPSHOT",           "camelConnectorPrefix": "swagger-operation",           "inputDataShape": {             "name": "Request",             "description": "API request payload",             "kind": "json-schema",             "specification": "..."           },           "outputDataShape": {             "name": "Response",             "description": "API response payload",             "kind": "json-schema",             "specification": "..."           },           "configuredProperties": {             "operationId": "operation-1"           }         },         "tags": [           "Resources"         ],         "actionType": "connector",         "dependencies": [           {             "type": "MAVEN",             "id": "io.syndesis.connector:connector-rest-swagger:1.3-SNAPSHOT"           }         ],         "pattern": "To"       },       {         "id": "io.syndesis.connector:connector-rest-swagger:1.3-SNAPSHOT:i-L9srD9OHru4SWE28qhkz:operation-4",         "name": "Delete listitem by ID",         "description": "Deletes the specified listitem",         "descriptor": {           "connectorId": "i-L9srD9OHru4SWE28qhkz",           "camelConnectorGAV": "io.syndesis.connector:connector-rest-swagger:1.3-SNAPSHOT",           "camelConnectorPrefix": "swagger-operation",           "inputDataShape": {             "name": "Request",             "description": "API request payload",             "kind": "json-schema",             "specification": "..."           },           "outputDataShape": {             "name": "Response",             "description": "API response payload",             "kind": "json-schema",             "specification": "..."           },           "configuredProperties": {             "operationId": "operation-4"           }         },         "tags": [           "Resources"         ],         "actionType": "connector",         "dependencies": [           {             "type": "MAVEN",             "id": "io.syndesis.connector:connector-rest-swagger:1.3-SNAPSHOT"           }         ],         "pattern": "To"       },       {         "id": "io.syndesis.connector:connector-rest-swagger:1.3-SNAPSHOT:i-L9srD9OHru4SWE28qhkz:operation-2",         "name": "Get a single listitem by ID",         "description": "Returns a listitem by ID.",         "descriptor": {           "connectorId": "i-L9srD9OHru4SWE28qhkz",           "camelConnectorGAV": "io.syndesis.connector:connector-rest-swagger:1.3-SNAPSHOT",           "camelConnectorPrefix": "swagger-operation",           "inputDataShape": {             "name": "Request",             "description": "API request payload",             "kind": "json-schema",             "specification": "..."           },           "outputDataShape": {             "name": "Response",             "description": "API response payload",             "kind": "json-schema",             "specification": "..."           },           "configuredProperties": {             "operationId": "operation-2"           }         },         "tags": [           "Resources"         ],         "actionType": "connector",         "dependencies": [           {             "type": "MAVEN",             "id": "io.syndesis.connector:connector-rest-swagger:1.3-SNAPSHOT"           }         ],         "pattern": "To"       },       {         "id": "io.syndesis.connector:connector-rest-swagger:1.3-SNAPSHOT:i-L9srD9OHru4SWE28qhkz:operation-0",         "name": "Gets all listitems",         "description": "Returns all list items based on the search criteria.",         "descriptor": {           "connectorId": "i-L9srD9OHru4SWE28qhkz",           "camelConnectorGAV": "io.syndesis.connector:connector-rest-swagger:1.3-SNAPSHOT",           "camelConnectorPrefix": "swagger-operation",           "inputDataShape": {             "name": "Request",             "description": "API request payload",             "kind": "json-schema",             "specification": "..."           },           "outputDataShape": {             "name": "Response",             "description": "API response payload",             "kind": "json-schema",             "specification": "..."           },           "configuredProperties": {             "operationId": "operation-0"           }         },         "tags": [           "Resources"         ],         "actionType": "connector",         "dependencies": [           {             "type": "MAVEN",             "id": "io.syndesis.connector:connector-rest-swagger:1.3-SNAPSHOT"           }         ],         "pattern": "To"       },       {         "id": "io.syndesis.connector:connector-rest-swagger:1.3-SNAPSHOT:i-L9srD9OHru4SWE28qhkz:operation-3",         "name": "Update listitem",         "description": "Updates listitem specified in the URL.  Only the fields provided in the supplied object will be updated, missing fields will not be altered.",         "descriptor": {           "connectorId": "i-L9srD9OHru4SWE28qhkz",           "camelConnectorGAV": "io.syndesis.connector:connector-rest-swagger:1.3-SNAPSHOT",           "camelConnectorPrefix": "swagger-operation",           "inputDataShape": {             "name": "Request",             "description": "API request payload",             "kind": "json-schema",             "specification": "..."           },           "outputDataShape": {             "name": "Response",             "description": "API response payload",             "kind": "json-schema",             "specification": "..."           },           "configuredProperties": {             "operationId": "operation-3"           }         },         "tags": [           "Resources"         ],         "actionType": "connector",         "dependencies": [           {             "type": "MAVEN",             "id": "io.syndesis.connector:connector-rest-swagger:1.3-SNAPSHOT"           }         ],         "pattern": "To"       }     ],     "name": "Concur List Items",     "properties": {       "host": {         "componentProperty": true,         "defaultValue": "https://www.concursolutions.com",         "deprecated": false,         "description": "Scheme hostname and port to direct the HTTP requests to in the form of https://hostname:port. Can be configured at the endpoint component or in the correspoding REST configuration in the Camel Context. If you give this component a name (e.g. petstore) that REST configuration is consulted first rest-swagger next and global configuration last. If set overrides any value found in the Swagger specification RestConfiguration. Can be overriden in endpoint configuration.",         "displayName": "Host",         "group": "producer",         "javaType": "java.lang.String",         "kind": "property",         "label": "producer",         "required": true,         "secret": false,         "type": "string"       },       "basePath": {         "componentProperty": true,         "defaultValue": "/api/v3.0",         "deprecated": false,         "description": "API basePath for example /v2. Default is unset if set overrides the value present in Swagger specification.",         "displayName": "Base path",         "group": "producer",         "javaType": "java.lang.String",         "kind": "property",         "label": "producer",         "required": true,         "secret": false,         "type": "string"       },       "authenticationType": {         "componentProperty": true,         "defaultValue": "oauth2",         "deprecated": false,         "description": "Type of authentication used to connect to the API",         "displayName": "Authentication Type",         "group": "producer",         "javaType": "java.lang.String",         "kind": "property",         "label": "producer",         "required": false,         "secret": false,         "type": "string",         "tags": [           "authentication-type"         ],         "enum": [           {             "label": "OAuth 2.0",             "value": "oauth2"           }         ]       },       "clientId": {         "componentProperty": true,         "deprecated": false,         "description": "OAuth Client ID, sometimes called Consumer Key",         "displayName": "OAuth Client ID",         "group": "producer",         "javaType": "java.lang.String",         "kind": "property",         "label": "producer",         "required": false,         "secret": false,         "type": "string",         "tags": [           "oauth-client-id"         ]       },       "clientSecret": {         "componentProperty": true,         "deprecated": false,         "description": "OAuth Client Secret, sometimes called Consumer Secret",         "displayName": "OAuth Client Secret",         "group": "producer",         "javaType": "java.lang.String",         "kind": "property",         "label": "producer",         "required": false,         "secret": true,         "type": "string",         "tags": [           "oauth-client-secret"         ]       },       "accessToken": {         "componentProperty": true,         "deprecated": false,         "description": "OAuth Access token",         "displayName": "OAuth Access token",         "group": "producer",         "javaType": "java.lang.String",         "kind": "property",         "label": "producer",         "required": false,         "secret": true,         "type": "string",         "tags": [           "oauth-access-token"         ]       },       "authorizationEndpoint": {         "componentProperty": true,         "defaultValue": "https://us-impl.api.concursolutions.com/oauth2/v0/authorize",         "deprecated": false,         "description": "URL for the start of the OAuth flow",         "displayName": "OAuth Authorization Endpoint URL",         "group": "producer",         "javaType": "java.lang.String",         "kind": "property",         "label": "producer",         "required": true,         "secret": false,         "type": "string",         "tags": [           "oauth-authorization-url"         ]       },       "tokenEndpoint": {         "componentProperty": true,         "defaultValue": "https://us-impl.api.concursolutions.com/oauth2/v0/token",         "deprecated": false,         "description": "URL to fetch the OAuth Access token",         "displayName": "OAuth Token Endpoint URL",         "group": "producer",         "javaType": "java.lang.String",         "kind": "property",         "label": "producer",         "required": false,         "secret": false,         "type": "string",         "tags": [           "oauth-access-token-url"         ]       },       "oauthScopes": {         "componentProperty": true,         "defaultValue": "LIST",         "deprecated": false,         "description": "URL to fetch the OAuth Access token",         "displayName": "OAuth Scopes",         "group": "producer",         "javaType": "java.lang.String",         "kind": "property",         "label": "producer",         "required": false,         "secret": false,         "type": "string",         "tags": [           "oauth-scope"         ]       },       "tokenStrategy": {         "componentProperty": true,         "defaultValue": "AUTHORIZATION_HEADER",         "deprecated": false,         "displayName": "OAuth Token strategy",         "group": "producer",         "javaType": "java.lang.String",         "kind": "property",         "label": "producer",         "required": false,         "secret": false,         "type": "hidden",         "tags": [           "oauth-token-strategy"         ]       },       "authorizeUsingParameters": {         "componentProperty": true,         "defaultValue": "true",         "deprecated": false,         "displayName": "OAuth Token strategy",         "group": "producer",         "javaType": "java.lang.String",         "kind": "property",         "label": "producer",         "required": false,         "secret": false,         "type": "hidden",         "tags": [           "oauth-authorize-using-parameters"         ]       },       "specification": {         "componentProperty": true,         "deprecated": false,         "description": "Swagger specification of the service",         "displayName": "Specification",         "group": "producer",         "javaType": "java.lang.String",         "kind": "property",         "label": "producer",         "required": true,         "secret": false,         "type": "hidden",         "tags": [           "upload",           "url"         ]       }     },     "configuredProperties": {       "tokenEndpoint": "https://us-impl.api.concursolutions.com/oauth2/v0/token",       "clientId": "72e68b28-5fbe-4a0d-8cfb-2407830e84bc",       "basePath": "/api/v3.0",       "host": "https://www.concursolutions.com",       "specification": "...",       "authorizeUsingParameters": "true",       "clientSecret": "deb604e2-7c34-4e8f-8cad-ad6d049a1a70",       "authenticationType": "oauth2",       "oauthScopes": "LIST",       "tokenStrategy": "AUTHORIZATION_HEADER",       "authorizationEndpoint": "https://us-impl.api.concursolutions.com/oauth2/v0/authorize"     }   },   "connectorId": "i-L9srD9OHru4SWE28qhkz",   "icon": "data:image/svg+xml,%3Csvg%20xmlns%3Asvg...",   "userId": "developer",   "lastUpdated": 1523520011369,   "createdDate": 1523520011317,   "name": "Concur List API",   "configuredProperties": {     "accessToken": "..."   },   "isDerived": true }]]&gt; ```  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt; `GET /api/v1/connections/{id}`  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create an API connector with OAuth support 2. Create a connection for that connector 3. Notice the warning being displayed </body>
		<created>2018-04-12 09:45:42</created>
		<closed>2018-04-12 10:06:46</closed>
	</bug>
	<bug>
		<id>2360</id>
		<title>Basic authentication not working in API connector</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; `connector-rest-swagger` concatenates String with the output `Base64.Encoder::encode` which returns a `byte[]` to create the `Authorization` header. This will not generate a valid basic authentication `Authorization` header.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; A valid `Authorization` header should be generated. </body>
		<created>2018-04-12 08:13:07</created>
		<closed>2018-04-12 13:19:48</closed>
	</bug>
	<bug>
		<id>2358</id>
		<title>CurrentConnectionService verbose logging to browser console</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem `CurrentConnectionService` seems to be logging whole JSON response for a connector once it's selected to browser console. Maybe it should go to `debug` only?  This is not really a bug just lacking a more specific label :)  ``` 2018-04-12 09:22:42,871 INFO [CurrentConnectionService] connection event: {"kind":"connection-check-connector","connection":{"connector":{"description":"AMQP Message Broker","icon":"fa-amqp","componentScheme":"amqp","connectorFactory":"io.syndesis.connector.amqp.AMQPConnectorFactory","actionsSummary":{"totalActions":3},"uses":0,"id":"amqp","version":2,"actions":[{"id":"io.syndesis:amqp-publish-action","name":"Publish messages","description":"Send data to the destination you specify.","descriptor":{"inputDataShape":{"kind":"any"},"outputDataShape":{"kind":"none"},"propertyDefinitionSteps":[{"description":"Specify AMQP destination properties, including Queue or Topic name","name":"Select the AMQP Destination","properties":{"deliveryPersistent":{"componentProperty":false,"defaultValue":"true","deprecated":false,"labelHint":"Message delivery is guaranteed when Persistent is selected.","displayName":"Persistent","group":"producer","javaType":"boolean","kind":"parameter","label":"producer","required":false,"secret":false,"type":"boolean","order":3},"destinationName":{"componentProperty":false,"deprecated":false,"labelHint":"Name of the queue or topic to send data to.","displayName":"Destination Name","group":"common","javaType":"java.lang.String","kind":"path","required":true,"secret":false,"type":"string","order":1},"destinationType":{"componentProperty":false,"defaultValue":"queue","deprecated":false,"labelHint":"By default, the destination is a Queue.","displayName":"Destination Type","group":"common","javaType":"java.lang.String","kind":"path","required":false,"secret":false,"type":"string","order":2,"enum":[{"label":"Topic","value":"topic"},{"label":"Queue","value":"queue"}]}}}]},"actionType":"connector","pattern":"To"},{"id":"io.syndesis:amqp-subscribe-action","name":"Subscribe for messages","description":"Receive data from the destination you specify.","descriptor":{"inputDataShape":{"kind":"none"},"outputDataShape":{"kind":"any"},"propertyDefinitionSteps":[{"description":"Specify AMQP destination properties, including Queue or Topic Name","name":"Select the AMQP Destination","properties":{"destinationName":{"componentProperty":false,"deprecated":false,"labelHint":"Name of the queue or topic to receive data from.","displayName":"Destination Name","group":"common","javaType":"java.lang.String","kind":"path","required":true,"secret":false,"type":"string","order":1},"destinationType":{"componentProperty":false,"defaultValue":"queue","deprecated":false,"labelHint":"By default, the destination is a Queue.","displayName":"Destination Type","group":"common","javaType":"java.lang.String","kind":"path","required":false,"secret":false,"type":"string","order":2,"enum":[{"label":"Topic","value":"topic"},{"label":"Queue","value":"queue"}]},"durableSubscriptionId":{"componentProperty":false,"deprecated":false,"labelHint":"Set the ID that lets connections close and reopen with missing messages. Connection type must be a topic.","displayName":"Durable Subscription ID","group":"consumer","javaType":"java.lang.String","kind":"parameter","label":"consumer","required":false,"secret":false,"type":"string","order":3},"messageSelector":{"componentProperty":false,"deprecated":false,"labelHint":"Specify a filter expression to receive only data that meets certain criteria.","displayName":"Message Selector","group":"consumer (advanced)","javaType":"java.lang.String","kind":"parameter","label":"consumer,advanced","required":false,"secret":false,"type":"string","order":4}}}]},"actionType":"connector","pattern":"From"},{"id":"io.syndesis:amqp-request-action","name":"Request response using messages","description":"Send data to the destination you specify and receive a response.","descriptor":{"inputDataShape":{"kind":"any"},"outputDataShape":{"kind":"any"},"propertyDefinitionSteps":[{"description":"Specify AMQP destination properties, including Queue or Topic Name","name":"Select the AMQP Destination","properties":{"destinationName":{"componentProperty":false,"deprecated":false,"labelHint":"Name of the queue or topic to receive data from.","displayName":"Destination Name","group":"common","javaType":"java.lang.String","kind":"path","required":true,"secret":false,"type":"string","order":1},"destinationType":{"componentProperty":false,"defaultValue":"queue","deprecated":false,"labelHint":"By default, the destination is a Queue.","displayName":"Destination Type","group":"common","javaType":"java.lang.String","kind":"path","required":false,"secret":false,"type":"string","order":2,"enum":[{"label":"Topic","value":"topic"},{"label":"Queue","value":"queue"}]},"durableSubscriptionId":{"componentProperty":false,"deprecated":false,"labelHint":"Set the ID that lets connections close and reopen with missing messages. Connection type must be a topic.","displayName":"Durable Subscription ID","group":"consumer","javaType":"java.lang.String","kind":"parameter","label":"consumer","required":false,"secret":false,"type":"string","order":3},"messageSelector":{"componentProperty":false,"deprecated":false,"labelHint":"Specify a filter expression to receive only data that meets certain criteria.","displayName":"Message Selector","group":"consumer (advanced)","javaType":"java.lang.String","kind":"parameter","label":"consumer,advanced","required":false,"secret":false,"type":"string","order":4}}}]},"actionType":"connector","pattern":"To"}],"tags":["verifier"],"name":"AMQP","properties":{"brokerCertificate":{"componentProperty":true,"deprecated":false,"description":"AMQ Broker X.509 PEM Certificate","displayName":"Broker Certificate","group":"security","javaType":"java.lang.String","kind":"property","label":"common,security","required":false,"secret":false,"type":"textarea","relation":[{"action":"ENABLE","when":[{"id":"skipCertificateCheck","value":"false"}]}],"order":6},"clientCertificate":{"componentProperty":true,"deprecated":false,"description":"AMQ Client X.509 PEM Certificate","displayName":"Client Certificate","group":"security","javaType":"java.lang.String","kind":"property","label":"common,security","required":false,"secret":false,"type":"textarea","relation":[{"action":"ENABLE","when":[{"id":"skipCertificateCheck","value":"false"}]}],"order":7},"clientID":{"componentProperty":true,"deprecated":false,"labelHint":"Required for connections to close and reopen without missing messages. Connection destination must be a topic.","displayName":"Client ID","group":"security","javaType":"java.lang.String","kind":"property","label":"common,security","required":false,"secret":false,"type":"string","order":4},"connectionUri":{"componentProperty":true,"deprecated":false,"labelHint":"Location to send data to or obtain data from.","displayName":"Connection URI","group":"common","javaType":"java.lang.String","kind":"property","label":"common","required":true,"secret":false,"type":"string","order":1},"password":{"componentProperty":true,"deprecated":false,"labelHint":"Password for the specified user account.","displayName":"Password","group":"security","javaType":"java.lang.String","kind":"property","label":"common,security","required":false,"secret":true,"type":"string","order":3},"skipCertificateCheck":{"componentProperty":true,"defaultValue":"false","deprecated":false,"labelHint":"Ensure certificate checks are enabled for secure production environments. Disable for convenience in only development environments.","displayName":"Check Certificates","group":"security","javaType":"java.lang.String","kind":"property","label":"common,security","required":false,"secret":false,"type":"string","order":5,"enum":[{"label":"Disable","value":"true"},{"label":"Enable","value":"false"}]},"username":{"componentProperty":true,"deprecated":false,"labelHint":"Access the broker with this users authorization credentials.","displayName":"User Name","group":"security","javaType":"java.lang.String","kind":"property","label":"common,security","required":false,"secret":false,"type":"string","order":2}},"dependencies":[{"type":"MAVEN","id":"io.syndesis.connector:connector-amqp:1.3-SNAPSHOT"}]},"icon":"fa-amqp","connectorId":"amqp"}} ``` ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot ![screen shot 2018-04-12 at 09 27 56](https://user-images.githubusercontent.com/5637792/38662203-d6cd76ac-3e33-11e8-82cc-9b8920616f6c.png) </body>
		<created>2018-04-12 07:30:45</created>
		<closed>2018-04-13 17:52:32</closed>
	</bug>
	<bug>
		<id>2339</id>
		<title>Atlasmap transformations use wrong character encoding</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  When transforming text in Atlasmap, e.g. to *prepend* something to a input string, special characters (e.g. characters with accents like ``) are not properly encoded.  Probably it applies to all transformations and other places where the user can insert text in Atlasmap.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Special characters should be encoded correctly.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; https://www.dropbox.com/s/yfc2kzjvzare6w6/Screenshot%20from%202018-04-11%2013-52-06.png?dl=0  https://www.dropbox.com/s/fko5rotjegvynz0/Screenshot%20from%202018-04-11%2012-34-16.png?dl=0  Note: it's a telegram to telegram integration with a `: ` string prepended using Atlasmap. While the text that is part of the body is encoded correctly, the text added by atlasmap at the beginning of the string is not.   ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt; N/A  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt; N/A  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create a integration (telegram-to-telegram in the example) 2. Add a datamapper step 3. In a datamapper mapping, add a "prepend" transformation 4. Use a special character like `` in the prepended text 5. Look at the result of the transformation in the destination system </body>
		<created>2018-04-11 11:55:27</created>
		<closed>2018-07-20 14:14:10</closed>
	</bug>
	<bug>
		<id>2333</id>
		<title>Integration List - "Draft" label and "Configuration Required" notification does not line up properly </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  In the Integration List View, when the "Draft" label and Configuration Required notification both appear in a row, the Configuration Required notification is being pushed off the row.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  Configuration Required notification should have its own individual column in a row, and align with the rest of the row content.   Also, with the new design (currently under design review), UX is proposing to remove the "Draft" label.   ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  &lt;img width="1434" alt="screen shot 2018-04-10 at 3 10 52 pm" src="https://user-images.githubusercontent.com/24943812/38578731-c5c246c4-3cd2-11e8-8290-ee45c92d29a4.png"&gt;   ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. 2. 3. 4.   </body>
		<created>2018-04-10 19:21:54</created>
		<closed>2018-04-18 11:58:50</closed>
	</bug>
	<bug>
		<id>2326</id>
		<title>Eliminate email drama by offering a single consistent email address</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Some instances of the application refer to `fuse-online-tech-preview@redhat.com` as the contact email address. Some others refer to `fuse-ignite-tech-preview@redhat.com`. Users are getting confused, emails are being lost. So. Much. Drama...   ## Expected behavior Let's remove drama from our lives and make `fuse-online-tech-preview@redhat.com` our unique contact email of choice! Also, it would be super-nice to centralize the email definition in a single location so we can rapidly update it no matter where it is referenced throughout the maze of HTML stravaganza of our application.  This is a job for... SUPER REDUX I18N!!!!!  </body>
		<created>2018-04-10 16:45:14</created>
		<closed>2018-04-12 12:57:10</closed>
	</bug>
	<bug>
		<id>2320</id>
		<title>TypeError: t.data.map is not a function when creating a SalesForce connector</title>
		<body>  ## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem While creating a SalesForce connector, my authentication step completed. When I entered a connector name and pressed create, nothing happened and the create button remained greyed out.   Looking at the debug output, we can see the following error:  {code} Failed to load resource: the server responded with a status of 500 (Internal Server Error) main.c960d81d3e86f12d7289.bundle.js:1 ERROR TypeError: t.data.map is not a function     at e.t.massageError (main.c960d81d3e86f12d7289.bundle.js:1)     at e._error (main.c960d81d3e86f12d7289.bundle.js:1)     at e.__tryOrUnsub (polyfills.00b2490f9e8f9b4c7b5e.bundle.js:1)     at e.error (polyfills.00b2490f9e8f9b4c7b5e.bundle.js:1)     at e._error (polyfills.00b2490f9e8f9b4c7b5e.bundle.js:1)     at e.error (polyfills.00b2490f9e8f9b4c7b5e.bundle.js:1)     at e._error (polyfills.00b2490f9e8f9b4c7b5e.bundle.js:1)     at e.error (polyfills.00b2490f9e8f9b4c7b5e.bundle.js:1)     at e.error (polyfills.00b2490f9e8f9b4c7b5e.bundle.js:1)     at e.T [as _error] (main.c960d81d3e86f12d7289.bundle.js:1) {code}  Stan was sitting next to me and did not see the same error after we enabled his account to my salesforce app. It seems to be something specific in this environment.  Clearing my authorization details and creating a new app did not help.    ## Expected behavior SalesForce connector should be created and usable.  ## Screenshot ![syndesis-error-sf](https://user-images.githubusercontent.com/650863/38566322-66ccedb6-3cb1-11e8-8034-2b85df5da7f1.jpg)  &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt;  No repeatable test outside of my environment.  If nothing else, we need a more descriptive idea of what is happening. Enabling Developer Tools for a Citizen user may not set the nice user friendly experience when troubleshooting issues. </body>
		<created>2018-04-10 15:20:45</created>
		<closed>2018-04-17 13:23:59</closed>
	</bug>
	<bug>
		<id>2318</id>
		<title>"Stop Integration" text on menu item should be "Unpublish" in integration history</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  On the active version in the history table the menu reads "Stop Integration", this should probably be "Unpublish" to be consistent with all the other places this menu item shows up.  &lt;img width="640" alt="screenshot 2018-04-10 10 39 04" src="https://user-images.githubusercontent.com/351660/38563768-a4d77ad2-3cab-11e8-905c-904fe1793039.png"&gt;  To reproduce you need to publish an integration, then check the integration history table and click on the dotty thing on the line that has the active version.</body>
		<created>2018-04-10 14:42:04</created>
		<closed>2018-04-11 13:31:40</closed>
	</bug>
	<bug>
		<id>2315</id>
		<title>Incorrect error message displayed when uploading an invalid swagger file</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  When uploading an invalid swagger file it appears the API can either return an HTTP 200 with an `error` attribute *or* return an HTTP 500 error response with the following:  ``` {"errorCode":500,"userMsg":"Please contact the administrator and file a bug report","developerMsg":"Internal Server Exception. Swagger specification does not provide a `schemes` definition and the Swagger specification was uploaded so the originating URL is lost to determine the scheme to use"} ```  In the latter case where the above response is received the wrong error message is shown in the UI:  &lt;img width="781" alt="screenshot 2018-04-10 09 52 58" src="https://user-images.githubusercontent.com/351660/38561050-0640be34-3ca5-11e8-808d-fae7c7a14359.png"&gt;  Probably caught by a generic error handler and not correctly propagated back to the component.  This can be reproduced by trying to create an API client connector with this swagger file:  [kie-server-swagger.json.txt](https://github.com/syndesisio/syndesis/files/1894902/kie-server-swagger.json.txt)  @chirino FYI</body>
		<created>2018-04-10 13:56:06</created>
		<closed>2018-04-11 17:24:34</closed>
	</bug>
	<bug>
		<id>2314</id>
		<title>Data Mapper icon bootstrap/ng-bootstrap tooltip overflow issue</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  When in the data mapper *sometimes* when hovering over buttons or icons the UI opens a tooltip, however when the tooltip element is triggered it causes the page to overflow, shifting all the elements on the page slightly.  This causes the tooltip to close, the page elements stop overflowing, but then because the user is still hovering the tooltip appears again.  Basically this means the tooltip flashes wildly and elements rapidly vibrate back and forth :-)  It's something that doesn't happen consistently but when it does you can sometimes click on the "show mappings" icon to make it stop.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  Hover tooltips shouldn't cause elements to overflow and scrollbars to appear.  </body>
		<created>2018-04-10 13:36:39</created>
		<closed>2018-04-11 13:01:34</closed>
	</bug>
	<bug>
		<id>2308</id>
		<title>If a Swagger specification has no tags the custom API connector wizard fails</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; For Swagger specifications that do not specify any tags for the operations `actionCountByTags` property might be undefined. In this case the wizard will be displayed only with the header and an exception will be logged to the browser console.  &lt;details&gt; &lt;summary&gt;Error from the console&lt;/summary&gt; &lt;pre&gt; ERROR  TypeError  columnNumber: 36  fileName: "https://syndesis.192.168.42.235.nip.io/customizations.module.chunk.js"  lineNumber: 926  message: "can't convert undefined to object"  ngDebugContext: Object { view: {}, nodeIndex: 1, nodeDef: {},  }  ngErrorLogger: function bound ()  stack: "set@https://syndesis.192.168.42.235.nip.io/customizations.module.chunk.js:926:36\nupdateProp@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:250182:5\ncheckAndUpdateDirectiveInline@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:249897:19\ncheckAndUpdateNodeInline@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:251456:20\ncheckAndUpdateNode@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:251399:16\ndebugCheckAndUpdateNode@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:252292:55\ndebugCheckDirectivesFn@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:252233:13\nView_ApiConnectorCreateComponent_2/&lt;@ng:///ApiConnectorModule/ApiConnectorCreateComponent.ngfactory.js:48:9\ndebugUpdateDirectives@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:252218:12\ncheckAndUpdateView@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:251365:5\ncallViewAction@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:251716:21\nexecEmbeddedViewsAction@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:251674:17\ncheckAndUpdateView@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:251366:5\ncallViewAction@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:251716:21\nexecComponentViewsAction@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:251648:13\ncheckAndUpdateView@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:251371:5\ncallViewAction@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:251716:21\nexecEmbeddedViewsAction@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:251674:17\ncheckAndUpdateView@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:251366:5\ncallViewAction@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:251716:21\nexecEmbeddedViewsAction@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:251674:17\ncheckAndUpdateView@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:251366:5\ncallViewAction@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:251716:21\nexecComponentViewsAction@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:251648:13\ncheckAndUpdateView@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:251371:5\ncallWithDebugContext@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:252619:39\ndebugCheckAndUpdateView@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:252156:12\n../../../core/esm5/core.js/&lt;/ViewRef_.prototype.detectChanges@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:249140:13\n../../../core/esm5/core.js/&lt;/ApplicationRef.prototype.tick/&lt;@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:243471:58\n../../../core/esm5/core.js/&lt;/ApplicationRef.prototype.tick@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:243471:13\nnext/&lt;@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:243304:99\n../../../../zone.js/dist/zone.js/&lt;/&lt;/ZoneDelegate.prototype.invoke@https://syndesis.192.168.42.235.nip.io/polyfills.bundle.js:7982:17\nonInvoke@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:242313:24\n../../../../zone.js/dist/zone.js/&lt;/&lt;/ZoneDelegate.prototype.invoke@https://syndesis.192.168.42.235.nip.io/polyfills.bundle.js:7981:17\n../../../../zone.js/dist/zone.js/&lt;/&lt;/Zone.prototype.run@https://syndesis.192.168.42.235.nip.io/polyfills.bundle.js:7732:24\n../../../core/esm5/core.js/&lt;/NgZone.prototype.run@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:242130:54\nnext@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:243304:69\n../../../core/esm5/core.js/&lt;/EventEmitter.prototype.subscribe/schedulerFn&lt;@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:241899:36\n../../../../rxjs/_esm5/Subscriber.js/SafeSubscriber.prototype.__tryOrUnsub@https://syndesis.192.168.42.235.nip.io/polyfills.bundle.js:3130:13\n../../../../rxjs/_esm5/Subscriber.js/SafeSubscriber.prototype.next@https://syndesis.192.168.42.235.nip.io/polyfills.bundle.js:3077:17\n../../../../rxjs/_esm5/Subscriber.js/Subscriber.prototype._next@https://syndesis.192.168.42.235.nip.io/polyfills.bundle.js:3018:9\n../../../../rxjs/_esm5/Subscriber.js/Subscriber.prototype.next@https://syndesis.192.168.42.235.nip.io/polyfills.bundle.js:2982:13\n../../../../rxjs/_esm5/Subject.js/Subject.prototype.next@https://syndesis.192.168.42.235.nip.io/polyfills.bundle.js:2715:17\n../../../core/esm5/core.js/&lt;/EventEmitter.prototype.emit@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:241879:24\ncheckStable@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:242278:13\nonLeave@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:242357:5\nonInvokeTask@https://syndesis.192.168.42.235.nip.io/vendor.bundle.js:242307:17\n../../../../zone.js/dist/zone.js/&lt;/&lt;/ZoneDelegate.prototype.invokeTask@https://syndesis.192.168.42.235.nip.io/polyfills.bundle.js:8014:17\n../../../../zone.js/dist/zone.js/&lt;/&lt;/Zone.prototype.runTask@https://syndesis.192.168.42.235.nip.io/polyfills.bundle.js:7782:28\n../../../../zone.js/dist/zone.js/&lt;/&lt;/ZoneTask.invokeTask@https://syndesis.192.168.42.235.nip.io/polyfills.bundle.js:8090:24\ninvokeTask@https://syndesis.192.168.42.235.nip.io/polyfills.bundle.js:9111:9\nglobalZoneAwareCallback@https://syndesis.192.168.42.235.nip.io/polyfills.bundle.js:9137:17\n"  __proto__: Object { stack: "",  } ApiConnectorCreateComponent.html:45:8 ERROR CONTEXT  ERROR CONTEXT {}elDef: Object { nodeIndex: 0, bindingIndex: 0, outputIndex: 0,  }elView: Object { def: {}, parent: {}, state: 268,  }nodeDef: Object { nodeIndex: 1, bindingIndex: 0, outputIndex: 1,  }nodeIndex: 1view: Object { def: {}, parent: {}, state: 268,  }__proto__: Object { elOrCompView: Getter, injector: Getter, component: Getter,  } ApiConnectorCreateComponent.html:45:8 &lt;/pre&gt; &lt;/details&gt;  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Display the available information and allow the user to proceed.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![screenshot-2018-4-10 syndesis 1](https://user-images.githubusercontent.com/1306050/38553577-fc287890-3cbf-11e8-8c78-585717d21114.png)  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt; Response from `POST /api/v1/connectors/custom/info` ```json {"actionsSummary":{"totalActions":1},"description":"description","icon":"data:image/svg+xml,%3Csvg%20xmlns%...","warnings":[{"error":"missing-schemes","message":"Unable to determine the scheme to use: Swagger specification does not provide a `schemes` definition and the Swagger specification was uploaded so the originating URL is lost.","property":"/schemes"},{"error":"missing-response-schema","message":"Operation GET /operation does not provide a response schema for code 200"}],"name":"title","properties":{"host":{"componentProperty":true,"deprecated":false,"description":"Scheme hostname and port to direct the HTTP requests to in the form of https://hostname:port. Can be configured at the endpoint component or in the correspoding REST configuration in the Camel Context. If you give this component a name (e.g. petstore) that REST configuration is consulted first rest-swagger next and global configuration last. If set overrides any value found in the Swagger specification RestConfiguration. Can be overriden in endpoint configuration.","displayName":"Host","group":"producer","javaType":"java.lang.String","kind":"property","label":"producer","required":false,"secret":false,"type":"string"},"basePath":{"componentProperty":true,"deprecated":false,"description":"API basePath for example /v2. Default is unset if set overrides the value present in Swagger specification.","displayName":"Base path","group":"producer","javaType":"java.lang.String","kind":"property","label":"producer","required":false,"secret":false,"type":"string"},"authenticationType":{"componentProperty":true,"defaultValue":"none","deprecated":false,"description":"Type of authentication used to connect to the API","displayName":"Authentication Type","group":"producer","javaType":"java.lang.String","kind":"property","label":"producer","required":false,"secret":false,"type":"string","tags":["authentication-type"],"enum":[{"label":"No Security","value":"none"}]},"specification":{"componentProperty":true,"deprecated":false,"description":"Swagger specification of the service","displayName":"Specification","group":"producer","javaType":"java.lang.String","kind":"property","label":"producer","required":false,"secret":false,"type":"hidden","tags":["upload","url"]}}} ```  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt; `POST /api/v1/connectors/custom/info`  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Try to create API connector with Swagger specification that has no tags </body>
		<created>2018-04-10 11:08:19</created>
		<closed>2018-04-11 07:41:46</closed>
	</bug>
	<bug>
		<id>2307</id>
		<title>Swagger specifications that are missing host/basePath/schemas fail to parse</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; We shouldn't fail for properties that the user can specify. For instance if a Swagger specification omits host/basePath or schemas we currently fail with an exception on `/api/v1/connectors/custom/info` endpoint and fail to provide the user with the feedback of the error. Omitting these can be done for Swagger specifications that are referenced via URL, as they can be determined from that URL. Users that download and then try to upload such specification will face issues.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Show errors/warnings on the Review Actions step of the API connector wizard. Let the user specify host/base path parameters.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![screenshot-2018-4-10 syndesis](https://user-images.githubusercontent.com/1306050/38552058-259e8980-3cbb-11e8-985a-446f538fb9b0.png)   ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt; ```http POST /api/v1/connectors/custom/info HTTP/1.1 Host: syndesis-staging.b6ff.rh-idev.openshiftapps.com Content-Length: 669 Content-Type: multipart/form-data; boundary=---------------------------10708986311158474562250751538  -----------------------------10708986311158474562250751538 Content-Disposition: form-data; name="specification"; filename="minimal_swagger.yaml" Content-Type: application/x-yaml  swagger: '2.0' info:   version: 0.0.0   title: title   description: description  paths:   /operation:     get:       summary: wat       responses:         200:           description: OK  -----------------------------10708986311158474562250751538 Content-Disposition: form-data; name="connectorSettings"; filename="connectorSettings" Content-Type: application/json  {"connectorTemplateId":"swagger-connector-template"} ```  ```http HTTP/1.1 500 Internal Server Error Content-Length: 295 Content-Type: application/json  {"errorCode":500,"userMsg":"Please contact the administrator and file a bug report","developerMsg":"Internal Server Exception. Swagger specification does not provide a `schemes` definition and the Swagger specification was uploaded so the originating URL is lost to determine the scheme to use"} ```  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt; `POST /api/v1/connectors/custom/info` `POST /api/v1/connectors/custom`  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Try to create API connector with minimal Swagger specification 2. 3. 4. </body>
		<created>2018-04-10 10:37:26</created>
		<closed>2018-04-11 15:47:04</closed>
	</bug>
	<bug>
		<id>2306</id>
		<title>host and basePath properties of API connector should be required</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Without `host` and `basePath` properties API connector is not valid. We should require the user to specify values when creating a connection for an API connector.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Require `host` and `basePath` to hold values.  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create API connector 2. Create a connection for that API connector without specifying (or removing) `Host` and `Base path` properties </body>
		<created>2018-04-10 10:09:21</created>
		<closed>2018-04-10 12:37:23</closed>
	</bug>
	<bug>
		<id>2302</id>
		<title>StaticEditionTest - Illegal key size or default parameters</title>
		<body>On my Mac I see the StaticEditionTest fail. Seems to work ok on our build environment though.   [ERROR] Failures:  [ERROR]   StaticEditionTest.shouldCreateEditionWithNonBase64Passwords:104 Unable to utilize encryption key: javax.crypto.spec.SecretKeySpec@17b0b [INFO]  [ERROR] Tests run: 67, Failures: 1, Errors: 0, Skipped: 0   java.lang.AssertionError: Unable to utilize encryption key: javax.crypto.spec.SecretKeySpec@15d1e at io.syndesis.server.endpoint.v1.state.StaticEditionTest$KeySourceAssert.canBeUsedForCryptography(StaticEditionTest.java:53) at io.syndesis.server.endpoint.v1.state.StaticEditionTest.shouldCreateEditionWithNonBase64Passwords(StaticEditionTest.java:104) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86) at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:538) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:760) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:460) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:206) Caused by: java.security.InvalidKeyException: Illegal key size or default parameters at javax.crypto.Cipher.checkCryptoPerm(Cipher.java:1026) at javax.crypto.Cipher.implInit(Cipher.java:801) at javax.crypto.Cipher.chooseProvider(Cipher.java:864) at javax.crypto.Cipher.init(Cipher.java:1249) at javax.crypto.Cipher.init(Cipher.java:1186) at io.syndesis.server.endpoint.v1.state.StaticEditionTest$KeySourceAssert.canBeUsedForCryptography(StaticEditionTest.java:51) ... 24 more </body>
		<created>2018-04-10 03:27:29</created>
		<closed>2018-04-10 14:23:01</closed>
	</bug>
	<bug>
		<id>2300</id>
		<title>Support page typo</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  "Troubleshooting" is misspelled:  &lt;img width="512" alt="screenshot 2018-04-09 16 51 00" src="https://user-images.githubusercontent.com/351660/38522409-74a93728-3c16-11e8-8d7c-b6e0130bcfbe.png"&gt; </body>
		<created>2018-04-09 20:53:07</created>
		<closed>2018-04-10 16:12:49</closed>
	</bug>
	<bug>
		<id>2297</id>
		<title>FTP Connection, UX Opportunities</title>
		<body>The Create and Edit page should have the fields in the same order. The starting order should probably be: host name username password  The Edit page should have a Validate Button always available w/o having to click the edit button.  The validate Button should be in the same place for both pages (create and edit).  Stretch Goal: The Validate button should be on every Connection in the same place.  Should this editor map to the primitives around editing content or artifacts that exist in (OpenShift.io, Decision Central, something else).  The popup Is, should tell you why I need to do something.  Why binary mode, why or why not do I choose this. Why or why not do I do passive. etc &lt;img width="252" alt="screen shot 2018-04-09 at 12 42 50 pm" src="https://user-images.githubusercontent.com/4389749/38516173-9c79bbd8-3bf3-11e8-913c-449f7498543a.png"&gt;</body>
		<created>2018-04-09 18:44:03</created>
		<closed>2018-04-11 09:53:46</closed>
	</bug>
	<bug>
		<id>2294</id>
		<title>Going to "support" breaks the toolbar styling on other pages</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem If you go to `/support` (from the help link in the toolbar), the toolbar border and box shadow goes away on other pages.  ## Expected behavior Going to `/support` shouldn't impact styles on other pages.  ## Tasks involved / Steps to Reproduce 1. Click the help icon in the top/right and choose "support" 2. Click on either "connections," "integrations," or "customizations" 3. Note the lack of a bottom border/shadow on the toolbar.  Possibly related to https://github.com/syndesisio/syndesis/issues/2276  cc @dongniwang </body>
		<created>2018-04-09 17:19:37</created>
		<closed>2018-04-17 17:11:13</closed>
	</bug>
	<bug>
		<id>2291</id>
		<title>Editing an integration does no longer work</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [*] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem When editing an integration the integration becomes invalid. Datamappings no longer work, config is wrong.  ## Expected behavior That it work work  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create an integration with data mapping 2. Publish and then try to edit the data mapping 3. The integration won't quite work anymore while editing the user is forced to start over.</body>
		<created>2018-04-09 16:38:52</created>
		<closed>2018-04-10 15:49:13</closed>
	</bug>
	<bug>
		<id>2289</id>
		<title>Telegram extension causes database connection failures</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem After adding the "telegram" extension and connection, using it in an integration, then updating the extension, the app will randomly start hanging (get the spinner icon on most pages). When I inspect the server log, I get a lot of postgres errors. I've uploaded my log files here - https://drive.google.com/file/d/1u-9w5VM4t_e1k8WRWsVwDeZ77dXZZjT9/view?usp=sharing  ## Tasks involved / Steps to Reproduce  I'm not sure at what point the app will start hanging, but following these steps will reliably reproduce the issue on my build.   1. Download the telegram extensions - https://drive.google.com/file/d/1NGjyKMr7xzJnKi6ct-E8Y04CwE9_jvnr/view?usp=sharing 2. Import the v1 extension 3. Setup a telegram connection 4. Publish an integration using the telegram connection (I used telegram to salesforce) 5. Update the telegram extension to v2 6. Just click click around and wait for pages to stop responding. </body>
		<created>2018-04-09 15:41:22</created>
		<closed>2018-04-11 07:38:16</closed>
	</bug>
	<bug>
		<id>2287</id>
		<title>Uploading an icon when creating an API connector is not working</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem I'm working with the staging site: https://syndesis-staging.b6ff.rh-idev.openshiftapps.com/ When I upload the todo app swagger.json file (by specifying the URL) and I upload an icon in the last review step before the connector is created, the icon I uploaded does not  appear. &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  ## Expected behavior When I upload an icon as part of creating an API connector then I expect the icon to appear in the details for the new API connector.  &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Click "Create API Connector" 2. Select use a URL and paste https://todo-syndesis-staging.b6ff.rh-idev.openshiftapps.com/swagger.json 3. Next &gt; Next &gt; Next 4. Click Browse and select a dropbox icon, which was just an icon I found for experimenting.  5. The dropbox icon appears:  ![image](https://user-images.githubusercontent.com/25067106/38500477-813246d0-3bd8-11e8-93ee-2fad723aed19.png) 6. Click "Create Connector". Then click the entry for the new connector to see its details.  7. The icon does not appear: ![image](https://user-images.githubusercontent.com/25067106/38500640-005aa970-3bd9-11e8-8f5d-7a73041c4912.png)    </body>
		<created>2018-04-09 13:37:25</created>
		<closed>2018-04-30 08:32:45</closed>
	</bug>
	<bug>
		<id>2280</id>
		<title>"Telegram" icon flickers on integration list page</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem If you import "Telegram" as an extension, make a connection out of it, and add it to an integration, the icon will flicker on the integration list page when that page content refreshes. The integration list content seems to refresh on some sort of interval, so just sit on that page and you should see the icon flicker.  I presume this problem exists elsewhere in the app (anywhere where the page refreshes like that) and could be an issue with any icon generated similarly to the telegram icon, and not a local file (i.e., `/api/v1/connectors/ext-io-syndesis-extensions-syndesis-connector-telegram/icon?extension:icon.png`)  ## Expected behavior Icon shouldn't flicker  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Import this extension https://drive.google.com/open?id=1Rg0IJXAlVRjFzq2AkELBQh254DxG5jts 2. Create a "telegram" connection 3. Create an integration with the telegram connection as the start or finish connection 4. Watch the integration list page for a few minutes </body>
		<created>2018-04-06 20:33:53</created>
		<closed>2019-02-05 17:29:06</closed>
	</bug>
	<bug>
		<id>2278</id>
		<title>Update URLs for links to customer portal user doc</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem The GA URLs for  Ignite user documentation on the Red Hat customer portal will be different than they were for the technology preview releases. The URLs no longer contain "jboss" and no longer contain "-tp".  &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  ## Expected behavior For GA, these are the correct URLs:  https://access.redhat.com/documentation/en-us/red_hat_fuse/7.0/html-single/integrating_applications_with_ignite/  https://access.redhat.com/documentation/en-us/red_hat_fuse/7.0/html-single/ignite_sample_integration_tutorials/  @fbolton could you please confirm that these URLs will be correct for GA? Thanks! &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  In the UI, the URLs need to be updated for - Selecting Help &gt; Sample Integration Tutorials  - Selecting  Help &gt; User Guide - Settings  page text ".. See the documentation for help."  This URL will be:  https://access.redhat.com/documentation/en-us/red_hat_fuse/7.0/html-single/integrating_applications_with_ignite/#obtaining-authorization-to-access-applications </body>
		<created>2018-04-06 20:12:16</created>
		<closed>2018-04-09 15:43:26</closed>
	</bug>
	<bug>
		<id>2277</id>
		<title>[Trivial] Update the email address for Contact Us for GA</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem In the staging UI, selecting Help &gt; Contact Us automatically displays fuse-ignite-tech-preview@redhat.com as the email address to send a message to. This will need to be something different for GA.  &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  ## Expected behavior @kcbabo  - What email address should this use? &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;     </body>
		<created>2018-04-06 20:01:15</created>
		<closed>2018-04-27 12:44:59</closed>
	</bug>
	<bug>
		<id>2276</id>
		<title>Breadcrumb not in full length on create API connector wizard pages </title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  In Create API Connector wizard, the breadcrumb on top of the page is not in full length and it looks larger than the usual ones. Also, the page is not displaying the correct breadcrumb.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  It should look like this:  ![image](https://user-images.githubusercontent.com/24943812/38438972-12dd900c-39aa-11e8-8519-3abc82fbd1b2.png)  Also, the correct breadcrumb should be: Home &gt; Customizations &gt; API Client Connector    ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![image](https://user-images.githubusercontent.com/24943812/38438852-bb7563b2-39a9-11e8-846c-83c12732f918.png)   ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create a new integration (I use twitter mention -&gt; salesforce update record) 1. Add a data mapper step (I map id -&gt; id) 1. Click "Customizations" 1. Click "Create API Connector" button </body>
		<created>2018-04-06 18:54:41</created>
		<closed>2018-04-17 01:45:32</closed>
	</bug>
	<bug>
		<id>2269</id>
		<title>Username should be displayed in header</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem The header across the entire application displays a user icon, but does not display the username alongside it. The original designs had the username and, in speaking with @dongniwang , we don't recall making a decision to remove it. Also, the code is still in the HTML template, so this is likely a bug, not a design change.  ## Expected behavior The username should be displayed.  ## Screenshot &lt;img width="1680" alt="screenshot 2018-04-06 11 12 44" src="https://user-images.githubusercontent.com/3844502/38429103-745bb88c-398b-11e8-8b93-b95d085adbbf.png"&gt; </body>
		<created>2018-04-06 15:13:49</created>
		<closed>2018-04-11 14:18:59</closed>
	</bug>
	<bug>
		<id>2262</id>
		<title>bin/install - fails to deploy older tags - workaround availble</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; `bin/install` script fails to deploy older tag. This is due to a change in the templates that broke retrocompatibility. As a workaround you can checkout the git tag corresponding to the tag you are trying to deploy and use that version of script and openshift templates.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. on current master run `bin/syndesis install --project myproject   --tag 1.3.4 --dev -y --verbose` 2. it will fail, being unable to set `OPENSHIFT_CONSOLE_URL` variable: `++(/data/repositories/work/syndesis/syndesis/tools/bin/commands/util/openshift_funcs:120): create_and_apply_template(): oc new-app --template=syndesis-dev -p ROUTE_HOSTNAME=myproject.192.168.42.202.nip.io -p OPENSHIFT_CONSOLE_URL= -p ` 3. 4. </body>
		<created>2018-04-06 08:08:56</created>
		<closed>2018-06-04 15:36:48</closed>
	</bug>
	<bug>
		<id>2251</id>
		<title>Newly created salesforce connection requires configuration</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Created a new salesforce connection using oauth2 via the Settings page.  After creating the connection, I found that the salesforce connection had a 'Configuration Required' message on it:  which is unexpected.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  I wouldn't expect any config updates needed for a connection that I just created and validated.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![capture](https://user-images.githubusercontent.com/351660/38376588-e78e986c-38c6-11e8-9e88-d6b898137fd9.PNG)  ![capture](https://user-images.githubusercontent.com/351660/38376667-1c188caa-38c7-11e8-97ba-b7ad52919217.PNG)  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Go to settings and plug your oauth creds into the salesforce client config 2. Create a new salesforce connection 3. See the above! 4. </body>
		<created>2018-04-05 15:48:23</created>
		<closed>2018-04-06 08:29:00</closed>
	</bug>
	<bug>
		<id>2247</id>
		<title>Integration data mapper issue</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Can't insert and edit data mapper step between twitter mention and salesforce create/update connections  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; I am able to add data mapper and edit it later.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create integration from Twitter Mention to Salesforce 2. In salesforce select create or update record --&gt; Contact --&gt;TwitterScreenName 3. insert data mapper step with some random mapping, it does not matter what 4. save integration as draft 5. navigate to integrations list 6. select the integration and click on Edit integration 7. note that there is error present - no data mapping step even though there is data mapper 8. click on data mapper step - it shows error 9. delete that data mapper step and try to create new one - it is not possible </body>
		<created>2018-04-05 14:30:34</created>
		<closed>2018-04-10 08:48:40</closed>
	</bug>
	<bug>
		<id>2246</id>
		<title>Imported integration shares history if integration with the same name already existed</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Imported integration shares history status if the same name was already used  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Imported integration has unique and new history, also there should be an option to change name of the integration which I am importing.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. import integration, I used this one  [Integration_import_export_test-export.zip](https://github.com/syndesisio/syndesis/files/1880359/Integration_import_export_test-export.zip)  2. publish the integration 3. delete the integration 4. import the integration again 5. check history of new imported integration - it shows that it was already published </body>
		<created>2018-04-05 14:15:40</created>
		<closed>2018-04-17 14:09:09</closed>
	</bug>
	<bug>
		<id>2245</id>
		<title>Imported integration has no status</title>
		<body>## This is a... &lt;!-- Check ONLY one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; After importing integration, there is no status of that integration in integration details or list.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; I would expect unpublished integration status after importing.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. import integration, I used this one [Integration_import_export_test-export.zip](https://github.com/syndesisio/syndesis/files/1880333/Integration_import_export_test-export.zip)  2. check integration status - there is none  </body>
		<created>2018-04-05 14:10:14</created>
		<closed>2018-04-06 08:06:41</closed>
	</bug>
	<bug>
		<id>2243</id>
		<title>Extensions - jdbc driver import doesn't work</title>
		<body>## This is a... [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request   ## The problem After adding extension with required jdbc driver, this is not loaded properly by SQL connector.  ## Expected behavior After adding extension with required jdbc driver, this driver is available for SQL connector.  ## Screenshot ![driver_unavailable](https://user-images.githubusercontent.com/2714974/38362320-a9f3b938-38d0-11e8-8404-0bbddc28af0e.png)   ## Request and Response Data URL: .../api/v1/connectors/sql/verifier  payload: {url: "jdbc:oracle:thin:@oracle-12cr1.hosts.mwqe.eng.bos.redhat.com:1521:dballo", user: "dballo15",} method: POST response: [{"status":"ERROR","scope":"PARAMETERS","errors":[{"code":"ILLEGAL_PARAMETER_VALUE","description":"No suitable driver found for jdbc:oracle:thin:@oracle-12cr1.hosts.mwqe.eng.bos.redhat.com:1521:dballo","parameters":["url"]}]}]  syndesis-meta log: [meta.log](https://github.com/syndesisio/syndesis/files/1880070/meta.log)    ## Tasks involved / Steps to Reproduce  1. download oracle driver ojdbc7.jar to: syndesis-extensions/syndesis-library-jdbc-driver/lib, (of the project git@github.com:syndesisio/syndesis-extensions.git) 2. in /syndesis-library-jdbc-driver/pom.xml change jdbc-driver systemPath to: ``` &lt;systemPath&gt;${project.basedir}/lib/ojdbc7.jar&lt;/systemPath&gt; ``` 2. mvn clean install 3. add target/syndesis-library-jdbc-1.0.0.jar file to Syndesis-&gt;Customizations-&gt;Extensions-&gt;Import Extension 4. wait until syndesis-meta pod has been recreated. 5. validate SQL connection to oracle DB:  (e.g:        Username: dballo15                Password: dballo15       atabase Name: dballo    Connection URL: jdbc:oracle:thin:@oracle-12cr1.hosts.mwqe.eng.bos.redhat.com:1521:dballo  ) </body>
		<created>2018-04-05 11:49:48</created>
		<closed>2018-05-10 11:36:15</closed>
	</bug>
	<bug>
		<id>2240</id>
		<title>Import multiple integrations</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Code seems to imply that we can export multiple integrations:  https://github.com/syndesisio/syndesis/blob/c9760574058f36a8ecd7c8f4d81c39b9f7e32a53/app/server/endpoint/src/main/java/io/syndesis/server/endpoint/v1/handler/integration/support/IntegrationSupportHandler.java#L155-L162  But we import only the first one:  https://github.com/syndesisio/syndesis/blob/c9760574058f36a8ecd7c8f4d81c39b9f7e32a53/app/server/endpoint/src/main/java/io/syndesis/server/endpoint/v1/handler/integration/support/IntegrationSupportHandler.java#L321-L340  ## Expected behavior If we export multiple integrations we should import multiple integrations.  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  `GET /integration-support/export.zip` `POST /integration-support/import` </body>
		<created>2018-04-05 09:11:22</created>
		<closed>2018-04-05 10:07:47</closed>
	</bug>
	<bug>
		<id>2238</id>
		<title>Action properties not shown for connector extensions</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  The [telegram extension](https://github.com/syndesisio/syndesis-extensions/tree/master/syndesis-connector-telegram) happens to have a `chatId` optional action property that is not shown in the ui.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  The `chatId` optional property should be shown and users can change the value.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; https://www.dropbox.com/s/l55toon79zosiar/Screenshot%20from%202018-04-05%2010-27-50.png?dl=0   ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  N/A  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt; N/A  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Import telegram extension 2. Create a telegram connection 3. Use it in a new integration 4. The `chatId` action property is not shown </body>
		<created>2018-04-05 08:32:35</created>
		<closed>2018-04-06 10:19:34</closed>
	</bug>
	<bug>
		<id>2223</id>
		<title>Should use HTTP method + path if summary is empty string</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Taken from https://github.com/syndesisio/syndesis/issues/1489#issuecomment-377207458, if summary text of an operation in Swagger file is empty, then we display `null`, we should display HTTP method and path instead.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Don't display `null` values.  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create API connector from a Swagger file that has `summary` of an operation as empty string </body>
		<created>2018-04-04 16:54:02</created>
		<closed>2018-04-10 08:26:33</closed>
	</bug>
	<bug>
		<id>2214</id>
		<title>Integration alert message formatting is off in list and details view</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Formatting problems with alert message on integration details and integration list pages.  ## Expected behavior Alignment/layout should be improved  ## Screenshot ![screen shot 2018-04-03 at 11 09 51 am](https://user-images.githubusercontent.com/35148959/38261461-ddc2159a-372f-11e8-9ebc-b34041b4dad8.png) ![screen shot 2018-04-03 at 11 09 35 am](https://user-images.githubusercontent.com/35148959/38261462-ddd3ff4e-372f-11e8-89b2-c0354065e15d.png)  ## Tasks involved / Steps to Reproduce 1. Create an integration 2. Update one of the connections 3. See alert on integration details and list views </body>
		<created>2018-04-03 16:13:30</created>
		<closed>2018-04-10 18:08:43</closed>
	</bug>
	<bug>
		<id>2211</id>
		<title>Creating API client connector, required fields need a required label</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem There is no visual indication which fields are required until you try to submit the form or focus out of the required field  ## Expected behavior There should be a red asterisk by the "Connector Name" label  ## Screenshot ![screen shot 2018-04-02 at 1 04 52 pm](https://user-images.githubusercontent.com/35148959/38208500-e0eea968-3676-11e8-838d-e1c7d2a6e9a9.png)  ## Tasks involved / Steps to Reproduce 1. Nav to Customizations 2. Create API Connector 3. Upload a swagger file (I used the todo app's) 4. Next through the steps until you get to the review step </body>
		<created>2018-04-02 18:09:46</created>
		<closed>2018-04-16 19:57:38</closed>
	</bug>
	<bug>
		<id>2209</id>
		<title>`syndesis build` executed on *fuse ignite 1.3* release fails</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; `syndesis build` executed on *fuse ignite 1.3* release fails:  [ERROR] Failed to execute goal org.apache.maven.plugins:maven-pmd-plugin:3.8:check (default) on project integration-project-generator: You have 1 PMD violation. For more details see: /hong/syndesis-fuse-ignite-1.3/app/integration/project-generator/target/pmd.xml  Contents on pmd.xml file -- https://gist.github.com/honghuac/eb14dfeb8601311c226323178eae28f6  </body>
		<created>2018-04-02 14:29:08</created>
		<closed>2018-04-05 10:07:45</closed>
	</bug>
	<bug>
		<id>2200</id>
		<title>Nullpointer exception during startup</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; This is observed from the test drive of the code from the current master branch.  Nullpointer exception was detected in a new deployment of **syndesis-rest** pod. https://gist.github.com/honghuac/76e239bbe7bf51422dc32b4c4ef0d278#file-gistfile1-txt-L11-L66  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; There should not be such exceptions during startup. </body>
		<created>2018-03-29 13:48:43</created>
		<closed>2018-03-30 12:35:53</closed>
	</bug>
	<bug>
		<id>2186</id>
		<title>Can no longer update an extension</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ x ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  After pulling the current master branch I can no longer seem to update an extension.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  Updating an extension via a jar with an incremented version and with property changes should be possible  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  error response:  ``` {"errorCode":500,"userMsg":"Please contact the administrator and file a bug report","developerMsg":"Internal Server Exception. There already exists a extension with name Telegram"} ```  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  When posting to:  ``` https://syndesis.192.168.1.127.nip.io/api/v1/extensions/i-L8hFeNWWCQSBnbQXdYFz/install ```  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Install an extension, in my case I used the syndesis-connector-telegram extension 2. Use the extension, though not sure if this is relevant 3. In the UI click 'update' from the extension list page 4. Upload a new version of the extension, in my case I incremented the `version` property in the pom and added a new property to the connection config.  @lburgazzoli FYI  blocks being able to complete #2151 as I can't trigger a connection message. </body>
		<created>2018-03-28 15:43:10</created>
		<closed>2018-03-29 20:48:08</closed>
	</bug>
	<bug>
		<id>2183</id>
		<title>Fix history icon for an integration that is being published.</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem and  Expected behavior while an integration is deploying, the new version in the history table should have a in progress icon instead of a check  ## Tasks involved / Steps to Reproduce 1. Deploy a new integration 2. 3. 4. </body>
		<created>2018-03-28 14:48:29</created>
		<closed>2018-03-29 06:22:43</closed>
	</bug>
	<bug>
		<id>2177</id>
		<title>LogStepHandler - Context ?</title>
		<body>https://github.com/syndesisio/syndesis/blob/414dff408386c8bf2b41df634b827f0604ccb225/app/integration/runtime/src/main/java/io/syndesis/integration/runtime/handlers/LogStepHandler.java#L52-L57  Hi @iocanel I have just stumbled in the above line, that look wrong since 2 different flags produce the same result.  I would have fixed this myself but I'm not sure what `context` is supposed to mean: `exchange` or just `headers`?  </body>
		<created>2018-03-28 11:41:40</created>
		<closed>2018-03-29 10:13:46</closed>
	</bug>
	<bug>
		<id>2167</id>
		<title>Endless "Unpublishing" state</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ x ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When I try to unpublish any integration, it stays in the "unpublishing" state endlessly.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  It should end in "unpublished" state.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![indefinite_unpublish](https://user-images.githubusercontent.com/4180208/37966802-ced6043a-31c9-11e8-8fce-e418ef53ecfb.gif)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create integration 2. Unpublish the integration 3. The integration stays in "unpublishing" state indefinitely </body>
		<created>2018-03-27 12:22:55</created>
		<closed>2018-04-12 16:42:55</closed>
	</bug>
	<bug>
		<id>2164</id>
		<title>Can't build Syndesis, Syndesis-cli is failing.</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem When building the full project, in syndesis-cli we get  ``` [INFO] --- duplicate-finder-maven-plugin:1.2.1:check (default) @ syndesis-cli --- [INFO] Checking compile classpath [INFO] Checking runtime classpath [INFO] Checking test classpath [WARNING] Found duplicate and different resources in [/home/oscerd/workspace/jboss-fuse/syndesis/app/cli/target/classes, io.syndesis.server:server-runtime:1.3-SNAPSHOT]: [WARNING]   application.yml [WARNING] Found duplicate classes/resources in compile classpath. [WARNING] Found duplicate and different resources in [/home/oscerd/workspace/jboss-fuse/syndesis/app/cli/target/classes, io.syndesis.server:server-runtime:1.3-SNAPSHOT]: [WARNING]   application.yml [WARNING] Found duplicate classes/resources in runtime classpath. [WARNING] Found duplicate and different resources in [/home/oscerd/workspace/jboss-fuse/syndesis/app/cli/target/classes, io.syndesis.server:server-runtime:1.3-SNAPSHOT]: [WARNING]   application.yml [WARNING] Found duplicate classes/resources in test classpath. . . . [ERROR] Failed to execute goal org.basepom.maven:duplicate-finder-maven-plugin:1.2.1:check (default) on project syndesis-cli: Found duplicate classes/resources! -&gt; [Help 1] ``` </body>
		<created>2018-03-27 08:00:16</created>
		<closed>2018-03-27 15:55:14</closed>
	</bug>
	<bug>
		<id>2155</id>
		<title>SQL deadlock detected after a soak test of 2M messages</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Having a soak test run on OCP, using NFS as a persistent volume for the postgres with 8 running mock integrations in total  (3x timer (1s) -&gt; amq, 2x amq -&gt; log, 3x timer (1s) -&gt; log )  after a weekend run (Uptime 2 days 20 hours 40 minutes), there are 2,171,371 Total Messages  the UI is unresponsive, with most of the API calls taking more than 30 seconds to run (30 seconds is the OpenShift HAProxy default limit)  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  Syndesis should be usable with even after the DB is filled with lots of message logs  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/ BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  (oc rsh to the syndesis-server pod) time curl -H "X-Forwarded-User: foobar" -H "X-Forwarded-Access-Token: foobar" 127.0.0.1:8080/api/v1/integration-support/overviews ` {   "items": [     {       "tags": [         "activemq",         "ext-io-syndesis-extensions-syndesis-connector-timer"       ],       "version": 2,       "deploymentVersion": 2,       "steps": [         {           "connection": {             "icon": "extension:icon.png",             "connectorId": "ext-io-syndesis-extensions-syndesis-connector-timer",             "name": "timer",             "id": "i-L8Hz5LixhoStjWXXQZ1z"           },           "stepKind": "endpoint",           "kind": "step",           "action": {             "name": "Simple Timer"           },           "id": "-L8HznxuOcxje_csrXF9"         },         {           "connection": {             "icon": "fa-puzzle-piece",             "connectorId": "activemq",             "name": "amq",             "id": "i-L8HzkmIxhoStjWXXQZ2z"           },           "stepKind": "endpoint",           "kind": "step",           "action": {             "name": "Publish messages"           },           "id": "-L8HzyniOcxje_csrXF9"         }       ],       "targetState": "Published",       "currentState": "Published",       "draft": false,       "name": "timer-amq",       "id": "i-L8I-AibxhoStjWXXQZ3z"     },     {       "tags": [         "activemq",         "ext-io-syndesis-extensions-syndesis-connector-log"       ],       "version": 1,       "deploymentVersion": 1,       "steps": [         {           "connection": {             "icon": "fa-puzzle-piece",             "connectorId": "activemq",             "name": "amq",             "id": "i-L8HzkmIxhoStjWXXQZ2z"           },           "stepKind": "endpoint",           "kind": "step",           "action": {             "name": "Subscribe for messages"           },           "id": "-L8IUSKVw1z3o5rWQZiE"         },         {           "connection": {             "icon": "extension:icon.png",             "connectorId": "ext-io-syndesis-extensions-syndesis-connector-log",             "name": "log",             "id": "i-L8HubiqxhoStjWXXQZ-z"           },           "stepKind": "endpoint",           "kind": "step",           "action": {             "name": "Simple Logger"           },           "id": "-L8IUUuqw1z3o5rWQZiE"         }       ],       "targetState": "Published",       "currentState": "Published",       "draft": false,       "name": "amq-log",       "id": "i-L8IUYHF-FH_bC1BYiKCz"     },     {       "tags": [         "activemq",         "ext-io-syndesis-extensions-syndesis-connector-timer"       ],       "version": 1,       "deploymentVersion": 1,       "steps": [         {           "connection": {             "icon": "extension:icon.png",             "connectorId": "ext-io-syndesis-extensions-syndesis-connector-timer",             "name": "timer",             "id": "i-L8Hz5LixhoStjWXXQZ1z"           },           "stepKind": "endpoint",           "kind": "step",           "action": {             "name": "Simple Timer"           },           "id": "-L8IUcFFw1z3o5rWQZiF"         },         {           "connection": {             "icon": "fa-puzzle-piece",             "connectorId": "activemq",             "name": "amq",             "id": "i-L8HzkmIxhoStjWXXQZ2z"           },           "stepKind": "endpoint",           "kind": "step",           "action": {             "name": "Publish messages"           },           "id": "-L8IUdzVw1z3o5rWQZiF"         }       ],       "targetState": "Published",       "currentState": "Published",       "draft": false,       "name": "timer-amq2",       "id": "i-L8IXmAN-FH_bC1BYiKDz"     },     {       "tags": [         "activemq",         "ext-io-syndesis-extensions-syndesis-connector-timer"       ],       "version": 1,       "deploymentVersion": 1,       "steps": [         {           "connection": {             "icon": "extension:icon.png",             "connectorId": "ext-io-syndesis-extensions-syndesis-connector-timer",             "name": "timer",             "id": "i-L8Hz5LixhoStjWXXQZ1z"           },           "stepKind": "endpoint",           "kind": "step",           "action": {             "name": "Simple Timer"           },           "id": "-L8IXqwJw1z3o5rWQZiG"         },         {           "connection": {             "icon": "fa-puzzle-piece",             "connectorId": "activemq",             "name": "amq",             "id": "i-L8HzkmIxhoStjWXXQZ2z"           },           "stepKind": "endpoint",           "kind": "step",           "action": {             "name": "Publish messages"           },           "id": "-L8IXsWPw1z3o5rWQZiG"         }       ],       "targetState": "Published",       "currentState": "Published",       "draft": false,       "name": "timer-amq3",       "id": "i-L8IXx8g-FH_bC1BYiKEz"     },     {       "tags": [         "activemq",         "ext-io-syndesis-extensions-syndesis-connector-log"       ],       "version": 1,       "deploymentVersion": 1,       "steps": [         {           "connection": {             "icon": "fa-puzzle-piece",             "connectorId": "activemq",             "name": "amq",             "id": "i-L8HzkmIxhoStjWXXQZ2z"           },           "stepKind": "endpoint",           "kind": "step",           "action": {             "name": "Subscribe for messages"           },           "id": "-L8IY8MBw1z3o5rWQZiI"         },         {           "connection": {             "icon": "extension:icon.png",             "connectorId": "ext-io-syndesis-extensions-syndesis-connector-log",             "name": "log",             "id": "i-L8HubiqxhoStjWXXQZ-z"           },           "stepKind": "endpoint",           "kind": "step",           "action": {             "name": "Simple Logger"           },           "id": "-L8IYB_iw1z3o5rWQZiI"         }       ],       "targetState": "Published",       "currentState": "Published",       "draft": false,       "name": "amq-log2",       "id": "i-L8IYE1l-FH_bC1BYiKFz"     },     {       "tags": [         "ext-io-syndesis-extensions-syndesis-connector-log",         "ext-io-syndesis-extensions-syndesis-connector-timer"       ],       "version": 1,       "deploymentVersion": 1,       "steps": [         {           "connection": {             "icon": "extension:icon.png",             "connectorId": "ext-io-syndesis-extensions-syndesis-connector-timer",             "name": "timer",             "id": "i-L8Hz5LixhoStjWXXQZ1z"           },           "stepKind": "endpoint",           "kind": "step",           "action": {             "name": "Simple Timer"           },           "id": "-L8ImSyB7KqrGvzWSSm9"         },         {           "connection": {             "icon": "extension:icon.png",             "connectorId": "ext-io-syndesis-extensions-syndesis-connector-log",             "name": "log",             "id": "i-L8HubiqxhoStjWXXQZ-z"           },           "stepKind": "endpoint",           "kind": "step",           "action": {             "name": "Simple Logger"           },           "id": "-L8ImUZ97KqrGvzWSSm9"         }       ],       "targetState": "Published",       "currentState": "Published",       "draft": false,       "name": "timer-log",       "id": "i-L8ImWoP-FH_bC1BYiKGz"     },     {       "tags": [         "ext-io-syndesis-extensions-syndesis-connector-log",         "ext-io-syndesis-extensions-syndesis-connector-timer"       ],       "version": 1,       "deploymentVersion": 1,       "steps": [         {           "connection": {             "icon": "extension:icon.png",             "connectorId": "ext-io-syndesis-extensions-syndesis-connector-timer",             "name": "timer",             "id": "i-L8Hz5LixhoStjWXXQZ1z"           },           "stepKind": "endpoint",           "kind": "step",           "action": {             "name": "Simple Timer"           },           "id": "-L8ImYv97KqrGvzWSSmA"         },         {           "connection": {             "icon": "extension:icon.png",             "connectorId": "ext-io-syndesis-extensions-syndesis-connector-log",             "name": "log",             "id": "i-L8HubiqxhoStjWXXQZ-z"           },           "stepKind": "endpoint",           "kind": "step",           "action": {             "name": "Simple Logger"           },           "id": "-L8Ima217KqrGvzWSSmA"         }       ],       "targetState": "Published",       "currentState": "Published",       "draft": false,       "name": "timer-log2",       "id": "i-L8ImcE7-FH_bC1BYiKHz"     },     {       "tags": [         "ext-io-syndesis-extensions-syndesis-connector-log",         "ext-io-syndesis-extensions-syndesis-connector-timer"       ],       "version": 1,       "deploymentVersion": 1,       "steps": [         {           "connection": {             "icon": "extension:icon.png",             "connectorId": "ext-io-syndesis-extensions-syndesis-connector-timer",             "name": "timer",             "id": "i-L8Hz5LixhoStjWXXQZ1z"           },           "stepKind": "endpoint",           "kind": "step",           "action": {             "name": "Simple Timer"           },           "id": "-L8ImoXu7KqrGvzWSSmB"         },         {           "connection": {             "icon": "extension:icon.png",             "connectorId": "ext-io-syndesis-extensions-syndesis-connector-log",             "name": "log",             "id": "i-L8HubiqxhoStjWXXQZ-z"           },           "stepKind": "endpoint",           "kind": "step",           "action": {             "name": "Simple Logger"           },           "id": "-L8ImqCw7KqrGvzWSSmB"         }       ],       "targetState": "Published",       "currentState": "Published",       "draft": false,       "name": "timer-log3",       "id": "i-L8ImsAR-FH_bC1BYiKIz"     }   ],   "totalCount": 8 } ` real12m6.170s  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Install the timer and log extensions 2. Deploy A-MQ broker 3. Create a few timer (1s) -&gt; amq   and  amq -&gt; log  integrations 4. let it run over a weekend 5. time API requests, responses used by UI need to be faster than millennials' attention span</body>
		<created>2018-03-26 11:18:07</created>
		<closed>2018-05-03 14:45:26</closed>
	</bug>
	<bug>
		<id>2147</id>
		<title>Message area overlaid with tabs on integration detail page</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  When an integration has messages they show up as inline alert boxes.  If you have the browser tools open these inline alert boxes get overlaid with the navigation tabs.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  The alert area should occupy space on the page properly and not get overlaid by the tabs.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![capture](https://user-images.githubusercontent.com/351660/37847171-49fb94ee-2ea6-11e8-905b-66e14e36564c.PNG)   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create an integration using a connection that has some configuration 1. Go to the connection detail page and change a configuration parameter for a connection 1. Go to the integration details page and look at what you've done. 1. ??? 1. PROFIT! </body>
		<created>2018-03-23 18:29:41</created>
		<closed>2018-03-24 08:57:41</closed>
	</bug>
	<bug>
		<id>2146</id>
		<title>Updating an existing connection causes a 404 response</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Changing a parameter on an existing connection and saving it causes an HTTP 404 error response.  The changes are still saved at least.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  Normally this should return HTTP 200.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  request URL -&gt; `https://syndesis.192.168.1.127.nip.io/api/v1/connections/i-L8DquY4w78OtY_k1OK-z`  response from the PUT request ``` {   "errorCode": 404,   "userMsg": "Please check your request data",   "developerMsg": "Entity Not Found Exception Integration Optional[i-L8D3Q3rw78OtY_k1OJsz] has been deleted" } ```  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Open the browser dev console and go to the network tab. 1. Create a connection, I guess maybe use it in an integration 1. Go to the connection detail page 1. Click 'Edit' and change a parameter 1.  Click 'Save'  If that doesn't do it, try deleting the integration and create a new one using the same connection, then go back and update the connection again.  It could be this occurred because I've used this connection in integrations that I've since deleted. </body>
		<created>2018-03-23 18:25:27</created>
		<closed>2018-04-17 13:51:30</closed>
	</bug>
	<bug>
		<id>2138</id>
		<title>AMQP: integration fails with exception `connectionFactory must be specified`</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Creating integration AMQP topic -&gt; AMQP topic fails with IllegalArgumentException in the runtime log.  ``` org.apache.camel.RuntimeCamelException: org.apache.camel.FailedToCreateRouteException: Failed to create route i-L8HsYGwiyBEXTVJXOjHz: Route(i-L8HsYGwiyBEXTVJXOjHz)[[From[amqp-1]] -&gt; [process[Pro... because of connectionFactory must be specified ```  Complete runtime log: https://gist.github.com/dsimansk/75538d919d1d985290a91e7ea6ca6640  Integration export: [AMQP publish-subscribe-request E2E-export.zip](https://github.com/syndesisio/syndesis/files/1841534/AMQP.publish-subscribe-request.E2E-export.zip)  AMQ template: https://github.com/syndesisio/syndesis-qe/blob/master/utilities/src/main/resources/templates/syndesis-amq.yml</body>
		<created>2018-03-23 12:50:13</created>
		<closed>2018-04-10 11:23:22</closed>
	</bug>
	<bug>
		<id>2130</id>
		<title>Activity Log Steps name are invalid for older integration versions.</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem ActivityLog step ids are specific to a given version of an activity.  The Activity log list can have activities from multiple versions of the integration.  Instead of using the current integration's definitions of what the steps are, it should use the integrations at the version specified in the activity to map the step ids.   The logic that needs updating is here: https://github.com/syndesisio/syndesis/blob/master/app/ui/src/app/integration/integration_detail/integration_activity/integration-activity.component.ts#L60  ## Steps to reproduce:  1) Run an integration, have it generate some activity. 2) edit the integration and replace steps with new steps.  Run the new version of the integration, generate some activity.   3) View integration Activity, new activity will display correctly, old activity will no since it's steps have been removed in the current integration.</body>
		<created>2018-03-22 15:59:27</created>
		<closed>2018-03-27 19:16:51</closed>
	</bug>
	<bug>
		<id>2124</id>
		<title>[Api connector] Delete connector button disabled when any related connection being used in an integration</title>
		<body>As it was discussed in https://github.com/syndesisio/syndesis/issues/1827 the Delete button should be enabled even if any related connection is being used in an integration.  Current warning displayed when deleting a connector doesn't correspond with current state. It had been agreed the warning is ok. It should be only possible to delete connectors anytime without consequences on running integrations.  I think this may be fixed after: [Api connector] Created connection data missing when related connector deleted https://github.com/syndesisio/syndesis/issues/2123</body>
		<created>2018-03-22 09:39:34</created>
		<closed>2018-06-05 18:39:43</closed>
	</bug>
	<bug>
		<id>2123</id>
		<title>[Api connector] Created connection data missing when related connector deleted </title>
		<body>## Steps to Reproduce  1. create a new custom connector 2. create a new connection from the connector 3. delete the connector  - the connection detail can't be opened  - there is also missing icon on the connection card - the connection can't be used in a new integration - it is not displayed in a list of available connections when creating an integration  It seems that if you delete a connector, then you lose all data of related connections.  The topic discussed in: https://github.com/syndesisio/syndesis/issues/1827 Fix causing the issue (probably): https://github.com/syndesisio/syndesis/pull/1958</body>
		<created>2018-03-22 09:27:05</created>
		<closed>2018-06-04 14:56:12</closed>
	</bug>
	<bug>
		<id>2122</id>
		<title>Adding a custom step causes a java.lang.IllegalArgumentException</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; This error appears in the integration pod log -- java.lang.IllegalArgumentException: PropertiesComponent with name properties must be defined in CamelContext to support property placeholders.  Full trace: https://gist.github.com/honghuac/ee422a0f9353be4348c7897a6efd45a2  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; This error should not appear, especially when FTP connector was successfully validated.  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt; Request -- data from http://product-catalog-lab3-product-catalog-service.apps.na1.openshift.opentlc.com/ Response -- data found on a remote host  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt; 1. Start Connection -- HTTP Connector 2. Finish Connection -- FTP Connector   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Existing integration that works runs smoothly. 2. Then, a custom step is added between the two connectors. 3. The integration is republished. 4. Error appears in the integration pod log. 5. Publishing is unsuccessful. </body>
		<created>2018-03-22 09:18:31</created>
		<closed>2018-04-11 12:18:41</closed>
	</bug>
	<bug>
		<id>2121</id>
		<title>Page redirection after technical extension creation</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Currently page redirection of the console, after successful import of tech extension, leads to the _Extension Import_ page .  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  It should be redirecting to the Extensions landing page instead: **https://host.name/customizations/extensions**</body>
		<created>2018-03-22 08:40:57</created>
		<closed>2018-04-17 17:30:55</closed>
	</bug>
	<bug>
		<id>2118</id>
		<title>Integration list page UI</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem * There is no padding at the top of the list in FF (screenshot) * CSS can be cleaned up and can utilize the scrollable body helpers  ## Expected behavior * List needs padding in FF * CSS should utilize helpers  ## Screenshot ![screen shot 2018-03-21 at 4 21 18 pm](https://user-images.githubusercontent.com/35148959/37738140-119a75c6-2d24-11e8-886e-3958aba7f223.png)</body>
		<created>2018-03-21 21:22:51</created>
		<closed>2018-03-22 15:30:16</closed>
	</bug>
	<bug>
		<id>2109</id>
		<title>Datamapper: Done button changed to Next since 1.3.2 version</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem For quiet some time the button in Datamapper UI was named `Done`, but now it's `Next`.  For the same integration steps DB (Periodic invoke) -&gt; DB (Stored procedure) the button values are different between 1.3.2 and master.  This values seems to be dynamic based on `step.configuredProperties`. Was there some recent changed in incoming properties?  https://github.com/syndesisio/syndesis/blob/989e089fe7141af1d82a8975e08ea4c0bc7eb1c3/app/ui/src/app/integration/edit-page/step-configure/step-configure.component.html#L3-L16   ## Screenshot  ![screen shot 2018-03-21 at 14 24 14](https://user-images.githubusercontent.com/5637792/37712251-9850f326-2d13-11e8-9df5-2ab06bdf2b00.png)  ![screen shot 2018-03-21 at 14 23 42](https://user-images.githubusercontent.com/5637792/37712252-98765b34-2d13-11e8-8333-5f978b5e6ff3.png)   ## Expected behavior Datamapper UI should be closed with `Done` button.  </body>
		<created>2018-03-21 13:23:18</created>
		<closed>2018-03-22 15:01:52</closed>
	</bug>
	<bug>
		<id>2104</id>
		<title>CSRF exploit using flash plugin</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem CSRF exploit using flash plugin.  ## Expected behavior 3rd party pages not being able to use Syndesis APIs.  ## Tasks involved / Steps to Reproduce  Reported by Andrej Vano.   He stated:  &gt; "Basic" CSRF attempts are blocked by CORS, but this method is able to bypass the CORS settings using a remote server and one flash file. &gt;  &gt; Here is the example that can be used against Syndesis (case 2): https://www.geekboy.ninja/blog/exploiting-json-cross-site-request-forgery-csrf-using-flash/ . &gt;  &gt; For the demonstration I used only the json "{"name":"attacker"}" that was sent to https://app-proj232514.6a63.fuse-ignite.openshiftapps.com/api/v1/connections that ended up creating a new connector with name "attacker". &gt; see:  https://www.geekboy.ninja/blog/exploiting-json-cross-site-request-forgery-csrf-using-flash/ </body>
		<created>2018-03-21 12:50:11</created>
		<closed>2018-08-02 09:06:29</closed>
	</bug>
	<bug>
		<id>2103</id>
		<title>Cannot create connection if connectors has no options</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; I tried to create a connection from a connector (created from a extension) that has no option. Apart from the fact that connections should be auto-created if the connector has no options (but this has to be discussed), now I cannot create a connection because code in the ui ([here](https://github.com/syndesisio/syndesis/blob/34080b96b7dc8e9d09b6549c85d20e46ed20ed3c/app/ui/src/app/connections/create-page/current-connection.ts#L253)) assumes that `properties` is defined in the connector, but it's not in this case.  ## Expected behavior Connections should be created successfully from connectors without properties to configure.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; N/A  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt; N/A  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt; N/A  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Build the syndesis-extension repo (`mvn clean install`) 2. Import the webhook (or timer) extension jar (from the target dir) using syndesis ui 3. Go to connections and create a connection from the webhook (or timer) connector 4. In the review page, write down a name and click on "Create" 5. A "null-reference" error appears in the console </body>
		<created>2018-03-21 12:47:00</created>
		<closed>2018-03-21 18:13:59</closed>
	</bug>
	<bug>
		<id>2101</id>
		<title>Integrations - User is randomly redirected to the Datamapper upon creating a basic step</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem For some weird reason (mostly related to the fact that monster component of `IntegrationStepSelectComponent` redirects users depending on Integration select/update events), the user is randomly redirected to the datamapper (`/integrations/{id}/edit/step-configure/1`) while creating a basic step or even just by clicking on `Basic Step` upon choosing the step type upfront.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Once clicking on "Basic Step", users should stay at the edit basic step page/component all the time until they click elsewhere to leave that page.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; N/A  ## Steps to Reproduce 1. Create an Integration and make sure there is a Datamapper intermediate step 2. Click "Edit Integration" and add a step BEFORE the Datamapper step. Choose "Basic Step". 3. At this stage, the problem might arise already. Otherwise got o [4] 4. Enter a filter step item and wait... </body>
		<created>2018-03-21 12:37:37</created>
		<closed>2018-04-17 17:48:10</closed>
	</bug>
	<bug>
		<id>2097</id>
		<title>Integration published state is incorrect</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Using the master branch code (dated March 21st), the integrations I now create do not reflect the correct publish status. Integration is indicated as not published, when it is actually active and working fine.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; State of integration needs to be synchronized with its active / dormant state.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![pub-bug](https://user-images.githubusercontent.com/8625482/37703221-e521b6c4-2d2f-11e8-961c-ab626a8bb7b8.png) </body>
		<created>2018-03-21 09:47:22</created>
		<closed>2018-07-18 13:57:33</closed>
	</bug>
	<bug>
		<id>2095</id>
		<title>Missing log entries</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; For an periodic sql query integrations start point with a period of 5 secondes, there seems some entries missing at the start:  ![image](https://user-images.githubusercontent.com/99080/37698704-4cd37b78-2ce4-11e8-9cf1-30f5d030124a.png)  Note that 10s distance between the first three entries. After this, period is always 5 seconds as it should be.</body>
		<created>2018-03-21 07:46:56</created>
		<closed>2018-06-07 17:34:17</closed>
	</bug>
	<bug>
		<id>2091</id>
		<title>Basic Filter UI</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem * no placeholder text for property name * condition dropdown has empty options * field hint/description wraps beside input * multiple rows wrap weird (floating issues)  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; * placeholder for property name should be "Property name" * dropdown shouldn't have empty options * hint should display below input * rows should wrap properly  ## Screenshot ![screen shot 2018-03-20 at 5 22 01 pm](https://user-images.githubusercontent.com/35148959/37685927-59cbb9ac-2c63-11e8-9e61-4c1ed62ed5a8.png)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create/edit integration 2. Add step 3. Choose "Basic Filter" 4. profit!  cc @dongniwang </body>
		<created>2018-03-20 22:23:43</created>
		<closed>2018-03-21 20:37:00</closed>
	</bug>
	<bug>
		<id>2086</id>
		<title>Extensions without icon should display a default one</title>
		<body>## This is a...  &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem No icon is displayed if a extension does not embed a icon.png or icon.pdf file.  ## Expected behavior A default icon, like the one used by api-client connectors should be used instead.  ## Screenshot N/A  ## Request and Response Data N/A  ## API Endpoints and Schemas N/A  ## Tasks involved / Steps to Reproduce 1. Create an extension of type connector without a icon.png file in META-INF/syndesis 2. Import the extension in Syndesis 3. Create a connection from the extension connector 4. The connection does not show a icon </body>
		<created>2018-03-20 16:45:55</created>
		<closed>2018-03-22 14:59:39</closed>
	</bug>
	<bug>
		<id>2075</id>
		<title>Syndesis Maven Plugin duplicates dependencies</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem I created a custom step extension project and ran the build which triggers the syndesis maven plugin to generate the json file. When looking at the json file I discovered the dependency entry duplicated but with different versions....one which was already in the source version of the json and then the new version taken from the pom.xml by the plugin.  ## Expected behavior I would have expected that the existing dependencies are reused in the json. In my case the 1.3-SNAPSHOT dependency should have been overwritten with the 1.3.0.fuse-000014 version instead of duplicating that dependency which makes no sense at all.  ## Screenshot The generated JSON: https://gist.github.com/lhein/e745970c811cc60da043668fb7c9466f The Project POM: https://gist.github.com/lhein/04771457354513dfc330c568f2fa3bb0 The original json in my project sources: https://gist.github.com/lhein/0356471d7aacedb3f8ae0290a107ba3c  ## Request and Response Data not applicable  ## API Endpoints and Schemas not appilicable   ## Tasks involved / Steps to Reproduce 1. create a step extension project and enter version 1.3-SNAPSHOT as shown in the gists 2. edit the pom.xml and change the syndesis version to 1.3.0.fuse-000014 3. run the build to regenerate the json file and build the jar 4. open the jar and check the json </body>
		<created>2018-03-20 06:59:46</created>
		<closed>2018-03-20 18:57:23</closed>
	</bug>
	<bug>
		<id>2071</id>
		<title>DB-to-DB integration: No action available</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Creating a DB-to-DB integration on master, doesn't allow you to specify the action for the end connection.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![image](https://user-images.githubusercontent.com/99080/37612043-4d7c7124-2ba4-11e8-8eaa-066d2f1976e1.png)  ## Request and Response Data &lt;!-- Many issues involve both the UI and it's backend, if possible capture relevant request and response data JSON messages and include it here. Request and response data can be gathered from your browser's developer tools on the 'Network' tab.    + As you reproduce the issue, take note of any network requests that are made.    + Requests that result in an error will be highlighted red.    + Click on line in the network tab and then the 'Headers' tab to get the request data  + Click on the 'Preview' or 'Response' tabs to get the response data.    + Pretty print the json too -&gt; http://jsonprettyprint.com/  BE CAREFUL NOT TO INCLUDE ANY USER TOKENS!!!!   Things like connection objects can contain sensitive data in their configuration, make sure to rip these out --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. New integration 2. Select "DB Connection" 3. Select "Periodic SQL" --&gt; "select * from contact" 4. "Done" 5. Select "DB ConnectioN" 6. No action offered  </body>
		<created>2018-03-19 17:38:12</created>
		<closed>2018-03-19 17:41:09</closed>
	</bug>
	<bug>
		<id>2065</id>
		<title>Monitoring - Activity: error to display data since 1.3.2 tag</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem It seems there's a regression in `1.3.2` and latest master that prevents displaying of activities. It's working as expected on `1.3.1`. The error from browser console below.   @deeleman is it related to the commit https://github.com/syndesisio/syndesis/commit/c779240933fefcafa8b037012e942a0aa30c582d ?  ``` 2018-03-19 13:47:39,091 ERROR [root] Error fetching activity records for integration ID i-L7yH_pRYe2XVUXIaQEvz TypeError: Cannot read property 'forEach' of undefined @ {anonymous}()@https://syndesis.192.168.64.17.nip.io/common.chunk.js:7226:32   SafeSubscriber._next()@https://syndesis.192.168.64.17.nip.io/common.chunk.js:7225:26   SafeSubscriber.webpackJsonp.../../../../rxjs/_esm5/Subscriber.js.SafeSubscriber.__tryOrSetError()@https://syndesis.192.168.64.17.nip.io/polyfills.bundle.js:2926:16   SafeSubscriber.webpackJsonp.../../../../rxjs/_esm5/Subscriber.js.SafeSubscriber.next()@https://syndesis.192.168.64.17.nip.io/polyfills.bundle.js:2866:27   Subscriber.webpackJsonp.../../../../rxjs/_esm5/Subscriber.js.Subscriber._next()@https://syndesis.192.168.64.17.nip.io/polyfills.bundle.js:2805:26   Subscriber.webpackJsonp.../../../../rxjs/_esm5/Subscriber.js.Subscriber.next()@https://syndesis.192.168.64.17.nip.io/polyfills.bundle.js:2769:18   DoSubscriber.webpackJsonp.../../../../rxjs/_esm5/operators/tap.js.DoSubscriber._next()@https://syndesis.192.168.64.17.nip.io/polyfills.bundle.js:6161:24   DoSubscriber.webpackJsonp.../../../../rxjs/_esm5/Subscriber.js.Subscriber.next()@https://syndesis.192.168.64.17.nip.io/polyfills.bundle.js:2769:18   CatchSubscriber.webpackJsonp.../../../../rxjs/_esm5/Subscriber.js.Subscriber._next()@https://syndesis.192.168.64.17.nip.io/polyfills.bundle.js:2805:26 ```  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot ![screen shot 2018-03-19 at 13 53 08](https://user-images.githubusercontent.com/5637792/37596639-27e8d23a-2b7d-11e8-9341-2b1bf1078785.png)   ## Request and Response Data  ```json [   {     "id": "i-L7yJe-qTeealRdrBnaqz",     "logts": "2018-03-19T12:53:45.143107529Z",     "at": 1521464025142,     "pod": "i-db-db-2-btl8t",     "ver": "1",     "status": "done",     "failed": false   },   {     "id": "i-L7yJbZaTeealRdrBnakz",     "logts": "2018-03-19T12:53:35.143932271Z",     "at": 1521464015142,     "pod": "i-db-db-2-btl8t",     "ver": "1",     "status": "done",     "failed": false   },   {     "id": "i-L7yJ_7KTeealRdrBnaez",     "logts": "2018-03-19T12:53:25.143172743Z",     "at": 1521464005141,     "pod": "i-db-db-2-btl8t",     "ver": "1",     "status": "done",     "failed": false   },   {     "id": "i-L7yJXg4TeealRdrBnaZz",     "logts": "2018-03-19T12:53:15.142806427Z",     "at": 1521463995141,     "pod": "i-db-db-2-btl8t",     "ver": "1",     "status": "done",     "failed": false   },   {     "id": "i-L7yJVEpTeealRdrBnaTz",     "logts": "2018-03-19T12:53:05.143404102Z",     "at": 1521463985141,     "pod": "i-db-db-2-btl8t",     "ver": "1",     "status": "done",     "failed": false   },   {     "id": "i-L7yJSnaTeealRdrBnaNz",     "logts": "2018-03-19T12:52:55.159079232Z",     "at": 1521463975142,     "pod": "i-db-db-2-btl8t",     "ver": "1",     "status": "done",     "failed": false   },   {     "id": "i-L7yJQMKTeealRdrBnaHz",     "logts": "2018-03-19T12:52:45.143426388Z",     "at": 1521463965141,     "pod": "i-db-db-2-btl8t",     "ver": "1",     "status": "done",     "failed": false   },   {     "id": "i-L7yJNv4TeealRdrBnaBz",     "logts": "2018-03-19T12:52:35.141632623Z",     "at": 1521463955141,     "pod": "i-db-db-2-btl8t",     "ver": "1",     "status": "done",     "failed": false   },   {     "id": "i-L7yJLToTeealRdrBna5z",     "logts": "2018-03-19T12:52:25.159943592Z",     "at": 1521463945140,     "pod": "i-db-db-2-btl8t",     "ver": "1",     "status": "done",     "failed": false   },   {     "id": "i-L7yJJ1ZTeealRdrBna-z",     "logts": "2018-03-19T12:52:15.141258436Z",     "at": 1521463935140,     "pod": "i-db-db-2-btl8t",     "ver": "1",     "status": "done",     "failed": false   } ] ```  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create simple DB-&gt;DB integration 2. Wait until `Published` 3. Check detail view -&gt; Activity tab </body>
		<created>2018-03-19 12:55:55</created>
		<closed>2018-03-20 19:00:07</closed>
	</bug>
	<bug>
		<id>2063</id>
		<title>No Data Type Specification was found error - when using Data Mapper</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [X] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; A "No Data Type Specification was found error" appears - when using Data Mapper - either as a step for a Salesforce Start Connection or a step for PostgresDB Start Connection. Also, more documentation + console tips should be created to help the developer with the use of Data Mapper.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Data Mapper should be able to recognise the Salesforce or PostgresDB schema.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![no-data-type](https://user-images.githubusercontent.com/8625482/37581417-797a22d8-2b83-11e8-8da7-da47418a8d18.png)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Set up a Salesforce connection as Start connection. Choose PostgresDB as a Finish connection. 2. Add a step between both connections. Note that the error appears. 3. Cancel the integration and start over. 4. Set up a PostgresDB connection as Start connection. Set up any connector as a Finish connection. 5. Add a step between both connections. Note that the error appears too.</body>
		<created>2018-03-19 06:40:35</created>
		<closed>2018-03-20 13:24:09</closed>
	</bug>
	<bug>
		<id>2062</id>
		<title>PostgresDB Connection yields no available actions</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; PostgresDB Connection used to provide a short list of actions: SQL Statement and Stored Procedure. It no longer does when set as a Finish Connection.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; PostgresDB Connection used to provide a short list of actions: SQL Statement and Stored Procedure.   ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![empty](https://user-images.githubusercontent.com/8625482/37580975-6f7b6686-2b81-11e8-9fec-eaf377ce82f1.png) ![empty2](https://user-images.githubusercontent.com/8625482/37581066-db97b888-2b81-11e8-809a-3b2a55974f41.png)   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Setup PostgresDB as the Finish Connection in any integration 2. No actions are shown</body>
		<created>2018-03-19 06:25:58</created>
		<closed>2018-03-19 18:03:58</closed>
	</bug>
	<bug>
		<id>2057</id>
		<title>syndesis-db never comes up again on restart</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When `syndesis-db` is stopped for any reason, OpenShift tries to restart it. But it will fail repeatedly todo so.  The error from the pod's log  ``` pg_ctl: another server might be running; trying to start server anyway waiting for server to start....LOG:  redirecting log output to logging collector process HINT:  Future log output will appear in directory "pg_log".  done server started ERROR: tuple already updated by self ```  There is no known way how to recover from this state except a **complete reinstallation**  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Just kill pod `syndesis-db` manually and see what happens </body>
		<created>2018-03-17 09:07:13</created>
		<closed>2018-03-19 13:54:06</closed>
	</bug>
	<bug>
		<id>2054</id>
		<title>Java Console cannot be opened on Syndesis pods</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ *] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem When going to the Openshift console and trying to open a java-console for either the syndesis-rest or syndesis-meta pod - it's not connecting.  ## Expected behavior Seeing the java console  ## Screenshot &lt;img width="774" alt="screen shot 2018-03-16 at 3 33 30 pm" src="https://user-images.githubusercontent.com/35576/37541066-a28b48ba-292f-11e8-9570-3ddd1848ed5e.png"&gt;   </body>
		<created>2018-03-16 19:35:51</created>
		<closed>2018-10-30 05:11:35</closed>
	</bug>
	<bug>
		<id>2051</id>
		<title>[AtlasMap] Integer Constant is treated as String</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [*] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Similar to https://github.com/syndesisio/syndesis/issues/2050 but with the constant set to type 'Integer' and value 1.  ## Expected behavior Should be able to insert a value of 1 into the 'completed' field.  Instead the resulting integration throws the following error:  &gt;  &gt; {"exchange":"i-L7j_ZX37p9Zk4j5no5Uz","status":"begin"} &gt; 2018-03-16 16:13:20.903 ERROR 1 --- [r://integration] o.a.camel.processor.DefaultErrorHandler  : Failed delivery for (MessageId: i-L7j_ZX57p9Zk4j5no5Vz on ExchangeId: i-L7j_ZX37p9Zk4j5no5Uz). Exhausted after delivery attempt: 1 caught: java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Integer &gt;  &gt; Message History &gt; --------------------------------------------------------------------------------------------------------------------------------------- &gt; RouteId              ProcessorId          Processor                                                                        Elapsed (ms) &gt; [i-L7jZmiEvIU90a4JF] [i-L7jZmiEvIU90a4JF] [timer://integration?period=1000                                               ] [         3] &gt; [i-L7jZmiEvIU90a4JF] [-L7jZVXJck98mnwjQ_] [sql-stored-1                                                                  ] [         1] &gt; [i-L7jZmiEvIU90a4JF] [-L7jZVXJck98mnwjQ_] [Processor@0x633fe06c                                                          ] [         0] &gt; [i-L7jZmiEvIU90a4JF] [to1               ] [atlas:mapping-step-2.json?sourceMapName=Syndesis.CAPTURED_OUT_MESSAGES_MAP    ] [         1] &gt;  &gt; Stacktrace &gt; --------------------------------------------------------------------------------------------------------------------------------------- &gt;  &gt; java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Integer &gt; at io.atlasmap.json.core.JsonFieldWriter.createValueNode(JsonFieldWriter.java:237) ~[atlas-json-core-1.33.5.jar!/:1.33.5] &gt; at io.atlasmap.json.core.JsonFieldWriter.writeValue(JsonFieldWriter.java:127) ~[atlas-json-core-1.33.5.jar!/:1.33.5] &gt; at io.atlasmap.json.core.JsonFieldWriter.write(JsonFieldWriter.java:116) ~[atlas-json-core-1.33.5.jar!/:1.33.5] &gt; at io.atlasmap.json.module.JsonModule.processTargetFieldMapping(JsonModule.java:160) ~[atlas-json-module-1.33.5.jar!/:1.33.5] &gt; at io.atlasmap.core.DefaultAtlasContext.processTargetFieldMappings(DefaultAtlasContext.java:420) ~[atlas-core-1.33.5.jar!/:1.33.5] &gt; at io.atlasmap.core.DefaultAtlasContext.process(DefaultAtlasContext.java:272) ~[atlas-core-1.33.5.jar!/:1.33.5] &gt; at org.apache.camel.component.atlasmap.AtlasEndpoint.onExchange(AtlasEndpoint.java:194) ~[camel-atlasmap-1.33.5.jar!/:na] &gt; at org.apache.camel.impl.ProcessorEndpoint$1.process(ProcessorEndpoint.java:71) ~[camel-core-2.20.1.jar!/:2.20.1] &gt; at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.20.1.jar!/:2.20.1] &gt; at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) ~[camel-core-2.20.1.jar!/:2.20.1] &gt; at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ~[camel-core-2.20.1.jar!/:2.20.1] &gt; at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.20.1.jar!/:2.20.1] &gt; at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.20.1.jar!/:2.20.1] &gt; at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.20.1.jar!/:2.20.1] &gt; at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.20.1.jar!/:2.20.1] &gt; at org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197) [camel-core-2.20.1.jar!/:2.20.1] &gt; at org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79) [camel-core-2.20.1.jar!/:2.20.1] &gt; at java.util.TimerThread.mainLoop(Timer.java:555) [na:1.8.0_151] &gt; at java.util.TimerThread.run(Timer.java:505) [na:1.8.0_151] &gt;  &gt; {"exchange":"i-L7j_ZX37p9Zk4j5no5Uz","status":"done","failed":true} &gt; 2018-03-16 16:13:20.904  WARN 1 --- [r://integration] o.a.camel.component.timer.TimerConsumer  : Error processing exchange. Exchange[i-L7j_ZX37p9Zk4j5no5Uz]. Caused by: [java.lang.ClassCastException - java.lang.String cannot be cast to java.lang.Integer] &gt;  &gt; java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Integer &gt; at io.atlasmap.json.core.JsonFieldWriter.createValueNode(JsonFieldWriter.java:237) ~[atlas-json-core-1.33.5.jar!/:1.33.5] &gt; at io.atlasmap.json.core.JsonFieldWriter.writeValue(JsonFieldWriter.java:127) ~[atlas-json-core-1.33.5.jar!/:1.33.5] &gt; at io.atlasmap.json.core.JsonFieldWriter.write(JsonFieldWriter.java:116) ~[atlas-json-core-1.33.5.jar!/:1.33.5] &gt; at io.atlasmap.json.module.JsonModule.processTargetFieldMapping(JsonModule.java:160) ~[atlas-json-module-1.33.5.jar!/:1.33.5] &gt; at io.atlasmap.core.DefaultAtlasContext.processTargetFieldMappings(DefaultAtlasContext.java:420) ~[atlas-core-1.33.5.jar!/:1.33.5] &gt; at io.atlasmap.core.DefaultAtlasContext.process(DefaultAtlasContext.java:272) ~[atlas-core-1.33.5.jar!/:1.33.5] &gt; at org.apache.camel.component.atlasmap.AtlasEndpoint.onExchange(AtlasEndpoint.java:194) ~[camel-atlasmap-1.33.5.jar!/:na] &gt; at org.apache.camel.impl.ProcessorEndpoint$1.process(ProcessorEndpoint.java:71) ~[camel-core-2.20.1.jar!/:2.20.1] &gt; at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.20.1.jar!/:2.20.1] &gt; at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) ~[camel-core-2.20.1.jar!/:2.20.1] &gt; at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ~[camel-core-2.20.1.jar!/:2.20.1] &gt; at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.20.1.jar!/:2.20.1] &gt; at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) ~[camel-core-2.20.1.jar!/:2.20.1] &gt; at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) ~[camel-core-2.20.1.jar!/:2.20.1] &gt; at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.20.1.jar!/:2.20.1] &gt; at org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197) [camel-core-2.20.1.jar!/:2.20.1] &gt; at org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79) [camel-core-2.20.1.jar!/:2.20.1] &gt; at java.util.TimerThread.mainLoop(Timer.java:555) [na:1.8.0_151] &gt; at java.util.TimerThread.run(Timer.java:505) [na:1.8.0_151] &gt;  &gt; {"exchange":"i-L7j_Zlg7p9Zk4j5no5Wz","status":"begin"}</body>
		<created>2018-03-16 16:24:21</created>
		<closed>2018-04-07 23:30:12</closed>
	</bug>
	<bug>
		<id>2050</id>
		<title>[AtlasMap] auto-conversion of Boolean to Integer fails</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [* ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Some database implement Boolean as a TINY INT, which is mapped to Integer. When trying to insert a Boolean value into such a field atlas map fails with:  &gt; Unable to auto-convert for sT=BOOLEAN tT=INTEGER tF=/completed msg=Invoking type convertor failed  ## Screenshot &lt;img width="822" alt="screen shot 2018-03-16 at 11 57 20 am" src="https://user-images.githubusercontent.com/35576/37530980-403cd674-2911-11e8-96cb-2c102956e0dc.png"&gt;  ## Expected behavior Either  1. we add a mapping in AltasMap that can convert Integer to Boolean or  2. we should support a 'transformation' during mapping configuration to do this.  ## Tasks involved / Steps to Reproduce  1. Start Connection: Periodic Stored Procedure - create_lead 2. Finish Connection: Invoke SQL: INSERT INTO TODO ( task, completed ) VALUES ( :#task, :#completed) 3. Add dataMapping as shown in screenshot, which adds the Boolean value so it's easy to test. In real life this should come from the Input data obviously.  </body>
		<created>2018-03-16 16:02:00</created>
		<closed>2018-04-07 23:35:52</closed>
	</bug>
	<bug>
		<id>2045</id>
		<title>Make WARN logs terser when unable/won't use client side state</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; During deserialization of client side state, stored in a HTTP cookie exception stack traces are logged to standard output like:  ``` 2018-03-16 12:36:28.276  WARN [-,e89ef4fb6072df7b,e89ef4fb6072df7b,false] 1 --- [  XNIO-3 task-3] i.s.s.endpoint.v1.state.ClientSideState  : Unable to restore client side state from cookie: cred-o2-fc89404d-470b-45d0-9f58-0c008d5acb0b=8fdGbR3eABht99hcL7AFkGTCxu4a00iURZAiJJr6iK9TTymiZyqzIgKehGzFwiOX7NoDeKk8whzTbugFIZ2jBS-evqeVjR50k9vCW9wnDIuLu941BXTM3NdYCMBTKQE-DhfYMPiweA8j2N-o5IxusvoVkwyD1wAYNxZBcVbfxYNvpDRAWQvUI3HFlaOnew6O907wUV_Ej8F0Gu0K-OajyxMAYw6oi2RUsoy5UqQFhavb_w18tk62VlV5lujCbeSloryI5TonOS22rDW-L35FyGcMXxBCxpgv9I2lrD-5rTYIOmm09zRqAlif6mu9eaMiXujlnKsaA7af9GSW6akuAH6xvgaSWIUzAwXUzX6j5F5yIGL9MIm-D7rbyKxkyBY_|MTUyMDk5NTU1Nw|qkm46Xe76Ew|-2QuUybfMNKsF3h9iXMf7A|KruB5tMvtSy62mVeDTtx6F7im4g  java.lang.IllegalArgumentException: Given value has timed out at: 2018-03-14T02:45:57Z at io.syndesis.server.endpoint.v1.state.ClientSideState.restoreWithTimestamp(ClientSideState.java:243) ~[server-endpoint-1.3.1.jar!/:1.3.1] at io.syndesis.server.endpoint.v1.state.ClientSideState.lambda$restoreFrom$0(ClientSideState.java:183) ~[server-endpoint-1.3.1.jar!/:1.3.1] at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267) ~[na:1.8.0_131] at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374) ~[na:1.8.0_131] at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ~[na:1.8.0_131] at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ~[na:1.8.0_131] at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ~[na:1.8.0_131] at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[na:1.8.0_131] at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ~[na:1.8.0_131] at io.syndesis.server.endpoint.v1.state.ClientSideState.restoreFrom(ClientSideState.java:189) ~[server-endpoint-1.3.1.jar!/:1.3.1] at io.syndesis.server.credential.CredentialFlowStateHelper.restoreFrom(CredentialFlowStateHelper.java:50) ~[server-credential-1.3.1.jar!/:1.3.1] at io.syndesis.server.credential.CredentialFlowState$Builder.restoreFrom(CredentialFlowState.java:63) ~[server-credential-1.3.1.jar!/:1.3.1] at io.syndesis.server.endpoint.v1.handler.connection.ConnectionHandler.create(ConnectionHandler.java:139) ~[server-endpoint-1.3.1.jar!/:1.3.1] ```  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  Log a WARN message that the state can't be deserialized, and a DEBUG level message with the stack trace. This way if not running with DEBUG level standard output is not filled with normally occurring stack traces.  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. When creating a connection to Twitter or Salesforce go through OAuth flow only half way, that is when prompted for username/password on Twitter/Salesforce don't login but go back to Syndesis 2. Wait 15mins 3. Make note that `cred-o**` cookie is present in the browser 4. Try to create a new connection to Twitter or Salesforce, should finish successfully 5. Open `syndesis-server` pod logs and notice that the whole exception is logged with WARN log level </body>
		<created>2018-03-16 14:07:25</created>
		<closed>2018-03-28 12:54:24</closed>
	</bug>
	<bug>
		<id>2027</id>
		<title>Investigate Apparent Memory Leaks on syndesis-server</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Syndesis Server pod appear to fail on its own, quite often on long running instances. There are hints that this might be some kind of memory leak, probably even an evident one, to notice with a profiler.  We need to investigate to better understand what's the root cause of this problem.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Not to crash !  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. no better details yet. it seems to occurr even with simple integrations 2. 3. 4. </body>
		<created>2018-03-15 16:32:46</created>
		<closed>2018-07-18 13:58:33</closed>
	</bug>
	<bug>
		<id>2024</id>
		<title>Select element in generated form isn't disabled when the form is read only</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  The select element rendered by a read-only form does not have the `disabled` attribute set, and therefore be interacted with.   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  If a dynamic form is configured to be read-only, the select element should be disabled or replaced with plain text, much like input fields.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  Example screenshot from the connection detail page for an AMQ connection:  ![usable-select](https://user-images.githubusercontent.com/351660/37472131-b44d1fae-2841-11e8-9c07-8382e058fb7b.PNG)   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create a new AMQ connection, just use whatever for the broker URL 2. Go to the detail page for your AMQ connection 3. Note the 'Skip Certificate Check' field can be changed while all the rest of the controls are disabled</body>
		<created>2018-03-15 15:14:30</created>
		<closed>2018-03-19 17:52:39</closed>
	</bug>
	<bug>
		<id>2023</id>
		<title>Let user to choose root element for XML Schema</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem When user define a custom data type for shapeless connection, they can upload XML Schema. But since XML Schema itself allows multiple elements to be defined, which of the element is really used for the payload is not declared in itself.  ## Expected behavior  We need to let user to choose which one of those elements is used as a root element of the payload. This would supposed to be happen in "Describe Data Type" page.  Then we need to store that selection as an extra property of DataShape, and provide it into datamapper, so that the datamapper would only show the selected root element as an available field.  </body>
		<created>2018-03-15 14:58:50</created>
		<closed>2018-03-15 15:20:49</closed>
	</bug>
	<bug>
		<id>2021</id>
		<title>Export has secrets in plain text</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [*] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## The problem Export file seems to contain some secrets in plain text.  ## Expected behavior All secrets should be encrpyted in the export file.  ## Screenshot  Robert Baumgartner report this via an email to me: He said he got an export containing:  ![inbox__776__-_hchirino_redhat_com_-_red_hat_mail](https://user-images.githubusercontent.com/103255/37469423-9cdfa68a-283b-11e8-9aa5-14d441377471.jpg)   ## API Endpoints and Schemas export api.  ## Tasks involved / Steps to Reproduce 1. Export an integration using the SF connection. 2. 3. 4. </body>
		<created>2018-03-15 14:29:06</created>
		<closed>2018-04-17 20:25:25</closed>
	</bug>
	<bug>
		<id>2015</id>
		<title>Leaking database connections</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem  At some point I got an error from the API:  ```json {"errorCode":500,"userMsg":"Please contact the administrator and file a bug report","developerMsg":"Internal Server Exception. org.postgresql.util.PSQLException: FATAL: remaining connection slots are reserved for non-replication superuser connections"} ```  When I looked into the database pod I found a number of processes as `idle in transaction`.  &lt;details&gt; &lt;summary&gt;syndesis-db process list&lt;/summary&gt; &lt;pre&gt; sh-4.2$ ps auxww USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND 1000060+     1  0.0  0.3 171452 14288 ?        Ss   Mar12   0:53 postgres 1000060+   103  0.0  0.0  95020  3692 ?        Ss   Mar12   0:02 postgres: logger process   1000060+   105  0.0  1.3 171572 54540 ?        Ss   Mar12   0:04 postgres: checkpointer process   1000060+   106  0.0  0.1 171452  4800 ?        Ss   Mar12   0:03 postgres: writer process   1000060+   107  0.0  0.1 171452  6484 ?        Ss   Mar12   0:03 postgres: wal writer process   1000060+   108  0.0  0.1 171872  6232 ?        Ss   Mar12   0:09 postgres: autovacuum launcher process   1000060+   109  0.0  0.0  97272  3940 ?        Ss   Mar12   0:35 postgres: stats collector process   1000060+  1279  0.0  0.3 172656 13044 ?        Ss   11:02   0:00 postgres: syndesis syndesis 172.17.0.2(47134) idle in transaction 1000060+  1315  0.0  0.5 172732 22840 ?        Ss   11:03   0:00 postgres: syndesis syndesis 172.17.0.2(47288) idle in transaction 1000060+  1316  0.0  0.5 172704 20788 ?        Ss   11:03   0:00 postgres: syndesis syndesis 172.17.0.2(47290) idle in transaction 1000060+  1350  0.0  0.6 172752 26604 ?        Ss   11:03   0:00 postgres: syndesis syndesis 172.17.0.2(47470) idle in transaction 1000060+  1464  0.0  0.4 172784 16584 ?        Ss   11:05   0:00 postgres: syndesis syndesis 172.17.0.2(48060) idle in transaction 1000060+  1567  0.0  0.5 172708 23552 ?        Ss   11:06   0:00 postgres: syndesis syndesis 172.17.0.2(48582) idle in transaction 1000060+  1751  0.0  0.5 172716 23620 ?        Ss   11:09   0:00 postgres: syndesis syndesis 172.17.0.2(49418) idle in transaction 1000060+  1855  0.0  0.5 172708 23548 ?        Ss   11:10   0:00 postgres: syndesis syndesis 172.17.0.2(49888) idle in transaction 1000060+  1900  0.0  0.5 172708 23548 ?        Ss   11:11   0:00 postgres: syndesis syndesis 172.17.0.2(50130) idle in transaction 1000060+  1981  0.0  0.5 172708 23548 ?        Ss   11:12   0:00 postgres: syndesis syndesis 172.17.0.2(50550) idle in transaction 1000060+  1993  0.0  0.5 172708 23544 ?        Ss   11:12   0:00 postgres: syndesis syndesis 172.17.0.2(50642) idle in transaction 1000060+  2006  0.0  0.5 172708 23544 ?        Ss   11:13   0:00 postgres: syndesis syndesis 172.17.0.2(50740) idle in transaction 1000060+  2197  0.0  0.5 172708 23544 ?        Ss   11:15   0:00 postgres: syndesis syndesis 172.17.0.2(51596) idle in transaction 1000060+  2220  0.0  0.5 172708 23548 ?        Ss   11:16   0:00 postgres: syndesis syndesis 172.17.0.2(51814) idle in transaction 1000060+  2232  0.0  0.6 172756 27756 ?        Ss   11:16   0:00 postgres: syndesis syndesis 172.17.0.2(51894) idle in transaction 1000060+  2280  0.0  0.6 172760 27588 ?        Ss   11:17   0:00 postgres: syndesis syndesis 172.17.0.2(52116) idle in transaction 1000060+  2292  0.0  0.3 172656 12992 ?        Ss   11:17   0:00 postgres: syndesis syndesis 172.17.0.2(52130) idle in transaction 1000060+  2293  0.0  0.6 172760 28064 ?        Ss   11:17   0:00 postgres: syndesis syndesis 172.17.0.2(52138) idle in transaction 1000060+  2294  0.0  0.3 172788 13000 ?        Ss   11:17   0:00 postgres: syndesis syndesis 172.17.0.2(52166) idle in transaction 1000060+  2307  0.0  0.6 172708 26096 ?        Ss   11:17   0:00 postgres: syndesis syndesis 172.17.0.2(52238) idle in transaction 1000060+  2309  0.0  0.7 172760 28892 ?        Ss   11:17   0:00 postgres: syndesis syndesis 172.17.0.2(52290) idle in transaction 1000060+  2321  0.0  0.7 172756 31684 ?        Ss   11:17   0:00 postgres: syndesis syndesis 172.17.0.2(52298) idle in transaction 1000060+  2403  0.0  0.7 172732 31984 ?        Ss   11:18   0:00 postgres: syndesis syndesis 172.17.0.2(52744) idle in transaction 1000060+  2448  0.0  0.7 172708 29660 ?        Ss   11:19   0:00 postgres: syndesis syndesis 172.17.0.2(53006) idle in transaction 1000060+  2496  0.0  0.8 172748 33828 ?        Ss   11:20   0:00 postgres: syndesis syndesis 172.17.0.2(53256) idle in transaction 1000060+  2587  0.0  0.8 172740 34344 ?        Ss   11:21   0:00 postgres: syndesis syndesis 172.17.0.2(53724) idle in transaction 1000060+  2589  0.0  0.7 172708 30916 ?        Ss   11:21   0:00 postgres: syndesis syndesis 172.17.0.2(53766) idle in transaction 1000060+  2647  0.0  0.4 172796 16540 ?        Ss   11:22   0:00 postgres: syndesis syndesis 172.17.0.2(54090) idle in transaction 1000060+  2659  0.0  0.7 172708 31956 ?        Ss   11:22   0:00 postgres: syndesis syndesis 172.17.0.2(54148) idle in transaction 1000060+  2900  0.0  0.4 172796 16540 ?        Ss   11:25   0:00 postgres: syndesis syndesis 172.17.0.2(55246) idle in transaction 1000060+  2967  0.0  0.8 172708 33816 ?        Ss   11:26   0:00 postgres: syndesis syndesis 172.17.0.2(55680) idle in transaction 1000060+  2968  0.0  0.3 172788 12968 ?        Ss   11:26   0:00 postgres: syndesis syndesis 172.17.0.2(55726) idle in transaction 1000060+  3025  0.0  0.4 172664 16336 ?        Ss   11:27   0:00 postgres: syndesis syndesis 172.17.0.2(56142) idle in transaction 1000060+  3026  0.0  0.8 172740 35800 ?        Ss   11:27   0:00 postgres: syndesis syndesis 172.17.0.2(56144) idle in transaction 1000060+  3119  0.0  0.8 172736 36092 ?        Ss   11:28   0:00 postgres: syndesis syndesis 172.17.0.2(56682) idle in transaction 1000060+  3120  0.0  0.3 172788 12972 ?        Ss   11:29   0:00 postgres: syndesis syndesis 172.17.0.2(56706) idle in transaction 1000060+  3132  0.0  0.9 172736 37144 ?        Ss   11:29   0:00 postgres: syndesis syndesis 172.17.0.2(56730) idle in transaction 1000060+  3133  0.0  0.3 172788 12916 ?        Ss   11:29   0:00 postgres: syndesis syndesis 172.17.0.2(56754) idle in transaction 1000060+  3145  0.0  0.9 172736 37528 ?        Ss   11:29   0:00 postgres: syndesis syndesis 172.17.0.2(56782) idle in transaction 1000060+  3146  0.0  0.8 172716 35504 ?        Ss   11:29   0:00 postgres: syndesis syndesis 172.17.0.2(56806) idle in transaction 1000060+  3260  0.0  0.8 172700 35444 ?        Ss   11:31   0:00 postgres: syndesis syndesis 172.17.0.2(57390) idle in transaction 1000060+  3261  0.0  0.9 172764 38748 ?        Ss   11:31   0:00 postgres: syndesis syndesis 172.17.0.2(57391) idle in transaction 1000060+  3306  0.0  0.8 172700 35924 ?        Ss   11:31   0:00 postgres: syndesis syndesis 172.17.0.2(57620) idle in transaction 1000060+  3330  0.0  0.9 172732 38316 ?        Ss   11:32   0:00 postgres: syndesis syndesis 172.17.0.2(57822) idle in transaction 1000060+  3331  0.0  0.8 172700 35928 ?        Ss   11:32   0:00 postgres: syndesis syndesis 172.17.0.2(57828) idle in transaction 1000060+  3413  0.0  0.8 172700 36388 ?        Ss   11:33   0:00 postgres: syndesis syndesis 172.17.0.2(58264) idle in transaction 1000060+  3425  0.0  0.9 172756 38840 ?        Ss   11:33   0:00 postgres: syndesis syndesis 172.17.0.2(58306) idle in transaction 1000060+  3526  0.0  0.9 172724 36904 ?        Ss   11:34   0:00 postgres: syndesis syndesis 172.17.0.2(58870) idle in transaction 1000060+  3549  0.0  1.0 172756 43064 ?        Ss   11:35   0:01 postgres: syndesis syndesis 172.17.0.2(58970) idle in transaction 1000060+  3630  0.0  1.0 172764 43368 ?        Ss   11:36   0:00 postgres: syndesis syndesis 172.17.0.2(59348) idle in transaction 1000060+  3642  0.0  0.3 172660 12968 ?        Ss   11:36   0:00 postgres: syndesis syndesis 172.17.0.2(59362) idle in transaction 1000060+  3653  0.0  1.0 172764 44220 ?        Ss   11:36   0:00 postgres: syndesis syndesis 172.17.0.2(59414) idle in transaction 1000060+  3655  0.0  0.3 172660 12968 ?        Ss   11:36   0:00 postgres: syndesis syndesis 172.17.0.2(59438) idle in transaction 1000060+  3667  0.0  1.1 172764 45416 ?        Ss   11:36   0:00 postgres: syndesis syndesis 172.17.0.2(59462) idle in transaction 1000060+  3668  0.0  1.0 172708 43204 ?        Ss   11:36   0:00 postgres: syndesis syndesis 172.17.0.2(59486) idle in transaction 1000060+  3760  0.0  1.0 172708 43156 ?        Ss   11:38   0:00 postgres: syndesis syndesis 172.17.0.2(59914) idle in transaction 1000060+  3772  0.0  1.0 172708 43156 ?        Ss   11:38   0:00 postgres: syndesis syndesis 172.17.0.2(60002) idle in transaction 1000060+  3785  0.0  1.0 172708 43160 ?        Ss   11:38   0:00 postgres: syndesis syndesis 172.17.0.2(60118) idle in transaction 1000060+  3821  0.0  1.0 172708 43156 ?        Ss   11:38   0:00 postgres: syndesis syndesis 172.17.0.2(60292) idle in transaction 1000060+  3833  0.0  1.0 172708 43156 ?        Ss   11:39   0:00 postgres: syndesis syndesis 172.17.0.2(60362) idle in transaction 1000060+  3845  0.0  1.0 172708 43156 ?        Ss   11:39   0:00 postgres: syndesis syndesis 172.17.0.2(60462) idle in transaction 1000060+  3869  0.0  1.1 172740 48212 ?        Ss   11:39   0:00 postgres: syndesis syndesis 172.17.0.2(60674) idle in transaction 1000060+  3904  0.0  1.2 172756 48808 ?        Ss   11:40   0:00 postgres: syndesis syndesis 172.17.0.2(60788) idle in transaction 1000060+  3905  0.0  1.1 172708 46436 ?        Ss   11:40   0:00 postgres: syndesis syndesis 172.17.0.2(60814) idle in transaction 1000060+  3940  0.0  1.1 172708 46436 ?        Ss   11:40   0:00 postgres: syndesis syndesis 172.17.0.2(32778) idle in transaction 1000060+  3953  0.0  1.2 172740 51396 ?        Ss   11:40   0:00 postgres: syndesis syndesis 172.17.0.2(32896) idle in transaction 1000060+  4213  0.0  1.1 172704 48448 ?        Ss   11:44   0:00 postgres: syndesis syndesis 172.17.0.2(34104) idle in transaction 1000060+  4214  0.0  1.1 172704 48516 ?        Ss   11:44   0:00 postgres: syndesis syndesis 172.17.0.2(34106) idle in transaction 1000060+  4240  0.0  1.1 172704 48448 ?        Ss   11:45   0:00 postgres: syndesis syndesis 172.17.0.2(34278) idle in transaction 1000060+  4283  0.0  1.1 172704 48448 ?        Ss   11:45   0:00 postgres: syndesis syndesis 172.17.0.2(34586) idle in transaction 1000060+  4296  0.0  1.1 172700 48444 ?        Ss   11:45   0:00 postgres: syndesis syndesis 172.17.0.2(34654) idle in transaction 1000060+  4469  0.0  1.2 172744 52184 ?        Ss   11:48   0:00 postgres: syndesis syndesis 172.17.0.2(35392) idle in transaction 1000060+  4470  0.0  1.2 172704 49260 ?        Ss   11:48   0:00 postgres: syndesis syndesis 172.17.0.2(35400) idle in transaction 1000060+  4518  0.0  1.2 172704 49260 ?        Ss   11:48   0:00 postgres: syndesis syndesis 172.17.0.2(35714) idle in transaction 1000060+  4531  0.0  1.2 172704 49256 ?        Ss   11:49   0:00 postgres: syndesis syndesis 172.17.0.2(35834) idle in transaction 1000060+  4920  0.0  1.2 172704 49256 ?        Ss   11:54   0:00 postgres: syndesis syndesis 172.17.0.2(37534) idle in transaction 1000060+  4932  0.1  1.3 172752 54480 ?        Ss   11:54   0:00 postgres: syndesis syndesis 172.17.0.2(37586) idle in transaction 1000060+  4956  0.0  1.2 172704 51564 ?        Ss   11:55   0:00 postgres: syndesis syndesis 172.17.0.2(37704) idle in transaction 1000060+  5013  0.0  1.3 172752 54708 ?        Ss   11:56   0:00 postgres: syndesis syndesis 172.17.0.2(38074) idle in transaction 1000060+  5071  0.1  1.3 172736 55336 ?        Ss   11:56   0:00 postgres: syndesis syndesis 172.17.0.2(38296) idle in transaction 1000060+  5072  0.0  1.3 172720 53472 ?        Ss   11:56   0:00 postgres: syndesis syndesis 172.17.0.2(38298) idle in transaction 1000060+  5234  0.0  1.3 172712 53420 ?        Ss   11:59   0:00 postgres: syndesis syndesis 172.17.0.2(39052) idle in transaction 1000060+  5247  0.0  1.3 172768 56100 ?        Ss   11:59   0:00 postgres: syndesis syndesis 172.17.0.2(39150) idle in transaction 1000060+  5271  0.1  1.4 172652 57548 ?        Ss   11:59   0:00 postgres: syndesis syndesis 172.17.0.2(39244) idle in transaction 1000060+  5413  0.2  1.3 172720 54064 ?        Ss   12:01   0:00 postgres: syndesis syndesis 172.17.0.2(39922) idle in transaction 1000060+  5462  0.0  0.3 172800 13108 ?        Ss   12:02   0:00 postgres: syndesis syndesis 172.17.0.2(40200) idle in transaction 1000060+  5597  0.0  0.0  11792  2776 ?        Ss+  12:04   0:00 /bin/sh 1000060+  5686  0.2  0.0  11784  2772 ?        Ss   12:05   0:00 /bin/sh 1000060+  5718  0.0  0.0  47468  3212 ?        R+   12:05   0:00 ps auxww 1000060+  8937  0.0  0.0  11784  2788 ?        Ss   Mar12   0:00 /bin/sh 1000060+  8946  0.0  0.1  80496  5656 ?        S+   Mar12   0:00 psql -U sampledb 1000060+  8947  0.0  0.3 173280 13036 ?        Ss   Mar12   0:00 postgres: sampledb sampledb [local] idle 1000060+ 30799  0.0  0.5 172732 22360 ?        Ss   10:19   0:00 postgres: syndesis syndesis 172.17.0.2(34350) idle in transaction 1000060+ 30800  0.0  0.3 172776 12860 ?        Ss   10:19   0:00 postgres: syndesis syndesis 172.17.0.2(34352) idle in transaction 1000060+ 30801  0.0  0.5 172732 22412 ?        Ss   10:19   0:00 postgres: syndesis syndesis 172.17.0.2(34354) idle in transaction 1000060+ 30802  0.0  0.3 172656 12640 ?        Ss   10:19   0:00 postgres: syndesis syndesis 172.17.0.2(34356) idle in transaction 1000060+ 30803  0.0  0.6 172728 24544 ?        Ss   10:19   0:00 postgres: syndesis syndesis 172.17.0.2(34358) idle in transaction 1000060+ 30804  0.0  0.3 172684 16040 ?        Ss   10:19   0:00 postgres: syndesis syndesis 172.17.0.2(34360) idle in transaction 1000060+ 30805  0.0  0.5 172736 22488 ?        Ss   10:19   0:00 postgres: syndesis syndesis 172.17.0.2(34362) idle in transaction 1000060+ 30806  0.0  0.5 172736 20960 ?        Ss   10:19   0:00 postgres: syndesis syndesis 172.17.0.2(34364) idle in transaction 1000060+ 30807  0.0  0.4 172644 16576 ?        Ss   10:19   0:00 postgres: syndesis syndesis 172.17.0.2(34366) idle in transaction 1000060+ 30808  0.0  0.4 173424 17204 ?        Ss   10:19   0:00 postgres: syndesis syndesis 172.17.0.2(34368) idle in transaction &lt;/pre&gt; &lt;/details&gt;  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  Not leak connections, OBVS.  ## Screenshot  ![leeks01-lg](https://user-images.githubusercontent.com/1306050/37462523-8a77e00e-2852-11e8-8cda-bb89b29c4158.jpg)  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt; I was fiddling with icon upload, perhaps something under `/api/v1/connectors/{id}/icon`  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; _(theory)_ 1. Create API connector 2. Try changing the icon a bunch of times </body>
		<created>2018-03-15 12:15:25</created>
		<closed>2018-03-15 14:02:08</closed>
	</bug>
	<bug>
		<id>2012</id>
		<title>UI, Datamapper, Persistent alert "Data Type Mismatch: Add a data mapping"</title>
		<body>[ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request   ## The problem 1. Alert  ```Data Type Mismatch: Add a data mapping step before this connection to resolve the difference.``` appears after 3rd step (see steps to reproduce below), but should have appeared after 2nd step already.  2. The alert is permanent. I.e. does not disappear after data mapping has been corrected.     Not even after publishing and reediting again.     This seems have no effect on integration functionality, it works OK.  ## Expected behavior 1. Alert should have appeared already after step 2. see steps to reproduce. 2. Alert disappears after data mapping has been corrected.  ## Screenshot permanent alert: ![Uploading persistent_alert.png]()   ## Tasks involved / Steps to Reproduce  1. Create DB to DB(Periodic SQL invocation/Invoke SQL) integration with datamapper step.      Or edit such existing integration. 2. Edit start connection action and choose different source DB table. 3. Edit finish connection action and choose different target DB table. 4. Correct Datamapper step.  </body>
		<created>2018-03-15 10:44:54</created>
		<closed>2018-10-21 14:25:50</closed>
	</bug>
	<bug>
		<id>2011</id>
		<title>Setting connection id instead of tags in connection</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem  Connection seems to have the connection id set in the `tags` field. Not sure when this is set, it might be when the connection is created.  ## Expected behavior  `tags` field should contain only tags, not ids.  ## Screenshot  ![screenshot-2018-3-15 syndesis](https://user-images.githubusercontent.com/1306050/37458142-5af5e154-2844-11e8-8294-ca4e0b50f58a.png)   ## Request and Response Data  ```shell $ jq .tags connection.json  [   "i-L7dBtUKe2I2NdegxppNz" ] ```  ## API Endpoints and Schemas   - Create new connection: `POST /api/v1/connections`  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create API-based connector 2. Create connection for the new connector </body>
		<created>2018-03-15 10:42:05</created>
		<closed>2018-03-15 14:38:33</closed>
	</bug>
	<bug>
		<id>2007</id>
		<title>Duplicate version declarations in "slack connector"</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; ``` [WARNING]  [WARNING] Some problems were encountered while building the effective model for io.syndesis.common:common-parent:pom:1.3-SNAPSHOT [WARNING] 'dependencyManagement.dependencies.dependency.(groupId:artifactId:type:classifier)' must be unique: io.syndesis.connector:connector-slack:jar -&gt; duplicate declaration of version ${project.version} @ io.syndesis:syndesis-parent:1.3-SNAPSHOT, /mnt/hudson_workspace/workspace/syndesis-release/app/pom.xml, line 928, column 19 [WARNING]  [WARNING] Some problems were encountered while building the effective model for io.syndesis:syndesis-parent:pom:1.3-SNAPSHOT [WARNING] 'dependencyManagement.dependencies.dependency.(groupId:artifactId:type:classifier)' must be unique: io.syndesis.connector:connector-slack:jar -&gt; duplicate declaration of version ${project.version} @ line 928, column 19 [WARNING]  [WARNING] It is highly recommended to fix these problems because they threaten the stability of your build. [WARNING]  [WARNING] For this reason, future Maven versions might no longer support building such malformed projects. [WARNING]  [INFO] ------------------------------------------------------------------------ [INFO] Reactor Build Order: ```  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Just build the connectors with maven or `syndesis -m connetor`</body>
		<created>2018-03-15 07:18:21</created>
		<closed>2018-03-15 08:11:06</closed>
	</bug>
	<bug>
		<id>1993</id>
		<title>AMQ and AMQP connections incorrectly offer RequestResponse as a finish connection action</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Dhiraj confirmed for me that AMQ and AMQP connections that are used as the finish connection in an integration should not perform the Request Response action. That was the behavior in TP3. But now, the staging site displays the Request Response action as a choice when you add an AMQ or AMQP connection as a finish connection.  &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; When you add an AMQ or AMQP connection as a finish connection, the only action choice should be Publish Messages.   ## Screenshot This appears when I am creating a new integration. I selected an AMQ connection as the finish connection, and these are the actions that I can select from. Request Response should NOT appear.  ![image](https://user-images.githubusercontent.com/25067106/37419998-2384254a-278c-11e8-8e06-46a750d2106a.png)    ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create an AMQ connection. 2. Create a new integration and add the start connection. 3. For the finish connection, select an AMQ connection. 4. Two actions are available here, publish and request/response. Only publish should be available.  </body>
		<created>2018-03-14 17:37:38</created>
		<closed>2018-04-04 19:13:20</closed>
	</bug>
	<bug>
		<id>1991</id>
		<title>Validate error for Salesforce connection</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem When I create a Salesforce connection with filling "Client Id" and "Client Secrent"  then leave everything else with default value, I got an empty validation error in UI and an Exception in meta pod log ``` 2018-03-14 16:07:20.214 ERROR 1 --- [  XNIO-3 task-6] i.s.c.meta.VerifierExceptionMapper       : Exception while handling request: POST /api/v1/connectors/salesforce/actions/io.syndesis.connector:connector-salesforce:salesforce-on-create --  |   | org.apache.camel.RuntimeCamelException: java.lang.IllegalArgumentException: You must specify parameters aligned with one of the supported authentication methods: for username and password authentication: userName, password, clientSecret; for refresh token authentication: refreshToken, clientSecret; for JWT: userName, keystore. And for every one of those loginUrl and clientId must be specified also.  | at org.apache.camel.util.ObjectHelper.wrapRuntimeCamelException(ObjectHelper.java:1831) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.component.salesforce.SalesforceMetaDataExtension.schemaFor(SalesforceMetaDataExtension.java:73) ~[camel-salesforce-2.20.1.jar!/:2.20.1]  | at org.apache.camel.component.salesforce.SalesforceMetaDataExtension.meta(SalesforceMetaDataExtension.java:51) ~[camel-salesforce-2.20.1.jar!/:2.20.1]  | at io.syndesis.connector.support.verifier.api.ComponentMetadataRetrieval.fetchMetaData(ComponentMetadataRetrieval.java:54) ~[connector-support-verifier-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT] ... Caused by: java.lang.IllegalArgumentException: You must specify parameters aligned with one of the supported authentication methods: for username and password authentication: userName, password, clientSecret; for refresh token authentication: refreshToken, clientSecret; for JWT: userName, keystore. And for every one of those loginUrl and clientId must be specified also. --  | at org.apache.camel.component.salesforce.SalesforceLoginConfig.getType(SalesforceLoginConfig.java:168) ~[camel-salesforce-2.20.1.jar!/:2.20.1]  | at org.apache.camel.component.salesforce.SalesforceLoginConfig.validate(SalesforceLoginConfig.java:217) ~[camel-salesforce-2.20.1.jar!/:2.20.1]  | at org.apache.camel.component.salesforce.internal.SalesforceSession.&lt;init&gt;(SalesforceSession.java:94) ~[camel-salesforce-2.20.1.jar!/:2.20.1]  | at org.apache.camel.component.salesforce.SalesforceComponent.createRestClient(SalesforceComponent.java:687) ~[camel-salesforce-2.20.1.jar!/:2.20.1]  | at org.apache.camel.component.salesforce.SalesforceClientTemplate.lambda$static$0(SalesforceClientTemplate.java:39) ~[camel-salesforce-2.20.1.jar!/:2.20.1]  | at org.apache.camel.component.salesforce.SalesforceClientTemplate.invoke(SalesforceClientTemplate.java:48) ~[camel-salesforce-2.20.1.jar!/:2.20.1]  | at org.apache.camel.component.salesforce.SalesforceMetaDataExtension.allObjectsSchema(SalesforceMetaDataExtension.java:62) ~[camel-salesforce-2.20.1.jar!/:2.20.1]  | at org.apache.camel.component.salesforce.SalesforceMetaDataExtension.schemaFor(SalesforceMetaDataExtension.java:71) ~[camel-salesforce-2.20.1.jar!/:2.20.1]  | ... 80 common frames omitted ``` ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. In UI, go to Connections -&gt; Create Connection 2. Choose Salesforce 3. Put "Client Id" and "Client Secrent" 4. Push "Validate" </body>
		<created>2018-03-14 16:55:46</created>
		<closed>2018-09-21 12:34:00</closed>
	</bug>
	<bug>
		<id>1988</id>
		<title>UI, Datamapper tools icons description is invisible.</title>
		<body>[ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request   ## The problem while adding / editing datamapper step, there are 4 links/icons on top right corner of datamapper UI (see picture)  While mouseover event, it looks like some description is shown, but is not visible for the user. In case of "table" element, description is semi-visible and interfering with the link itself, so that user has problem to click on that link itself (this "table" description is blinking, if the mouse pointer is in interference area).  ## Expected behavior Buttons descriptions are visible and do not interfere with links themselves.  ## Screenshot invisible descrition: ![dm_tools_description_not_visible](https://user-images.githubusercontent.com/2714974/37412421-2861ea16-27a5-11e8-95b9-50e6753e9032.png)   semivisible blinking "table" descrition: ![dm_tools_table_decription](https://user-images.githubusercontent.com/2714974/37412462-40853ef4-27a5-11e8-8b09-178613637c61.png)   ## Tasks involved / Steps to Reproduce 1. create/edit integration  2. add / edit datamapper step, so that you are provided with datamapper UI </body>
		<created>2018-03-14 15:34:36</created>
		<closed>2018-03-29 16:15:32</closed>
	</bug>
	<bug>
		<id>1985</id>
		<title>Extension input labels using description</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [*] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Say you use an extension that looks like this: ![rngerroraction_java_-_syndesis-parent_-____sandbox_syndesis_](https://user-images.githubusercontent.com/103255/37410365-dc98bc82-2776-11e8-8c79-a519b773f061.jpg)  When it's used in an integration it shows up like this: ![syndesis_-_development](https://user-images.githubusercontent.com/103255/37410399-eaf66a2c-2776-11e8-9af0-c5583be146d1.jpg)  The displayName should be shown, but instead the description is showing up as the input box label.  ## Expected behavior Lable should be "Failure Rate" </body>
		<created>2018-03-14 15:02:00</created>
		<closed>2018-03-14 15:54:49</closed>
	</bug>
	<bug>
		<id>1983</id>
		<title>Steps data in the integration activity log graph does match the one at the integration overview object</title>
		<body>## This is a... &lt;!-- Check one of the following options with "" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem The Integration activity logs endpoint (`/api/v1/activity/integrations/{id}`) returns a cursor of records related to steps logs that are meant to be rendered at the subviews within the activities listview displayed at the activity tab in the integration detail page.  The information returned by the aforementioned API endpoint does not include the step name, so it must be retrieved straight from the Integration overview graph, by picking the name of the step whose ID matches the one on each step log.  Unfortunately, as we can see by the graphs below, the IDs provided do not match:  #### Integration overview graph (excerpt):  ```json   "steps": [     {       "connection": {         "connectorId": "sql",         "icon": "fa-database",         "name": "PostgresDB",         "id": "5"       },       "action": {         "name": "Periodic SQL invocation"       },       "kind": "step",       "stepKind": "endpoint",       "id": "-L7PHtACrdmuSqA48niv"     },     {       "action": {},       "kind": "step",       "stepKind": "mapper",       "name": "Data Mapper",       "id": "-L7PHxnNrdmuSqA48niw"     },     {       "connection": {         "connectorId": "sql",         "icon": "fa-database",         "name": "PostgresDB",         "id": "5"       },       "action": {         "name": "Invoke stored procedure"       },       "kind": "step",       "stepKind": "endpoint",       "id": "-L7PHwHXrdmuSqA48niv"     }   ], ```  #### Any given activity log entry ```json   {     "id": "i-L7ZVynK_OXU13YIGIRwz",     "logts": "2018-03-14T12:37:28.408534847Z",     "at": 1521031048405,     "pod": "i-my-db-to-db-integration-1-fwbqw",     "ver": "1",     "status": "done",     "failed": false,     "steps": [       {         "id": "i-L7ZVynL_OXU13YIGIRxz",         "at": 1521031048406,         "duration": 876661       },       {         "id": "i-L7ZVynM_OXU13YIGIRyz",         "at": 1521031048407,         "duration": 28664361       }     ]   } ```  ## Expected behavior The step ids in the integration graph should match the ones on each activity log object. ![captura de pantalla 2018-03-14 a las 13 57 18](https://user-images.githubusercontent.com/1104146/37405646-774dedba-2795-11e8-9ace-427031ef83cf.png)   ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt; - Integration overview: `/api/v1/integrations/{INTEGRATION_ID}/overview` - Integration activity: `/api/v1/activity/integrations/{INTEGRATION_ID}`  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create an integration and wait for it to be published 2. Go to the integration detail page and click on the activity tab 3. Unfold any of the listview rows 4. Rows there should display the actual step name instead of `n/a` </body>
		<created>2018-03-14 13:45:07</created>
		<closed>2018-03-15 15:00:47</closed>
	</bug>
	<bug>
		<id>1982</id>
		<title>Integration Unpublishing is without "in progress" indicator</title>
		<body>[ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x ] Bug report  [ ] Documentation issue or request   ## The problem While integration is un-publishing, there is no "in progress" indicator that shows unpublishing process is going on.  ## Expected behavior See. e.g.   'publishing' process, which is OK.  ## Screenshot is: ![missing_in_progress_wheel](https://user-images.githubusercontent.com/2714974/37403321-b571b204-278e-11e8-9a6d-fc30ecedfc0a.png)   should be: ![ok](https://user-images.githubusercontent.com/2714974/37403350-d39b9704-278e-11e8-9ca7-5cd8b3859243.png)  ## Steps to Reproduce 1. Create and publish integration. 2. Once it is in 'Published' state, unpublish it. </body>
		<created>2018-03-14 12:55:05</created>
		<closed>2018-04-04 12:00:02</closed>
	</bug>
	<bug>
		<id>1975</id>
		<title>Uptime metric is broken for system and integrations</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Uptime metric for system and integrations are both N/A until an integration actually runs.  Once an integration does run, the uptime (for both) only reflects the time since the first run of the integration and now.  Uptime should reflect when the system started (for dashboard system metrics) and when an integration started. </body>
		<created>2018-03-14 03:07:53</created>
		<closed>2018-03-15 22:51:52</closed>
	</bug>
	<bug>
		<id>1961</id>
		<title>Inconsistent input data of database connector</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Inconsistent input data of database connector. Also I have no idea why new data mapper step still thought that there is old SQL statement.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; I would expect that one step cannot have 2 different input data types and data mapper has updated information about surrounding connections     ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; ![out](https://user-images.githubusercontent.com/14313995/37351732-060ee794-26dc-11e8-94ca-d4bed8de969b.gif)  1. Create integration  2. Start step: Database connection with periodic SQL statement  "SELECT * FROM contact WHERE first_name = 'Joe'" 3. Finish step: Database connection with Invoke SQL statement  "SELECT * FROM contact WHERE first_name = ':#PARAM'"  status:  Input Data Type : json-schema  Cannot create data mapper step even if you want to use parameter in the SQL query.   4. change finish SQL statement to "UPDATE TODO SET completed=1 WHERE TASK = :#TASK"  status: Input Data Type : SQL Parameter  You can now create data mapper step.  5. change finish SQL statement back to "SELECT * FROM contact WHERE first_name = ':#PARAM'"  status: Input Data Type : SQL Parameter  You can now create data mapper - but it still thinks that you want parameter TASK. </body>
		<created>2018-03-13 15:36:20</created>
		<closed>2018-03-14 14:20:56</closed>
	</bug>
	<bug>
		<id>1956</id>
		<title>Import/Export: Toast Notifications on Import</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ x ] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Removed PatternFly toast notifications on importing per request, but need to re-add them.  ## Expected behavior When importing a single or multiple integrations, only one toast notification should appear.  ## Screenshot [Full Designs](https://github.com/syndesisio/syndesis/blob/master/ux/designs/importexport/importexport.md)   ## API Endpoints and Schemas N/A  ## Tasks involved / Steps to Reproduce 1. Navigate to Integrations &gt; Import. 2. Upload an integration. 3. Select 'Done' in the Review step. 4. No toast notification is shown. </body>
		<created>2018-03-13 00:47:50</created>
		<closed>2018-05-24 07:51:37</closed>
	</bug>
	<bug>
		<id>1955</id>
		<title>Import/Export: Conflicts in Drag and Drop &amp; Multi Select/Import</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Multiple vs single, drag and drop vs select sometimes seem to conflict. The following have been observed: - Multiple integrations cannot be selected with traditional file select. - Drag and drop import allow for multiple integrations, but in the Review section only show the first imported integration.  ## Expected behavior User should be able to upload multiple integrations and see all in the review section, currently only the first is shown.   ## Screenshot I guess you'll just have to trust me..  [Full Designs](https://github.com/syndesisio/syndesis/blob/master/ux/designs/importexport/importexport.md)   ## API Endpoints and Schemas N/A  ## Tasks involved / Steps to Reproduce The first issue: 1. Navigate to Integrations &gt; Import 2. Try to select multiple files using the traditional file select button. Only one is selectable.  The second (likely relevant) issue: 1. Drag and drop multiple integrations that are different. 2. The review page will show only the first integration repeated by the number of integrations imported. </body>
		<created>2018-03-13 00:41:05</created>
		<closed>2018-03-23 13:04:59</closed>
	</bug>
	<bug>
		<id>1954</id>
		<title>Import/Export: Review Step Endpoint</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Use the integration overview endpoint to reflect data that is returned from the API in the Review section.  ## Expected behavior Review step is mostly blank.  ## Screenshot &lt;img width="1014" alt="screenshot 2018-03-12 20 20 33" src="https://user-images.githubusercontent.com/3844502/37315970-d81c0f50-2632-11e8-8af4-0f38a6f7b31c.png"&gt;  [Full Designs](https://github.com/syndesisio/syndesis/blob/master/ux/designs/importexport/importexport.md)  ## API Endpoints and Schemas Integration support endpoint: `/api/v1/integration-support`  ## Tasks involved / Steps to Reproduce 1. Navigate to Integrations &gt; Import 2. Upload exported integration zip file. 3. Review step should display information about the uploaded integration, but is mostly blank.  </body>
		<created>2018-03-13 00:26:49</created>
		<closed>2018-03-22 18:06:16</closed>
	</bug>
	<bug>
		<id>1952</id>
		<title>Data Type Mismatch for "Invoke SQL" step</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Invoke SQL step has now input data required as json-schema even if you don't use variables in SQL query. Whole intagration works even with this warning so it is misleading for the end user - data type mismatch but it works??  ![datatypemissmatch](https://user-images.githubusercontent.com/14313995/37296564-a21830b2-261b-11e8-8570-068bd7b9bf1f.png)  Adding data mapper step looks like this: ![datamappersteperror](https://user-images.githubusercontent.com/14313995/37296669-f2593814-261b-11e8-837d-55c3307fd2c2.png)   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlisting the acceptance criteria. --&gt; Invoke SQL step has no input data required if it doesn't use variables in the query  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![invokesql](https://user-images.githubusercontent.com/14313995/37296296-d8e12802-261a-11e8-8425-30183ff0f181.png)     </body>
		<created>2018-03-12 16:41:57</created>
		<closed>2018-03-14 23:52:45</closed>
	</bug>
	<bug>
		<id>1949</id>
		<title>Salesforce connection creation fails - regression</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Salesforce connection creation fails with the following error: https://gist.github.com/honghuac/05958dd0ed84348f8343111b65f342c3   ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; The creation process should be successful, and the user must not be seeing this page (which loads after the failure) at all: ![ra](https://user-images.githubusercontent.com/8625482/37281498-36c03ab0-262c-11e8-9b03-31dab13540ae.png) </body>
		<created>2018-03-12 11:31:39</created>
		<closed>2018-03-28 16:34:29</closed>
	</bug>
	<bug>
		<id>1948</id>
		<title>Invalid cookie header - message appears when Connection creation fails</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## The problem The following error messages appear "Invalid Cookie Header": https://gist.github.com/honghuac/4f9a6357d5e9f782183642328a288771 upon the authorization of a Twitter app, as part of the Connection creation process.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Creation of connection should complete successfully.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![spinning](https://user-images.githubusercontent.com/8625482/37280164-f50a2db4-2627-11e8-94f2-80752c5c642a.png)   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Re-create a new Twitter connection on the current code base of Fuse Ingnite. 2. This problem will emerge.  </body>
		<created>2018-03-12 11:03:53</created>
		<closed>2018-03-28 12:38:34</closed>
	</bug>
	<bug>
		<id>1947</id>
		<title>Save as draft redirect not working</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When I try to create an integration in draft state, the page is not redirected to integration listing. The integration is created, but there is no info for the user, it really happened.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![save_as_draft](https://user-images.githubusercontent.com/4180208/37278392-dc23a374-25e7-11e8-9d52-45ae9f284715.gif)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create some integration  2. Click "save as draft" 3. Enter name of the integration 4. Click "save as draft" </body>
		<created>2018-03-12 10:26:28</created>
		<closed>2018-03-12 11:25:14</closed>
	</bug>
	<bug>
		<id>1932</id>
		<title>Advanced filter: page title has changed to `ExpressionFilter`</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Is it intentional change?     ## Expected behavior When selecting Advanced Filter step, title page should say `Configure Advanced Filter`  ## Screenshot &lt;img width="759" alt="screen shot 2018-03-09 at 14 22 48" src="https://user-images.githubusercontent.com/5637792/37209371-62604e28-23a5-11e8-835a-ffcf44e57a5e.png"&gt; </body>
		<created>2018-03-09 13:24:39</created>
		<closed>2018-03-09 16:03:35</closed>
	</bug>
	<bug>
		<id>1930</id>
		<title>Period for Periodic SQL invocation can not be set</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  When trying to update the timer value of an already existing SQL conection with periodic select action, this will not be saved.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  The updated value should be saved and used when the integration gets published.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![image](https://user-images.githubusercontent.com/99080/37206886-c83f1356-239a-11e8-9051-791dc930358c.png)   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create an integration with db-2-db,initial connection: periodic polling 2. Use default (1000) 3. Publish 4. Update integration again, by changing 1000 to 5000 5. Save 6. Still 1000 is active. </body>
		<created>2018-03-09 12:08:51</created>
		<closed>2018-03-12 18:54:02</closed>
	</bug>
	<bug>
		<id>1924</id>
		<title>SQL connector: NPE when mapped field is empty</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem There's a NPE for integration `SF on create -&gt; Mapping -&gt;Database` when any of a mapped field isn't provided upon SF's object creation.  ```gherkin #mapping created is counting with e.g. Phone field When she creates mapping from "Company" to "company" And she creates mapping from "Email" to "email" And she creates mapping from "Phone" to "phone" And she creates mapping from "FirstName" to "first_and_last_name" And she combines "FirstName" as "1" with "LastName" as "2" to "first_and_last_name" using "Space" separator   #but new Lead is proving just following fields And create SF lead with first name: "Karol1", last name: "Stieranka1", email: "k1stieranka1@istrochem.sk" and company: "Istrochem" And validate DB created new lead with first name: "Karol1", last name: "Stieranka1", email: "k1stieranka1@istrochem.sk"  ```  ```   Message History --  | ---------------------------------------------------------------------------------------------------------------------------------------  | RouteId              ProcessorId          Processor                                                                        Elapsed (ms)  | [i-L792pr4sF9olezya] [i-L792pr4sF9olezya] [salesforce-salesforce-1://syndesis_Lead_c?notifyForFields=ALL&amp;notifyForOperati] [       787]  | [i-L792pr4sF9olezya] [-L792nU19GGbI2HZOG] [Processor@0x48106381                                                          ] [         3]  | [i-L792pr4sF9olezya] [-L792oWX9GGbI2HZOG] [atlas:mapping-step-2.json?sourceMapName=Syndesis.CAPTURED_OUT_MESSAGES_MAP    ] [       757]  | [i-L792pr4sF9olezya] [-L792oWX9GGbI2HZOG] [Processor@0x18483b8b                                                          ] [         1]  | [i-L792pr4sF9olezya] [-L792oA49GGbI2HZOG] [sql-stored-3                                                                  ] [        15]  |   | Stacktrace  | ---------------------------------------------------------------------------------------------------------------------------------------  |   | java.lang.NullPointerException: null  | at java.util.Hashtable.put(Hashtable.java:460) ~[na:1.8.0_151]  | at java.util.Hashtable.putAll(Hashtable.java:524) ~[na:1.8.0_151]  | at io.syndesis.connector.sql.common.JSONBeanUtil.parsePropertiesFromJSONBean(JSONBeanUtil.java:65) ~[connector-sql-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT]  | at io.syndesis.connector.sql.customizer.SqlStoredConnectorCustomizer.doBeforeProducer(SqlStoredConnectorCustomizer.java:36) ~[connector-sql-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT]  | at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.20.1.jar!/:2.20.1]  | at io.syndesis.integration.component.proxy.ComponentProxyProducer.process(ComponentProxyProducer.java:44) ~[integration-component-proxy-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT]  | at org.apache.camel.processor.SendProcessor$2.doInAsyncProducer(SendProcessor.java:178) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.impl.ProducerCache.doInAsyncProducer(ProducerCache.java:445) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:173) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.InterceptorToAsyncProcessorBridge.process(InterceptorToAsyncProcessorBridge.java:67) ~[camel-core-2.20.1.jar!/:2.20.1]  | at io.syndesis.integration.runtime.logging.IntegrationLoggingInterceptStrategy.lambda$wrapProcessorInInterceptors$0(IntegrationLoggingInterceptStrategy.java:45) ~[integration-runtime-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT]  | at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.InterceptorToAsyncProcessorBridge.process(InterceptorToAsyncProcessorBridge.java:76) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.Pipeline.access$100(Pipeline.java:43) [camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.Pipeline$1.done(Pipeline.java:157) [camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.Enricher$1.done(Enricher.java:237) [camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.component.salesforce.internal.processor.JsonRestProcessor.processResponse(JsonRestProcessor.java:218) [camel-salesforce-2.20.1.jar!/:2.20.1]  | at org.apache.camel.component.salesforce.internal.processor.AbstractRestProcessor$6.onResponse(AbstractRestProcessor.java:381) [camel-salesforce-2.20.1.jar!/:2.20.1]  | at org.apache.camel.component.salesforce.internal.client.DefaultRestClient$DelegatingClientCallback.onResponse(DefaultRestClient.java:503) [camel-salesforce-2.20.1.jar!/:2.20.1]  | at org.apache.camel.component.salesforce.internal.client.AbstractClientBase$1.onComplete(AbstractClientBase.java:218) [camel-salesforce-2.20.1.jar!/:2.20.1]  | at org.eclipse.jetty.client.ResponseNotifier.notifyComplete(ResponseNotifier.java:193) [jetty-client-9.4.7.v20170914.jar!/:9.4.7.v20170914]  | at org.eclipse.jetty.client.ResponseNotifier.notifyComplete(ResponseNotifier.java:185) [jetty-client-9.4.7.v20170914.jar!/:9.4.7.v20170914]  | at org.eclipse.jetty.client.HttpReceiver.terminateResponse(HttpReceiver.java:459) [jetty-client-9.4.7.v20170914.jar!/:9.4.7.v20170914]  | at org.eclipse.jetty.client.HttpReceiver.responseSuccess(HttpReceiver.java:405) [jetty-client-9.4.7.v20170914.jar!/:9.4.7.v20170914]  | at org.eclipse.jetty.client.http.HttpReceiverOverHTTP.messageComplete(HttpReceiverOverHTTP.java:297) [jetty-client-9.4.7.v20170914.jar!/:9.4.7.v20170914]  | at org.eclipse.jetty.http.HttpParser.parseFields(HttpParser.java:1068) [jetty-http-9.4.7.v20170914.jar!/:9.4.7.v20170914]  | at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:1393) [jetty-http-9.4.7.v20170914.jar!/:9.4.7.v20170914]  | at org.eclipse.jetty.client.http.HttpReceiverOverHTTP.parse(HttpReceiverOverHTTP.java:170) [jetty-client-9.4.7.v20170914.jar!/:9.4.7.v20170914]  | at org.eclipse.jetty.client.http.HttpReceiverOverHTTP.process(HttpReceiverOverHTTP.java:131) [jetty-client-9.4.7.v20170914.jar!/:9.4.7.v20170914]  | at org.eclipse.jetty.client.http.HttpReceiverOverHTTP.receive(HttpReceiverOverHTTP.java:70) [jetty-client-9.4.7.v20170914.jar!/:9.4.7.v20170914]  | at org.eclipse.jetty.client.http.HttpChannelOverHTTP.receive(HttpChannelOverHTTP.java:130) [jetty-client-9.4.7.v20170914.jar!/:9.4.7.v20170914]  | at org.eclipse.jetty.client.http.HttpConnectionOverHTTP.onFillable(HttpConnectionOverHTTP.java:116) [jetty-client-9.4.7.v20170914.jar!/:9.4.7.v20170914]  | at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:279) [jetty-io-9.4.7.v20170914.jar!/:9.4.7.v20170914]  | at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:104) [jetty-io-9.4.7.v20170914.jar!/:9.4.7.v20170914]  | at org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:289) [jetty-io-9.4.7.v20170914.jar!/:9.4.7.v20170914]  | at org.eclipse.jetty.io.ssl.SslConnection$3.succeeded(SslConnection.java:149) [jetty-io-9.4.7.v20170914.jar!/:9.4.7.v20170914]  | at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:104) [jetty-io-9.4.7.v20170914.jar!/:9.4.7.v20170914]  | at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:124) [jetty-io-9.4.7.v20170914.jar!/:9.4.7.v20170914]  | at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:247) [jetty-util-9.4.7.v20170914.jar!/:9.4.7.v20170914]  | at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:140) [jetty-util-9.4.7.v20170914.jar!/:9.4.7.v20170914]  | at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131) [jetty-util-9.4.7.v20170914.jar!/:9.4.7.v20170914]  | at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:243) [jetty-util-9.4.7.v20170914.jar!/:9.4.7.v20170914]  | at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:679) [jetty-util-9.4.7.v20170914.jar!/:9.4.7.v20170914]  | at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:597) [jetty-util-9.4.7.v20170914.jar!/:9.4.7.v20170914]  | at java.lang.Thread.run(Thread.java:748) [na:1.8.0_151]  |   | {"exchange":"i-L793bDcXbaU6IRwhTGhz","status":"done","failed":true}   ```  </body>
		<created>2018-03-09 09:29:55</created>
		<closed>2018-03-09 11:16:05</closed>
	</bug>
	<bug>
		<id>1921</id>
		<title>Integration Name containing underscores throws validation error on BC</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem When I name my integration with underscores, e.g. `sql_sql` there's an exception thrown in `syndesis-server` that prevents creation of BC and DC.   ```  javax.validation.ConstraintViolationException: Constraint Validations: metadata.name must match "^[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*$" on bean: BuildConfig(apiVersion=v1, kind=BuildConfig, metadata=ObjectMeta(annotations={syndesis.io/integration-id=i-L78yu8YsF9olezyaCaiz, syndesis.io/deployment-version=1, syndesis.io/integration-name=sql_sql}, clusterName=null, creationTimestamp=null, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, labels={syndesis.io/integration-id=i-L78yu8YsF9olezyaCaiz, syndesis.io/username=developer, syndesis.io/deployment-version=1}, name=i-sql_sql, namespace=null, ownerReferences=[], resourceVersion=null, selfLink=null, uid=null, additionalProperties={}), spec=BuildConfigSpec(completionDeadlineSeconds=null, nodeSelector={}, output=BuildOutput(imageLabels=[], pushSecret=null, to=ObjectReference(apiVersion=null, fieldPath=null, kind=ImageStreamTag, name=i-sql_sql:latest, namespace=null, resourceVersion=null, uid=null, additionalProperties={}), additionalProperties={}), postCommit=null, resources=null, revision=null, runPolicy=SerialLatestOnly, serviceAccount=null, source=BuildSource(binary=null, contextDir=null, dockerfile=null, git=null, images=[], secrets=[], sourceSecret=null, type=Binary, additionalProperties={}), strategy=BuildStrategy(customStrategy=null, dockerStrategy=null, jenkinsPipelineStrategy=null, sourceStrategy=SourceBuildStrategy(env=[EnvVar(name=MAVEN_OPTS, value=-XX:+UseG1GC -XX:+UseStringDeduplication -Xmx310m, valueFrom=null, additionalProperties={}), EnvVar(name=BUILD_LOGLEVEL, value=1, valueFrom=null, additionalProperties={})], forcePull=null, from=ObjectReference(apiVersion=null, fieldPath=null, kind=ImageStreamTag, name=syndesis-s2i:latest, namespace=, resourceVersion=null, uid=null, additionalProperties={}), incremental=false, pullSecret=null, runtimeArtifacts=[], runtimeImage=null, scripts=null, additionalProperties={}), type=Source, additionalProperties={}), triggers=[], additio --  | nalProperties={}), status=null, additionalProperties={})  | at io.fabric8.kubernetes.api.builder.ValidationUtils.validate(ValidationUtils.java:36) ~[kubernetes-model-1.0.74.jar!/:1.0.74]  | at io.fabric8.openshift.api.model.BuildConfigBuilder.build(BuildConfigBuilder.java:51) ~[kubernetes-model-1.0.74.jar!/:1.0.74]  | at io.fabric8.openshift.api.model.DoneableBuildConfig.done(DoneableBuildConfig.java:27) ~[kubernetes-model-1.0.74.jar!/:1.0.74]  | at io.syndesis.server.openshift.OpenShiftServiceImpl.ensureBuildConfig(OpenShiftServiceImpl.java:306) ~[server-openshift-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT]  | at io.syndesis.server.openshift.OpenShiftServiceImpl.build(OpenShiftServiceImpl.java:59) ~[server-openshift-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT]  | at io.syndesis.server.controller.integration.online.PublishHandler.build(PublishHandler.java:156) ~[server-controller-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT]  | at io.syndesis.server.controller.integration.online.PublishHandler$BuildStepPerformer.perform(PublishHandler.java:313) ~[server-controller-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT]  | at io.syndesis.server.controller.integration.online.PublishHandler.execute(PublishHandler.java:101) ~[server-controller-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT]  | at io.syndesis.server.controller.StateChangeHandler.execute(StateChangeHandler.java:33) [server-controller-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT]  | at io.syndesis.server.controller.integration.IntegrationController.lambda$callStateChangeHandler$11(IntegrationController.java:186) [server-controller-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT]  | at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_131]  | at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_131]  | at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]  |   | 2018-03-09 08:58:30.831  INFO [-,,,] 1 --- [tion Controller] i.s.s.c.i.IntegrationController          : Integration i-L78yu8YsF9olezyaCaiz : Setting status to Pending (Constraint Validations: metadata.name must match "^[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*$" on bean: BuildConfig(apiVersion=v1, kind=BuildConfig, metadata=ObjectMeta(annotations={syndesis.io/integration-id=i-L78yu8YsF9olezyaCaiz, syndesis.io/deployment-version=1, syndesis.io/integration-name=sql_sql}, clusterName=null, creationTimestamp=null, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, labels={syndesis.io/integration-id=i-L78yu8YsF9olezyaCaiz, syndesis.io/username=developer, syndesis.io/deployment-version=1}, name=i-sql_sql, namespace=null, ownerReferences=[], resourceVersion=null, selfLink=null, uid=null, additionalProperties={}), spec=BuildConfigSpec(completionDeadlineSeconds=null, nodeSelector={}, output=BuildOutput(imageLabels=[], pushSecret=null, to=ObjectReference(apiVersion=null, fieldPath=null, kind=ImageStreamTag, name=i-sql_sql:latest, namespace=null, resourceVersion=null, uid=null, additionalProperties={}), additionalProperties={}), postCommit=null, resources=null, revision=null, runPolicy=SerialLatestOnly, serviceAccount=null, source=BuildSource(binary=null, contextDir=null, dockerfile=null, git=null, images=[], secrets=[], sourceSecret=null, type=Binary, additionalProperties={}), strategy=BuildStrategy(customStrategy=null, dockerStrategy=null, jenkinsPipelineStrategy=null, sourceStrategy=SourceBuildStrategy(env=[EnvVar(name=MAVEN_OPTS, value=-XX:+UseG1GC -XX:+UseStringDeduplication -Xmx310m, valueFrom=null, additionalProperties={}), EnvVar(name=BUILD_LOGLEVEL, value=1, valueFrom=null, additionalProperties={})], forcePull=null, from=ObjectReference(apiVersion=null, fieldPath=null, kind=ImageStreamTag, name=syndesis-s2i:latest, namespace=, resourceVersion=null, uid=null, additionalProperties={}), incremental=false, pullSecret=null, runtimeArtifacts=[  | ], runtimeImage=null, scripts=null, additionalProperties={}), type=Source, additionalProperties={}), triggers=[], additionalProperties={}), status=null, additionalProperties={}))   ```  ## Expected behavior Name can contain dashes. </body>
		<created>2018-03-09 09:02:50</created>
		<closed>2018-03-09 11:52:58</closed>
	</bug>
	<bug>
		<id>1907</id>
		<title>Missing icons: HTTPS, MQTT</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem There're missing icons for the following connectors **HTTPS** (probably should be the same as HTTP), **MQTT** and **SFTP** (tracked separately in #1706).   Note: FTP icon seems a bit generic maybe.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot ![screen shot 2018-03-08 at 16 59 49](https://user-images.githubusercontent.com/5637792/37161128-266116cc-22f2-11e8-90e4-5ea6f11af1b8.png)  Cc @dongniwang @sjcox-rh </body>
		<created>2018-03-08 16:01:52</created>
		<closed>2018-03-13 20:23:11</closed>
	</bug>
	<bug>
		<id>1903</id>
		<title>Integration project build failure to push image</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [ x ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Publishing an integration shows it stuck in pending state.  When I look at the openshift console, I see the build pod has a red X.  This is after deleting my previous syndesis namespace this morning and reinstalling after pulling.  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  The integration project should build  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  consulting the log for the integration build pod I see:  ``` [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 26.177 s [INFO] Finished at: 2018-03-08T15:00:00+00:00 [INFO] Final Memory: 34M/113M [INFO] ------------------------------------------------------------------------ Copying Maven artifacts from /tmp/src/target to /deployments ... Running: cp *.jar /deployments Checking for SpringBoot archive... Found project-0.1-SNAPSHOT.jar... ... done  Pushing image 172.30.1.1:5000/syndesis/i-test-1:latest ... Warning: Push failed, retrying in 5s ... Warning: Push failed, retrying in 5s ... Warning: Push failed, retrying in 5s ... Warning: Push failed, retrying in 5s ... Warning: Push failed, retrying in 5s ... Warning: Push failed, retrying in 5s ... Warning: Push failed, retrying in 5s ... Registry server Address:  Registry server User Name: serviceaccount Registry server Email: serviceaccount@example.org Registry server Password: &lt;&lt;non-empty&gt;&gt; error: build error: Failed to push image: After retrying 6 times, Push image still failed ```  And the server pod's logs doesn't show anything interesting to me at least -&gt; https://gist.github.com/gashcrumb/3a5c92588dcf93a05aded91894fe0a23  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create a simple db =&gt; db integration 2. Try and publish it. 3. ??? 4. Profit! </body>
		<created>2018-03-08 15:09:33</created>
		<closed>2018-09-21 12:33:59</closed>
	</bug>
	<bug>
		<id>1896</id>
		<title>Timeout error when Publishing an integration</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem  On local minishift setup, publishing a simple integration produces this error.  Browser console logs these lines:  ``` https://syndesis.192.168.42.228.nip.io/api/v1/metrics/integrations/i-L74XXXEhcQ5XEA1ykevz  500 (Internal Server Error) https://syndesis.192.168.42.228.nip.io/api/v1/metrics/integrations/i-L74XXXEhcQ5XEA1ykevz 504 (Gateway Time-out) https://syndesis.192.168.42.228.nip.io/api/v1/metrics/integrations/i-L74XXXEhcQ5XEA1ykevz 504 (Gateway Time-out) ```  But the error is actually non blocking. On my system the build pod took `i-paolo-2-build               0/1Completed   0          7m` to build. After that the pod is published correctly and the UI page even displays the correct information.   Server logs: ``` syndesis-server-1-fzlmg syndesis-server 2018-03-08 12:16:38.554 ERROR [-,,,] 1 --- [tion Controller] i.s.s.c.integration.online.BaseHandler   : Integration [paolo]: [ERROR] Activation failure syndesis-server-1-fzlmg syndesis-server  syndesis-server-1-fzlmg syndesis-server io.fabric8.kubernetes.client.KubernetesClientException: Operation: [get]  for kind: [Build]  with name: [i-paolo-1]  in namespace: [myproject]  failed. syndesis-server-1-fzlmg syndesis-server at io.fabric8.kubernetes.client.KubernetesClientException.launderThrowable(KubernetesClientException.java:62) ~[kubernetes-client-2.4.1.jar!/:na] syndesis-server-1-fzlmg syndesis-server at io.fabric8.kubernetes.client.KubernetesClientException.launderThrowable(KubernetesClientException.java:71) ~[kubernetes-client-2.4.1.jar!/:na] syndesis-server-1-fzlmg syndesis-server at io.fabric8.kubernetes.client.dsl.base.BaseOperation.getMandatory(BaseOperation.java:217) ~[kubernetes-client-2.4.1.jar!/:na] syndesis-server-1-fzlmg syndesis-server at io.fabric8.kubernetes.client.dsl.base.BaseOperation.get(BaseOperation.java:181) ~[kubernetes-client-2.4.1.jar!/:na] syndesis-server-1-fzlmg syndesis-server at io.syndesis.server.openshift.OpenShiftServiceImpl.waitForBuild(OpenShiftServiceImpl.java:337) ~[server-openshift-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT] syndesis-server-1-fzlmg syndesis-server at io.syndesis.server.openshift.OpenShiftServiceImpl.build(OpenShiftServiceImpl.java:63) ~[server-openshift-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT] syndesis-server-1-fzlmg syndesis-server at io.syndesis.server.controller.integration.online.PublishHandler.build(PublishHandler.java:156) ~[server-controller-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT] syndesis-server-1-fzlmg syndesis-server at io.syndesis.server.controller.integration.online.PublishHandler$BuildStepPerformer.perform(PublishHandler.java:313) ~[server-controller-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT] syndesis-server-1-fzlmg syndesis-server at io.syndesis.server.controller.integration.online.PublishHandler.execute(PublishHandler.java:101) ~[server-controller-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT] syndesis-server-1-fzlmg syndesis-server at io.syndesis.server.controller.StateChangeHandler.execute(StateChangeHandler.java:33) [server-controller-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT] syndesis-server-1-fzlmg syndesis-server at io.syndesis.server.controller.integration.IntegrationController.lambda$callStateChangeHandler$11(IntegrationController.java:186) [server-controller-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT] syndesis-server-1-fzlmg syndesis-server at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_131] syndesis-server-1-fzlmg syndesis-server at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_131] syndesis-server-1-fzlmg syndesis-server at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131] syndesis-server-1-fzlmg syndesis-server Caused by: java.net.SocketTimeoutException: Read timed out syndesis-server-1-fzlmg syndesis-server at java.net.SocketInputStream.socketRead0(Native Method) ~[na:1.8.0_131] syndesis-server-1-fzlmg syndesis-server at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) ~[na:1.8.0_131] syndesis-server-1-fzlmg syndesis-server at java.net.SocketInputStream.read(SocketInputStream.java:171) ~[na:1.8.0_131] syndesis-server-1-fzlmg syndesis-server at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[na:1.8.0_131] syndesis-server-1-fzlmg syndesis-server at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_131] syndesis-server-1-fzlmg syndesis-server at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_131] syndesis-server-1-fzlmg syndesis-server at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:983) ~[na:1.8.0_131] syndesis-server-1-fzlmg syndesis-server at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:940) ~[na:1.8.0_131] syndesis-server-1-fzlmg syndesis-server at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_131] syndesis-server-1-fzlmg syndesis-server at okio.Okio$2.read(Okio.java:139) ~[okio-1.13.0.jar!/:na] syndesis-server-1-fzlmg syndesis-server at okio.AsyncTimeout$2.read(AsyncTimeout.java:237) ~[okio-1.13.0.jar!/:na] syndesis-server-1-fzlmg syndesis-server at okio.RealBufferedSource.indexOf(RealBufferedSource.java:345) ~[okio-1.13.0.jar!/:na] syndesis-server-1-fzlmg syndesis-server at okio.RealBufferedSource.readUtf8LineStrict(RealBufferedSource.java:217) ~[okio-1.13.0.jar!/:na] syndesis-server-1-fzlmg syndesis-server at okio.RealBufferedSource.readUtf8LineStrict(RealBufferedSource.java:211) ~[okio-1.13.0.jar!/:na] syndesis-server-1-fzlmg syndesis-server at okhttp3.internal.http1.Http1Codec.readResponseHeaders(Http1Codec.java:189) ~[okhttp-3.8.0.jar!/:na] syndesis-server-1-fzlmg syndesis-server at okhttp3.internal.http.CallServerInterceptor.intercept(CallServerInterceptor.java:75) ~[okhttp-3.8.0.jar!/:na] syndesis-server-1-fzlmg syndesis-server at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92) ~[okhttp-3.8.0.jar!/:na] syndesis-server-1-fzlmg syndesis-server at okhttp3.internal.connection.ConnectInterceptor.intercept(ConnectInterceptor.java:45) ~[okhttp-3.8.0.jar!/:na] syndesis-server-1-fzlmg syndesis-server at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92) ~[okhttp-3.8.0.jar!/:na] syndesis-server-1-fzlmg syndesis-server at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:67) ~[okhttp-3.8.0.jar!/:na] syndesis-server-1-fzlmg syndesis-server at okhttp3.internal.cache.CacheInterceptor.intercept(CacheInterceptor.java:93) ~[okhttp-3.8.0.jar!/:na] syndesis-server-1-fzlmg syndesis-server at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92) ~[okhttp-3.8.0.jar!/:na] syndesis-server-1-fzlmg syndesis-server at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:67) ~[okhttp-3.8.0.jar!/:na] syndesis-server-1-fzlmg syndesis-server at okhttp3.internal.http.BridgeInterceptor.intercept(BridgeInterceptor.java:93) ~[okhttp-3.8.0.jar!/:na] syndesis-server-1-fzlmg syndesis-server at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92) ~[okhttp-3.8.0.jar!/:na] syndesis-server-1-fzlmg syndesis-server at okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept(RetryAndFollowUpInterceptor.java:120) ~[okhttp-3.8.0.jar!/:na] syndesis-server-1-fzlmg syndesis-server at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92) ~[okhttp-3.8.0.jar!/:na] syndesis-server-1-fzlmg syndesis-server at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:67) ~[okhttp-3.8.0.jar!/:na] syndesis-server-1-fzlmg syndesis-server at io.fabric8.openshift.client.internal.OpenShiftOAuthInterceptor.intercept(OpenShiftOAuthInterceptor.java:64) ~[openshift-client-2.4.1.jar!/:na] syndesis-server-1-fzlmg syndesis-server at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92) ~[okhttp-3.8.0.jar!/:na] syndesis-server-1-fzlmg syndesis-server at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:67) ~[okhttp-3.8.0.jar!/:na] syndesis-server-1-fzlmg syndesis-server at okhttp3.RealCall.getResponseWithInterceptorChain(RealCall.java:185) ~[okhttp-3.8.0.jar!/:na] syndesis-server-1-fzlmg syndesis-server at okhttp3.RealCall.execute(RealCall.java:69) ~[okhttp-3.8.0.jar!/:na] syndesis-server-1-fzlmg syndesis-server at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:377) ~[kubernetes-client-2.4.1.jar!/:na] syndesis-server-1-fzlmg syndesis-server at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:343) ~[kubernetes-client-2.4.1.jar!/:na] syndesis-server-1-fzlmg syndesis-server at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleGet(OperationSupport.java:312) ~[kubernetes-client-2.4.1.jar!/:na] syndesis-server-1-fzlmg syndesis-server at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleGet(OperationSupport.java:295) ~[kubernetes-client-2.4.1.jar!/:na] syndesis-server-1-fzlmg syndesis-server at io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleGet(BaseOperation.java:753) ~[kubernetes-client-2.4.1.jar!/:na] syndesis-server-1-fzlmg syndesis-server at io.fabric8.kubernetes.client.dsl.base.BaseOperation.getMandatory(BaseOperation.java:206) ~[kubernetes-client-2.4.1.jar!/:na] syndesis-server-1-fzlmg syndesis-server ... 11 common frames omitted syndesis-server-1-fzlmg syndesis-server  ```    ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Simplest db to db integration 2. 3. 4. </body>
		<created>2018-03-08 12:26:50</created>
		<closed>2018-04-04 12:28:17</closed>
	</bug>
	<bug>
		<id>1895</id>
		<title>"No supported source type was found" when editing datamapper step</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When edition an existing integration and clicking around, one eventually get an errror:  ``` No supported source data type was found. Data type needs to be configured before Data Mapper step is added.  ``` ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; No error should occur ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![image](https://user-images.githubusercontent.com/99080/37148302-44bb6898-22ca-11e8-9ba6-d252963c532a.png)  ![image](https://user-images.githubusercontent.com/99080/37148374-8eb37878-22ca-11e8-9258-46ccb1805ee5.png)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create integration as described in #1894  2. Select integration from overview 3. "edit integration" 4. Select datamapper step 5. "Cancel" 6. Select initial connection 7. Select datamapper step again --&gt; boom </body>
		<created>2018-03-08 11:18:54</created>
		<closed>2018-03-08 15:44:14</closed>
	</bug>
	<bug>
		<id>1894</id>
		<title>Exception on empty resultset in sql-connector</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [X] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; When doing a db-to-db integration with a periodic select `select * from todo` and todo is empty, then the following exception occurs for the integration:  ``` 2018-03-08 11:02:57.553  WARN 1 --- [r://integration] o.a.camel.component.timer.TimerConsumer  : Error processing exchange. Exchange[i-L74GnoCT_48Vf2Brqaez]. Caused by: [java.lang.IllegalStateException - Got an empty collection]  java.lang.IllegalStateException: Got an empty collection at io.syndesis.connector.sql.customizer.SqlStartConnectorCustomizer.doAfterProducer(SqlStartConnectorCustomizer.java:49) ~[connector-sql-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT] at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) ~[camel-core-2.20.1.jar!/:2.20.1] at io.syndesis.integration.component.proxy.ComponentProxyProducer.process(ComponentProxyProducer.java:44) ~[integration-component-proxy-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT] at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.InterceptorToAsyncProcessorBridge.process(InterceptorToAsyncProcessorBridge.java:67) ~[camel-core-2.20.1.jar!/:2.20.1] at io.syndesis.integration.runtime.logging.IntegrationLoggingInterceptStrategy.lambda$wrapProcessorInInterceptors$0(IntegrationLoggingInterceptStrategy.java:45) ~[integration-runtime-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT] at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.InterceptorToAsyncProcessorBridge.process(InterceptorToAsyncProcessorBridge.java:76) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79) [camel-core-2.20.1.jar!/:2.20.1] at java.util.TimerThread.mainLoop(Timer.java:555) [na:1.8.0_151] at java.util.TimerThread.run(Timer.java:505) [na:1.8.0_151] ```  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; Should be a no-op   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create a simple integration DB-mapper-DB 2. "select * from todo" for the initial connection 3. Call add_lead as stored procedure for the output connection 4. Add a datamapping from "task" to "last_and_firstname" </body>
		<created>2018-03-08 11:14:05</created>
		<closed>2018-03-09 11:35:00</closed>
	</bug>
	<bug>
		<id>1880</id>
		<title>Integration Detail: history/version listing is missing</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem History part of detail page is not showing and no sign of it in HTML code also.  ## Expected behavior https://github.com/syndesisio/syndesis/blob/master/ux/designs/integration_details/integration_details_page.md#no-draft  ## Screenshot ![screen shot 2018-03-07 at 16 46 43](https://user-images.githubusercontent.com/5637792/37102045-3a1fef6a-2227-11e8-8fa4-55bfe00e489c.png) </body>
		<created>2018-03-07 15:48:37</created>
		<closed>2018-03-21 13:33:56</closed>
	</bug>
	<bug>
		<id>1872</id>
		<title>Deployments hanging in OS after integration delete, pods scaled to 0</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  I tried to delete integration. The delete action in syndesis removed the integration from syndesis, there is however a deployment in OpenShift hanging, with pods scaled to 0.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![deployments_hanging](https://user-images.githubusercontent.com/4180208/37091306-f119bcd4-2207-11e8-9a05-07ed4f5af70f.png)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create integration 2. Delete integration 3. Go to OpenShift console 4. See, there is a deployment left after the integration was deleted </body>
		<created>2018-03-07 12:04:45</created>
		<closed>2018-03-08 08:51:35</closed>
	</bug>
	<bug>
		<id>1867</id>
		<title>Basic Filter: list of field names for Salesforce object is empty</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem `datalist` element is not empty when Basic Filter is added to integration like `SF-&gt;Basic Filter-&gt;Datamapper-&gt;DB`. Resulting in no autocompletion for SF object fields to filter. However same use case with Twitter Mention action is working fine.  ## Expected behavior User is able to select field name to filter on from a populated list.   Cc @gashcrumb @paoloantinori  </body>
		<created>2018-03-07 08:43:29</created>
		<closed>2018-03-08 23:35:07</closed>
	</bug>
	<bug>
		<id>1859</id>
		<title>Integration fail to start: "EXTENSION_TAG": value not one of declared Enum instance names: [MAVEN, EXTENSION]</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Integration fails to deploy  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ``` i-paolo2-2-wdbmx i-paolo2 Error starting ApplicationContext. To display the auto-configuration report re-run your application with 'debug' enabled. i-paolo2-2-wdbmx i-paolo2 2018-03-06 21:20:45.412 ERROR 1 --- [           main] o.s.boot.SpringApplication               : Application startup failed i-paolo2-2-wdbmx i-paolo2  i-paolo2-2-wdbmx i-paolo2 org.apache.camel.spring.boot.CamelSpringBootInitializationException: java.lang.IllegalArgumentException: com.fasterxml.jackson.databind.exc.InvalidFormatException: Can not deserialize value of type io.syndesis.common.model.Dependency$Type from String "EXTENSION_TAG": value not one of declared Enum instance names: [MAVEN, EXTENSION] i-paolo2-2-wdbmx i-paolo2  at [Source: org.springframework.boot.loader.jar.ZipInflaterInputStream@289f15e9; line: 313, column: 20] (through reference chain: io.syndesis.common.model.integration.Integration$Builder["steps"]-&gt;java.util.ArrayList[0]-&gt;io.syndesis.common.model.integration.Step$Builder["connection"]-&gt;io.syndesis.common.model.connection.Connection$Builder["connector"]-&gt;io.syndesis.common.model.connection.Connector$Builder["dependencies"]-&gt;java.util.ArrayList[1]-&gt;io.syndesis.common.model.Dependency$Builder["type"]) i-paolo2-2-wdbmx i-paolo2 at org.apache.camel.spring.boot.RoutesCollector.onApplicationEvent(RoutesCollector.java:250) ~[camel-spring-boot-2.20.1.jar!/:2.20.1] i-paolo2-2-wdbmx i-paolo2 at org.apache.camel.spring.boot.RoutesCollector.onApplicationEvent(RoutesCollector.java:57) ~[camel-spring-boot-2.20.1.jar!/:2.20.1] i-paolo2-2-wdbmx i-paolo2 at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172) ~[spring-context-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] i-paolo2-2-wdbmx i-paolo2 at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165) ~[spring-context-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] i-paolo2-2-wdbmx i-paolo2 at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139) ~[spring-context-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] i-paolo2-2-wdbmx i-paolo2 at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:393) ~[spring-context-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] i-paolo2-2-wdbmx i-paolo2 at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:347) ~[spring-context-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] i-paolo2-2-wdbmx i-paolo2 at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:883) ~[spring-context-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] i-paolo2-2-wdbmx i-paolo2 at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.finishRefresh(EmbeddedWebApplicationContext.java:144) ~[spring-boot-1.5.8.RELEASE.jar!/:1.5.8.RELEASE] i-paolo2-2-wdbmx i-paolo2 at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546) ~[spring-context-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] i-paolo2-2-wdbmx i-paolo2 at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) ~[spring-boot-1.5.8.RELEASE.jar!/:1.5.8.RELEASE] i-paolo2-2-wdbmx i-paolo2 at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.8.RELEASE.jar!/:1.5.8.RELEASE] i-paolo2-2-wdbmx i-paolo2 at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.8.RELEASE.jar!/:1.5.8.RELEASE] i-paolo2-2-wdbmx i-paolo2 at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.8.RELEASE.jar!/:1.5.8.RELEASE] i-paolo2-2-wdbmx i-paolo2 at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.8.RELEASE.jar!/:1.5.8.RELEASE] i-paolo2-2-wdbmx i-paolo2 at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.8.RELEASE.jar!/:1.5.8.RELEASE] i-paolo2-2-wdbmx i-paolo2 at io.syndesis.example.Application.main(Application.java:13) [classes!/:na] i-paolo2-2-wdbmx i-paolo2 at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_151] i-paolo2-2-wdbmx i-paolo2 at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_151] i-paolo2-2-wdbmx i-paolo2 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151] i-paolo2-2-wdbmx i-paolo2 at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151] i-paolo2-2-wdbmx i-paolo2 at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48) [project-0.1-SNAPSHOT.jar:na] i-paolo2-2-wdbmx i-paolo2 at org.springframework.boot.loader.Launcher.launch(Launcher.java:87) [project-0.1-SNAPSHOT.jar:na] i-paolo2-2-wdbmx i-paolo2 at org.springframework.boot.loader.Launcher.launch(Launcher.java:50) [project-0.1-SNAPSHOT.jar:na] i-paolo2-2-wdbmx i-paolo2 at org.springframework.boot.loader.PropertiesLauncher.main(PropertiesLauncher.java:587) [project-0.1-SNAPSHOT.jar:na] i-paolo2-2-wdbmx i-paolo2 Caused by: java.lang.IllegalArgumentException: com.fasterxml.jackson.databind.exc.InvalidFormatException: Can not deserialize value of type io.syndesis.common.model.Dependency$Type from String "EXTENSION_TAG": value not one of declared Enum instance names: [MAVEN, EXTENSION] i-paolo2-2-wdbmx i-paolo2  at [Source: org.springframework.boot.loader.jar.ZipInflaterInputStream@289f15e9; line: 313, column: 20] (through reference chain: io.syndesis.common.model.integration.Integration$Builder["steps"]-&gt;java.util.ArrayList[0]-&gt;io.syndesis.common.model.integration.Step$Builder["connection"]-&gt;io.syndesis.common.model.connection.Connection$Builder["connector"]-&gt;io.syndesis.common.model.connection.Connector$Builder["dependencies"]-&gt;java.util.ArrayList[1]-&gt;io.syndesis.common.model.Dependency$Builder["type"]) i-paolo2-2-wdbmx i-paolo2 at io.syndesis.integration.runtime.IntegrationRuntimeAutoConfiguration$1.beforeApplicationStart(IntegrationRuntimeAutoConfiguration.java:67) ~[integration-runtime-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT] i-paolo2-2-wdbmx i-paolo2 at org.apache.camel.spring.boot.RoutesCollector.onApplicationEvent(RoutesCollector.java:152) ~[camel-spring-boot-2.20.1.jar!/:2.20.1] i-paolo2-2-wdbmx i-paolo2 ... 24 common frames omitted i-paolo2-2-wdbmx i-paolo2 Caused by: com.fasterxml.jackson.databind.exc.InvalidFormatException: Can not deserialize value of type io.syndesis.common.model.Dependency$Type from String "EXTENSION_TAG": value not one of declared Enum instance names: [MAVEN, EXTENSION] i-paolo2-2-wdbmx i-paolo2  at [Source: org.springframework.boot.loader.jar.ZipInflaterInputStream@289f15e9; line: 313, column: 20] (through reference chain: io.syndesis.common.model.integration.Integration$Builder["steps"]-&gt;java.util.ArrayList[0]-&gt;io.syndesis.common.model.integration.Step$Builder["connection"]-&gt;io.syndesis.common.model.connection.Connection$Builder["connector"]-&gt;io.syndesis.common.model.connection.Connector$Builder["dependencies"]-&gt;java.util.ArrayList[1]-&gt;io.syndesis.common.model.Dependency$Builder["type"]) i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.exc.InvalidFormatException.from(InvalidFormatException.java:74) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.DeserializationContext.weirdStringException(DeserializationContext.java:1410) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.DeserializationContext.handleWeirdStringValue(DeserializationContext.java:926) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.std.EnumDeserializer._deserializeAltString(EnumDeserializer.java:189) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.std.EnumDeserializer.deserialize(EnumDeserializer.java:126) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:504) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.impl.MethodProperty.deserializeSetAndReturn(MethodProperty.java:116) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.BuilderBasedDeserializer.vanillaDeserialize(BuilderBasedDeserializer.java:266) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.BuilderBasedDeserializer.deserialize(BuilderBasedDeserializer.java:154) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:287) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:259) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:26) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:504) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.impl.MethodProperty.deserializeSetAndReturn(MethodProperty.java:116) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.BuilderBasedDeserializer.vanillaDeserialize(BuilderBasedDeserializer.java:266) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.BuilderBasedDeserializer.deserialize(BuilderBasedDeserializer.java:154) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.datatype.jdk8.OptionalDeserializer.deserialize(OptionalDeserializer.java:100) ~[jackson-datatype-jdk8-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.datatype.jdk8.OptionalDeserializer.deserialize(OptionalDeserializer.java:13) ~[jackson-datatype-jdk8-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:504) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.impl.MethodProperty.deserializeSetAndReturn(MethodProperty.java:116) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.BuilderBasedDeserializer.vanillaDeserialize(BuilderBasedDeserializer.java:266) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.BuilderBasedDeserializer.deserialize(BuilderBasedDeserializer.java:154) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.datatype.jdk8.OptionalDeserializer.deserialize(OptionalDeserializer.java:100) ~[jackson-datatype-jdk8-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.datatype.jdk8.OptionalDeserializer.deserialize(OptionalDeserializer.java:13) ~[jackson-datatype-jdk8-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:504) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.impl.MethodProperty.deserializeSetAndReturn(MethodProperty.java:116) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.BuilderBasedDeserializer.vanillaDeserialize(BuilderBasedDeserializer.java:266) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.BuilderBasedDeserializer.deserialize(BuilderBasedDeserializer.java:154) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:287) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:259) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:26) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:504) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.impl.MethodProperty.deserializeSetAndReturn(MethodProperty.java:116) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.BuilderBasedDeserializer.vanillaDeserialize(BuilderBasedDeserializer.java:266) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.deser.BuilderBasedDeserializer.deserialize(BuilderBasedDeserializer.java:154) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:1626) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1186) ~[jackson-databind-2.8.10.jar!/:2.8.10] i-paolo2-2-wdbmx i-paolo2 at io.syndesis.integration.runtime.IntegrationRouteBuilder.loadIntegration(IntegrationRouteBuilder.java:95) ~[integration-runtime-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT] i-paolo2-2-wdbmx i-paolo2 at io.syndesis.integration.runtime.IntegrationRouteBuilder.configure(IntegrationRouteBuilder.java:106) ~[integration-runtime-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT] i-paolo2-2-wdbmx i-paolo2 at org.apache.camel.builder.RouteBuilder.checkInitialized(RouteBuilder.java:462) ~[camel-core-2.20.1.jar!/:2.20.1] i-paolo2-2-wdbmx i-paolo2 at org.apache.camel.builder.RouteBuilder.configureRoutes(RouteBuilder.java:402) ~[camel-core-2.20.1.jar!/:2.20.1] i-paolo2-2-wdbmx i-paolo2 at org.apache.camel.builder.RouteBuilder.addRoutesToCamelContext(RouteBuilder.java:383) ~[camel-core-2.20.1.jar!/:2.20.1] i-paolo2-2-wdbmx i-paolo2 at org.apache.camel.impl.DefaultCamelContext$1.call(DefaultCamelContext.java:1032) ~[camel-core-2.20.1.jar!/:2.20.1] i-paolo2-2-wdbmx i-paolo2 at org.apache.camel.impl.DefaultCamelContext$1.call(DefaultCamelContext.java:1029) ~[camel-core-2.20.1.jar!/:2.20.1] i-paolo2-2-wdbmx i-paolo2 at org.apache.camel.impl.DefaultCamelContext.doWithDefinedClassLoader(DefaultCamelContext.java:3268) ~[camel-core-2.20.1.jar!/:2.20.1] i-paolo2-2-wdbmx i-paolo2 at org.apache.camel.impl.DefaultCamelContext.addRoutes(DefaultCamelContext.java:1029) ~[camel-core-2.20.1.jar!/:2.20.1] i-paolo2-2-wdbmx i-paolo2 at io.syndesis.integration.runtime.IntegrationRuntimeAutoConfiguration$1.beforeApplicationStart(IntegrationRuntimeAutoConfiguration.java:65) ~[integration-runtime-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT] i-paolo2-2-wdbmx i-paolo2 ... 25 common frames omitted i-paolo2-2-wdbmx i-paolo2  ```   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. just deploy a simple db to db integration 2. 3. 4. </body>
		<created>2018-03-06 21:23:52</created>
		<closed>2018-03-06 21:41:12</closed>
	</bug>
	<bug>
		<id>1841</id>
		<title>Integration ID should be sanitized (start with alphanumeric char)</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem ``` io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://openshift.default.svc/oapi/v1/namespaces/syndesis/buildconfigs. Message: BuildConfig "crud4-read-create-inbuilt-e2e" is invalid: metadata.labels: Invalid value: "-L6vhGutyFz_uhplUNxx": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?'). Received status: Status(apiVersion=v1, code=422, details=StatusDetails(causes=[StatusCause(field=metadata.labels, message=Invalid value: "-L6vhGutyFz_uhplUNxx": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?'), reason=FieldValueInvalid, additionalProperties={})], group=null, kind=BuildConfig, name=crud4-read-create-inbuilt-e2e, retryAfterSeconds=null, additionalProperties={}), kind=Status, message=BuildConfig "crud4-read-create-inbuilt-e2e" is invalid: metadata.labels: Invalid value: "-L6vhGutyFz_uhplUNxx": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?'), metadata=ListMeta(resourceVersion=null, selfLink=null, additionalProperties={}), reason=Invalid, status=Failure, additionalProperties={}). --  | at io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:470) ~[kubernetes-client-2.4.1.jar!/:na]  | at io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:409) ~[kubernetes-client-2.4.1.jar!/:na]  | at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:379) ~[kubernetes-client-2.4.1.jar!/:na]  | at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:343) ~[kubernetes-client-2.4.1.jar!/:na]  | at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:226) ~[kubernetes-client-2.4.1.jar!/:na]  | at io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:741) ~[kubernetes-client-2.4.1.jar!/:na]  | at io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:334) ~[kubernetes-client-2.4.1.jar!/:na]  | at io.fabric8.kubernetes.client.dsl.base.BaseOperation.createOrReplace(BaseOperation.java:403) ~[kubernetes-client-2.4.1.jar!/:na]  | at io.fabric8.kubernetes.client.dsl.base.BaseOperation$2.apply(BaseOperation.java:372) ~[kubernetes-client-2.4.1.jar!/:na]  | at io.fabric8.openshift.api.model.DoneableBuildConfig.done(DoneableBuildConfig.java:27) ~[kubernetes-model-1.0.74.jar!/:1.0.74]  | at io.syndesis.server.openshift.OpenShiftServiceImpl.ensureBuildConfig(OpenShiftServiceImpl.java:306) ~[server-openshift-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT]  | at io.syndesis.server.openshift.OpenShiftServiceImpl.build(OpenShiftServiceImpl.java:59) ~[server-openshift-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT]  | at io.syndesis.server.controller.integration.online.PublishHandler.build(PublishHandler.java:155) ~[server-controller-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT]  | at io.syndesis.server.controller.integration.online.PublishHandler$BuildStepPerformer.perform(PublishHandler.java:313) ~[server-controller-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT]  | at io.syndesis.server.controller.integration.online.PublishHandler.execute(PublishHandler.java:101) ~[server-controller-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT]  | at io.syndesis.server.controller.StateChangeHandler.execute(StateChangeHandler.java:33) [server-controller-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT]  | at io.syndesis.server.controller.integration.IntegrationController.lambda$callStateChangeHandler$11(IntegrationController.java:186) [server-controller-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT]  | at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_131]  | at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_131]  | at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]    ```  I've noticed that sometimes Integration can't be build/deployed due to error log in `syndesis-server` coming from OpenShift API.  Actual Integration ID: `-L6vhGutyFz_uhplUNxx`.    </body>
		<created>2018-03-06 14:32:21</created>
		<closed>2018-03-06 21:32:59</closed>
	</bug>
	<bug>
		<id>1832</id>
		<title>The case of missing `specification` property</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem  Running an integration with API connector fails to load Swagger specification. The stack trace is: ``` Caused by: java.lang.IllegalArgumentException: The given Swagger specification could not be loaded from `file:/tmp/swagger-operation1065033880072210483.swagger`. Tried loading using Camel's resource resolution and using Swagger's own resource resolution. Swagger tends to swallow exceptions while parsing, try specifying Java system property `debugParser` (e.g. `-DdebugParser=true`), the exception that occured when loading using Camel's resource loader follows at org.apache.camel.component.rest.swagger.RestSwaggerEndpoint.loadSpecificationFrom(RestSwaggerEndpoint.java:471) ~[camel-rest-swagger-2.20.1.jar!/:2.20.1] at org.apache.camel.component.rest.swagger.RestSwaggerEndpoint.createProducer(RestSwaggerEndpoint.java:154) ~[camel-rest-swagger-2.20.1.jar!/:2.20.1] at org.apache.camel.component.connector.DefaultConnectorEndpoint.createProducer(DefaultConnectorEndpoint.java:51) ~[camel-connector-2.20.1.jar!/:2.20.1] at org.apache.camel.impl.ProducerCache.doGetProducer(ProducerCache.java:573) ~[camel-core-2.20.1.jar!/:2.20.1] ... 107 common frames omitted Caused by: com.fasterxml.jackson.databind.JsonMappingException: No content to map due to end-of-input  at [Source: java.io.FileInputStream@e0847a9; line: 1, column: 0] at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:270) ~[jackson-databind-2.8.10.jar!/:2.8.10] at com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:3854) ~[jackson-databind-2.8.10.jar!/:2.8.10] at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3799) ~[jackson-databind-2.8.10.jar!/:2.8.10] at com.fasterxml.jackson.databind.ObjectMapper.readTree(ObjectMapper.java:2337) ~[jackson-databind-2.8.10.jar!/:2.8.10] at org.apache.camel.component.rest.swagger.RestSwaggerEndpoint.loadSpecificationFrom(RestSwaggerEndpoint.java:460) ~[camel-rest-swagger-2.20.1.jar!/:2.20.1] ... 110 common frames omitted ```  Seems that we don't map the properties from the OpenShift secret to the connector at runtime. Case in point the Swagger REST connector (akka custom API connector).  I see the secret was generated as:  ``` # #Tue Mar 06 08:06:44 UTC 2018 swagger-operation.configurations.swagger-operation-3.host=... sql-1.password=... swagger-operation.configurations.swagger-operation-3.authenticationType=none swagger-operation.configurations.swagger-operation-3.specification=... ```  This comes from `configuredProperties` of a Connector and don't seem to be set on the connector.  ## Expected behavior  Set `configuredProperties` from the Connector model to the Connector instance.  ## Screenshot  ![](https://media3.giphy.com/media/l3q2RauzE5Vzf7iYo/giphy.gif)  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create Custom API connector 2. Create an Integration using this connector 3. Observe the exception in the integration log 4. </body>
		<created>2018-03-06 08:42:22</created>
		<closed>2018-03-06 11:29:06</closed>
	</bug>
	<bug>
		<id>1828</id>
		<title>Integration Editor: `Save as Draft` doesn't proceed to next page</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem `Save as Draft` successfully submit a request to backend but doesn't process to detail page afterwards.  ## Expected behavior User should be redirected to `Integration Detail` after successful submit op.   ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create integration  2. `Save as Draft`</body>
		<created>2018-03-05 20:36:32</created>
		<closed>2018-03-05 20:43:26</closed>
	</bug>
	<bug>
		<id>1827</id>
		<title>API Connector: delete button is missing</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem There's no `Delete` button anymore in the listed item.  ## Expected behavior Delete button is displayed in a listed item.  ## Screenshot &lt;img width="1231" alt="screen shot 2018-03-05 at 21 18 14" src="https://user-images.githubusercontent.com/5637792/36997768-fb3092ae-20ba-11e8-88a0-5bf79eedde28.png"&gt; </body>
		<created>2018-03-05 20:20:27</created>
		<closed>2018-03-13 11:03:57</closed>
	</bug>
	<bug>
		<id>1826</id>
		<title>API Connector: debug element forgotten in list?</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem It seems there's an debug `pre` element left on API Connectors list page.  ## Screenshot &lt;img width="1179" alt="screen shot 2018-03-05 at 21 16 08" src="https://user-images.githubusercontent.com/5637792/36997613-7c8e5dbe-20ba-11e8-8c86-bb001c509358.png"&gt; </body>
		<created>2018-03-05 20:17:26</created>
		<closed>2018-03-06 18:33:11</closed>
	</bug>
	<bug>
		<id>1825</id>
		<title>Monitoring Activity: version value mismatch</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Version displayed per Activity is altering between real value and `Uknown version`.  ## Expected behavior Version per Activity is the same for specific revision.  ## Screenshot &lt;img width="1175" alt="screen shot 2018-03-05 at 20 59 45" src="https://user-images.githubusercontent.com/5637792/36996993-8553308e-20b8-11e8-9a3b-b6f83c7331a0.png"&gt; </body>
		<created>2018-03-05 20:05:35</created>
		<closed>2018-04-16 16:19:27</closed>
	</bug>
	<bug>
		<id>1824</id>
		<title>Monitoring Metrics: values aren't updated in Integration Detail view</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Metrics values aren't reflected when accessed via Integration Details-&gt;Metrics. However on Dashboard is seems fine.  ## Expected behavior Metrics have same values displayed in both widgets.   ## Screenshot Dashboard: &lt;img width="1168" alt="screen shot 2018-03-05 at 20 32 22" src="https://user-images.githubusercontent.com/5637792/36995541-9c151aca-20b4-11e8-9c30-948079dc7ed5.png"&gt;   Integration Detail: &lt;img width="1186" alt="screen shot 2018-03-05 at 20 32 16" src="https://user-images.githubusercontent.com/5637792/36995547-a07e75e8-20b4-11e8-98fe-8793a3269813.png"&gt;  Cc @deeleman @Stefan365  </body>
		<created>2018-03-05 19:36:04</created>
		<closed>2018-03-08 16:09:02</closed>
	</bug>
	<bug>
		<id>1823</id>
		<title>Integration Detail: name can't be changed with 415 Unsupported Media Type</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [x] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem Changing integration name via edit button produces HTTP `415 Unsupported Media Type` error in toast notification and browser console.  ## Expected behavior Name can be changed without error.  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt; ``` PATCH /api/v1/integrations/-L6rX5kzqEGaSvkbV_Py HTTP/1.1 Host: syndesis.192.168.64.16.nip.io Connection: keep-alive Content-Length: 4 Pragma: no-cache Cache-Control: no-cache Accept: application/json, text/plain, */* Origin: https://syndesis.192.168.64.16.nip.io User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.170 Safari/537.36 Vivaldi/1.95.1077.50 content-type: text/plain DNT: 1 Referer: https://syndesis.192.168.64.16.nip.io/integrations/-L6rX5kzqEGaSvkbV_Py Accept-Encoding: gzip, deflate, br Accept-Language: en-GB,en-US;q=0.9,en;q=0.8 Cookie: b2a2e2613ad00502bbe3dae4fed6f03a=19e20e8002a42202f8081ae828bbc1de; _oauth_proxy=ZGV2ZWxvcGVyQGNsdXN0ZXIubG9jYWx8THRaYzlPeStTZ1htd2RPNmd6QWw4OVBRWVhxbk5sVmN6VlJPNGZBSWJGTGp5WVE1cjdHNzNhTHVTeXEzbWJiM2JINHBxVlF4aWJWZmViQT18LTYyMTM1NTk2ODAwfA==|1520263071|mHfFOb0lq85RCdh9KeHwWE1--PI= ```  Payload (this seems suspicious): ``` name ```  Response: ``` developerMsg:"RESTEASY003065: Cannot consume content type" errorCode:415 userMsg:"Given request is not acceptable" ```  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create integration  2. Wait until published 3. Navigate to Integration Detail page 4. Try changing name </body>
		<created>2018-03-05 19:16:16</created>
		<closed>2018-03-08 16:38:07</closed>
	</bug>
	<bug>
		<id>1818</id>
		<title>Response from integration activity is not ordered</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem  The response from `/api/v1/activity/integrations/{id}` doesn't seem to be ordered. On refresh from the UI this becomes a usability issue.  Actually I'm not entirely that it makes sense for the API to return 10 records for a newly created &amp; published integration. Seems to me that the number of records should be about 2?  ## Expected behavior  Activities should have deterministic order, probably chronological.  ## Screenshot ![issue-2018-03-05_17 12 17](https://user-images.githubusercontent.com/1306050/36986113-4c7c116e-2099-11e8-8958-edc3adfcae7a.gif)  ## API Endpoints and Schemas  `/api/v1/activity/integrations/{id}`  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create &amp; publish integration 2. Refresh integration activity screen 3. 4. </body>
		<created>2018-03-05 16:20:06</created>
		<closed>2018-03-06 19:39:13</closed>
	</bug>
	<bug>
		<id>1808</id>
		<title>JsonDBTest must not write fixed to "/tmp/test"</title>
		<body>but instead create an own temporary directory which gets cleaned up after the test.  This took me two hours to find out because an old DB from a previous run has been reused.</body>
		<created>2018-03-04 22:31:12</created>
		<closed>2018-03-05 11:22:22</closed>
	</bug>
	<bug>
		<id>1791</id>
		<title>Incorrect total integration count in the donut</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt; Integration total is incorrect on the dashboard  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt; I have 2 integrations here and the total is showing 4  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt; ![screenshot from 2018-03-02 10-43-29](https://user-images.githubusercontent.com/351660/36907557-e84b9794-1e06-11e8-9bca-91e103d4c0ce.png)</body>
		<created>2018-03-02 15:46:38</created>
		<closed>2018-03-09 20:08:53</closed>
	</bug>
	<bug>
		<id>1789</id>
		<title>Integration Export doesn't work</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem When using the export on an integration we have an error:  `GET https://syndesis.192.168.99.100.nip.io/api/v1/integration-support/export.zip?id=-L6b0OwJ7DOOHytH4lIX 500 (Internal Server Error) ERROR Error: Uncaught (in promise): Object: {"message":"An unexpected HTTP error occured. Please check stack strace","debugMessage":"An unexpected HTTP error occured. Please check stack strace"}     at E (polyfills.00b2490f9e8f9b4c7b5e.bundle.js:1)     at E (polyfills.00b2490f9e8f9b4c7b5e.bundle.js:1)     at polyfills.00b2490f9e8f9b4c7b5e.bundle.js:1     at t.invokeTask (polyfills.00b2490f9e8f9b4c7b5e.bundle.js:1)     at Object.onInvokeTask (main.12f2abea5612e7e78f5c.bundle.js:1)     at t.invokeTask (polyfills.00b2490f9e8f9b4c7b5e.bundle.js:1)     at e.runTask (polyfills.00b2490f9e8f9b4c7b5e.bundle.js:1)     at v (polyfills.00b2490f9e8f9b4c7b5e.bundle.js:1)     at e.invokeTask [as invoke] (polyfills.00b2490f9e8f9b4c7b5e.bundle.js:1)     at _ (polyfills.00b2490f9e8f9b4c7b5e.bundle.js:1)`  and in syndesis-rest log  `2018-03-02 14:15:08.162 ERROR [-,,,] 1 --- [  XNIO-3 task-8] io.undertow.request                      : UT005023: Exception handling request to /api/v1/integration-support/export.zip  |   | org.jboss.resteasy.spi.UnhandledException: java.lang.NoClassDefFoundError: org/h2/jdbcx/JdbcDataSource  | at org.jboss.resteasy.core.ExceptionHandler.handleApplicationException(ExceptionHandler.java:78) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final]  | at org.jboss.resteasy.core.ExceptionHandler.handleException(ExceptionHandler.java:222) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final]  | at org.jboss.resteasy.core.SynchronousDispatcher.writeException(SynchronousDispatcher.java:175) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final]  | at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:418) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final]  | at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:209) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final]  | at org.jboss.resteasy.plugins.server.servlet.ServletContainerDispatcher.service(ServletContainerDispatcher.java:227) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final]  | at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:56) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final]  | at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:51) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final]  | at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) ~[javax.servlet-api-3.1.0.jar!/:3.1.0]  | at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:85) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) ~[spring-boot-1.5.8.RELEASE.jar!/:1.5.8.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96) ~[spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110) ~[spring-boot-actuator-1.5.8.RELEASE.jar!/:1.5.8.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.security.web.authentication.preauth.AbstractPreAuthenticatedProcessingFilter.doFilter(AbstractPreAuthenticatedProcessingFilter.java:121) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:64) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE]  | at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) ~[spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) ~[spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108) ~[spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81) ~[spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at org.springframework.cloud.sleuth.instrument.web.TraceFilter.doFilter(TraceFilter.java:186) ~[spring-cloud-sleuth-core-1.2.5.RELEASE.jar!/:1.2.5.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) ~[spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:106) ~[spring-boot-actuator-1.5.8.RELEASE.jar!/:1.5.8.RELEASE]  | at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:64) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:131) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) ~[undertow-core-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) ~[undertow-core-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) ~[undertow-core-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) ~[undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.server.Connectors.executeRootHandler(Connectors.java:332) [undertow-core-1.4.21.Final.jar!/:1.4.21.Final]  | at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) [undertow-core-1.4.21.Final.jar!/:1.4.21.Final]  | at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_141]  | at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_141]  | at java.lang.Thread.run(Thread.java:748) [na:1.8.0_141]  | Caused by: java.lang.NoClassDefFoundError: org/h2/jdbcx/JdbcDataSource  | at io.syndesis.jsondb.impl.MemorySqlJsonDB.create(MemorySqlJsonDB.java:59) ~[rest-jsondb-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT]  | at io.syndesis.rest.v1.handler.integration.support.IntegrationSupportHandler.export(IntegrationSupportHandler.java:181) ~[rest-endpoint-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT]  | at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_141]  | at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_141]  | at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_141]  | at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_141]  | at org.jboss.resteasy.core.MethodInjectorImpl.invoke(MethodInjectorImpl.java:140) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final]  | at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTarget(ResourceMethodInvoker.java:294) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final]  | at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:248) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final]  | at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:235) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final]  | at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:402) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final]  | ... 104 common frames omitted`  ## Expected behavior Integration exported  ## Screenshot  ## API Endpoints and Schemas  ## Tasks involved / Steps to Reproduce  ## Tasks involved / Steps to Reproduce 1. Create an integration  2. Publish it 3. Export the integration </body>
		<created>2018-03-02 14:23:44</created>
		<closed>2018-03-06 16:25:28</closed>
	</bug>
	<bug>
		<id>1782</id>
		<title>Mapping with `kind=java` not using inspections</title>
		<body>## This is a... &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;  ## The problem  When using input data shapes with `kind=java` a ``No data type specification was found for subsequent step` error is displayed.  ## Expected behavior  I think for data shapes with `kind=java`, or perhaps in general with data shapes that have no `specification` inspection endpoint should be invoked.  Perhaps a proper solution is to migrate all connectors that have `kind=java` to the newest model, as I think the connector Maven plugin will set `specification` on the data shape.  ## Screenshot  ![screenshot-2018-3-2 syndesis - development](https://user-images.githubusercontent.com/1306050/36894055-87acd520-1e0a-11e8-9209-d9e809f912bf.png)  ## Tasks involved / Steps to Reproduce 1. Create a integration with Salesforce Fetch Record action at the end 2. Try to add data mapping step  See #1166</body>
		<created>2018-03-02 10:13:32</created>
		<closed>2018-09-21 12:33:57</closed>
	</bug>
	<bug>
		<id>1781</id>
		<title>'Add a data mapping step' link leads to `null` page in Firefox</title>
		<body>## This is a...  - [ ] Feature request - [ ] Regression (a behavior that used to work and stopped working in a new release) - [x] Bug report - [ ] Documentation issue or request   ## The problem  In firefox `href="javascript: null"` leads to a blank page with `null` on it. Perhaps we should use `javascript: void` instead?  ## Expected behavior  Adding a mapper step and displaying the mapping view.  ## Screenshot  ![issue-2018-03-02_10 54 22](https://user-images.githubusercontent.com/1306050/36893603-f8929876-1e08-11e8-98f5-3baf71f2fbd3.gif)  ## Tasks involved / Steps to Reproduce 1. Using Firefox 2. Create a integration 3. Try to add data mapping step via warning bubble  </body>
		<created>2018-03-02 10:01:51</created>
		<closed>2018-03-02 14:33:43</closed>
	</bug>
	<bug>
		<id>1780</id>
		<title>jsondb's DELETE's using a lot of CPU in postgresql</title>
		<body>## This is a... [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [x] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem  I left the integration running for 12 hours and the number of records to jsondb increased to over 500K, with that many rows issuing DELETE SQL statements uses resources significantly.  Notice the CPU TIME of PID 538:  ```shell $ ps auxww USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND 1000070+     1  0.0  0.1 171452  2776 ?        Ss   Mar01   0:06 postgres 1000070+   107  0.0  0.0  95020   780 ?        Ss   Mar01   0:00 postgres: logger process   1000070+   109  0.0  3.3 171572 69072 ?        Ss   Mar01   0:07 postgres: checkpointer process   1000070+   110  0.0  3.3 171452 68712 ?        Ss   Mar01   0:10 postgres: writer process   1000070+   111  0.0  0.1 171452  2216 ?        Ss   Mar01   0:13 postgres: wal writer process   1000070+   112  0.0  0.6 171872 12668 ?        Ss   Mar01   0:01 postgres: autovacuum launcher process   1000070+   113  0.0  0.0  97272  1108 ?        Ss   Mar01   0:08 postgres: stats collector process   1000070+   532  0.0  0.1 172268  3108 ?        Ss   Mar01   0:00 postgres: syndesis syndesis 172.17.0.2(47648) idle 1000070+   533  0.0  0.0 172268  1424 ?        Ss   Mar01   0:00 postgres: syndesis syndesis 172.17.0.2(47650) idle 1000070+   534  0.0  0.0 172268  1424 ?        Ss   Mar01   0:00 postgres: syndesis syndesis 172.17.0.2(47652) idle 1000070+   535  0.0  0.0 172268  1424 ?        Ss   Mar01   0:00 postgres: syndesis syndesis 172.17.0.2(47654) idle 1000070+   536  0.0  0.0 172268  1424 ?        Ss   Mar01   0:00 postgres: syndesis syndesis 172.17.0.2(47656) idle 1000070+   537  0.0  0.0 172268  1428 ?        Ss   Mar01   0:00 postgres: syndesis syndesis 172.17.0.2(47658) idle 1000070+   538 32.7  3.4 173556 71732 ?        Rs   Mar01 242:36 postgres: syndesis syndesis 172.17.0.2(47660) DELETE 1000070+   539  2.0  3.4 173036 70484 ?        Ss   Mar01  15:23 postgres: syndesis syndesis 172.17.0.2(47662) idle 1000070+   540  0.0  0.3 173148  7500 ?        Ss   Mar01   0:00 postgres: syndesis syndesis 172.17.0.2(47664) idle 1000070+   541  0.7  3.4 173244 71568 ?        Ss   Mar01   5:40 postgres: syndesis syndesis 172.17.0.2(47666) idle 1000070+ 12798  0.0  0.1  11784  2700 ?        Ss   08:15   0:00 /bin/sh 1000070+ 13146  0.0  0.1  47468  3024 ?        R+   08:21   0:00 ps auxww ```  ```sql # select * from pg_stat_activity;  datid | datname  |  pid  | usesysid | usename  | application_name | client_addr | client_hostname | client_port |         backend_start         |          xact_start           |          query_start          |         state_change          | waiting | state  | backend_xid | backend_xmin |                                                 query                                                   -------+----------+-------+----------+----------+------------------+-------------+-----------------+-------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------+---------+--------+-------------+--------------+--------------------------------------------------------------------------------------------------------  16385 | syndesis |   532 |    16384 | syndesis |                  | 172.17.0.2  |                 |       47648 | 2018-03-01 20:00:45.265613+00 |                               | 2018-03-01 20:00:45.343247+00 | 2018-03-01 20:00:45.343279+00 | f       | idle   |             |              | SET extra_float_digits = 3  16385 | syndesis |   533 |    16384 | syndesis |                  | 172.17.0.2  |                 |       47650 | 2018-03-01 20:00:45.379894+00 |                               | 2018-03-01 20:00:45.382083+00 | 2018-03-01 20:00:45.382108+00 | f       | idle   |             |              | SET extra_float_digits = 3  16385 | syndesis |   534 |    16384 | syndesis |                  | 172.17.0.2  |                 |       47652 | 2018-03-01 20:00:45.386756+00 |                               | 2018-03-01 20:00:45.388448+00 | 2018-03-01 20:00:45.388467+00 | f       | idle   |             |              | SET extra_float_digits = 3  16385 | syndesis |   535 |    16384 | syndesis |                  | 172.17.0.2  |                 |       47654 | 2018-03-01 20:00:45.392657+00 |                               | 2018-03-01 20:00:45.394147+00 | 2018-03-01 20:00:45.394164+00 | f       | idle   |             |              | SET extra_float_digits = 3  16385 | syndesis |   536 |    16384 | syndesis |                  | 172.17.0.2  |                 |       47656 | 2018-03-01 20:00:45.398642+00 |                               | 2018-03-01 20:00:45.401067+00 | 2018-03-01 20:00:45.401085+00 | f       | idle   |             |              | SET extra_float_digits = 3  16385 | syndesis |   537 |    16384 | syndesis |                  | 172.17.0.2  |                 |       47658 | 2018-03-01 20:00:45.405194+00 |                               | 2018-03-01 20:00:45.406874+00 | 2018-03-01 20:00:45.406894+00 | f       | idle   |             |              | SET extra_float_digits = 3  16385 | syndesis |   538 |    16384 | syndesis |                  | 172.17.0.2  |                 |       47660 | 2018-03-01 20:00:45.41097+00  | 2018-03-02 08:22:59.538506+00 | 2018-03-02 08:23:13.43341+00  | 2018-03-02 08:23:13.433411+00 | f       | active |       29967 |        29967 | DELETE from jsondb where path LIKE $1 OR path in ( $2, $3, $4, $5, $6, $7 )  16385 | syndesis |   539 |    16384 | syndesis |                  | 172.17.0.2  |                 |       47662 | 2018-03-01 20:00:45.416607+00 |                               | 2018-03-02 07:33:13.565059+00 | 2018-03-02 07:33:13.565213+00 | f       | idle   |             |              | select path,value,ovalue from jsondb where path LIKE $1 order by path ASC  16385 | syndesis |   540 |    16384 | syndesis |                  | 172.17.0.2  |                 |       47664 | 2018-03-01 20:00:45.423629+00 |                               | 2018-03-01 20:08:30.549945+00 | 2018-03-01 20:08:30.550305+00 | f       | idle   |             |              | select path,value,ovalue from jsondb where path LIKE $1 and path &gt;= $2 and path &lt; $3 order by path ASC  16385 | syndesis |   541 |    16384 | syndesis |                  | 172.17.0.2  |                 |       47666 | 2018-03-01 20:00:45.429155+00 |                               | 2018-03-02 08:23:13.39786+00  | 2018-03-02 08:23:13.397908+00 | f       | idle   |             |              | select path,value,ovalue from jsondb where path LIKE $1 order by path ASC  12442 | postgres | 13199 |       10 | postgres | psql             |             |                 |          -1 | 2018-03-02 08:22:17.360923+00 | 2018-03-02 08:23:13.4525+00   | 2018-03-02 08:23:13.4525+00   | 2018-03-02 08:23:13.452502+00 | f       | active |             |        29967 | select * from pg_stat_activity; (11 rows) ```  Root cause seems to be jsondb's implementation of `update`:  https://github.com/syndesisio/syndesis/blob/9441747dd46ee10df599942105b8ab112f82dfa5/app/rest/jsondb/src/main/java/io/syndesis/jsondb/impl/SqlJsonDB.java#L474  Triggered from:  https://github.com/syndesisio/syndesis/blob/9441747dd46ee10df599942105b8ab112f82dfa5/app/rest/db-logging/src/main/java/io/syndesis/rest/dblogging/controller/ActivityTrackingController.java#L287  Full stack:  ``` "Logs Controller" #19 prio=5 os_prio=0 tid=0x00007f8426379800 nid=0x71 runnable [0x00007f84140d8000]    java.lang.Thread.State: RUNNABLE at java.net.SocketInputStream.socketRead0(Native Method) at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) at java.net.SocketInputStream.read(SocketInputStream.java:171) at java.net.SocketInputStream.read(SocketInputStream.java:141) at org.postgresql.core.VisibleBufferedInputStream.readMore(VisibleBufferedInputStream.java:145) at org.postgresql.core.VisibleBufferedInputStream.ensureBytes(VisibleBufferedInputStream.java:114) at org.postgresql.core.VisibleBufferedInputStream.read(VisibleBufferedInputStream.java:73) at org.postgresql.core.PGStream.ReceiveChar(PGStream.java:274) at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:1661) at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:257) - locked &lt;0x00000000edccf958&gt; (a org.postgresql.core.v3.QueryExecutorImpl) at org.postgresql.jdbc2.AbstractJdbc2Statement.execute(AbstractJdbc2Statement.java:512) at org.postgresql.jdbc2.AbstractJdbc2Statement.executeWithFlags(AbstractJdbc2Statement.java:388) at org.postgresql.jdbc2.AbstractJdbc2Statement.execute(AbstractJdbc2Statement.java:381) at sun.reflect.GeneratedMethodAccessor104.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.tomcat.jdbc.pool.StatementFacade$StatementProxy.invoke(StatementFacade.java:114) at com.sun.proxy.$Proxy144.execute(Unknown Source) at org.skife.jdbi.v2.SQLStatement.internalExecute(SQLStatement.java:1327) at org.skife.jdbi.v2.Update.execute(Update.java:56) at org.skife.jdbi.v2.BasicHandle.update(BasicHandle.java:305) at io.syndesis.jsondb.impl.SqlJsonDB.deleteJsonRecords(SqlJsonDB.java:514) at io.syndesis.jsondb.impl.SqlJsonDB.access$100(SqlJsonDB.java:74) at io.syndesis.jsondb.impl.SqlJsonDB$BatchManager.deleteRecordsForSet(SqlJsonDB.java:395) at io.syndesis.jsondb.impl.SqlJsonDB.lambda$update$18(SqlJsonDB.java:474) at io.syndesis.jsondb.impl.SqlJsonDB$$Lambda$240/125309362.accept(Unknown Source) at io.syndesis.jsondb.impl.SqlJsonDB.withTransaction(SqlJsonDB.java:550) at io.syndesis.jsondb.impl.SqlJsonDB.update(SqlJsonDB.java:451) at io.syndesis.jsondb.JsonDB.update(JsonDB.java:141) at io.syndesis.rest.dblogging.controller.ActivityTrackingController.processEventQueue(ActivityTrackingController.java:287) at io.syndesis.rest.dblogging.controller.ActivityTrackingController$$Lambda$49/522173599.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) ```  ## Expected behavior  Not taking 100% CPU.  ## Screenshot  ![fine](https://user-images.githubusercontent.com/1306050/36890588-d14c4cd0-1dfe-11e8-80d9-7e1bf30478f9.png)  ## Tasks involved / Steps to Reproduce 1. Create an integration 2. Let it run for a while 3. Cook some CPUs </body>
		<created>2018-03-02 08:48:44</created>
		<closed>2019-02-20 16:48:09</closed>
	</bug>
	<bug>
		<id>1769</id>
		<title>Flacky SQL test</title>
		<body> The following errors happens every third run or so, and should be fixed as it impacts our release process:  ``` 00:10:12.230 Tests run: 11, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 2.994 sec &lt;&lt;&lt; FAILURE! - in io.syndesis.connector.sql.common.SqlParserTest 00:10:12.230 io.syndesis.connector.sql.common.SqlParserTest  Time elapsed: 0.109 sec  &lt;&lt;&lt; ERROR! 00:10:12.230 java.sql.SQLException: Operation 'DROP TABLE' cannot be performed on object 'NAME0' because there is an open ResultSet dependent on that object. 00:10:12.230 at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) 00:10:12.230 at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) 00:10:12.230 at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) 00:10:12.230 at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source) 00:10:12.230 at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source) 00:10:12.230 at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source) 00:10:12.230 at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source) 00:10:12.230 at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source) 00:10:12.230 at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source) 00:10:12.230 at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source) 00:10:12.230 at io.syndesis.connector.sql.common.SqlParserTest.afterClass(SqlParserTest.java:154) 00:10:12.230 at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) 00:10:12.230 at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) 00:10:12.230 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) 00:10:12.230 at java.lang.reflect.Method.invoke(Method.java:498) 00:10:12.230 at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) 00:10:12.230 at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) 00:10:12.230 at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) 00:10:12.230 at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33) 00:10:12.230 at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48) 00:10:12.230 at org.junit.rules.RunRules.evaluate(RunRules.java:20) 00:10:12.230 at org.junit.runners.ParentRunner.run(ParentRunner.java:363) 00:10:12.230 at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:367) 00:10:12.230 at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:274) 00:10:12.230 at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238) 00:10:12.230 at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:161) 00:10:12.230 at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:290) 00:10:12.230 at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:242) 00:10:12.230 at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:121) 00:10:12.230 Caused by: ERROR X0X95: Operation 'DROP TABLE' cannot be performed on object 'NAME0' because there is an open ResultSet dependent on that object. 00:10:12.230 at org.apache.derby.iapi.error.StandardException.newException(Unknown Source) 00:10:12.230 at org.apache.derby.iapi.error.StandardException.newException(Unknown Source) 00:10:12.230 at org.apache.derby.impl.sql.conn.GenericLanguageConnectionContext.verifyNoOpenResultSets(Unknown Source) 00:10:12.230 at org.apache.derby.impl.sql.GenericPreparedStatement.prepareToInvalidate(Unknown Source) 00:10:12.230 at org.apache.derby.impl.sql.depend.BasicDependencyManager.coreInvalidateFor(Unknown Source) 00:10:12.230 at org.apache.derby.impl.sql.depend.BasicDependencyManager.invalidateFor(Unknown Source) 00:10:12.230 at org.apache.derby.impl.sql.execute.DropTableConstantAction.executeConstantAction(Unknown Source) 00:10:12.230 at org.apache.derby.impl.sql.execute.MiscResultSet.open(Unknown Source) 00:10:12.230 at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source) 00:10:12.230 at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source) 00:10:12.230 ... 22 more 00:10:12.230   00:10:13.156 Running io.syndesis.connector.sql.stored.SqlStoredConnectorMetaDataExtensionTest ``` </body>
		<created>2018-03-01 20:55:43</created>
		<closed>2018-03-12 13:50:11</closed>
	</bug>
	<bug>
		<id>1744</id>
		<title>Unable to add steps</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [X] Regression (a behavior that used to work and stopped working in a new release) [ ] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem &lt;!-- Briefly describe the issue you are experiencing (or the feature you want to see implemented on Syndesis). + For BUGS, tell us what you were trying to do and what happened instead. + For NEW FEATURES, describe the _User Persona_ demanding it and its use case. --&gt;  Unable to add steps between connections, the error shown on browser's console is:  ``` main.34c31e3c4bd63a61a994.bundle.js:1 ERROR TypeError: Cannot read property 'properties' of undefined     at t.getProperties (main.34c31e3c4bd63a61a994.bundle.js:1)     at n.loadFormSetup (1.2418b268c2b57bd28321.chunk.js:1)     at n.loadForm (1.2418b268c2b57bd28321.chunk.js:1)     at e._next (1.2418b268c2b57bd28321.chunk.js:1)     at e.__tryOrSetError (polyfills.00b2490f9e8f9b4c7b5e.bundle.js:1)     at e.next (polyfills.00b2490f9e8f9b4c7b5e.bundle.js:1)     at e._next (polyfills.00b2490f9e8f9b4c7b5e.bundle.js:1)     at e.next (polyfills.00b2490f9e8f9b4c7b5e.bundle.js:1)     at e._next (polyfills.00b2490f9e8f9b4c7b5e.bundle.js:1)     at e.next (polyfills.00b2490f9e8f9b4c7b5e.bundle.js:1) Ct @ main.34c31e3c4bd63a61a994.bundle.js:1 ```  ## Expected behavior &lt;!-- Describe what the desired behavior would be, enlistin gthe acceptance criteria. --&gt;  ## Screenshot &lt;!-- For features/bugs tackling with UI functionality, drag and drop a screenshot depicting the desired presentation layer or supporting the UX narrative for the new functionality. --&gt;  ![image](https://user-images.githubusercontent.com/1868933/36830395-c227b39c-1d23-11e8-9909-155265e6a675.png)  ## API Endpoints and Schemas &lt;!-- For features or bugfixes entailing data exchanges between the UI and the REST API, enlist the different endpoints available and the payload/response schemas. --&gt;  ## Tasks involved / Steps to Reproduce &lt;!-- Enlist all the acceptance criteria for new features or the steps required to reproduce the bug/regression reported. --&gt; 1. Create an integration 2. Add a `Periodic SQL Invocation` action 3. Add a `Invoke Stored procedure` action 4. Add a datamapper step </body>
		<created>2018-03-01 06:44:33</created>
		<closed>2018-03-01 17:41:44</closed>
	</bug>
	<bug>
		<id>1730</id>
		<title>Metrics UI missing values</title>
		<body>## This is a... &lt;!-- Check one of the following options with "x" --&gt; &lt;pre&gt;&lt;code&gt; [ ] Feature request [ ] Regression (a behavior that used to work and stopped working in a new release) [*] Bug report  &lt;!-- Please search GitHub for a similar issue or PR before submitting --&gt; [ ] Documentation issue or request &lt;/code&gt;&lt;/pre&gt;   ## The problem A number of metric values are not set in the UI and the UI is not refresh with the underlaying data changes.  ## Screenshot &lt;img width="1315" alt="screen shot 2018-02-28 at 11 51 20 am" src="https://user-images.githubusercontent.com/35576/36800571-d53bde32-1c7d-11e8-9f0a-5b9521e0a983.png"&gt;  While the underlaying api says: &lt;img width="839" alt="screen shot 2018-02-28 at 11 52 58 am" src="https://user-images.githubusercontent.com/35576/36800815-714ea0d4-1c7e-11e8-8adc-1a9f66a2de2e.png"&gt;  The last process message should be populated, the uptime is wrong and the data is not refreshed. When hitting refresh myself the tab changes to the 'Description' tab. </body>
		<created>2018-02-28 16:55:29</created>
		<closed>2018-03-05 16:54:07</closed>
	</bug>
	<bug>
		<id>1724</id>
		<title>FTP download action, buttons order is wrong.</title>
		<body>Steps to reproduce: 1. Select Create Integration. 2. Select start connection FTP. 3. Select action "download"     - fill 1. form ..."Done"     - fill 2. form ... "Next" ...  In step 3. you will fill first form and via "Done" button you enter second form. After filling out second form, you finish this step by clicking on "Next" Order of these buttons should be opposite. i.e. Next -&gt; Done  1. form: ![download1](https://user-images.githubusercontent.com/2714974/36790694-f6f421e8-1c95-11e8-9252-e8730a16a2d5.png)  2. form: ![download2](https://user-images.githubusercontent.com/2714974/36790885-81a10018-1c96-11e8-81e9-29c79ffff259.png) </body>
		<created>2018-02-28 13:51:38</created>
		<closed>2018-03-05 19:57:07</closed>
	</bug>
	<bug>
		<id>1722</id>
		<title>Bug  - DB to DB Integration container yields an error on Minishift Console </title>
		<body>### The problem  After successfully creating an Integration on Syndesis between two DB connections, I try to consume the `/activity/integrations/{integrationId}` API endpoint, but it returns an empty collection all the time.  After checking the Minishift Console, we can see the following error notified at the overview page:  ![captura de pantalla 2018-02-28 a las 14 29 06](https://user-images.githubusercontent.com/1104146/36789815-262be386-1c93-11e8-9216-30687d5b0cc4.png)  After checking the application console, we can reach to the following exception at the logs:  ```bash java.lang.IllegalArgumentException: There's no DataShapeKinds with string ' none' at io.syndesis.model.DataShapeKinds.fromString(DataShapeKinds.java:51)  ~[common-model-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT] ```  This prevents that integration to be deployed, hence the empty activity dataset returned by the API.  ### Steps to reproduce  1. Go to integrations, remove any previous existing integration and click on `Create Integration`` 2. Select `PostgreDB`and then click on `Periodic SQL Invocation` 3. Enter `SELECT * FROM CONTACT` as _SQL Statement_ and set the _Period_ to 2000 or whatever rocks your boat. Click on _Done_ when... done. 4. Select again `PostgreDB` as the target connection and then click on `Periodic Stored Procedure Invocation`. 5. Select `add_lead`, click _Done_. 6. Add an intermediate step and click `Datamapper`. In the two areas displayed, drag `company` from one area to another and save your changes. 7. Click _Publish_ at the top right corner. 6. Wait for the Integration to be _published_ and then check its status at the Minishift Console.</body>
		<created>2018-02-28 13:26:58</created>
		<closed>2018-02-28 17:10:14</closed>
	</bug>
	<bug>
		<id>1718</id>
		<title>Stored Procedure Selection is not set in edit screen</title>
		<body>I created a DB2DB scenario, Periodic SQL: SELECT * FROM CONTACT, and into the add_lead stored procedure, with an added mapping step. When going back to edit the stored procedure selection it is not set.  &lt;img width="1301" alt="screen shot 2018-02-27 at 4 04 45 pm" src="https://user-images.githubusercontent.com/35576/36758688-2ff2a630-1be3-11e8-8306-2294606e49dc.png"&gt;</body>
		<created>2018-02-27 22:25:23</created>
		<closed>2018-02-28 14:38:47</closed>
	</bug>
	<bug>
		<id>1713</id>
		<title>NPE in DB2StoredProc Integration</title>
		<body>Create an integration using Periodic SQL Action with SELECT * FROM CONTACT, and as finish action use the add_lead stored procedure and add a datamapper step.  In the integration logs:  {"exchange":"-L6O07Dn_RcMOI_t54ow","step":"-L6O-7ppxXrDM2Hmb4z1","id":"-L6O07UP_RcMOI_t54oz","duration":11125425,"failure":"java.lang.NullPointerException\n\tat java.util.concurrent.ConcurrentHashMap.get(ConcurrentHashMap.java:936)\n\tat org.apache.camel.com.github.benmanes.caffeine.cache.BoundedLocalCache.getIfPresent(BoundedLocalCache.java:1525)\n\tat org.apache.camel.com.github.benmanes.caffeine.cache.BoundedLocalCache.get(BoundedLocalCache.java:1520)\n\tat org.apache.camel.util.LRUCache.get(LRUCache.java:132)\n\tat org.apache.camel.component.sql.stored.CallableStatementWrapperFactory.getTemplateStoredProcedure(CallableStatementWrapperFactory.java:67)\n\tat org.apache.camel.component.sql.stored.CallableStatementWrapper.populateStatement(CallableStatementWrapper.java:104)\n\tat org.apache.camel.component.sql.stored.SqlStoredProducer$1.execute(SqlStoredProducer.java:69)\n\tat org.apache.camel.component.sql.stored.CallableStatementWrapper.call(CallableStatementWrapper.java:55)\n\tat org.apache.camel.component.sql.stored.SqlStoredProducer.process(SqlStoredProducer.java:43)\n\tat org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:138)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:101)\n\tat io.syndesis.integration.component.proxy.ComponentProxyProducer.process(ComponentProxyProducer.java:44)\n\tat org.apache.camel.processor.SendProcessor$2.doInAsyncProducer(SendProcessor.java:178)\n\tat org.apache.camel.impl.ProducerCache.doInAsyncProducer(ProducerCache.java:445)\n\tat org.apache.camel.processor.SendProcessor.process(SendProcessor.java:173)\n\tat org.apache.camel.processor.InterceptorToAsyncProcessorBridge.process(InterceptorToAsyncProcessorBridge.java:67)\n\tat io.syndesis.integration.runtime.logging.IntegrationLoggingInterceptStrategy.lambda$wrapProcessorInInterceptors$0(IntegrationLoggingInterceptStrategy.java:45)\n\tat org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61)\n\tat org.apache.camel.processor.InterceptorToAsyncProcessorBridge.process(InterceptorToAsyncProcessorBridge.java:76)\n\tat org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110)\n\tat org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:97)\n\tat io.syndesis.integration.runtime.OutMessageCaptureInterceptStrategy.lambda$wrapProcessorInInterceptors$0(OutMessageCaptureInterceptStrategy.java:54)\n\tat org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61)\n\tat org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110)\n\tat org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548)\n\tat org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:138)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:101)\n\tat org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548)\n\tat org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201)\n\tat org.apache.camel.processor.MulticastProcessor.doProcessSequential(MulticastProcessor.java:701)\n\tat org.apache.camel.processor.MulticastProcessor.doProcessSequential(MulticastProcessor.java:624)\n\tat org.apache.camel.processor.MulticastProcessor.process(MulticastProcessor.java:248)\n\tat org.apache.camel.processor.Splitter.process(Splitter.java:114)\n\tat org.apache.camel.processor.InterceptorToAsyncProcessorBridge.process(InterceptorToAsyncProcessorBridge.java:67)\n\tat io.syndesis.integration.runtime.logging.IntegrationLoggingInterceptStrategy.lambda$wrapProcessorInInterceptors$0(IntegrationLoggingInterceptStrategy.java:45)\n\tat org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61)\n\tat org.apache.camel.processor.InterceptorToAsyncProcessorBridge.process(InterceptorToAsyncProcessorBridge.java:76)\n\tat org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110)\n\tat org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:97)\n\tat io.syndesis.integration.runtime.OutMessageCaptureInterceptStrategy.lambda$wrapProcessorInInterceptors$0(OutMessageCaptureInterceptStrategy.java:54)\n\tat org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61)\n\tat org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110)\n\tat org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548)\n\tat org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:138)\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:101)\n\tat org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201)\n\tat org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197)\n\tat org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79)\n\tat java.util.TimerThread.mainLoop(Timer.java:555)\n\tat java.util.TimerThread.run(Timer.java:505)\n"} 2018-02-27 20:46:48.309 ERROR 1 --- [r://integration] o.a.camel.processor.DefaultErrorHandler  : Failed delivery for (MessageId: -L6O07UN_RcMOI_t54oy on ExchangeId: -L6O07Dn_RcMOI_t54ow). Exhausted after delivery attempt: 1 caught: java.lang.NullPointerException  Message History --------------------------------------------------------------------------------------------------------------------------------------- RouteId              ProcessorId          Processor                                                                        Elapsed (ms) [-L6O-IF1amUpOJAXmF] [-L6O-IF1amUpOJAXmF] [timer://integration?period=1000                                               ] [      1402] [-L6O-IF1amUpOJAXmF] [-L6O-9fhxXrDM2Hmb4] [atlas:mapping-step-2.json?sourceMapName=Syndesis.CAPTURED_OUT_MESSAGES_MAP    ] [      1061] [-L6O-IF1amUpOJAXmF] [-L6O-7ppxXrDM2Hmb4] [sql-stored-3                                                                  ] [        18]  Stacktrace ---------------------------------------------------------------------------------------------------------------------------------------  java.lang.NullPointerException: null at java.util.concurrent.ConcurrentHashMap.get(ConcurrentHashMap.java:936) ~[na:1.8.0_151] at org.apache.camel.com.github.benmanes.caffeine.cache.BoundedLocalCache.getIfPresent(BoundedLocalCache.java:1525) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.com.github.benmanes.caffeine.cache.BoundedLocalCache.get(BoundedLocalCache.java:1520) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.util.LRUCache.get(LRUCache.java:132) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.component.sql.stored.CallableStatementWrapperFactory.getTemplateStoredProcedure(CallableStatementWrapperFactory.java:67) ~[camel-sql-2.20.1.jar!/:2.20.1] at org.apache.camel.component.sql.stored.CallableStatementWrapper.populateStatement(CallableStatementWrapper.java:104) ~[camel-sql-2.20.1.jar!/:2.20.1] at org.apache.camel.component.sql.stored.SqlStoredProducer$1.execute(SqlStoredProducer.java:69) ~[camel-sql-2.20.1.jar!/:2.20.1] at org.apache.camel.component.sql.stored.CallableStatementWrapper.call(CallableStatementWrapper.java:55) ~[camel-sql-2.20.1.jar!/:2.20.1] at org.apache.camel.component.sql.stored.SqlStoredProducer.process(SqlStoredProducer.java:43) ~[camel-sql-2.20.1.jar!/:2.20.1] at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.20.1.jar!/:2.20.1] at io.syndesis.integration.component.proxy.ComponentProxyProducer.process(ComponentProxyProducer.java:44) ~[integration-component-proxy-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT] at org.apache.camel.processor.SendProcessor$2.doInAsyncProducer(SendProcessor.java:178) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.impl.ProducerCache.doInAsyncProducer(ProducerCache.java:445) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:173) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.InterceptorToAsyncProcessorBridge.process(InterceptorToAsyncProcessorBridge.java:67) [camel-core-2.20.1.jar!/:2.20.1] at io.syndesis.integration.runtime.logging.IntegrationLoggingInterceptStrategy.lambda$wrapProcessorInInterceptors$0(IntegrationLoggingInterceptStrategy.java:45) [integration-runtime-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT] at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.InterceptorToAsyncProcessorBridge.process(InterceptorToAsyncProcessorBridge.java:76) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:97) ~[camel-core-2.20.1.jar!/:2.20.1] at io.syndesis.integration.runtime.OutMessageCaptureInterceptStrategy.lambda$wrapProcessorInInterceptors$0(OutMessageCaptureInterceptStrategy.java:54) ~[integration-runtime-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT] at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.MulticastProcessor.doProcessSequential(MulticastProcessor.java:701) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.MulticastProcessor.doProcessSequential(MulticastProcessor.java:624) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.MulticastProcessor.process(MulticastProcessor.java:248) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.Splitter.process(Splitter.java:114) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.InterceptorToAsyncProcessorBridge.process(InterceptorToAsyncProcessorBridge.java:67) [camel-core-2.20.1.jar!/:2.20.1] at io.syndesis.integration.runtime.logging.IntegrationLoggingInterceptStrategy.lambda$wrapProcessorInInterceptors$0(IntegrationLoggingInterceptStrategy.java:45) [integration-runtime-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT] at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.InterceptorToAsyncProcessorBridge.process(InterceptorToAsyncProcessorBridge.java:76) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:97) ~[camel-core-2.20.1.jar!/:2.20.1] at io.syndesis.integration.runtime.OutMessageCaptureInterceptStrategy.lambda$wrapProcessorInInterceptors$0(OutMessageCaptureInterceptStrategy.java:54) ~[integration-runtime-1.3-SNAPSHOT.jar!/:1.3-SNAPSHOT] at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79) ~[camel-core-2.20.1.jar!/:2.20.1] at java.util.TimerThread.mainLoop(Timer.java:555) ~[na:1.8.0_151] at java.util.TimerThread.run(Timer.java:505) ~[na:1.8.0_151]</body>
		<created>2018-02-27 20:54:09</created>
		<closed>2018-02-28 15:54:35</closed>
	</bug>
	<bug>
		<id>1701</id>
		<title>DataBuckets exception - Incompatible Source Document 'null'</title>
		<body>I created test for data buckets in syndesis-qe repo, but created integration does not work with exception in integrations pod logs: [exception.txt](https://github.com/syndesisio/syndesis/files/1763726/exception.txt)   My integration is:  Database - database - datamapper - salesforce   You can see feature file of the test here so you can easily reproduce this issue, just follow those steps:  [feature.txt](https://github.com/syndesisio/syndesis/files/1763741/feature.txt)  I am using output of first database connector in data mapper. Note that if I delete second database step, this integration works as expected so it looks like first database output is not available in data mapper step.   I am not sure if data buckets are already fully implemented as its epic issue https://github.com/syndesisio/syndesis/issues/1110 is still in open state. If it is the case at least we already have some tests.</body>
		<created>2018-02-27 16:40:23</created>
		<closed>2018-03-02 11:29:51</closed>
	</bug>
	<bug>
		<id>1692</id>
		<title>FTP connector: datashape definition display errors in UI</title>
		<body>Steps to reproduce: 1. Select Create Integration. 2. Select start connection FTP. 3. Select action "download" and specify details 4. Select finish connection FTP. 5. Select action "upload" and specify details. 6. add datamapper step.  7. then you are provided wit datamapper gui.  this looks strange, see pictures. ![ftp_datamapper1](https://user-images.githubusercontent.com/2714974/36728069-c84be640-1bbf-11e8-9f9e-122c6530e4b9.png) ![ftp_datamapper2](https://user-images.githubusercontent.com/2714974/36728075-cabbda98-1bbf-11e8-85cb-256a4e49d4c7.png)   Perhaps in some cases (like FTP?) datamapper step doesn't make sense and user shouldn't have this option.  </body>
		<created>2018-02-27 12:12:35</created>
		<closed>2018-02-27 14:43:35</closed>
	</bug>
	<bug>
		<id>1675</id>
		<title>missing id for select element  </title>
		<body>Element  ``` &lt;select class="duration-input__select ng-pristine ng-valid ng-touched"&gt; ``` is missing id.  ![missing_id](https://user-images.githubusercontent.com/2714974/36669241-8234da0c-1af4-11e8-889e-45f4ca4856e6.png) </body>
		<created>2018-02-26 11:57:39</created>
		<closed>2018-02-27 19:37:43</closed>
	</bug>
	<bug>
		<id>1641</id>
		<title>Integration scaled down using OpenShift is not noticed by Syndesis</title>
		<body>When I scale down integration pod on OpenShift (simulating sort of issue, where the pod is not available), integration on syndesis remains in "Published" state. Syndesis backend does not notice, the integration is down. There should probably be some sort of integration liveness check on syndesis side, which would notify the user, the integration is not available.  The described behavior:  ![rest_ignores_integ_delete](https://user-images.githubusercontent.com/4180208/36539807-5220e4f6-17d8-11e8-835f-f23caee11b0a.gif) </body>
		<created>2018-02-22 12:57:34</created>
		<closed>2018-07-12 16:40:04</closed>
	</bug>
	<bug>
		<id>1614</id>
		<title>Unable to create integration</title>
		<body>There is an issue when creating integration. Steps can't be created.  The issue:  ![integration_not_create](https://user-images.githubusercontent.com/4180208/36412113-0dfa8ce8-1619-11e8-9f68-f41e4ea99975.gif)  JS console log:  [console.log](https://github.com/syndesisio/syndesis/files/1739197/console.log) </body>
		<created>2018-02-20 07:37:17</created>
		<closed>2018-02-20 14:54:38</closed>
	</bug>
	<bug>
		<id>1581</id>
		<title>Impossible to rollback to a previous deployment.</title>
		<body></body>
		<created>2018-02-15 13:19:30</created>
		<closed>2018-03-14 16:07:25</closed>
	</bug>
	<bug>
		<id>1580</id>
		<title>Multiple published deployments for a single integration.</title>
		<body></body>
		<created>2018-02-15 13:18:52</created>
		<closed>2018-03-20 12:04:15</closed>
	</bug>
	<bug>
		<id>1578</id>
		<title>When creating integration in Draft state, indefinite waiting for redirect to integration page</title>
		<body>I create simple integration and saved it as a draft. I expected redirect to integrations listing, the page however did not redirect. I experienced this issue on newest build of syndesis.  ![indefinite_draft](https://user-images.githubusercontent.com/4180208/36248514-111b671a-1238-11e8-9e62-8ea98d74aef4.gif)  </body>
		<created>2018-02-15 09:08:31</created>
		<closed>2018-02-20 14:54:38</closed>
	</bug>
	<bug>
		<id>1576</id>
		<title>datamapper picks up wrong step for the target data shape at first</title>
		<body>This is a screenshot when adding a datamapper step as a **Step 2**. In this case target data must be the input from **Step 3**, but not from **Step 4** ![screenshot from 2018-02-14 20-20-54](https://user-images.githubusercontent.com/265462/36236611-fb2510d2-11c4-11e8-9521-37033d75424f.png) Once you exit the datamapper config view and revisit the Step 2 datamapper again, then expected target data type is retrieved (i.e. from **Step 3**). ![screenshot from 2018-02-14 20-21-17](https://user-images.githubusercontent.com/265462/36236619-06fb0b14-11c5-11e8-910c-84c0bc392768.png)  ~~When adding a datamapper step, `Step` object of datamapper is not yet registered into integration, so the **Step 3** SQL is still Step 2 at this point. It will needs to check if it's adding or revisiting existing.~~ No, Step object is already added, and now it doesn't reproduce for me...</body>
		<created>2018-02-15 01:36:46</created>
		<closed>2018-02-15 02:17:56</closed>
	</bug>
	<bug>
		<id>1566</id>
		<title>DB connector Periodic SQL/Stored Procedure Invocation actions not working</title>
		<body>On a fresh build, the PostgresDB connection is the only Connection provided OOTB (it seems), so I selected it to create an Integration, but neither of the actions are working properly.  I think @KurtStam was not able to reproduce the issue, so this might be just a problem in my env.  ### To reproduce: 1. From the Dashboard or Integrations list page, select Create Integration. 2. Select PostgresDB (or equivalent) as the connection. If there is no PostgresDB connection, create one using the Database connector. 3. Select either option as the action ("Periodic stored procedure invocation" or "Periodic SQL invocation"). 4. Name your stored procedure (or add the SQL statement, depending on which action you selected) to activate the "Done" button. 5. Click the blue activated "Done" button.  At this point, nothing happens, but a few errors in the browser console appear. See screenshots below.  ``` Failed to load resource: the server responded with a status of 500 (Internal Server Error) ERROR Error: Uncaught (in promise): SyntaxError: Unexpected token u in JSON at position 0 SyntaxError: Unexpected token u in JSON at position 0 ```  Network tab: ``` {"errorCode":500,"developerMsg":"Unable to fetch and process metadata"} ```     ### Screenshots  &lt;img width="1680" alt="screenshot 2018-02-14 11 26 10" src="https://user-images.githubusercontent.com/3844502/36215485-415ba0ca-117a-11e8-8d47-2dde58e550f4.png"&gt;  &lt;img width="1680" alt="screenshot 2018-02-14 11 26 40" src="https://user-images.githubusercontent.com/3844502/36215487-430d326c-117a-11e8-95cd-b854e04bd1a5.png"&gt;    ### Logs  Tried to obtain verifier and REST pod logs to no avail. Potentially could be a UI-related issue, however, the OS console is showing a toast notification "Server connection interrupted" which means it could need further testing.  &lt;img width="1679" alt="screenshot 2018-02-14 11 21 07" src="https://user-images.githubusercontent.com/3844502/36215180-62edf630-1179-11e8-8f40-447ea1533c48.png"&gt;  &lt;img width="1677" alt="screenshot 2018-02-14 11 21 40" src="https://user-images.githubusercontent.com/3844502/36215184-6475159c-1179-11e8-988b-3d95744f5099.png"&gt;  cc @KurtStam </body>
		<created>2018-02-14 16:29:39</created>
		<closed>2018-03-01 23:08:07</closed>
	</bug>
	<bug>
		<id>1559</id>
		<title>Unable to publish unpublished integration using it's "version 1"</title>
		<body>When I unpublished integration and afterwards I tried to publish it using the history "version:1", where there is also "publish" option in the dropdown window, the integration won't start. The whole history seems to not work as expected, I encounter the same issue, when I try to revert the integration to some point in the history, the integration simply won't start. ![out](https://user-images.githubusercontent.com/4180208/36202915-ed740edc-1185-11e8-96fa-192d63e46b66.gif)   </body>
		<created>2018-02-14 11:52:43</created>
		<closed>2018-04-04 11:58:28</closed>
	</bug>
	<bug>
		<id>1545</id>
		<title>[UI] Import integration multiple toast notifications</title>
		<body>I see too much enthusiasm here, for a single successful import operation  ![screenshot from 2018-02-13 17-27-23](https://user-images.githubusercontent.com/1520602/36161180-55b8085c-10e3-11e8-8edc-86fb064be214.png) </body>
		<created>2018-02-13 16:29:20</created>
		<closed>2018-07-18 14:03:00</closed>
	</bug>
	<bug>
		<id>1538</id>
		<title>Able to create duplicate connections</title>
		<body>During the course of testing, I was able to create duplicate connections. This is proof that the duplicate entity check can be circumvented.  ![duplicate-connections](https://user-images.githubusercontent.com/8625482/36133499-4d63e34e-10b9-11e8-8f10-6da6a92a6450.png) </body>
		<created>2018-02-13 04:27:56</created>
		<closed>2018-03-27 21:29:15</closed>
	</bug>
	<bug>
		<id>1525</id>
		<title>User is stuck if twitter without "To" actions is picked at a "To" position</title>
		<body>If you start from database and then pick Twitter as destination, you'll be stuck and the only way to escape is to start a new integration.  ![screenshot-2018-2-12 syndesis 1](https://user-images.githubusercontent.com/1306050/36092210-def403e4-0fe6-11e8-88f5-e8f01dbebfba.png)  I think we should not allow selection of connections at a place that the action does not fit, i.e. `From` at start and `To` in other places.  Related to #253 </body>
		<created>2018-02-12 10:22:32</created>
		<closed>2018-02-13 13:34:55</closed>
	</bug>
	<bug>
		<id>1512</id>
		<title>syndesis-upgrade: "migrate_db"</title>
		<body>#### Migrate Database  If the database schema has changed for the new version to apply, then migration is required. Since our internal homegrown database JsonDB only supports a Java-based access, this migration needs to be performed with Java.  A Java CLI tool, which is stored in the `syndesis-rest` Docker image and which can be started with `/deployments/migrate-jsondb.sh` takes the following command line arguments:  * Connection parameters to the Postgresql database (URL, user, password) * A directory holding the migration scripts written in JavaScript  This directory contains a migration script for every schema version:  .Example upgrade directory ``` /upgrade-jsondb/     ...     20.js     21.js     23.js     ... ```  Each upgrade script can only upgrade from the prior version. In this example, if the DB is currently at schema `20` and the target schema is `23`, then the scripts `21.js` and `23.js` are executed.  These scripts contain a single javascript function:  .Simple JavaScript API ```javascript function upgrade(jsondb) {    // Perform migration by iterating of jsondb documents,    // transforming them and then storing them back  } ```  with `jsondb` a still to defined context object for accessing, querying and updating JsonDB  These scripts can be part of the `syndesis-rest` Docker image so that an outside CLI tool just needs to call  .Starting the migration ```bash oc port-forward $(pod syndesis-db) 5432:5432 docker run syndesis/syndesis-rest --net=host \      /deployment/migrate-jsondb.sh \          --url jdbc://localhost:5432 --user admin --password admin \          --target-schema 23 ```  NOTE: The upgrade script and mechanism could also be used internally by the syndesis-rest application to perform an upgrade during startup. However, this is recommended only for a development setup as there is no easy way to rollback if things go wrong.  #### Rollback If any of the upgrade scripts fail with an error, a DB rollback needs to be performed. For this, the backup created in the previous &lt;&lt;step-backup-db, step&gt;&gt; needs to be played back (on a fresh database). </body>
		<created>2018-02-09 20:33:36</created>
		<closed>2018-05-04 08:49:21</closed>
	</bug>
	<bug>
		<id>1489</id>
		<title>Blank action for API Client connectors</title>
		<body>If both the summary and description is available in the swagger doc (Yes, sometimes people do that.. ), the list of action will be blank.   &lt;img width="1565" alt="screen shot 2018-02-08 at 2 12 29 pm" src="https://user-images.githubusercontent.com/2534483/35993180-83e66fbe-0cda-11e8-9f2b-8add5153cc86.png"&gt; </body>
		<created>2018-02-08 20:33:14</created>
		<closed>2018-02-12 13:50:08</closed>
	</bug>
	<bug>
		<id>1442</id>
		<title>[custom api connector] Disallow deleting a connector while there exists a related connection</title>
		<body>If there is a connection created from a custom connector we need to disallow deleting the connector. Because there is data missing for the connection then. (at least an icon what I have noticed)</body>
		<created>2018-02-06 14:50:41</created>
		<closed>2018-02-27 18:14:13</closed>
	</bug>
	<bug>
		<id>1438</id>
		<title>Pod with a new integration can replace any other existing pod on openshift with same name</title>
		<body>If there is an existing pod named X and you create and publish a new integration also with the very same name X then the old pod will be replaced by the new one. It can destroy whole Syndesis app.</body>
		<created>2018-02-06 14:11:22</created>
		<closed>2018-03-02 11:53:54</closed>
	</bug>
	<bug>
		<id>1435</id>
		<title>[custom api connector] "Used by integrations by X times" shows 0 despite it's being used</title>
		<body> ![todointegration](https://user-images.githubusercontent.com/8707251/35859868-1517388c-0b42-11e8-9ffa-4b2994d13d43.png)  ![todoconnector](https://user-images.githubusercontent.com/8707251/35859804-c4d8c7d2-0b41-11e8-8e0a-8d30c8129539.png) </body>
		<created>2018-02-06 12:33:13</created>
		<closed>2018-03-19 17:53:07</closed>
	</bug>
	<bug>
		<id>1433</id>
		<title>[custom api connector] Icon can't be changed sometimes</title>
		<body>If I want to change an icon on the api connector detail page, sometimes it works, sometimes doesn't. I'm putting down 2 cases that may be related.   **Case1:**  - Petstore api connector: If I change a connector's icon, the icon of a connection based on this connector will be changed  - TODO api connector: If I change a connector's icon, the icon of a connection based on this connector will NOT be changed  Why it behaves in different way for different connectors?    **Case 2:**  On Connector detail page:  1. I change an icon from icon 1 to icon 2  - the icon displayed on the connector detail page is still 1  2. I change an icon to icon 3 - the icon displayed on the connector detail page changes to Icon 2  and so on... That means that displaying the icon is 1 step behind the current setting. Refreshing the page refreshes the icon to the current state that is set. </body>
		<created>2018-02-06 12:09:40</created>
		<closed>2018-03-26 11:12:00</closed>
	</bug>
	<bug>
		<id>1426</id>
		<title>ERROR Error: StaticInjectorError[t -&gt; t]: </title>
		<body>Since disabling the tour didn't fix this, am creating a new issue to track it separately and consolidate the previous issues that were closed with the PR merge.  ``` ERROR Error: StaticInjectorError[t -&gt; t]:    StaticInjectorError(Platform: core)[t -&gt; t]:      NullInjectorError: No provider for t!     at t.get (main.d18da4935f56d031b283.bundle.js:1)     at main.d18da4935f56d031b283.bundle.js:1     at t (main.d18da4935f56d031b283.bundle.js:1)     at t.get (main.d18da4935f56d031b283.bundle.js:1)     at main.d18da4935f56d031b283.bundle.js:1     at t (main.d18da4935f56d031b283.bundle.js:1)     at t.get (main.d18da4935f56d031b283.bundle.js:1)     at Ai (main.d18da4935f56d031b283.bundle.js:1)     at t.get (main.d18da4935f56d031b283.bundle.js:1)     at Ai (main.d18da4935f56d031b283.bundle.js:1) Ct @ main.d18da4935f56d031b283.bundle.js:1 t.handleError @ main.d18da4935f56d031b283.bundle.js:1 (anonymous) @ main.d18da4935f56d031b283.bundle.js:1 t.invoke @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 e.run @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 t.runOutsideAngular @ main.d18da4935f56d031b283.bundle.js:1 t.tick @ main.d18da4935f56d031b283.bundle.js:1 (anonymous) @ main.d18da4935f56d031b283.bundle.js:1 t.invoke @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 onInvoke @ main.d18da4935f56d031b283.bundle.js:1 t.invoke @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 e.run @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 t.run @ main.d18da4935f56d031b283.bundle.js:1 next @ main.d18da4935f56d031b283.bundle.js:1 e.object.i @ main.d18da4935f56d031b283.bundle.js:1 e.__tryOrUnsub @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 e.next @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 e._next @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 e.next @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 e.next @ main.d18da4935f56d031b283.bundle.js:1 e.emit @ main.d18da4935f56d031b283.bundle.js:1 He @ main.d18da4935f56d031b283.bundle.js:1 ze @ main.d18da4935f56d031b283.bundle.js:1 onInvokeTask @ main.d18da4935f56d031b283.bundle.js:1 t.invokeTask @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 e.runTask @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 e.invokeTask @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 _ @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 g @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 XMLHttpRequest.send (async) (anonymous) @ VM195256:1 b @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 t.scheduleTask @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 onScheduleTask @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 t.scheduleTask @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 e.scheduleTask @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 e.scheduleMacroTask @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 d @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 (anonymous) @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 R.i.(anonymous function) @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 (anonymous) @ main.d18da4935f56d031b283.bundle.js:1 t._trySubscribe @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 t.subscribe @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 t.call @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 t.subscribe @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 t.call @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 t.subscribe @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 t.call @ main.d18da4935f56d031b283.bundle.js:1 t.subscribe @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 C @ main.d18da4935f56d031b283.bundle.js:1 Fe @ main.d18da4935f56d031b283.bundle.js:1 e @ main.d18da4935f56d031b283.bundle.js:1 t.list @ main.d18da4935f56d031b283.bundle.js:1 t.loadAll @ main.d18da4935f56d031b283.bundle.js:1 n.ngOnInit @ 2.0b5da4db55b8ff5d9029.chunk.js:1 (anonymous) @ main.d18da4935f56d031b283.bundle.js:1 (anonymous) @ main.d18da4935f56d031b283.bundle.js:1 Jo @ main.d18da4935f56d031b283.bundle.js:1 ws @ main.d18da4935f56d031b283.bundle.js:1 (anonymous) @ 2.0b5da4db55b8ff5d9029.chunk.js:1 updateDirectives @ main.d18da4935f56d031b283.bundle.js:1 Ko @ main.d18da4935f56d031b283.bundle.js:1 is @ main.d18da4935f56d031b283.bundle.js:1 rs @ main.d18da4935f56d031b283.bundle.js:1 Ko @ main.d18da4935f56d031b283.bundle.js:1 is @ main.d18da4935f56d031b283.bundle.js:1 rs @ main.d18da4935f56d031b283.bundle.js:1 Ko @ main.d18da4935f56d031b283.bundle.js:1 is @ main.d18da4935f56d031b283.bundle.js:1 ns @ main.d18da4935f56d031b283.bundle.js:1 Ko @ main.d18da4935f56d031b283.bundle.js:1 t.detectChanges @ main.d18da4935f56d031b283.bundle.js:1 (anonymous) @ main.d18da4935f56d031b283.bundle.js:1 t.tick @ main.d18da4935f56d031b283.bundle.js:1 (anonymous) @ main.d18da4935f56d031b283.bundle.js:1 t.invoke @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 onInvoke @ main.d18da4935f56d031b283.bundle.js:1 t.invoke @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 e.run @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 t.run @ main.d18da4935f56d031b283.bundle.js:1 next @ main.d18da4935f56d031b283.bundle.js:1 e.object.i @ main.d18da4935f56d031b283.bundle.js:1 e.__tryOrUnsub @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 e.next @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 e._next @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 e.next @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 e.next @ main.d18da4935f56d031b283.bundle.js:1 e.emit @ main.d18da4935f56d031b283.bundle.js:1 He @ main.d18da4935f56d031b283.bundle.js:1 onHasTask @ main.d18da4935f56d031b283.bundle.js:1 t.hasTask @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 t._updateTaskCount @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 e._updateTaskCount @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 e.runTask @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 v @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 e.invokeTask @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 _ @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 g @ polyfills.4b47010fa12e595e9f8e.bundle.js:1 ```  follow on from #1407 #1404   @rhuss @deeleman FYI  This also reproduces when using a dev build with AOT enabled.</body>
		<created>2018-02-05 21:40:24</created>
		<closed>2018-02-08 19:10:26</closed>
	</bug>
	<bug>
		<id>1418</id>
		<title>Twitter mention action, config page throws `SyntaxError: Unexpected token u in JSON at position 0`</title>
		<body>As the action object doesn't have `propertyDefinitionSteps` in the response, so this line of code blows up:  https://github.com/syndesisio/syndesis/blob/master/app/ui/src/app/integration/edit-page/action-configure/action-configure.component.ts#L194</body>
		<created>2018-02-05 18:22:47</created>
		<closed>2018-02-06 07:18:02</closed>
	</bug>
	<bug>
		<id>1407</id>
		<title>JavaScript error when opening "OAuth Settings"</title>
		<body>Happens on master:  ![image](https://user-images.githubusercontent.com/99080/35792186-1631d4bc-0a4c-11e8-9504-dd1a44dc2c70.png) </body>
		<created>2018-02-05 07:11:05</created>
		<closed>2018-02-05 19:18:07</closed>
	</bug>
	<bug>
		<id>1404</id>
		<title>UI broken when trying to create an integration</title>
		<body>On a fresh install I cannot add a connection and the javascript console says  @NgModule.entryComponents?     at me (main.c73dd27201e8e31ff75e.bundle.js:1)     at t.resolveComponentFactory (main.c73dd27201e8e31ff75e.bundle.js:1)     at t.resolveComponentFactory (main.c73dd27201e8e31ff75e.bundle.js:1)     at t.attach (main.c73dd27201e8e31ff75e.bundle.js:1)     at e.t.show (main.c73dd27201e8e31ff75e.bundle.js:1)     at e.showTourStep (main.c73dd27201e8e31ff75e.bundle.js:1)     at e.t.showStep (main.c73dd27201e8e31ff75e.bundle.js:1)     at e.t.setCurrentStep (main.c73dd27201e8e31ff75e.bundle.js:1)     at main.c73dd27201e8e31ff75e.bundle.js:1     at t.invokeTask (polyfills.d4f4adfcb33bf016dc64.bundle.js:1) Ct @ main.c73dd27201e8e31ff75e.bundle.js:1 main.c73dd27201e8e31ff75e.bundle.js:1 ERROR Error: StaticInjectorError[t -&gt; t]:    StaticInjectorError(Platform: core)[t -&gt; t]:      NullInjectorError: No provider for t!     at t.get (main.c73dd27201e8e31ff75e.bundle.js:1)     at main.c73dd27201e8e31ff75e.bundle.js:1     at t (main.c73dd27201e8e31ff75e.bundle.js:1)     at t.get (main.c73dd27201e8e31ff75e.bundle.js:1)     at main.c73dd27201e8e31ff75e.bundle.js:1     at t (main.c73dd27201e8e31ff75e.bundle.js:1)     at t.get (main.c73dd27201e8e31ff75e.bundle.js:1)     at Ar (main.c73dd27201e8e31ff75e.bundle.js:1)     at t.get (main.c73dd27201e8e31ff75e.bundle.js:1)     at Ar (main.c73dd27201e8e31ff75e.bundle.js:1) Ct @ main.c73dd27201e8e31ff75e.bundle.js:1 main.c73dd27201e8e31ff75e.bundle.js:1 ERROR Error: No component factory found for t. Did you add it to @NgModule.entryComponents?     at me (main.c73dd27201e8e31ff75e.bundle.js:1)     at t.resolveComponentFactory (main.c73dd27201e8e31ff75e.bundle.js:1)     at t.resolveComponentFactory (main.c73dd27201e8e31ff75e.bundle.js:1)     at t.attach (main.c73dd27201e8e31ff75e.bundle.js:1)     at e.t.show (main.c73dd27201e8e31ff75e.bundle.js:1)     at e.showTourStep (main.c73dd27201e8e31ff75e.bundle.js:1)     at e.t.showStep (main.c73dd27201e8e31ff75e.bundle.js:1)     at e.t.setCurrentStep (main.c73dd27201e8e31ff75e.bundle.js:1)     at main.c73dd27201e8e31ff75e.bundle.js:1     at t.invokeTask (polyfills.d4f4adfcb33bf016dc64.bundle.js:1) Ct @ main.c73dd27201e8e31ff75e.bundle.js:1 49main.c73dd27201e8e31ff75e.bundle.js:1 ERROR Error: StaticInjectorError[t -&gt; t]:    StaticInjectorError(Platform: core)[t -&gt; t]:      NullInjectorError: No provider for t!     at t.get (main.c73dd27201e8e31ff75e.bundle.js:1)     at main.c73dd27201e8e31ff75e.bundle.js:1     at t (main.c73dd27201e8e31ff75e.bundle.js:1)     at t.get (main.c73dd27201e8e31ff75e.bundle.js:1)     at main.c73dd27201e8e31ff75e.bundle.js:1     at t (main.c73dd27201e8e31ff75e.bundle.js:1)     at t.get (main.c73dd27201e8e31ff75e.bundle.js:1)     at Ar (main.c73dd27201e8e31ff75e.bundle.js:1)     at t.get (main.c73dd27201e8e31ff75e.bundle.js:1)     at Ar (main.c73dd27201e8e31ff75e.bundle.js:1) Ct @ main.c73dd27201e8e31ff75e.bundle.js:1 main.c73dd27201e8e31ff75e.bundle.js:1 ERROR TypeError: Cannot read property 'descriptor' of undefined     at l.configuredPropertiesForMetadataCall (2.a4890f03ebc718c36bea.chunk.js:1)     at l.initialize (2.a4890f03ebc718c36bea.chunk.js:1)     at e._next (2.a4890f03ebc718c36bea.chunk.js:1)     at e.__tryOrSetError (polyfills.d4f4adfcb33bf016dc64.bundle.js:1)     at e.next (polyfills.d4f4adfcb33bf016dc64.bundle.js:1)     at e._next (polyfills.d4f4adfcb33bf016dc64.bundle.js:1)     at e.next (polyfills.d4f4adfcb33bf016dc64.bundle.js:1)     at e._next (polyfills.d4f4adfcb33bf016dc64.bundle.js:1)     at e.next (polyfills.d4f4adfcb33bf016dc64.bundle.js:1)     at e._subscribe (main.c73dd27201e8e31ff75e.bundle.js:1) Ct @ main.c73dd27201e8e31ff75e.bundle.js:1 main.c73dd27201e8e31ff75e.bundle.js:1 ERROR Error: No component factory found for t. Did you add it to @NgModule.entryComponents?     at me (main.c73dd27201e8e31ff75e.bundle.js:1)     at t.resolveComponentFactory (main.c73dd27201e8e31ff75e.bundle.js:1)     at t.resolveComponentFactory (main.c73dd27201e8e31ff75e.bundle.js:1)     at t.attach (main.c73dd27201e8e31ff75e.bundle.js:1)     at e.t.show (main.c73dd27201e8e31ff75e.bundle.js:1)     at e.showTourStep (main.c73dd27201e8e31ff75e.bundle.js:1)     at e.t.showStep (main.c73dd27201e8e31ff75e.bundle.js:1)     at e.t.setCurrentStep (main.c73dd27201e8e31ff75e.bundle.js:1)     at main.c73dd27201e8e31ff75e.bundle.js:1</body>
		<created>2018-02-05 04:01:53</created>
		<closed>2018-02-05 19:18:07</closed>
	</bug>
	<bug>
		<id>1402</id>
		<title>Read Timeoute for Metrics collector on Minishift</title>
		<body>When running on Minishift I get this exception every 2-10 seconds in the syndesis-rest logs:  ``` 2018-02-04 18:02:28.976 ERROR [-,,,] 1 --- [pool-5-thread-1] i.s.r.m.collector.MetricsCollector       : Error while iterating integration pods.  io.fabric8.kubernetes.client.KubernetesClientException: Operation: [list]  for kind: [Pod]  with name: [null]  in namespace: [myproject]  failed. at io.fabric8.kubernetes.client.KubernetesClientException.launderThrowable(KubernetesClientException.java:62) ~[kubernetes-client-2.4.1.jar!/:na] at io.fabric8.kubernetes.client.KubernetesClientException.launderThrowable(KubernetesClientException.java:71) ~[kubernetes-client-2.4.1.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.BaseOperation.list(BaseOperation.java:585) ~[kubernetes-client-2.4.1.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.BaseOperation.list(BaseOperation.java:68) ~[kubernetes-client-2.4.1.jar!/:na] at io.syndesis.rest.metrics.collector.MetricsCollector.run(MetricsCollector.java:97) ~[metrics-collector-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_131] at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [na:1.8.0_131] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [na:1.8.0_131] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [na:1.8.0_131] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_131] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_131] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131] Caused by: java.net.SocketTimeoutException: timeout at okio.Okio$4.newTimeoutException(Okio.java:230) ~[okio-1.13.0.jar!/:na] at okio.AsyncTimeout.exit(AsyncTimeout.java:285) ~[okio-1.13.0.jar!/:na] at okio.AsyncTimeout$2.read(AsyncTimeout.java:241) ~[okio-1.13.0.jar!/:na] at okio.RealBufferedSource.indexOf(RealBufferedSource.java:345) ~[okio-1.13.0.jar!/:na] at okio.RealBufferedSource.readUtf8LineStrict(RealBufferedSource.java:217) ~[okio-1.13.0.jar!/:na] at okio.RealBufferedSource.readUtf8LineStrict(RealBufferedSource.java:211) ~[okio-1.13.0.jar!/:na] at okhttp3.internal.http1.Http1Codec.readResponseHeaders(Http1Codec.java:189) ~[okhttp-3.8.0.jar!/:na] at okhttp3.internal.http.CallServerInterceptor.intercept(CallServerInterceptor.java:75) ~[okhttp-3.8.0.jar!/:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92) ~[okhttp-3.8.0.jar!/:na] at okhttp3.internal.connection.ConnectInterceptor.intercept(ConnectInterceptor.java:45) ~[okhttp-3.8.0.jar!/:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92) ~[okhttp-3.8.0.jar!/:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:67) ~[okhttp-3.8.0.jar!/:na] at okhttp3.internal.cache.CacheInterceptor.intercept(CacheInterceptor.java:93) ~[okhttp-3.8.0.jar!/:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92) ~[okhttp-3.8.0.jar!/:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:67) ~[okhttp-3.8.0.jar!/:na] at okhttp3.internal.http.BridgeInterceptor.intercept(BridgeInterceptor.java:93) ~[okhttp-3.8.0.jar!/:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92) ~[okhttp-3.8.0.jar!/:na] at okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept(RetryAndFollowUpInterceptor.java:120) ~[okhttp-3.8.0.jar!/:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92) ~[okhttp-3.8.0.jar!/:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:67) ~[okhttp-3.8.0.jar!/:na] at io.fabric8.openshift.client.internal.OpenShiftOAuthInterceptor.intercept(OpenShiftOAuthInterceptor.java:64) ~[openshift-client-2.4.1.jar!/:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92) ~[okhttp-3.8.0.jar!/:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:67) ~[okhttp-3.8.0.jar!/:na] at okhttp3.RealCall.getResponseWithInterceptorChain(RealCall.java:185) ~[okhttp-3.8.0.jar!/:na] at okhttp3.RealCall.execute(RealCall.java:69) ~[okhttp-3.8.0.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:377) ~[kubernetes-client-2.4.1.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:343) ~[kubernetes-client-2.4.1.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:327) ~[kubernetes-client-2.4.1.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.BaseOperation.list(BaseOperation.java:583) ~[kubernetes-client-2.4.1.jar!/:na] ... 9 common frames omitted Caused by: java.net.SocketTimeoutException: Read timed out at java.net.SocketInputStream.socketRead0(Native Method) ~[na:1.8.0_131] at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) ~[na:1.8.0_131] at java.net.SocketInputStream.read(SocketInputStream.java:171) ~[na:1.8.0_131] at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[na:1.8.0_131] at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_131] at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_131] at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:983) ~[na:1.8.0_131] at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:940) ~[na:1.8.0_131] at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_131] at okio.Okio$2.read(Okio.java:139) ~[okio-1.13.0.jar!/:na] at okio.AsyncTimeout$2.read(AsyncTimeout.java:237) ~[okio-1.13.0.jar!/:na] ... 35 common frames omitted ```  Maybe we can make that timeout situation logging a bit less verbose, too ?  </body>
		<created>2018-02-04 18:59:58</created>
		<closed>2018-02-07 17:37:15</closed>
	</bug>
	<bug>
		<id>1395</id>
		<title>NPE in metrics collector after fresh installation</title>
		<body>``` 2018-02-03 12:02:31.422  INFO [-,,,] 1 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) 2018-02-03 12:02:31.986 ERROR [-,,,] 1 --- [pool-5-thread-1] i.s.r.m.collector.MetricsCollector       : Error while iterating integration pods.  java.lang.NullPointerException: null at com.fasterxml.jackson.core.JsonFactory.createParser(JsonFactory.java:879) ~[jackson-core-2.8.10.jar!/:2.8.10] at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2877) ~[jackson-databind-2.8.10.jar!/:2.8.10] at io.syndesis.jsondb.dao.JsonDbDao.fetchIds(JsonDbDao.java:129) ~[jsondb-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] at io.syndesis.dao.manager.DataManager.lambda$fetchIds$2(DataManager.java:245) ~[dao-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] at io.syndesis.dao.manager.DataManager.doWithDataAccessObject(DataManager.java:385) ~[dao-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] at io.syndesis.dao.manager.DataManager.fetchIds(DataManager.java:245) ~[dao-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] at io.syndesis.rest.metrics.collector.MetricsCollector.run(MetricsCollector.java:116) ~[metrics-collector-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_131] at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [na:1.8.0_131] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [na:1.8.0_131] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [na:1.8.0_131] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_131] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_131] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131] ```</body>
		<created>2018-02-03 12:04:07</created>
		<closed>2018-02-05 03:53:21</closed>
	</bug>
	<bug>
		<id>1387</id>
		<title>Settings page, 'save' button doesn't come back out of the 'submitting' state</title>
		<body>Once you copypasta your credentials and click 'Save' it stays in it's submitting state with the little spinny.  The network request completes with an HTTP 204 but the page doesn't pick up the response.</body>
		<created>2018-02-02 16:12:44</created>
		<closed>2018-02-08 18:58:38</closed>
	</bug>
	<bug>
		<id>1386</id>
		<title>Forms a bit broken post angular 5 upgrade</title>
		<body>``` SyndesisFormComponent.html:140 ERROR TypeError: Cannot read property 'element' of undefined     at Object.eval [as updateDirectives] (SyndesisFormComponent.html:161)     at Object.debugUpdateDirectives [as updateDirectives] (core.js:14638)     at checkAndUpdateView (core.js:13785)     at callViewAction (core.js:14136)     at execEmbeddedViewsAction (core.js:14094)     at checkAndUpdateView (core.js:13786)     at callViewAction (core.js:14136)     at execEmbeddedViewsAction (core.js:14094)     at checkAndUpdateView (core.js:13786)     at callViewAction (core.js:14136) ```</body>
		<created>2018-02-02 15:48:05</created>
		<closed>2018-02-02 17:48:28</closed>
	</bug>
	<bug>
		<id>1385</id>
		<title>Do not generate PushTopics with Names longer that 25 characters</title>
		<body>When Salesforce streaming connector creates a PushTopic it should supply a Name that is not longer than 25 characters.  As per [documentation](https://developer.salesforce.com/docs/atlas.en-us.210.0.api.meta/object_ref/pushtopic.htm).</body>
		<created>2018-02-02 15:34:30</created>
		<closed>2018-02-05 14:26:20</closed>
	</bug>
	<bug>
		<id>1382</id>
		<title>WARN  i.a.c.DefaultAtlasConversionService - Converter ... exists.</title>
		<body>Lots of Atlasmap warning on start up:  ``` 14:19:17.341 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.String aleady exists. 14:19:17.341 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Boolean aleady exists. 14:19:17.342 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Long aleady exists. 14:19:17.342 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Byte aleady exists. 14:19:17.342 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Short aleady exists. 14:19:17.342 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Character aleady exists. 14:19:17.342 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Double aleady exists. 14:19:17.343 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Float aleady exists. 14:19:17.343 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Integer aleady exists. 14:19:17.344 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.String aleady exists. 14:19:17.344 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Boolean aleady exists. 14:19:17.344 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Long aleady exists. 14:19:17.344 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Byte aleady exists. 14:19:17.345 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Short aleady exists. 14:19:17.345 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Character aleady exists. 14:19:17.345 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Double aleady exists. 14:19:17.345 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Float aleady exists. 14:19:17.345 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Integer aleady exists. 14:19:17.350 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.String aleady exists. 14:19:17.350 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Boolean aleady exists. 14:19:17.350 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Long aleady exists. 14:19:17.351 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Byte aleady exists. 14:19:17.351 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Short aleady exists. 14:19:17.351 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Character aleady exists. 14:19:17.351 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Double aleady exists. 14:19:17.351 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Float aleady exists. 14:19:17.351 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Integer aleady exists. 14:19:17.352 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.String aleady exists. 14:19:17.353 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Boolean aleady exists. 14:19:17.353 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Long aleady exists. 14:19:17.353 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Byte aleady exists. 14:19:17.353 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Short aleady exists. 14:19:17.353 [main] WARN  i.a.c.DefaultAtlasConversionService - Converter between java.lang.Object and java.lang.Character aleady exists. 14:19:17.354 ```</body>
		<created>2018-02-02 14:21:30</created>
		<closed>2018-02-02 14:51:03</closed>
	</bug>
	<bug>
		<id>1375</id>
		<title>Datamapper initialization omits datashape from extension</title>
		<body>When I have JMS -&gt; My ext(with defined shape) -&gt; Datamapper -&gt; DB. Looking at the initialization of Datamapper in network tab, there's query for `jms connector` and `db connector` not the custom extension.  The extension is here: https://github.com/dsimansk/syndesis-extension-tp3  @lburgazzoli @gashcrumb @igarashitm </body>
		<created>2018-02-02 11:31:02</created>
		<closed>2018-02-26 20:59:47</closed>
	</bug>
	<bug>
		<id>1366</id>
		<title>bad SQL grammer on parameterized integer field</title>
		<body>Possibly the integer value is also single quoted? #### SQL ```sql INSERT INTO TODO (TASK, COMPLETED) VALUES (:#TASK, :#COMPLETED) ``` #### Error ``` org.springframework.jdbc.BadSqlGrammarException: PreparedStatementCallback; bad SQL grammar []; nested exception is org.postgresql.util.PSQLException: ERROR: column "completed" is of type integer but expression is of type character varying --  | Hint: You will need to rewrite or cast the expression.  | Position: 48  | at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.doTranslate(SQLErrorCodeSQLExceptionTranslator.java:231) ~[spring-jdbc-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:73) ~[spring-jdbc-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:649) ~[spring-jdbc-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at org.apache.camel.component.sql.SqlProducer.process(SqlProducer.java:116) ~[camel-sql-2.20.1.jar!/:2.20.1]  | at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.component.connector.ConnectorProducer.process(ConnectorProducer.java:45) ~[camel-connector-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.InterceptorToAsyncProcessorBridge.process(InterceptorToAsyncProcessorBridge.java:67) ~[camel-core-2.20.1.jar!/:2.20.1]  | at io.syndesis.integration.runtime.SyndesisLoggingSupport.lambda$null$3(SyndesisLoggingSupport.java:109) ~[integration-runtime-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT]  | at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.InterceptorToAsyncProcessorBridge.process(InterceptorToAsyncProcessorBridge.java:76) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.InterceptorToAsyncProcessorBridge.process(InterceptorToAsyncProcessorBridge.java:67) ~[camel-core-2.20.1.jar!/:2.20.1]  | at io.syndesis.integration.runtime.OutMessageCaptureInterceptStrategy.lambda$wrapProcessorInInterceptors$0(OutMessageCaptureInterceptStrategy.java:53) ~[integration-runtime-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT]  | at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.InterceptorToAsyncProcessorBridge.process(InterceptorToAsyncProcessorBridge.java:76) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:110) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.util.AsyncProcessorHelper.process(AsyncProcessorHelper.java:109) [camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.Pipeline.process(Pipeline.java:80) [camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.component.twitter.consumer.DefaultTwitterConsumer.poll(DefaultTwitterConsumer.java:98) [camel-twitter-2.20.1.jar!/:2.20.1]  | at org.apache.camel.impl.ScheduledPollConsumer.doRun(ScheduledPollConsumer.java:174) [camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.impl.ScheduledPollConsumer.run(ScheduledPollConsumer.java:101) [camel-core-2.20.1.jar!/:2.20.1]  | at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_151]  | at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [na:1.8.0_151]  | at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [na:1.8.0_151]  | at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [na:1.8.0_151]  | at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_151]  | at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_151]  | at java.lang.Thread.run(Thread.java:748) [na:1.8.0_151]  | Caused by: org.postgresql.util.PSQLException: ERROR: column "completed" is of type integer but expression is of type character varying  | Hint: You will need to rewrite or cast the expression.  | Position: 48  | at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2455) ~[postgresql-9.4.1212.jre7.jar!/:9.4.1212.jre7]  | at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2155) ~[postgresql-9.4.1212.jre7.jar!/:9.4.1212.jre7]  | at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:288) ~[postgresql-9.4.1212.jre7.jar!/:9.4.1212.jre7]  | at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:430) ~[postgresql-9.4.1212.jre7.jar!/:9.4.1212.jre7]  | at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:356) ~[postgresql-9.4.1212.jre7.jar!/:9.4.1212.jre7]  | at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:168) ~[postgresql-9.4.1212.jre7.jar!/:9.4.1212.jre7]  | at org.postgresql.jdbc.PgPreparedStatement.execute(PgPreparedStatement.java:157) ~[postgresql-9.4.1212.jre7.jar!/:9.4.1212.jre7]  | at org.apache.commons.dbcp.DelegatingPreparedStatement.execute(DelegatingPreparedStatement.java:172) ~[commons-dbcp-1.4.jar!/:1.4]  | at org.apache.commons.dbcp.DelegatingPreparedStatement.execute(DelegatingPreparedStatement.java:172) ~[commons-dbcp-1.4.jar!/:1.4]  | at org.apache.camel.component.sql.SqlProducer$2.doInPreparedStatement(SqlProducer.java:161) ~[camel-sql-2.20.1.jar!/:2.20.1]  | at org.apache.camel.component.sql.SqlProducer$2.doInPreparedStatement(SqlProducer.java:116) ~[camel-sql-2.20.1.jar!/:2.20.1]  | at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:633) ~[spring-jdbc-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | ... 35 common frames omitted  </body>
		<created>2018-02-02 01:39:35</created>
		<closed>2018-04-07 23:29:11</closed>
	</bug>
	<bug>
		<id>1364</id>
		<title>SQL INSERT fails on action config</title>
		<body>I put this SQL ```sql INSERT INTO todo VALUES ( ':#task', ':#completed' ) ``` Then Done button doesn't finish the action config, and got following error in verifier log ``` java.lang.IllegalStateException: Unable to fetch and process metadata at io.syndesis.verifier.v1.MetadataEndpoint.fetchMetadata(MetadataEndpoint.java:65) ~[classes!/:1.2-SNAPSHOT] at io.syndesis.verifier.v1.ActionDefinitionEndpoint.definition(ActionDefinitionEndpoint.java:43) ~[classes!/:1.2-SNAPSHOT] at sun.reflect.GeneratedMethodAccessor33.invoke(Unknown Source) ~[na:na] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_131] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_131] at org.jboss.resteasy.core.MethodInjectorImpl.invoke(MethodInjectorImpl.java:140) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTarget(ResourceMethodInvoker.java:294) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:248) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.core.ResourceLocatorInvoker.invokeOnTargetObject(ResourceLocatorInvoker.java:138) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.core.ResourceLocatorInvoker.invoke(ResourceLocatorInvoker.java:101) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:402) [resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:209) [resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.plugins.server.servlet.ServletContainerDispatcher.service(ServletContainerDispatcher.java:227) [resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:56) [resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:51) [resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) [javax.servlet-api-3.1.0.jar!/:3.1.0] at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:85) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) [spring-boot-1.5.8.RELEASE.jar!/:1.5.8.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at org.springframework.web.filter.AbstractRequestLoggingFilter.doFilterInternal(AbstractRequestLoggingFilter.java:244) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110) [spring-boot-actuator-1.5.8.RELEASE.jar!/:1.5.8.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:106) [spring-boot-actuator-1.5.8.RELEASE.jar!/:1.5.8.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:64) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:131) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) [undertow-core-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) [undertow-core-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) [undertow-core-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) [undertow-core-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) [undertow-core-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) [undertow-core-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) [undertow-servlet-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.server.Connectors.executeRootHandler(Connectors.java:332) [undertow-core-1.4.20.Final.jar!/:1.4.20.Final] at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:812) [undertow-core-1.4.20.Final.jar!/:1.4.20.Final] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_131] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_131] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131] Caused by: java.lang.IllegalStateException: java.sql.SQLException: Table does not exist in schema null at io.syndesis.connector.sql.SqlConnectorMetaDataExtension.meta(SqlConnectorMetaDataExtension.java:49) ~[sql-common-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] at io.syndesis.verifier.v1.MetadataEndpoint.fetchMetadata(MetadataEndpoint.java:60) ~[classes!/:1.2-SNAPSHOT] ... 77 common frames omitted Caused by: java.sql.SQLException: Table does not exist in schema null at io.syndesis.connector.sql.SqlStatementMetaData.addTable(SqlStatementMetaData.java:48) ~[sql-common-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] at io.syndesis.connector.sql.SqlStatementParser.parseInsert(SqlStatementParser.java:97) ~[sql-common-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] at io.syndesis.connector.sql.SqlStatementParser.parse(SqlStatementParser.java:78) ~[sql-common-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] at io.syndesis.connector.sql.SqlConnectorMetaDataExtension.parseStatement(SqlConnectorMetaDataExtension.java:58) ~[sql-common-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] at io.syndesis.connector.sql.SqlConnectorMetaDataExtension.meta(SqlConnectorMetaDataExtension.java:44) ~[sql-common-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] ... 78 common frames omitted ```</body>
		<created>2018-02-01 23:33:22</created>
		<closed>2018-02-02 00:42:00</closed>
	</bug>
	<bug>
		<id>1358</id>
		<title>Connection verification error shown as successful verification</title>
		<body>Currently our SQL verifier is broken (#1357), that means that `POST /api/v1/connectors/sql/verifier` endpoint returns:  ```json [   {     "status":"UNSUPPORTED",     "scope":"PARAMETERS",     "errors":[       {         "code":"internal-error",         "description":"No action sql used for the verification known",         "parameters":[],         "attributes":{}       }     ]   } ] ```  Which in turn is presented as:  ![screenshot-2018-2-1 syndesis](https://user-images.githubusercontent.com/1306050/35692801-8d4efdea-077c-11e8-8d9a-dc34394689e3.png) </body>
		<created>2018-02-01 17:20:31</created>
		<closed>2018-02-13 16:28:45</closed>
	</bug>
	<bug>
		<id>1357</id>
		<title>SQL verifier not being detected</title>
		<body>The SQL verifier extension ([SqlConnectorVerifierExtension](https://github.com/syndesisio/syndesis/blob/master/app/connectors/connectors/sql/sql-common/src/main/java/io/syndesis/connector/sql/SqlConnectorVerifierExtension.java)) is not part of the SQL Camel component so when [ComponentVerifier](https://github.com/syndesisio/syndesis/blob/master/app/connectors/connector-verifier/src/main/java/io/syndesis/verifier/api/ComponentVerifier.java) tries to [resolve it](https://github.com/syndesisio/syndesis/blob/b371c00a0148d732505192592ebe0bbbc0920596/app/connectors/connector-verifier/src/main/java/io/syndesis/verifier/api/ComponentVerifier.java#L93) it does not resolve.  So verification of SQL connection doesn't work.</body>
		<created>2018-02-01 17:17:17</created>
		<closed>2018-02-02 12:23:03</closed>
	</bug>
	<bug>
		<id>1345</id>
		<title>JsonDBTest intermittently fails</title>
		<body>Once in a long while JsonDBTest fails with:  ``` java.lang.AssertionError:   Expected size:&lt;2&gt; but was:&lt;1&gt; in: &lt;[{"name"="Ana Chirino"}]&gt; at io.syndesis.jsondb.impl.JsonDBTest.testPush(JsonDBTest.java:324) ```  We should investigate, this could mean that we're missing a cache invalidation or there could be race condition.</body>
		<created>2018-02-01 10:24:12</created>
		<closed>2018-03-12 15:29:13</closed>
	</bug>
	<bug>
		<id>1334</id>
		<title>Can't save changes to a draft integration</title>
		<body>No idea if the draft state plays any role, but anyhoo, steps to reproduce:  1)  Open the browser JS console and go to the network tab 1)  Create an integration with 2 steps 1)  Click 'save as draft' 1)  Note in the browser tab the `GET` response when fetching the integration, there should be 2 steps 1)  Edit the integraiton, add another step in the middle 1)  Click 'save as draft' 1)  Note the `PUT` request, there should be 3 steps 1)  Once the detail page loads up, note the `GET` request, there's only 2 steps.  Also noticed that updating the configuration for a given step doesn't appear to save either, have verified that the `PUT` request for the update contains the new value.</body>
		<created>2018-01-31 17:31:55</created>
		<closed>2018-02-15 13:27:28</closed>
	</bug>
	<bug>
		<id>1302</id>
		<title>SQL Query checker: ResultSet not positioned properly</title>
		<body>Query checker alarms "ResultSet not positioned properly, perhaps you need to call next." when there is mixture of parameters and literal values in SQL query.  Examples WRONG (alarm): INSERT INTO TODO(task, completed) VALUES (:#TASK, 0);  OK: INSERT INTO TODO(task, completed) VALUES (:#TASK, :#COMPLETED); INSERT INTO TODO(task, completed) VALUES ('Some taks', 0);  (this occurs in TP3)</body>
		<created>2018-01-30 08:42:29</created>
		<closed>2018-02-09 14:00:58</closed>
	</bug>
	<bug>
		<id>1296</id>
		<title>Kebab menu broken in integration list</title>
		<body>I'm unable to select any option in the kebab menu on the integration list page.  The menu is visible upon click, but selecting an option does nothing.  Using Chrome.</body>
		<created>2018-01-29 21:19:52</created>
		<closed>2018-01-30 18:45:48</closed>
	</bug>
	<bug>
		<id>1295</id>
		<title>Field selection/completion broken in Filter Step</title>
		<body>Filter step no longer features a dropdown containing available field names.  Autocomplete when typing does not show all fields either.</body>
		<created>2018-01-29 21:16:27</created>
		<closed>2018-02-08 01:54:06</closed>
	</bug>
	<bug>
		<id>1280</id>
		<title>Create Connection page displays a "Register Applications" subpage</title>
		<body>After numerous rounds of testing, an unfamiliar subpage titled "Register Application" appears. Previously tests sees the Twitter, Salesforces, AMQ, AWS S3 icons appear instead of this subpage.  ![fi-register](https://user-images.githubusercontent.com/8625482/35498603-f8816b86-0509-11e8-8687-ef955dc24f09.png) </body>
		<created>2018-01-29 07:35:04</created>
		<closed>2018-02-22 17:08:21</closed>
	</bug>
	<bug>
		<id>1273</id>
		<title>TP3 &amp; master: JavaScript Error when opening pages.</title>
		<body>This happens on fresh install of the current TP3 image (i.e. on that 1.2.6):  ![image](https://user-images.githubusercontent.com/99080/35480578-6e194e8a-0411-11e8-9c7a-a898497dfe50.png)  Not sure whether this is an issue on the build or in general. @dsimansk do you see something like this on the productised images, too ?</body>
		<created>2018-01-28 08:57:40</created>
		<closed>2018-02-08 11:43:24</closed>
	</bug>
	<bug>
		<id>1261</id>
		<title>Double left arrow before "Home" in breadcrumbs</title>
		<body>I've seen this when you create or edit an integration, but it may be other places on the site, too. The icon is `fa-angle-double-left`  ![image](https://user-images.githubusercontent.com/35148959/35450415-90ced3f6-0285-11e8-9194-adf1cb5da04d.png) </body>
		<created>2018-01-26 16:44:25</created>
		<closed>2018-02-08 21:22:43</closed>
	</bug>
	<bug>
		<id>1207</id>
		<title>Dropdown menu items on integration list flash when hovered, clicks don't work</title>
		<body>Noticed this yesterday, as did @kahboom, this menu has apparently decided to stop working properly.  When you click on the dropdown icon on a row in the integration list, the menu appears but when you hover over menu items you can see the highlight rapidly blinks.  The click handlers also don't appear to work properly any more as well.</body>
		<created>2018-01-24 15:50:09</created>
		<closed>2018-01-24 16:31:53</closed>
	</bug>
	<bug>
		<id>1199</id>
		<title>Can't remove datamapper from integration</title>
		<body>When I try to edit integration and remove the datamapper step from it, the integration is rebuilt on OS, redeployed and everything looks OK, however the integration still contains the mapper step. On syndesis side everything looks OK, no mapper step here, but it is present in running pod on OS (I can see it in the logs).</body>
		<created>2018-01-24 13:09:15</created>
		<closed>2018-04-04 07:23:17</closed>
	</bug>
	<bug>
		<id>1172</id>
		<title> String "Activated": value not one of declared Enum instance names: [Draft, Active, Pending, Error, Inactive, Undeployed]</title>
		<body>Got error activating a deployment.  ``` Caused by: com.fasterxml.jackson.databind.exc.InvalidFormatException: Can not deserialize value of type io.syndesis.model.integration.IntegrationDeploymentState from String "Activated": value not one of declared Enum instance names: [Draft, Active, Pending, Error, Inactive, Undeployed]  at [Source: io.undertow.servlet.spec.ServletInputStreamImpl@7fbb3b54; line: 394, column: 20] (through reference chain: io.syndesis.model.integration.Integration$Builder["desiredStatus"]) at com.fasterxml.jackson.databind.exc.InvalidFormatException.from(InvalidFormatException.java:74) ~[jackson-databind-2.8.10.jar!/:2.8.10] at com.fasterxml.jackson.databind.DeserializationContext.weirdStringException(DeserializationContext.java:1410) ~[jackson-databind-2.8.10.jar!/:2.8.10] at com.fasterxml.jackson.databind.DeserializationContext.handleWeirdStringValue(DeserializationContext.java:926) ~[jackson-databind-2.8.10.jar!/:2.8.10] at com.fasterxml.jackson.databind.deser.std.EnumDeserializer._deserializeAltString(EnumDeserializer.java:189) ~[jackson-databind-2.8.10.jar!/:2.8.10] at com.fasterxml.jackson.databind.deser.std.EnumDeserializer.deserialize(EnumDeserializer.java:126) ~[jackson-databind-2.8.10.jar!/:2.8.10] ```</body>
		<created>2018-01-23 04:07:44</created>
		<closed>2018-01-23 14:51:20</closed>
	</bug>
	<bug>
		<id>1149</id>
		<title>Editing datamapper: can't cancel changes easilly when editing integration</title>
		<body>There is an issue with datamapper editing. I can't easily remove the changes I made, the only way to cancel them is to exit the Integration editing completely. The issue: ![out](https://user-images.githubusercontent.com/4180208/35156426-17c8bd18-fd31-11e7-8bcd-6dc5ba514bcf.gif)  The biggest problem however with this issue is, that when I don't exit the integration editing, and I hit "edit integration", even though I hit cancel before in the datamapper editing section, the new integration contains the changes in datamapper.</body>
		<created>2018-01-19 14:59:09</created>
		<closed>2018-03-16 17:20:03</closed>
	</bug>
	<bug>
		<id>1086</id>
		<title>There should be only one "import extension" action button on Extension empty state page </title>
		<body>This applies to both API client connector and Extension empty states. The top right small action button should only appear in the list view.   ![screen shot 2018-01-15 at 1 29 48 pm](https://user-images.githubusercontent.com/24943812/34999414-9cfcfffa-faaf-11e7-9e3a-66599700348b.png)  cc: @seanforyou23 @gashcrumb @kahboom @deeleman (not sure who worked on this feature, so I tagged all of you...)</body>
		<created>2018-01-16 16:25:03</created>
		<closed>2018-01-16 18:11:07</closed>
	</bug>
	<bug>
		<id>1077</id>
		<title>We require `apiBase` property for custom API connectors</title>
		<body>If `apiBase` is not defined in `config.json` URL being used by `ApiConnectorService` contains `undefined`, like:      https://syndesis..../undefined/api/v1undefined/api/v1/connectors?query=connectorGroupId=swagger-connector-template  This is currently manifested at our staging (https://syndesis-staging.b6ff.rh-idev.openshiftapps.com/) environment. I wonder if this will occur when we productize, if so that would make it a blocker for TP3.  @deeleman can you take a look? cc @dsimansk </body>
		<created>2018-01-16 10:15:03</created>
		<closed>2018-01-16 14:15:54</closed>
	</bug>
	<bug>
		<id>1047</id>
		<title>Advanced filter not loading</title>
		<body>When I try to add Advanced filter to an integration there's just infinite loading spinner with the following browser console exception.  @gashcrumb is it related to Basic filter fix actually, because Advanced filter was working yesterday for me.  ``` vendor.1aef838c4a5fa5657cd0.bundle.js:1 ERROR Error: Uncaught (in promise): TypeError: Cannot convert undefined or null to object TypeError: Cannot convert undefined or null to object     at Function.keys (&lt;anonymous&gt;)     at t.loadFormSetup (/2.3d08ad3091edc782fca0.chunk.js:1)     at /2.3d08ad3091edc782fca0.chunk.js:1     at t.invoke (polyfills.2c1aa39973715b94b1ea.bundle.js:1)     at Object.onInvoke (vendor.1aef838c4a5fa5657cd0.bundle.js:1)     at t.invoke (polyfills.2c1aa39973715b94b1ea.bundle.js:1)     at n.run (polyfills.2c1aa39973715b94b1ea.bundle.js:1)     at polyfills.2c1aa39973715b94b1ea.bundle.js:1     at t.invokeTask (polyfills.2c1aa39973715b94b1ea.bundle.js:1)     at Object.onInvokeTask (vendor.1aef838c4a5fa5657cd0.bundle.js:1)     at t.invokeTask (polyfills.2c1aa39973715b94b1ea.bundle.js:1)     at n.runTask (polyfills.2c1aa39973715b94b1ea.bundle.js:1)     at u (polyfills.2c1aa39973715b94b1ea.bundle.js:1)     at XMLHttpRequest.invoke (polyfills.2c1aa39973715b94b1ea.bundle.js:1)     at Function.keys (&lt;anonymous&gt;)     at t.loadFormSetup (/2.3d08ad3091edc782fca0.chunk.js:1)     at /2.3d08ad3091edc782fca0.chunk.js:1     at t.invoke (polyfills.2c1aa39973715b94b1ea.bundle.js:1)     at Object.onInvoke (vendor.1aef838c4a5fa5657cd0.bundle.js:1)     at t.invoke (polyfills.2c1aa39973715b94b1ea.bundle.js:1)     at n.run (polyfills.2c1aa39973715b94b1ea.bundle.js:1)     at polyfills.2c1aa39973715b94b1ea.bundle.js:1     at t.invokeTask (polyfills.2c1aa39973715b94b1ea.bundle.js:1)     at Object.onInvokeTask (vendor.1aef838c4a5fa5657cd0.bundle.js:1)     at t.invokeTask (polyfills.2c1aa39973715b94b1ea.bundle.js:1)     at n.runTask (polyfills.2c1aa39973715b94b1ea.bundle.js:1)     at u (polyfills.2c1aa39973715b94b1ea.bundle.js:1)     at XMLHttpRequest.invoke (polyfills.2c1aa39973715b94b1ea.bundle.js:1)     at new g (polyfills.2c1aa39973715b94b1ea.bundle.js:1)     at l (polyfills.2c1aa39973715b94b1ea.bundle.js:1)     at polyfills.2c1aa39973715b94b1ea.bundle.js:1     at t.invokeTask (polyfills.2c1aa39973715b94b1ea.bundle.js:1)     at Object.onInvokeTask (vendor.1aef838c4a5fa5657cd0.bundle.js:1)     at t.invokeTask (polyfills.2c1aa39973715b94b1ea.bundle.js:1)     at n.runTask (polyfills.2c1aa39973715b94b1ea.bundle.js:1)     at u (polyfills.2c1aa39973715b94b1ea.bundle.js:1)     at XMLHttpRequest.invoke (polyfills.2c1aa39973715b94b1ea.bundle.js:1) ```</body>
		<created>2018-01-12 16:00:08</created>
		<closed>2018-01-15 15:18:47</closed>
	</bug>
	<bug>
		<id>1034</id>
		<title>lombok.Data anno is not processed via ./tools/bin/syndesis</title>
		<body>When I run `./tools/bin/syndesis` without building sql connector ahead, I got ``` java.lang.Error:  Unresolved compilation problems:  The method getTableNames() is undefined for the type SqlStatementMetaData The method getInParams() is undefined for the type SqlStatementMetaData The method getTypeValue() is undefined for the type SqlParam The method getName() is undefined for the type SqlParam The method getTypeValue() is undefined for the type SqlParam The method getTypeValue() is undefined for the type SqlParam ``` those are supposed to be added by the annotation processor. `./tools/bin/syndesis` should trigger it for the sql connector build.</body>
		<created>2018-01-11 18:26:19</created>
		<closed>2018-01-11 19:11:58</closed>
	</bug>
	<bug>
		<id>1029</id>
		<title>API connector: uploaded image (icon) doesn't display anywhere</title>
		<body>![apiconnectoriconupload](https://user-images.githubusercontent.com/8707251/34832223-8da603a4-f6e9-11e7-93b0-ca25e5f8356d.png) </body>
		<created>2018-01-11 15:08:22</created>
		<closed>2018-01-12 19:10:08</closed>
	</bug>
	<bug>
		<id>1020</id>
		<title>When editing integration, I can't remove second step after the one added </title>
		<body>There is a strange behavior when I edit integration. When I insert a new step between some existing steps, I can't remove the step, which is right behind this inserted step. It happens also when I insert 2 new steps, I don't think this is desirable behavior. There is a recording of the behavior: ![cant_remove_second_item](https://user-images.githubusercontent.com/4180208/34822336-e1e890f8-f6c6-11e7-8d1e-2dc530f3c644.gif) </body>
		<created>2018-01-11 10:59:35</created>
		<closed>2018-01-11 15:01:31</closed>
	</bug>
	<bug>
		<id>1010</id>
		<title>Left navigation menu doesn't collapse as expected in integration editor  </title>
		<body>Was looking at the staging site with the UXD team, noticed the left navigation menu (hamburger menu) doesn't collapse automatically when in integration editor view. Clicking on the hamburger icon does nothing...   The left navigation menu should collapse when users are in integration editor view (create integration flow) .   cc: @seanforyou23 @gashcrumb @sjcox-rh @amysueg   &lt;img width="1432" alt="screen shot 2018-01-10 at 2 52 46 pm" src="https://user-images.githubusercontent.com/24943812/34792479-21fa72ee-f616-11e7-8232-8926626b4180.png"&gt; </body>
		<created>2018-01-10 20:03:42</created>
		<closed>2018-02-22 13:39:39</closed>
	</bug>
	<bug>
		<id>1006</id>
		<title>'Next' button present on page 3 of create connection wizard</title>
		<body>Noticed this today while testing:  ![download](https://user-images.githubusercontent.com/351660/34782061-911dccd2-f5f5-11e7-92f7-c765e091d206.png)  Need to restrict the 'Next' button to page 2 only.  @seanforyou23 FYI...</body>
		<created>2018-01-10 16:01:48</created>
		<closed>2018-01-11 17:15:12</closed>
	</bug>
	<bug>
		<id>1000</id>
		<title>API connector: integration fails to start due to missing operation</title>
		<body>I have a `DB-&gt;Todo API` integration that should create new record via todo-example API, but the Camel context fails to start with the following exception.  The naming of operations seem to be incorrect? ``` Failed to create route flow1: Route(flow1)[[From[sql-start-connector-1?query=SELECT+*+FROM... because of Failed to create Producer for endpoint: swagger-operation-3. Reason: java.lang.IllegalArgumentException: The specified operation with ID: `null` cannot be found in the Swagger specification loaded from `file:/tmp/swagger-operation-3404004334764459470.swagger`. Operations defined in the specification are: operation-0, operation-1, operation-2, operation-3, operation-4 ```   &lt;details&gt; &lt;summary&gt;Exception in log&lt;/summary&gt;  ``` Error starting ApplicationContext. To display the auto-configuration report re-run your application with 'debug' enabled.  | 2018-01-10 09:55:56.078 ERROR 1 --- [           main] o.s.boot.SpringApplication               : Application startup failed  |   | org.apache.camel.RuntimeCamelException: org.apache.camel.FailedToCreateRouteException: Failed to create route flow1: Route(flow1)[[From[sql-start-connector-1?query=SELECT+*+FROM... because of Failed to create Producer for endpoint: swagger-operation-3. Reason: java.lang.IllegalArgumentException: The specified operation with ID: `null` cannot be found in the Swagger specification loaded from `file:/tmp/swagger-operation-3404004334764459470.swagger`. Operations defined in the specification are: operation-0, operation-1, operation-2, operation-3, operation-4  | at org.apache.camel.util.ObjectHelper.wrapRuntimeCamelException(ObjectHelper.java:1831) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.spring.SpringCamelContext.start(SpringCamelContext.java:136) ~[camel-spring-2.20.1.jar!/:2.20.1]  | at org.apache.camel.spring.SpringCamelContext.onApplicationEvent(SpringCamelContext.java:174) ~[camel-spring-2.20.1.jar!/:2.20.1]  | at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172) ~[spring-context-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165) ~[spring-context-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139) ~[spring-context-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:393) ~[spring-context-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:347) ~[spring-context-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:883) ~[spring-context-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.finishRefresh(EmbeddedWebApplicationContext.java:144) ~[spring-boot-1.5.8.RELEASE.jar!/:1.5.8.RELEASE]  | at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546) ~[spring-context-4.3.12.RELEASE.jar!/:4.3.12.RELEASE]  | at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) ~[spring-boot-1.5.8.RELEASE.jar!/:1.5.8.RELEASE]  | at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.8.RELEASE.jar!/:1.5.8.RELEASE]  | at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.8.RELEASE.jar!/:1.5.8.RELEASE]  | at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.8.RELEASE.jar!/:1.5.8.RELEASE]  | at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.8.RELEASE.jar!/:1.5.8.RELEASE]  | at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.8.RELEASE.jar!/:1.5.8.RELEASE]  | at io.syndesis.example.Application.main(Application.java:13) [classes!/:na]  | at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_141]  | at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_141]  | at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_141]  | at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_141]  | at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48) [project-0.1-SNAPSHOT.jar:na]  | at org.springframework.boot.loader.Launcher.launch(Launcher.java:87) [project-0.1-SNAPSHOT.jar:na]  | at org.springframework.boot.loader.Launcher.launch(Launcher.java:50) [project-0.1-SNAPSHOT.jar:na]  | at org.springframework.boot.loader.PropertiesLauncher.main(PropertiesLauncher.java:587) [project-0.1-SNAPSHOT.jar:na]  | Caused by: org.apache.camel.FailedToCreateRouteException: Failed to create route flow1: Route(flow1)[[From[sql-start-connector-1?query=SELECT+*+FROM... because of Failed to create Producer for endpoint: swagger-operation-3. Reason: java.lang.IllegalArgumentException: The specified operation with ID: `null` cannot be found in the Swagger specification loaded from `file:/tmp/swagger-operation-3404004334764459470.swagger`. Operations defined in the specification are: operation-0, operation-1, operation-2, operation-3, operation-4  | at org.apache.camel.impl.RouteService.warmUp(RouteService.java:147) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.impl.DefaultCamelContext.doWarmUpRoutes(DefaultCamelContext.java:3945) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.impl.DefaultCamelContext.safelyStartRouteServices(DefaultCamelContext.java:3852) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.impl.DefaultCamelContext.doStartOrResumeRoutes(DefaultCamelContext.java:3638) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.impl.DefaultCamelContext.doStartCamel(DefaultCamelContext.java:3490) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.impl.DefaultCamelContext.access$000(DefaultCamelContext.java:208) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.impl.DefaultCamelContext$2.call(DefaultCamelContext.java:3249) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.impl.DefaultCamelContext$2.call(DefaultCamelContext.java:3245) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.impl.DefaultCamelContext.doWithDefinedClassLoader(DefaultCamelContext.java:3268) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.impl.DefaultCamelContext.doStart(DefaultCamelContext.java:3245) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.impl.DefaultCamelContext.start(DefaultCamelContext.java:3168) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.spring.SpringCamelContext.start(SpringCamelContext.java:133) ~[camel-spring-2.20.1.jar!/:2.20.1]  | ... 24 common frames omitted  | Caused by: org.apache.camel.FailedToCreateProducerException: Failed to create Producer for endpoint: swagger-operation-3. Reason: java.lang.IllegalArgumentException: The specified operation with ID: `null` cannot be found in the Swagger specification loaded from `file:/tmp/swagger-operation-3404004334764459470.swagger`. Operations defined in the specification are: operation-0, operation-1, operation-2, operation-3, operation-4  | at org.apache.camel.impl.ProducerCache.doGetProducer(ProducerCache.java:578) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.impl.ProducerCache.acquireProducer(ProducerCache.java:168) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.SendProcessor.doStart(SendProcessor.java:248) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:60) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:104) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:90) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.RedeliveryErrorHandler.doStart(RedeliveryErrorHandler.java:1472) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.support.ChildServiceSupport.start(ChildServiceSupport.java:44) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.support.ChildServiceSupport.start(ChildServiceSupport.java:31) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:60) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:104) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:90) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.interceptor.DefaultChannel.doStart(DefaultChannel.java:160) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:60) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:104) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:62) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:104) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:90) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.MulticastProcessor.doStart(MulticastProcessor.java:1172) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:60) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:104) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.util.ServiceHelper.startServices(ServiceHelper.java:90) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.processor.DelegateAsyncProcessor.doStart(DelegateAsyncProcessor.java:80) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.util.ServiceHelper.startService(ServiceHelper.java:75) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.impl.RouteService.startChildService(RouteService.java:370) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.impl.RouteService.doWarmUp(RouteService.java:196) ~[camel-core-2.20.1.jar!/:2.20.1]  | at org.apache.camel.impl.RouteService.warmUp(RouteService.java:145) ~[camel-core-2.20.1.jar!/:2.20.1]  | ... 36 common frames omitted  | Caused by: java.lang.IllegalArgumentException: The specified operation with ID: `null` cannot be found in the Swagger specification loaded from `file:/tmp/swagger-operation-3404004334764459470.swagger`. Operations defined in the specification are: operation-0, operation-1, operation-2, operation-3, operation-4  | at org.apache.camel.component.rest.swagger.RestSwaggerEndpoint.createProducer(RestSwaggerEndpoint.java:182) ~[camel-rest-swagger-2.20.1.jar!/:2.20.1]  | at org.apache.camel.component.connector.DefaultConnectorEndpoint.createProducer(DefaultConnectorEndpoint.java:51) ~[camel-connector-2.20.1.jar!/:2.20.1]  | at org.apache.camel.impl.ProducerCache.doGetProducer(ProducerCache.java:573) ~[camel-core-2.20.1.jar!/:2.20.1]  | ... 70 common frames omitted ```  &lt;/details&gt;</body>
		<created>2018-01-10 10:04:13</created>
		<closed>2018-01-10 11:40:35</closed>
	</bug>
	<bug>
		<id>999</id>
		<title>API connector: default params can't be overwritten in wizard</title>
		<body>In todo-example, there's only generic [hostname](https://github.com/syndesisio/todo-example/blob/master/swagger.json#L11) declaration for obvious reasons. However, when I follow the API connector wizard to the last step and customize those parameters my changes aren't reflected on a connector itself.  E.g. when I want to create new connection, there're still only defaults. as provided in swagger file.  ![screen shot 2018-01-10 at 09 54 53](https://user-images.githubusercontent.com/5637792/34763735-71238556-f5ec-11e7-8d84-9b5d4a76c090.png)  And in detail view also  ![screen shot 2018-01-10 at 09 56 27](https://user-images.githubusercontent.com/5637792/34763771-8dce3886-f5ec-11e7-9437-e8c2f67ccb20.png)    </body>
		<created>2018-01-10 08:56:58</created>
		<closed>2018-01-10 16:15:56</closed>
	</bug>
	<bug>
		<id>998</id>
		<title>Syndesis Help hyperlink does not work</title>
		<body>The link at the end of "Find out more at Syndesis Help" isn't working.  ![dead_link](https://user-images.githubusercontent.com/8625482/34762478-e3fb40b0-f622-11e7-9f48-891514c80717.png) </body>
		<created>2018-01-10 08:25:41</created>
		<closed>2018-01-11 14:59:27</closed>
	</bug>
	<bug>
		<id>996</id>
		<title>API connector: can't create connector from yaml file</title>
		<body>UI wizard still can't create API connector from yaml either from URL or direct upload. There's an exception in `syndesis-rest` log.  Cc @zregvart   &lt;details&gt;   &lt;summary&gt;syndesis-rest log&lt;/summary&gt;  ``` 2018-01-10 07:14:32.040 ERROR [-,53a4d55d3b93cdcc,53a4d55d3b93cdcc,false] 1 --- [  XNIO-3 task-5] .s.r.v.h.e.SyndesisServerExceptionMapper : Internal Server Exception. Unable to process JSON references  java.lang.IllegalStateException: Unable to process JSON references at io.syndesis.connector.generator.swagger.JsonSchemaHelper.resolveSchemaForReference(JsonSchemaHelper.java:105) ~[connector-generator-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] at io.syndesis.connector.generator.swagger.DataShapeHelper.createShapeFromReference(DataShapeHelper.java:93) ~[connector-generator-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] at io.syndesis.connector.generator.swagger.DataShapeHelper.createShapeFromProperty(DataShapeHelper.java:89) ~[connector-generator-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] at io.syndesis.connector.generator.swagger.DataShapeHelper.createShapeFromResponse(DataShapeHelper.java:59) ~[connector-generator-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] at io.syndesis.connector.generator.swagger.SwaggerUnifiedShapeConnectorGenerator.lambda$createDescriptor$4(SwaggerUnifiedShapeConnectorGenerator.java:166) ~[connector-generator-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] at java.util.Optional.map(Optional.java:215) ~[na:1.8.0_131] at io.syndesis.connector.generator.swagger.SwaggerUnifiedShapeConnectorGenerator.createDescriptor(SwaggerUnifiedShapeConnectorGenerator.java:166) ~[connector-generator-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] at io.syndesis.connector.generator.swagger.BaseSwaggerConnectorGenerator.configureConnector(BaseSwaggerConnectorGenerator.java:191) ~[connector-generator-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] at io.syndesis.connector.generator.swagger.BaseSwaggerConnectorGenerator.generate(BaseSwaggerConnectorGenerator.java:86) ~[connector-generator-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] at io.syndesis.rest.v1.handler.connection.CustomConnectorHandler.lambda$create$0(CustomConnectorHandler.java:64) ~[rest-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] at io.syndesis.rest.v1.handler.connection.BaseConnectorGeneratorHandler.withGeneratorAndTemplate(BaseConnectorGeneratorHandler.java:52) ~[rest-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] at io.syndesis.rest.v1.handler.connection.CustomConnectorHandler.create(CustomConnectorHandler.java:63) ~[rest-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_131] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_131] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_131] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_131] at org.jboss.resteasy.core.MethodInjectorImpl.invoke(MethodInjectorImpl.java:140) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTarget(ResourceMethodInvoker.java:294) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:248) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.core.ResourceLocatorInvoker.invokeOnTargetObject(ResourceLocatorInvoker.java:138) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.core.ResourceLocatorInvoker.invoke(ResourceLocatorInvoker.java:101) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:402) [resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:209) [resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.plugins.server.servlet.ServletContainerDispatcher.service(ServletContainerDispatcher.java:227) [resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:56) [resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:51) [resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) [javax.servlet-api-3.1.0.jar!/:3.1.0] at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:85) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) [spring-boot-1.5.8.RELEASE.jar!/:1.5.8.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110) [spring-boot-actuator-1.5.8.RELEASE.jar!/:1.5.8.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.authentication.preauth.AbstractPreAuthenticatedProcessingFilter.doFilter(AbstractPreAuthenticatedProcessingFilter.java:121) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:64) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) [spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at org.springframework.cloud.sleuth.instrument.web.TraceFilter.doFilter(TraceFilter.java:186) [spring-cloud-sleuth-core-1.2.5.RELEASE.jar!/:1.2.5.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:106) [spring-boot-actuator-1.5.8.RELEASE.jar!/:1.5.8.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:64) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:131) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) [undertow-core-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) [undertow-core-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) [undertow-core-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) [undertow-core-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) [undertow-core-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) [undertow-core-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) [undertow-servlet-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.server.Connectors.executeRootHandler(Connectors.java:332) [undertow-core-1.4.21.Final.jar!/:1.4.21.Final] at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) [undertow-core-1.4.21.Final.jar!/:1.4.21.Final] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_131] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_131] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131] Caused by: com.fasterxml.jackson.core.JsonParseException: Unexpected character ('-' (code 45)) in numeric value: expected digit (0-9) to follow minus sign, for valid numeric value  at [Source: mem:specification; line: 1, column: 3] at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1702) ~[jackson-core-2.8.10.jar!/:2.8.10] at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:558) ~[jackson-core-2.8.10.jar!/:2.8.10] at com.fasterxml.jackson.core.base.ParserBase.reportUnexpectedNumberChar(ParserBase.java:1058) ~[jackson-core-2.8.10.jar!/:2.8.10] at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleInvalidNumberStart(UTF8StreamJsonParser.java:2811) ~[jackson-core-2.8.10.jar!/:2.8.10] at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._parseNegNumber(UTF8StreamJsonParser.java:1446) ~[jackson-core-2.8.10.jar!/:2.8.10] at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:861) ~[jackson-core-2.8.10.jar!/:2.8.10] at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:772) ~[jackson-core-2.8.10.jar!/:2.8.10] at com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:3850) ~[jackson-databind-2.8.10.jar!/:2.8.10] at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3799) ~[jackson-databind-2.8.10.jar!/:2.8.10] at com.fasterxml.jackson.databind.ObjectMapper.readTree(ObjectMapper.java:2474) ~[jackson-databind-2.8.10.jar!/:2.8.10] at me.andrz.jackson.JsonContext.getNode(JsonContext.java:51) ~[jackson-json-reference-core-0.2.1.jar!/:na] at me.andrz.jackson.JsonReferenceProcessor.process(JsonReferenceProcessor.java:107) ~[jackson-json-reference-core-0.2.1.jar!/:na] at me.andrz.jackson.JsonReferenceProcessor.process(JsonReferenceProcessor.java:96) ~[jackson-json-reference-core-0.2.1.jar!/:na] at io.syndesis.connector.generator.swagger.JsonSchemaHelper.resolveSchemaForReference(JsonSchemaHelper.java:103) ~[connector-generator-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] ... 125 common frames omitted ```  &lt;/details&gt;   </body>
		<created>2018-01-10 07:20:41</created>
		<closed>2018-01-10 10:59:28</closed>
	</bug>
	<bug>
		<id>980</id>
		<title>We should not send empty-valued `configuredProperties` for new custom connector</title>
		<body>When creating a new API connector we currently send over `configuredProperties` that contain empty (`""`) values, these are trimmed-to-null and not accepted by Immutables as Map values.  ```json {   "connectorTemplateId":"swagger-connector-template",   "configuredProperties":{     "authenticationType":"none",     "authorizationEndpoint":"",     "tokenEndpoint":"",     "host":"https://api.hsbc.com",     "basePath":"/"   },   "specificationFile":{    },   "actionsSummary":{     "actionCountByTags":{       "ATMs":5     },     "totalActions":5   },   "description":"",   "errors":[    ],   "warnings":[    ],   "name":"API",   "properties":{     "authenticationType":{       "componentProperty":true,       "defaultValue":"none",       "deprecated":false,       "description":"Type of authentication used to connect to the API",       "displayName":"Authentication Type",       "group":"producer",       "javaType":"java.lang.String",       "kind":"property",       "label":"producer",       "required":false,       "secret":false,       "type":"string",       "tags":[         "authentication-type"       ],       "enum":[         {           "label":"No Security",           "value":"none"         }       ]     },     "basePath":{       "componentProperty":true,       "defaultValue":"/",       "deprecated":false,       "description":"API basePath for example /v2. Default is unset if set overrides the value present in Swagger specification.",       "displayName":"Base path",       "group":"producer",       "javaType":"java.lang.String",       "kind":"property",       "label":"producer",       "required":false,       "secret":false,       "type":"string",       "tags":[        ],       "enum":[        ]     },     "host":{       "componentProperty":true,       "defaultValue":"https://api.hsbc.com",       "deprecated":false,       "description":"Scheme hostname and port to direct the HTTP requests to in the form of https://hostname:port. Can be configured at the endpoint component or in the correspoding REST configuration in the Camel Context. If you give this component a name (e.g. petstore) that REST configuration is consulted first rest-swagger next and global configuration last. If set overrides any value found in the Swagger specification RestConfiguration. Can be overriden in endpoint configuration.",       "displayName":"Host",       "group":"producer",       "javaType":"java.lang.String",       "kind":"property",       "label":"producer",       "required":false,       "secret":false,       "type":"string",       "tags":[        ],       "enum":[        ]     },     "specification":{       "componentProperty":true,       "deprecated":false,       "description":"Swagger specification of the service",       "displayName":"Specification",       "group":"producer",       "javaType":"java.lang.String",       "kind":"property",       "label":"producer",       "required":false,       "secret":false,       "type":"hidden",       "tags":[         "upload",         "url"       ],       "enum":[        ]     }   } } ```</body>
		<created>2018-01-09 13:43:17</created>
		<closed>2018-01-09 21:58:42</closed>
	</bug>
	<bug>
		<id>977</id>
		<title>DataShapes not taken into account </title>
		<body>As today the datamapper set-up does not take into account any other step than those of type `endpoint` this result in `extension` steps being ignored so if you have:  ``` connector-1 --&gt; extension --&gt; mapper --&gt; connector-2 ```  The mapper uses datashapes info from `conenctor-1` ignoring any information from the extension.  @syndesisio/ui-api can someone have a look ?  </body>
		<created>2018-01-09 12:30:14</created>
		<closed>2018-01-09 21:00:22</closed>
	</bug>
	<bug>
		<id>970</id>
		<title>Autocomplete to pick a property in basic filter not working</title>
		<body>To reproduce create an Integration with Twitter connection as a start and add a basic filter step. The `path` property (first one on the left) should offer autocomplete.  In the Twitter to Salesforce [sample integration docs](https://access.redhat.com/documentation/en-us/red_hat_jboss_fuse/7.0-tp/html-single/fuse_ignite_sample_integration_tutorial/index#t2sf-add-basic-filter-step) we make a note of the autocomplete, is this a **blocker**?  Seems that the `&lt;datalist&gt;` for `path` is not populated with the result from shape inspection. Not sure if the error below is related.  &lt;details&gt; &lt;summary&gt;console error&lt;/summary&gt; ERROR ErrorcolumnNumber: 48645fileName: "https://syndesis.192.168.42.178.nip.io/polyfills.37f8c6bb16e03e965027.bundle.js"lineNumber: 1message: "No component factory found for t. Did you add it to @NgModule.entryComponents?"ngComponent: function t()originalStack: "g@https://syndesis.192.168.42.178.nip.io/polyfills.37f8c6bb16e03e965027.bundle.js:1:48645\nZ@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:36043\n/oeL/&lt;/oa&lt;/t.prototype.resolveComponentFactory@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:103724\n/oeL/&lt;/oa&lt;/t.prototype.resolveComponentFactory@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:103674\n2YgE/a&lt;/t.prototype.attach@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:207216\nNynv/Re&lt;/t.prototype.show@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:1094236\nNynv/Ra&lt;/e.prototype.showTourStep@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:1289753\nNynv/re&lt;/t.prototype.showStep@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:1079567\nNynv/re&lt;/t.prototype.setCurrentStep@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:1079287\nNynv/re&lt;/t.prototype.goToStep/&lt;/&lt;@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:1079020\neFQL/&lt;/&lt;/S&lt;/w&lt;/t.prototype.invokeTask@https://syndesis.192.168.42.178.nip.io/polyfills.37f8c6bb16e03e965027.bundle.js:1:56655\nonInvokeTask@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:36837\neFQL/&lt;/&lt;/S&lt;/w&lt;/t.prototype.invokeTask@https://syndesis.192.168.42.178.nip.io/polyfills.37f8c6bb16e03e965027.bundle.js:1:56568\neFQL/&lt;/&lt;/S&lt;/b&lt;/n.prototype.runTask@https://syndesis.192.168.42.178.nip.io/polyfills.37f8c6bb16e03e965027.bundle.js:1:51544\nt/this.invoke@https://syndesis.192.168.42.178.nip.io/polyfills.37f8c6bb16e03e965027.bundle.js:1:57616\ne@https://syndesis.192.168.42.178.nip.io/polyfills.37f8c6bb16e03e965027.bundle.js:1:42863\n"stack: "g@https://syndesis.192.168.42.178.nip.io/polyfills.37f8c6bb16e03e965027.bundle.js:1:48645\nZ@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:36043\n/oeL/&lt;/oa&lt;/t.prototype.resolveComponentFactory@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:103724\n/oeL/&lt;/oa&lt;/t.prototype.resolveComponentFactory@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:103674\n2YgE/a&lt;/t.prototype.attach@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:207216\nNynv/Re&lt;/t.prototype.show@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:1094236\nNynv/Ra&lt;/e.prototype.showTourStep@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:1289753\nNynv/re&lt;/t.prototype.showStep@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:1079567\nNynv/re&lt;/t.prototype.setCurrentStep@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:1079287\nNynv/re&lt;/t.prototype.goToStep/&lt;/&lt;@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:1079020\neFQL/&lt;/&lt;/S&lt;/w&lt;/t.prototype.invokeTask@https://syndesis.192.168.42.178.nip.io/polyfills.37f8c6bb16e03e965027.bundle.js:1:56655\nonInvokeTask@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:36837\neFQL/&lt;/&lt;/S&lt;/w&lt;/t.prototype.invokeTask@https://syndesis.192.168.42.178.nip.io/polyfills.37f8c6bb16e03e965027.bundle.js:1:56568\neFQL/&lt;/&lt;/S&lt;/b&lt;/n.prototype.runTask@https://syndesis.192.168.42.178.nip.io/polyfills.37f8c6bb16e03e965027.bundle.js:1:51544\nt/this.invoke@https://syndesis.192.168.42.178.nip.io/polyfills.37f8c6bb16e03e965027.bundle.js:1:57616\ne@https://syndesis.192.168.42.178.nip.io/polyfills.37f8c6bb16e03e965027.bundle.js:1:42863\n"zoneAwareStack: "g@https://syndesis.192.168.42.178.nip.io/polyfills.37f8c6bb16e03e965027.bundle.js:1:48645\nZ@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:36043\n/oeL/&lt;/oa&lt;/t.prototype.resolveComponentFactory@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:103724\n/oeL/&lt;/oa&lt;/t.prototype.resolveComponentFactory@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:103674\n2YgE/a&lt;/t.prototype.attach@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:207216\nNynv/Re&lt;/t.prototype.show@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:1094236\nNynv/Ra&lt;/e.prototype.showTourStep@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:1289753\nNynv/re&lt;/t.prototype.showStep@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:1079567\nNynv/re&lt;/t.prototype.setCurrentStep@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:1079287\nNynv/re&lt;/t.prototype.goToStep/&lt;/&lt;@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:1079020\neFQL/&lt;/&lt;/S&lt;/w&lt;/t.prototype.invokeTask@https://syndesis.192.168.42.178.nip.io/polyfills.37f8c6bb16e03e965027.bundle.js:1:56655\nonInvokeTask@https://syndesis.192.168.42.178.nip.io/vendor.717ef79426402b8f00f2.bundle.js:1:36837\neFQL/&lt;/&lt;/S&lt;/w&lt;/t.prototype.invokeTask@https://syndesis.192.168.42.178.nip.io/polyfills.37f8c6bb16e03e965027.bundle.js:1:56568\neFQL/&lt;/&lt;/S&lt;/b&lt;/n.prototype.runTask@https://syndesis.192.168.42.178.nip.io/polyfills.37f8c6bb16e03e965027.bundle.js:1:51544\nt/this.invoke@https://syndesis.192.168.42.178.nip.io/polyfills.37f8c6bb16e03e965027.bundle.js:1:57616\ne@https://syndesis.192.168.42.178.nip.io/polyfills.37f8c6bb16e03e965027.bundle.js:1:42863\n"__proto__: Object {  } vendor.717ef79426402b8f00f2.bundle.js:1:32153 &lt;details&gt;</body>
		<created>2018-01-09 11:01:35</created>
		<closed>2018-01-10 20:41:10</closed>
	</bug>
	<bug>
		<id>964</id>
		<title>DB connection validation always succeeds</title>
		<body>Regardless what the input is:  ![image](https://user-images.githubusercontent.com/99080/34714290-512e3f52-f529-11e7-9498-153ad513b605.png) </body>
		<created>2018-01-09 09:39:24</created>
		<closed>2018-02-02 17:11:39</closed>
	</bug>
	<bug>
		<id>962</id>
		<title>Secret fields should have autocomplete=off attribute</title>
		<body>Or perhaps `autocomplete=new-password`?  https://developer.mozilla.org/en-US/docs/Web/Security/Securing_your_site/Turning_off_form_autocompletion#The_autocomplete_attribute_and_login_fields</body>
		<created>2018-01-09 08:48:00</created>
		<closed>2018-01-31 19:45:24</closed>
	</bug>
	<bug>
		<id>961</id>
		<title>Navigating between steps when editing integration doesn't work</title>
		<body>When trying to navigate between steps with one of the steps open unexpectedly the same step is shown. Funny, the document location seems to be the same when navigating directly.  I made a video:  ![step-routing](https://user-images.githubusercontent.com/1306050/34710372-4bf3c6dc-f51b-11e7-9cf8-4bce73d1034d.gif)   </body>
		<created>2018-01-09 07:59:18</created>
		<closed>2018-01-09 21:00:22</closed>
	</bug>
	<bug>
		<id>948</id>
		<title>Extensions: Import page is called Update when creating fresh extension</title>
		<body>Shouldn't be the title`Import` for the first time importing the extension jar and `Update` for the update of existing one?  ![screen shot 2018-01-08 at 12 49 41](https://user-images.githubusercontent.com/5637792/34669544-7ae6ce84-f472-11e7-8058-eeeb43f62494.png) </body>
		<created>2018-01-08 11:52:04</created>
		<closed>2018-01-08 20:35:24</closed>
	</bug>
	<bug>
		<id>944</id>
		<title>API connector: wizard is stuck on Basic auth is used</title>
		<body>Our [todo-example](https://github.com/syndesisio/todo-example/blob/master/swagger.json#L173-L177) defines Basic auth in swagger that causes some trouble to the UI wizard.  Browser console error ``` vendor.7ec7098e6313e0e15893.bundle.js:1 ERROR TypeError: Cannot read property 'defaultValue' of undefined     at n.ngOnInit (2.627bf80f6122cd2a77ea.chunk.js:1)     at Cn (vendor.7ec7098e6313e0e15893.bundle.js:1)     at dr (vendor.7ec7098e6313e0e15893.bundle.js:1)     at cr (vendor.7ec7098e6313e0e15893.bundle.js:1)     at jr (vendor.7ec7098e6313e0e15893.bundle.js:1)     at Object.updateDirectives (2.627bf80f6122cd2a77ea.chunk.js:1)     at Object.updateDirectives (vendor.7ec7098e6313e0e15893.bundle.js:1)     at ur (vendor.7ec7098e6313e0e15893.bundle.js:1)     at Cr (vendor.7ec7098e6313e0e15893.bundle.js:1)     at wr (vendor.7ec7098e6313e0e15893.bundle.js:1)     at ur (vendor.7ec7098e6313e0e15893.bundle.js:1)     at Cr (vendor.7ec7098e6313e0e15893.bundle.js:1)     at _r (vendor.7ec7098e6313e0e15893.bundle.js:1)     at ur (vendor.7ec7098e6313e0e15893.bundle.js:1)     at Cr (vendor.7ec7098e6313e0e15893.bundle.js:1) ```  IMHO the UI code is looking for `authenticationType.defaultValue` &amp;&amp; `authorizationEndpoint.defaultValue` but in case of Basic Auth, only the authenticationType is present.  https://github.com/syndesisio/syndesis/blob/537727fa366179fa8e1ddad9c63b6f617cf71ab3/app/ui/src/app/customizations/api-connector/api-connector-create/api-connector-auth/api-connector-auth.component.ts#L21-L27  syndesis-rest response for `/connectors/custom/info` query ``` "authenticationType": {       "componentProperty": true,       "defaultValue": "basic",       "deprecated": false,       "description": "Type of authentication used to connect to the API",       "displayName": "Authentication Type",       "group": "producer",       "javaType": "java.lang.String",       "kind": "property",       "label": "producer",       "required": false,       "secret": false,       "type": "string",       "tags": [         "authentication-type"       ],       "enum": [         {           "label": "HTTP Basic Authentication",           "value": "basic"         }       ]     }, ```     </body>
		<created>2018-01-08 09:23:50</created>
		<closed>2018-01-08 12:42:56</closed>
	</bug>
	<bug>
		<id>943</id>
		<title>API connector: canceling wizard on previous error returns to empty page</title>
		<body>Update: this behaviour happens only if there's an error in wizard, like unrecognized Basic auth issue https://github.com/syndesisio/syndesis/issues/944  Hitting `Cancel` button (+ confirming the modal) should redirect back the list page probably. Currently it goes to empty page for path `customizations/api-connector/create/swagger-connector`.  ![screen shot 2018-01-08 at 10 02 32](https://user-images.githubusercontent.com/5637792/34664218-14278df8-f45b-11e7-9751-0bfc77dd84f7.png)       </body>
		<created>2018-01-08 09:03:23</created>
		<closed>2018-01-08 11:30:24</closed>
	</bug>
	<bug>
		<id>933</id>
		<title>Integration S3&gt;S3: FailedToCreateRouteException</title>
		<body>I hit an exception when trying to create a S3&gt;S3 integration. There seems to be an issue with the secret key in the integration, it's set to: "secretKey=xxxxxx"  The exception: `` org.apache.camel.RuntimeCamelException: org.apache.camel.FailedToCreateRouteException: Failed to create route flow1: Route(flow1)[[From[aws-s3-polling-bucket-connector?accessKey... because of The request signature we calculated does not match the signature you provided. Check your key and signing method. (Service: Amazon S3; Status Code: 403; Error Code: SignatureDoesNotMatch; Request ID: 5E388EB207AE6FA8; S3 Extended Request ID: KB/LYi+eV6nAwWGl1IZY9tAGzEDyAxkqu6/8DWXe4QWAg0GUXOAIrhz6P64g4yBhPV250p7/LdU=) ``  The full integration pod log is attached. [asdf-2-zx291.log](https://github.com/syndesisio/syndesis/files/1606956/asdf-2-zx291.log) </body>
		<created>2018-01-05 15:19:02</created>
		<closed>2018-01-29 08:18:44</closed>
	</bug>
	<bug>
		<id>931</id>
		<title>API connector: swagger file upload doesn't work</title>
		<body>I can select a file from my HDD but nothing happens after that. I can't continue to the next wizard step when creating a new API connector. ![uploadswagger](https://user-images.githubusercontent.com/8707251/34612894-edfd7970-f22b-11e7-98a2-fd7a40fd38cb.png) </body>
		<created>2018-01-05 14:20:35</created>
		<closed>2018-01-05 17:08:44</closed>
	</bug>
	<bug>
		<id>929</id>
		<title>API connector: swagger file in yaml format</title>
		<body>@zregvart has create an API definition for our Todo app. But our wizard seems a bit picky about yaml file format. Should we just stick with json for now?   https://github.com/syndesisio/todo-example/blob/master/swagger.yaml  For the GH's raw link: &lt;img width="739" alt="screen shot 2018-01-05 at 14 58 46" src="https://user-images.githubusercontent.com/5637792/34612209-0297ea12-f229-11e7-9ef6-2aaf998ae117.png"&gt;  For direct Minishift link to Todo: &lt;img width="745" alt="screen shot 2018-01-05 at 15 00 03" src="https://user-images.githubusercontent.com/5637792/34612261-4a10938a-f229-11e7-917a-58915d23c124.png"&gt;  </body>
		<created>2018-01-05 14:02:18</created>
		<closed>2018-01-08 13:20:56</closed>
	</bug>
	<bug>
		<id>927</id>
		<title>Integration S2I build is not using pre-baked jars</title>
		<body>See the s2i build [log](https://gist.github.com/dsimansk/7dc70a4112bb9dfb0cf60869029ab309) for `Twitter -&gt; Salesforce`.   @chirino @jimmidyson is syndesis-s2i image still generated properly? </body>
		<created>2018-01-05 10:37:18</created>
		<closed>2018-04-27 10:06:35</closed>
	</bug>
	<bug>
		<id>926</id>
		<title>API connectors list: An unexpected HTTP error occured</title>
		<body>@deeleman There's a an error in browser console that includes URL doesn't look quiet right.  ``` Failed to load undefinedhttps://syndesis.192.168.64.14.nip.io/api/v1undefinedhttps://syndesis.192.168.64.14.nip.io/api/v1/connectors?query=connectorGroupId%3Dswagger-connector-template: Cross origin requests are only supported for protocol schemes: http, data, chrome, chrome-extension, https.  ```  ```   config.json: |     {       "apiEndpoint": "https://syndesis.192.168.64.14.nip.io/api/v1",       "title": "Syndesis",       "datamapper": {         "baseJavaInspectionServiceUrl": "https://syndesis.192.168.64.14.nip.io/v2/atlas/java/",         "baseXMLInspectionServiceUrl": "https://syndesis.192.168.64.14.nip.io/v2/atlas/xml/",         "baseJSONInspectionServiceUrl": "https://syndesis.192.168.64.14.nip.io/v2/atlas/json/",         "baseMappingServiceUrl": "https://syndesis.192.168.64.14.nip.io/v2/atlas/"       },       "branding": {         "logoWhiteBg": "assets/images/syndesis-logo-svg-white.svg",         "logoDarkBg": "assets/images/syndesis-logo-svg-white.svg",         "iconWhiteBg": "assets/images/glasses_logo_square.png",         "iconDarkBg": "assets/images/glasses_logo_square.png",         "appName": "Syndesis",         "favicon32": "/favicon-32x32.png",         "favicon16": "/favicon-16x16.png",         "touchIcon": "/apple-touch-icon.png"      }     } ```   </body>
		<created>2018-01-05 10:17:39</created>
		<closed>2018-01-05 11:07:31</closed>
	</bug>
	<bug>
		<id>912</id>
		<title>Integrations: infinite loading loop when S3 to S3 Copy Object action is selected</title>
		<body>I experience similar, but not quite the same issue as in https://github.com/syndesisio/syndesis/issues/908. The waiting for integration is also indefinite, but there is also an error in the browser console, as can be seen on the screenshot:  ![s3_integration_waiting](https://user-images.githubusercontent.com/4180208/34563563-56c7c444-f153-11e7-9791-4944e26527f4.png) </body>
		<created>2018-01-04 12:30:14</created>
		<closed>2018-01-04 15:28:20</closed>
	</bug>
	<bug>
		<id>910</id>
		<title>DB connector: SQL invoke with named parameter throws exception</title>
		<body>For the following integration ``` --- flows: - steps:   - kind: endpoint     uri: sql-start-connector-1     properties:       query: SELECT * FROM CONTACT       schedulerPeriod: "5000"   - kind: endpoint     uri: atlas:mapping-step-2.json   - kind: endpoint     uri: sql-connector-3     properties:       query: INSERT INTO TODO (task) VALUES (:#task) ```   ``` 2018-01-04 09:57:26.218 ERROR 1 --- [ector-component] o.a.camel.processor.DefaultErrorHandler  : Failed delivery for (MessageId: ID-crud1-read-update-e2e-6-v6zhg-1515059641988-0-164 on ExchangeId: ID-crud1-read-update-e2e-6-v6zhg-1515059641988-0-163). Exhausted after delivery attempt: 1 caught: org.apache.camel.RuntimeExchangeException: Cannot find key [task] in message body or headers to use when setting named parameter in query [INSERT INTO TODO (task) VALUES (:?task)] on the exchange: Exchange[ID-crud1-read-update-e2e-6-v6zhg-1515059641988-0-163]  Message History --------------------------------------------------------------------------------------------------------------------------------------- RouteId              ProcessorId          Processor                                                                        Elapsed (ms) [flow1             ] [flow1             ] [timer://sql-sql-start-connector-component?period=5000                         ] [        11] [flow1             ] [to1               ] [atlas:mapping-step-2.json                                                     ] [         1] [flow1             ] [to2               ] [sql-connector-3?query=INSERT+INTO+TODO+%28task%29+VALUES+%28%3A%23task%29     ] [         9]  Stacktrace ---------------------------------------------------------------------------------------------------------------------------------------  org.apache.camel.RuntimeExchangeException: Cannot find key [task] in message body or headers to use when setting named parameter in query [INSERT INTO TODO (task) VALUES (:?task)] on the exchange: Exchange[ID-crud1-read-update-e2e-6-v6zhg-1515059641988-0-163] at org.apache.camel.component.sql.DefaultSqlPrepareStatementStrategy$PopulateIterator.next(DefaultSqlPrepareStatementStrategy.java:280) ~[camel-sql-2.20.1.jar!/:2.20.1] at org.apache.camel.component.sql.DefaultSqlPrepareStatementStrategy.populateStatement(DefaultSqlPrepareStatementStrategy.java:130) ~[camel-sql-2.20.1.jar!/:2.20.1] at org.apache.camel.component.sql.SqlProducer$2.doInPreparedStatement(SqlProducer.java:146) ~[camel-sql-2.20.1.jar!/:2.20.1] at org.apache.camel.component.sql.SqlProducer$2.doInPreparedStatement(SqlProducer.java:116) ~[camel-sql-2.20.1.jar!/:2.20.1] at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:633) ~[spring-jdbc-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at org.apache.camel.component.sql.SqlProducer.process(SqlProducer.java:116) ~[camel-sql-2.20.1.jar!/:2.20.1] at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.component.connector.ConnectorProducer.process(ConnectorProducer.java:45) ~[camel-connector-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.MulticastProcessor.doProcessSequential(MulticastProcessor.java:701) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.MulticastProcessor.doProcessSequential(MulticastProcessor.java:624) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.MulticastProcessor.process(MulticastProcessor.java:248) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.Splitter.process(Splitter.java:114) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79) [camel-core-2.20.1.jar!/:2.20.1] at java.util.TimerThread.mainLoop(Timer.java:555) [na:1.8.0_141] at java.util.TimerThread.run(Timer.java:505) [na:1.8.0_141]  2018-01-04 09:57:26.219 ```</body>
		<created>2018-01-04 10:04:02</created>
		<closed>2018-01-04 22:37:05</closed>
	</bug>
	<bug>
		<id>909</id>
		<title>Integrations: Done button is disabled for Invoke Stored Procedure action</title>
		<body>`Invoke Stored Procedure` actions has only dropdown for procedure name parameter, hence there's no sql command input to validate the `Done` button is disable without any chance to proceed further.  &lt;img width="500" alt="screen shot 2018-01-04 at 10 09 46" src="https://user-images.githubusercontent.com/5637792/34556654-7c4d54e8-f137-11e7-83bc-c88c6bbbfa02.png"&gt; </body>
		<created>2018-01-04 09:11:21</created>
		<closed>2018-01-04 15:28:20</closed>
	</bug>
	<bug>
		<id>908</id>
		<title>Integrations: infinite loading loop when Twitter Mention action is selected </title>
		<body>When I'm trying to create integration with Twitter Mention action there's infinite loading loop without any particular error in `syndesis-rest` or browser console. Also the response for twitter-mention is returned correctly with HTTP 200 code.  But e.g. Twitter Search behaves normally and when selected the details form is displayed.   ``` {   "componentScheme": "twitter-timeline",   "connectorCustomizers": [],   "inputDataShape": {     "kind": "none"   },   "outputDataShape": {     "kind": "java",     "type": "twitter4j.Status"   },   "propertyDefinitionSteps": [],   "configuredProperties": {     "timelineType": "MENTIONS",     "delay": "30000"   } ```  ![screen shot 2018-01-04 at 09 58 58](https://user-images.githubusercontent.com/5637792/34556271-fa01ed10-f135-11e7-9ce1-04265d8b3cf8.png)           </body>
		<created>2018-01-04 08:58:45</created>
		<closed>2018-01-04 15:28:20</closed>
	</bug>
	<bug>
		<id>906</id>
		<title>Customizations: API client connectors list not loading</title>
		<body>In current version when accessing Customizations page the list of API client connectors keep loading with the following errors in browser console. As a side-effect it also breaks tab navigation to `Extensions` and redirects back to `/customizations/api-connector` instead of `/customizations/tech-extensions`.  @deeleman any thoughts?  ``` ERROR TypeError: Cannot read property 'getApiConnectorList' of undefined     at t.getEndpointUrl (main.6474b290bc5de004cd8e.bundle.js:1)     at t.setEndpointUrl (main.6474b290bc5de004cd8e.bundle.js:1)     at l.list (3.c456a70f57252b990640.chunk.js:1)     at l.ngOnInit (3.c456a70f57252b990640.chunk.js:1)     at Cn (vendor.7ec7098e6313e0e15893.bundle.js:1)     at dr (vendor.7ec7098e6313e0e15893.bundle.js:1)     at cr (vendor.7ec7098e6313e0e15893.bundle.js:1)     at jr (vendor.7ec7098e6313e0e15893.bundle.js:1)     at Object.updateDirectives (3.c456a70f57252b990640.chunk.js:1)     at Object.updateDirectives (vendor.7ec7098e6313e0e15893.bundle.js:1)     at ur (vendor.7ec7098e6313e0e15893.bundle.js:1)     at Cr (vendor.7ec7098e6313e0e15893.bundle.js:1)     at wr (vendor.7ec7098e6313e0e15893.bundle.js:1)     at ur (vendor.7ec7098e6313e0e15893.bundle.js:1)     at Cr (vendor.7ec7098e6313e0e15893.bundle.js:1) ```  ``` vendor.7ec7098e6313e0e15893.bundle.js:1 ERROR TypeError: Cannot read property 'do' of undefined     at n.ngOnInit (0.3fdb59d6235c75a872b5.chunk.js:1)     at Cn (vendor.7ec7098e6313e0e15893.bundle.js:1)     at dr (vendor.7ec7098e6313e0e15893.bundle.js:1)     at cr (vendor.7ec7098e6313e0e15893.bundle.js:1)     at jr (vendor.7ec7098e6313e0e15893.bundle.js:1)     at Object.updateDirectives (3.c456a70f57252b990640.chunk.js:1)     at Object.updateDirectives (vendor.7ec7098e6313e0e15893.bundle.js:1)     at ur (vendor.7ec7098e6313e0e15893.bundle.js:1)     at Cr (vendor.7ec7098e6313e0e15893.bundle.js:1)     at _r (vendor.7ec7098e6313e0e15893.bundle.js:1)     at ur (vendor.7ec7098e6313e0e15893.bundle.js:1)     at Cr (vendor.7ec7098e6313e0e15893.bundle.js:1)     at wr (vendor.7ec7098e6313e0e15893.bundle.js:1)     at ur (vendor.7ec7098e6313e0e15893.bundle.js:1)     at Cr (vendor.7ec7098e6313e0e15893.bundle.js:1) ```</body>
		<created>2018-01-04 08:39:53</created>
		<closed>2018-01-04 16:41:42</closed>
	</bug>
	<bug>
		<id>898</id>
		<title>Custom API Connector details endpoint must return an 'actionsSummary' property</title>
		<body>This is required for #272 and it currently a blocker that prevents us from finalizing this epic.  The UI application performs calls to `/connectors/{id}` in order to fetch the data graph required to render the custom API connector details page. The expected returning message should feature the same response model we get when validating swagger files when creating a new api connector, in order to preserve data consistency with the create wizard calls so the application can reuse the connector summary components.  More specifically, any custom connector based on a swagger file will feature an `actionsSummary` property with a `actionCountByTags` and `totalActions` nested properties. The closest we get from the aforementioned API call is a property named `summary` that does not feature such information either way and we will want to observe the same data model across the board anyways.  Definition of done: Refactor the `/connectors/{id}` endpoint to return a revamped response model where the `summary` property is renamed to `actionsSummary` (or vice versa) and contains the required `actionCountByTags` and `totalActions` properties.  [EDIT]: I just checked that the `/api/{version}/connectors?query=connectorGroupId%3D**{templateId}**` endpoint returns a cursor of API connectors featuring each one the same data scheme as the detail endpoint above. therefore we would need the aforementioned changes to be featured in the output of this endpoint as well.    </body>
		<created>2018-01-03 18:47:30</created>
		<closed>2018-01-09 13:55:14</closed>
	</bug>
	<bug>
		<id>889</id>
		<title>AMQ: `Client ID` on connection prevents reuse of same JMS connection in integration </title>
		<body>Hi @dhirajsb, I wonder if moving `Client ID` property to create connection flow is a good idea from a usability standpoint. Currently I can't create e.g. `topic -&gt; queue` integration on a same AMQ connection because, client ID gets propagated to both endpoints and exception is thrown.  ``` flows: - steps:   - kind: endpoint     uri: activemq-subscribe-1     properties:       destinationName: cheese       destinationType: topic       durableSubscriptionId: syndesis-client       messageSelector: exampleSelector   - kind: endpoint     uri: activemq-publish-2     properties:       destinationName: food       destinationType: queue       persistent: "false" ```  application.properties ``` activemq-subscribe.configurations.activemq-subscribe-1.clientID=syndesis-client activemq-publish.configurations.activemq-publish-2.clientID=syndesis-client ```  ```  2018-01-03 11:05:43.936 ERROR 1 --- [           main] o.a.camel.component.sjms.SjmsConsumer    : Unable to create the MessageConsumer --  |   | javax.jms.JMSException: You cannot create a durable subscriber without specifying a unique clientID on a Connection   ```  What is the difference between `Client ID` defined on Connection directly versus `Durable Subscription ID` provided configuring `Subscribe for messages` action?   `Durable Subscription ID`seems to have no effect (prorably better to create a separate issue for it?).  Cc @jimmidyson fyi.          </body>
		<created>2018-01-03 11:14:37</created>
		<closed>2018-03-06 13:57:14</closed>
	</bug>
	<bug>
		<id>846</id>
		<title>Error while re-deploy an integration </title>
		<body>When an integration is modified and redeployed I see the following errors:  ``` Receiving source from STDIN as archive ... Pulling image "172.30.1.1:5000/syndesis/mentions2todo:latest" ... tar: artifacts/m2/aopalliance/aopalliance/1.0: Cannot utime: Operation not permitted tar: artifacts/m2/aopalliance/aopalliance/1.0: Cannot change mode to rwx------: Operation not permitted tar: artifacts/m2/aopalliance/aopalliance: Cannot utime: Operation not permitted tar: artifacts/m2/aopalliance/aopalliance: Cannot change mode to rwx------: Operation not permitted tar: artifacts/m2/aopalliance: Cannot utime: Operation not permitted tar: artifacts/m2/aopalliance: Cannot change mode to rwx------: Operation not permitted tar: artifacts/m2/asm/asm/3.2: Cannot utime: Operation not permitted tar: artifacts/m2/asm/asm/3.2: Cannot change mode to rwx------: Operation not permitted tar: artifacts/m2/asm/asm/3.3.1: Cannot utime: Operation not permitted tar: artifacts/m2/asm/asm/3.3.1: Cannot change mode to rwx------: Operation not permitted tar: artifacts/m2/asm/asm: Cannot utime: Operation not permitted tar: artifacts/m2/asm/asm: Cannot change mode to rwx------: Operation not permitted tar: artifacts/m2/asm/asm-analysis/3.2: Cannot utime: Operation not permitted tar: artifacts/m2/asm/asm-analysis/3.2: Cannot change mode to rwx------: Operation not permitted tar: artifacts/m2/asm/asm-analysis: Cannot utime: Operation not permitted tar: artifacts/m2/asm/asm-analysis: Cannot change mode to rwx------: Operation not permitted tar: artifacts/m2/asm/asm-commons/3.2: Cannot utime: Operation not permitted tar: artifacts/m2/asm/asm-commons/3.2: Cannot change mode to rwx------: Operation not permitted tar: artifacts/m2/asm/asm-commons/3.3.1: Cannot utime: Operation not permitted tar: artifacts/m2/asm/asm-commons/3.3.1: Cannot change mode to rwx------: Operation not permitted tar: artifacts/m2/asm/asm-commons: Cannot utime: Operation not permitted tar: artifacts/m2/asm/asm-commons: Cannot change mode to rwx------: Operation not permitted tar: artifacts/m2/asm/asm-parent/3.2: Cannot utime: Operation not permitted tar: artifacts/m2/asm/asm-parent/3.2: Cannot change mode to rwx------: Operation not permitted tar: artifacts/m2/asm/asm-parent/3.3.1: Cannot utime: Operation not permitted ... tar: Exiting with failure status due to previous errors error: build error: non-zero (13) exit code from syndesis/syndesis-s2i@sha256:6fe3a0a821a98e9c2430e9a0ce5fccfddafa0ec5faa50ad14e191161be81f613 ```  Then the new integration is not properly re-deployed as i.e. an outdated syndesis-s2i is downloaded but UI shows it as running. </body>
		<created>2017-12-20 13:39:28</created>
		<closed>2017-12-20 16:59:13</closed>
	</bug>
	<bug>
		<id>835</id>
		<title>Guided Tour Toggle &amp; FTU Only</title>
		<body>It disappeared. I remember there was discussion of it always appearing even if you are not a first time user, but I must have missed the memo about it getting disabled completely for now. We need to resolve this by using a flag that determines whether the user is truly a first time user or not (unless that's already in place?).</body>
		<created>2017-12-19 16:37:32</created>
		<closed>2018-01-29 16:27:45</closed>
	</bug>
	<bug>
		<id>824</id>
		<title>Reorder depedency for `--backend` switch</title>
		<body>@lburgazzoli related to #765 I think this need to be also reordered to `runtime connectors rest verifier`. https://github.com/syndesisio/syndesis/blob/de6f0b53fce240062c7f2a12505ffa985c3cfbaa/tools/bin/commands/build#L120-L122 </body>
		<created>2017-12-19 12:14:52</created>
		<closed>2017-12-19 12:38:17</closed>
	</bug>
	<bug>
		<id>813</id>
		<title>Tech extensions: clicking Cancel on Update page should go to List page</title>
		<body>When I have `Update` page of existing extension opened and hit `Cancel` then `Import` page is displayed. It's a bit strange behaviour. Imho it'd be better to go back to `List`.</body>
		<created>2017-12-18 07:57:37</created>
		<closed>2017-12-21 13:07:58</closed>
	</bug>
	<bug>
		<id>812</id>
		<title>Tech extensions: update page displays internal ID</title>
		<body>Should we display ID of tech ext. in such a format?  ![screen shot 2017-12-18 at 08 39 15](https://user-images.githubusercontent.com/5637792/34094805-114646c0-e3cf-11e7-8b51-650a41a9ae56.png) </body>
		<created>2017-12-18 07:48:46</created>
		<closed>2018-01-03 18:12:40</closed>
	</bug>
	<bug>
		<id>807</id>
		<title>Typo in title of panel</title>
		<body>In the Customize area, when the "API Client Connectors" tab is selected, the title of the panel is "API Client Connector". That title is missing the final "s" (it should be plural, and match the tab). Low priority item, but reflects poorly on overall quality. Thanks. &lt;img width="269" alt="titletypo" src="https://user-images.githubusercontent.com/31700119/34053471-fdd851fa-e194-11e7-8cb9-1c0c76f5c57e.png"&gt; </body>
		<created>2017-12-15 17:39:34</created>
		<closed>2018-01-05 09:36:54</closed>
	</bug>
	<bug>
		<id>792</id>
		<title>Integration with periodic invoke SQL logs mapper warning</title>
		<body>For such an integration with [mapping](https://gist.github.com/dsimansk/076afc0bdee3e53f8980d7dc6fb61d28). The integration itself seems to be working fine. Therefor it's rather cosmetic issue I guess.  Cc @KurtStam   ``` --- flows: - steps:   - kind: endpoint     uri: sql-start-connector:SELECT * FROM CONTACT?schedulerPeriod=5000   - kind: endpoint     uri: atlas:mapping-step-2.json   - kind: endpoint     uri: sql-stored-connector:add_lead(VARCHAR ${body[first_and_last_name]}, VARCHAR ${body[company]}, VARCHAR ${body[phone]}, VARCHAR ${body[email]}, VARCHAR ${body[lead_source]}, VARCHAR ${body[lead_status]}, VARCHAR ${body[rating]}) ```  Log warning: ``` 2017-12-15 12:13:03.620  WARN 1 --- [ector-component] o.a.c.component.atlasmap.AtlasEndpoint   : There's no source document with docId='SQL_PARAM_OUT', returning default: docId='null', path='null' ```    </body>
		<created>2017-12-15 12:16:02</created>
		<closed>2018-01-02 17:01:34</closed>
	</bug>
	<bug>
		<id>791</id>
		<title>Invoke SQL on start position throws mapping error</title>
		<body>When I try simple SQL integration, there is a mapping exception thrown. The same integration works fine with `Periodic Invoke SQL`.  Cc @KurtStam   ``` --- flows: - steps:   - kind: endpoint     uri: sql-connector:SELECT * FROM CONTACT   - kind: endpoint     uri: atlas:mapping-step-2.json   - kind: endpoint     uri: sql-stored-connector:add_lead(VARCHAR ${body[first_and_last_name]}, VARCHAR ${body[company]}, VARCHAR ${body[phone]}, VARCHAR ${body[email]}, VARCHAR ${body[lead_source]}, VARCHAR ${body[lead_status]}, VARCHAR ${body[rating]})  ```  ``` 017-12-15 11:02:13.870 ERROR 1 --- [0FROM%20CONTACT] o.a.camel.processor.DefaultErrorHandler  : Failed delivery for (MessageId: ID-db-to-db-2-b62q7-1513335506727-0-848 on ExchangeId: ID-db-to-db-2-b62q7-1513335506727-0-847). Exhausted after delivery attempt: 1 caught: io.atlasmap.api.AtlasException: Incompatible Source Document '{first_name=Joe, last_name=Jackson, company=Red Hat, lead_source=db, create_date=2017-12-13}'  Message History --------------------------------------------------------------------------------------------------------------------------------------- RouteId              ProcessorId          Processor                                                                        Elapsed (ms) [flow1             ] [flow1             ] [sql-sql-connector-component://SELECT%20*%20FROM%20CONTACT                     ] [         1] [flow1             ] [to1               ] [atlas:mapping-step-2.json                                                     ] [         0]  Stacktrace ---------------------------------------------------------------------------------------------------------------------------------------  io.atlasmap.api.AtlasException: Incompatible Source Document '{first_name=Joe, last_name=Jackson, company=Red Hat, lead_source=db, create_date=2017-12-13}' at io.atlasmap.json.module.JsonModule.processPreSourceExecution(JsonModule.java:81) ~[atlas-json-module-1.32.1.jar!/:1.32.1] at io.atlasmap.core.DefaultAtlasContext.process(DefaultAtlasContext.java:235) ~[atlas-core-1.32.1.jar!/:1.32.1] at org.apache.camel.component.atlasmap.AtlasEndpoint.onExchange(AtlasEndpoint.java:222) ~[camel-atlasmap-1.32.1.jar!/:na] at org.apache.camel.impl.ProcessorEndpoint$1.process(ProcessorEndpoint.java:71) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ~[camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.util.AsyncProcessorHelper.process(AsyncProcessorHelper.java:109) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.processor.Pipeline.process(Pipeline.java:80) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.component.sql.SqlConsumer.processBatch(SqlConsumer.java:233) [camel-sql-2.20.1.jar!/:2.20.1] at org.apache.camel.component.sql.SqlConsumer$1.doInPreparedStatement(SqlConsumer.java:153) [camel-sql-2.20.1.jar!/:2.20.1] at org.apache.camel.component.sql.SqlConsumer$1.doInPreparedStatement(SqlConsumer.java:112) [camel-sql-2.20.1.jar!/:2.20.1] at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:633) [spring-jdbc-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:662) [spring-jdbc-4.3.12.RELEASE.jar!/:4.3.12.RELEASE] at org.apache.camel.component.sql.SqlConsumer.poll(SqlConsumer.java:168) [camel-sql-2.20.1.jar!/:2.20.1] at org.apache.camel.impl.ScheduledPollConsumer.doRun(ScheduledPollConsumer.java:174) [camel-core-2.20.1.jar!/:2.20.1] at org.apache.camel.impl.ScheduledPollConsumer.run(ScheduledPollConsumer.java:101) [camel-core-2.20.1.jar!/:2.20.1] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_141] at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [na:1.8.0_141] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [na:1.8.0_141] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [na:1.8.0_141] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_141] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_141] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_141] ```</body>
		<created>2017-12-15 11:13:56</created>
		<closed>2017-12-21 02:21:59</closed>
	</bug>
	<bug>
		<id>767</id>
		<title>Env provisioning fails with a rate of 25% on some systems</title>
		<body>Some of our pods depend on other to be fully functional. An example of this is `syndesis-rest` that depends on `syndesis-db` and `syndesis-verifier`</body>
		<created>2017-12-14 16:57:34</created>
		<closed>2018-04-27 14:28:03</closed>
	</bug>
	<bug>
		<id>761</id>
		<title>Unable to build integration pod</title>
		<body>I created minishift instance with OpenShift 3.7.0 using:      syndesis minishift --full-reset --install -p syndesis -i docker --openshift-version 3.7.0  When I publish a integration via the UI a build gets scheduled and ends with error.  [buildpod.log](https://github.com/syndesisio/syndesis/files/1559449/buildpod.log) </body>
		<created>2017-12-14 14:05:28</created>
		<closed>2017-12-21 11:48:52</closed>
	</bug>
	<bug>
		<id>757</id>
		<title>SQL connectors declare scheduler options as endpointOptions</title>
		<body>`endpointOptions` property in `camel-connector.json` is reserved for properties that are passed to the delegated component, we cannot place scheduler options there as they would be passed to the delegate when delegate endpoint is created, this will lead to errors if the delegate component is not lenient about endpoint properties.</body>
		<created>2017-12-14 12:38:03</created>
		<closed>2017-12-14 15:27:07</closed>
	</bug>
	<bug>
		<id>755</id>
		<title>Tech extension: can't retry a failed upload</title>
		<body>In case of error while uploading an extension i.e. the extension do not have the required metadata, the UI gets stuck to the upload page but it is not possible to retry to upload the extension again as the upload button does not show the file chooser any more.</body>
		<created>2017-12-14 12:16:43</created>
		<closed>2018-03-19 10:38:50</closed>
	</bug>
	<bug>
		<id>754</id>
		<title>Tech extension: Importing extension without metadata produces wrong error </title>
		<body>When importing an extension that does not have meta data, the error reported by the beck-end is wrong:      Please check your sorting arguments  The received error is:  ```json {     "errorCode":400,     "userMsg":"Please check your sorting arguments",     "developerMsg":"Illegal Argument on Call Cannot find manifest file (META-INF/syndesis/syndesis-extension-definition.json) inside JAR" } ```</body>
		<created>2017-12-14 10:09:18</created>
		<closed>2017-12-14 12:43:25</closed>
	</bug>
	<bug>
		<id>739</id>
		<title>Tech extension: Importing extension even when click on cancel button</title>
		<body>After uploading tech extension file, on "Review Details and Confirm Import" view, Tech extension is imported even when you click on cancel button.</body>
		<created>2017-12-13 10:01:59</created>
		<closed>2017-12-14 12:43:25</closed>
	</bug>
	<bug>
		<id>733</id>
		<title>Dashboard: kebab menu in Top 5 Integration table is not working</title>
		<body>When clicking on any action nothing happens. It seems that actions aren't initialized as links in HTML code properly.  ![screen shot 2017-12-13 at 09 01 18](https://user-images.githubusercontent.com/5637792/33928062-c4159b50-dfe4-11e7-8119-9b9dfb873e02.png)    </body>
		<created>2017-12-13 08:06:21</created>
		<closed>2017-12-28 09:13:47</closed>
	</bug>
	<bug>
		<id>732</id>
		<title>Rest can't create BC after kubernetes-client upgrade</title>
		<body>Dragons have been deployed upon us.  @paoloantinori you might want to look at this one. Caused by https://github.com/syndesisio/syndesis/pull/711.  ```  2017-12-13 07:48:08.692 ERROR [-,,,] 1 --- [pool-3-thread-1] i.s.c.integration.IntegrationController  : Error while processing integration status for integration -L0Dq4Dr3bq905vqX1_Y --  |   | io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: GET at: https://openshift.default.svc/apis/build.openshift.io/v1/namespaces/syndesis/builds?labelSelector=openshift.io/build-config.name%3Ddb-int&amp;fieldSelector=status%3DRunning. Message: No field label conversion function found for version: build.openshift.io/v1. Received status: Status(apiVersion=v1, code=400, details=null, kind=Status, message=No field label conversion function found for version: build.openshift.io/v1, metadata=ListMeta(resourceVersion=null, selfLink=null, additionalProperties={}), reason=BadRequest, status=Failure, additionalProperties={}).  | at io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:470) ~[kubernetes-client-3.1.1.jar!/:na]  | at io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:409) ~[kubernetes-client-3.1.1.jar!/:na]  | at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:379) ~[kubernetes-client-3.1.1.jar!/:na]  | at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:343) ~[kubernetes-client-3.1.1.jar!/:na]  | at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:327) ~[kubernetes-client-3.1.1.jar!/:na]  | at io.fabric8.kubernetes.client.dsl.base.BaseOperation.list(BaseOperation.java:605) ~[kubernetes-client-3.1.1.jar!/:na]  | at io.fabric8.kubernetes.client.dsl.base.BaseOperation.list(BaseOperation.java:70) ~[kubernetes-client-3.1.1.jar!/:na]  | at io.syndesis.openshift.OpenShiftServiceImpl.isBuildStarted(OpenShiftServiceImpl.java:143) ~[openshift-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT]  | at io.syndesis.controllers.integration.online.ActivateHandler.isBuildStarted(ActivateHandler.java:151) ~[controllers-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT]  | at io.syndesis.controllers.integration.online.ActivateHandler.execute(ActivateHandler.java:93) ~[controllers-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT]  | at io.syndesis.controllers.integration.IntegrationController.lambda$callStatusChangeHandler$10(IntegrationController.java:175) ~[controllers-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT]  | at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_131]  | at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_131]  | at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]   ```</body>
		<created>2017-12-13 07:51:55</created>
		<closed>2017-12-20 15:35:37</closed>
	</bug>
	<bug>
		<id>729</id>
		<title>Set `connectorGroupId` along with `connectorGroup` in SwaggerConnectorGenerator</title>
		<body>We're setting `connectorGroup` on the newly generated custom Connector, but not the `connectorGroupId`. We're filtering by `connectorGroupId` and it should be set also.</body>
		<created>2017-12-12 22:09:40</created>
		<closed>2017-12-12 22:38:15</closed>
	</bug>
	<bug>
		<id>724</id>
		<title>Filtering list results from API ignores values with `-` character</title>
		<body>When specifying query: `query=connectorGroupId%3Dswagger-connector-template` the `FilterOptionsParser`s `VALID_QUERY_PATTERN` doesn't match so there is no filtering performed. </body>
		<created>2017-12-12 20:21:32</created>
		<closed>2017-12-12 20:49:56</closed>
	</bug>
	<bug>
		<id>718</id>
		<title>Action Configure: Exception Handling</title>
		<body>Exception handling in the UI for the DB connector on save.  ![Exception Handling](https://github.com/syndesisio/syndesis/raw/cac32465b92d780a3f0440c5b542b1ece489ae99/ux/designs/databaseconnection/img/errors.png)  Full designs [here](https://github.com/syndesisio/syndesis/blob/cac32465b92d780a3f0440c5b542b1ece489ae99/ux/designs/databaseconnection/databaseconnection.md#create-an-integration-with-database-as-a-start-connection).  cc @KurtStam </body>
		<created>2017-12-12 18:16:39</created>
		<closed>2018-01-03 03:26:05</closed>
	</bug>
	<bug>
		<id>698</id>
		<title>DB Connector: SQL parser doesn't recognize parameters for LIKE</title>
		<body>e.g.  this is ok: ``` DELETE FROM TODO WHERE task = :#task ```  but datamapper cannot recognize these parameters: ``` DELETE FROM TODO WHERE task LIKE ':#task' DELETE FROM TODO WHERE task LIKE '%:#task%' ```</body>
		<created>2017-12-11 17:07:15</created>
		<closed>2018-10-08 11:46:51</closed>
	</bug>
	<bug>
		<id>673</id>
		<title>Rename ID for DB connector</title>
		<body>In Create Connection wizard, otherwise the Validate button doesn't show up.</body>
		<created>2017-12-08 15:46:05</created>
		<closed>2017-12-08 16:15:32</closed>
	</bug>
	<bug>
		<id>669</id>
		<title>integration with DB connection fails to deploy</title>
		<body>If I create integration with DB connections  (example, according to: https://drive.google.com/file/d/1eNO13gB4Q5i13SxkC1MFM8AT9vRxLIZm/view or https://drive.google.com/file/d/1A6LgMd4Y8SvYw_pjvE4GqlJpGVlZTto2/view)  Integration do not reach 'Active' status (status 'In progress' persists).  oc get pods: ``` skusobnaintegra-1-build       0/1       Completed          0          3m skusobnaintegra-2-vpt3j       0/1       CrashLoopBackOff   4          2m ```   oc logs skusobnaintegra-1-build: ``` Receiving source from STDIN as archive ... Pulling image "172.30.1.1:5000/syndesis-project-r/skusobnaintegra:latest" ... pulling image error : Error: image syndesis-project-r/skusobnaintegra:latest not found  Starting S2I Java Build ..... S2I source build with plain binaries detected Copying binaries from /tmp/src to /deployments ... Checking for SpringBoot archive... ... done   Pushing image 172.30.1.1:5000/syndesis-project-r/skusobnaintegra:latest ... Pushed 0/26 layers, 0% complete Pushed 1/26 layers, 4% complete Push successful ```   oc logs skusobnaintegra-2-vpt3j: ``` ERROR: Neither $JAVA_MAIN_CLASS nor $JAVA_APP_JAR is set and 0 found in /deployments (1 expected) ``` </body>
		<created>2017-12-08 12:30:56</created>
		<closed>2017-12-19 15:51:25</closed>
	</bug>
	<bug>
		<id>668</id>
		<title>Sf-&gt;DB integration "Invalid Operation syndesis_Lead_create"</title>
		<body>The Sf-&gt;DB integration is not working. I followed the [SF-&gt;DB documentation](https://access.redhat.com/documentation/en-us/red_hat_jboss_fuse/7.0-tp/html-single/fuse_ignite_sample_integration_tutorial/) and created the integration. After I try to create new Lead in SF, the following error occured:   ```Caused by: org.apache.camel.FailedToCreateProducerException: Failed to create Producer for endpoint: salesforce-on-create-component://getSObject?rawPayload=true&amp;sObjectName=Lead. Reason: java.lang.IllegalArgumentException: Invalid Operation syndesis_Lead_create```  Full integration log attached: [integration.log](https://github.com/syndesisio/syndesis/files/1542537/integration.log) </body>
		<created>2017-12-08 12:00:15</created>
		<closed>2017-12-19 13:40:04</closed>
	</bug>
	<bug>
		<id>635</id>
		<title>Class inspection for twitter4j.Status not found </title>
		<body>@rhuss @zregvart is it possible that inspection wasn't generated for latest image?  ``` {   "ClassInspectionRequest": {     "jsonType": "io.atlasmap.java.v2.ClassInspectionRequest",     "classpath": "",     "className": "twitter4j.Status",     "disablePrivateOnlyFields": false,     "disableProtectedOnlyFields": false,     "disablePublicOnlyFields": false,     "disablePublicGetterSetterFields": false   } } ```  ``` {   "ClassInspectionResponse" : {     "jsonType" : "io.atlasmap.java.v2.ClassInspectionResponse",     "javaClass" : {       "jsonType" : "io.atlasmap.java.v2.JavaClass",       "status" : "NOT_FOUND",       "className" : "twitter4j.Status",       "javaEnumFields" : {         "javaEnumField" : [ ]       },       "javaFields" : {         "javaField" : [ ]       }     },     "executionTime" : 0   } } ```</body>
		<created>2017-12-06 15:16:49</created>
		<closed>2018-01-04 13:56:49</closed>
	</bug>
	<bug>
		<id>631</id>
		<title>Swagger connector generator generates wrong host connector parameter</title>
		<body>In Swagger connector generator we use the `host` parameter from the Swagger specification, we should also consider `schemes` property and generate the URL as the underlying REST Swagger Camel component.</body>
		<created>2017-12-06 14:23:24</created>
		<closed>2017-12-08 11:34:12</closed>
	</bug>
	<bug>
		<id>629</id>
		<title>Imported integration should be created after modal submission</title>
		<body>Currently when importing zip file, the Integration is created right after finishing of upload process.  It's a bit confusing to have `OK` and `Cancel` button that doesn't have impact on the import process.  ![screen shot 2017-12-06 at 13 33 52](https://user-images.githubusercontent.com/5637792/33661932-355933f4-da8a-11e7-8526-66f65516a5d7.png) </body>
		<created>2017-12-06 12:36:42</created>
		<closed>2018-01-08 15:19:24</closed>
	</bug>
	<bug>
		<id>625</id>
		<title>Integration turns "Active" although it fails on OpenShift to startup</title>
		<body>Due to an error in the SQL connector, an integration did startup properly, so that the pod got restarted three times until going into CrashLoopback. However, for Syndesis this integration went "Active" for some reason.</body>
		<created>2017-12-06 09:31:44</created>
		<closed>2017-12-21 17:22:51</closed>
	</bug>
	<bug>
		<id>624</id>
		<title>Wrong label for SQL Query</title>
		<body>As the input for the SQL connector (action: "Invoke SQL") can be actually any SQL, the label "Query" is misleading  ![image](https://user-images.githubusercontent.com/99080/33653554-b55a136a-da6d-11e7-89f5-ad96989bfe36.png) </body>
		<created>2017-12-06 09:11:06</created>
		<closed>2017-12-13 16:12:04</closed>
	</bug>
	<bug>
		<id>622</id>
		<title>ActiveMQ connection verifier doesn't honour provided values</title>
		<body>Regardless of provided values for Connection, the validation is always successful.  ![screen shot 2017-12-06 at 09 48 05](https://user-images.githubusercontent.com/5637792/33652754-d4df5cf2-da6a-11e7-9ff7-642d4579395c.png)   Verifier log: ``` 2017-12-06 08:49:24.410  WARN 1 --- [ XNIO-2 task-22] o.apache.activemq.broker.BrokerService   : Memory Usage for the Broker (1024mb) is more than the maximum available for the JVM: 228 mb - resetting to 70% of maximum available: 159 mb 2017-12-06 08:49:24.415  INFO 1 --- [ XNIO-2 task-22] o.apache.activemq.broker.BrokerService   : Using Persistence Adapter: MemoryPersistenceAdapter 2017-12-06 08:49:24.415  INFO 1 --- [ XNIO-2 task-22] o.apache.activemq.broker.BrokerService   : Apache ActiveMQ 5.15.2 (localhost, ID:syndesis-verifier-1-9hgqn-40167-1512545194998-0:498) is starting 2017-12-06 08:49:24.416  INFO 1 --- [  JMX connector] o.a.a.broker.jmx.ManagementContext       : JMX consoles can connect to service:jmx:rmi:///jndi/rmi://localhost:1099/jmxrmi 2017-12-06 08:49:24.416  INFO 1 --- [ XNIO-2 task-22] o.apache.activemq.broker.BrokerService   : Apache ActiveMQ 5.15.2 (localhost, ID:syndesis-verifier-1-9hgqn-40167-1512545194998-0:498) started 2017-12-06 08:49:24.416  WARN 1 --- [ XNIO-2 task-22] o.apache.activemq.broker.BrokerService   : Temporary Store limit is 51200 mb (current store usage is 0 mb). The data directory: /deployments only has 2590 mb of usable space. - resetting to maximum available disk space: 2590 mb 2017-12-06 08:49:24.417  INFO 1 --- [ XNIO-2 task-22] o.a.activemq.broker.TransportConnector   : Connector vm://localhost started 2017-12-06 08:49:24.426  INFO 1 --- [ XNIO-2 task-22] o.a.activemq.broker.TransportConnector   : Connector vm://localhost stopped 2017-12-06 08:49:24.426  INFO 1 --- [ XNIO-2 task-22] o.apache.activemq.broker.BrokerService   : Apache ActiveMQ 5.15.2 (localhost, ID:syndesis-verifier-1-9hgqn-40167-1512545194998-0:498) is shutting down 2017-12-06 08:49:24.427  INFO 1 --- [ XNIO-2 task-22] o.apache.activemq.broker.BrokerService   : Apache ActiveMQ 5.15.2 (localhost, ID:syndesis-verifier-1-9hgqn-40167-1512545194998-0:498) uptime 0.017 seconds 2017-12-06 08:49:24.427  INFO 1 --- [ XNIO-2 task-22] o.apache.activemq.broker.BrokerService   : Apache ActiveMQ 5.15.2 (localhost, ID:syndesis-verifier-1-9hgqn-40167-1512545194998-0:498) is shutdown ``` </body>
		<created>2017-12-06 08:51:24</created>
		<closed>2017-12-07 22:40:30</closed>
	</bug>
	<bug>
		<id>608</id>
		<title>Update mvnw to 3.5.2</title>
		<body>as 3.5.0 has timestamp issue when deploying snapshots.</body>
		<created>2017-12-05 11:20:16</created>
		<closed>2017-12-06 08:44:53</closed>
	</bug>
	<bug>
		<id>596</id>
		<title>Anothe SQL Test Error</title>
		<body>See https://963-105563335-gh.circle-artifacts.com/0/workspace/test_log.txt :   ``` component://SELECT%20\*%20FROM%20NAME%20ORDER%20BY%20id" 06:33:17.862 [main           ] DEBUG agement.DefaultManagementAgent - Unregistered MBean with ObjectName: org.apache.camel:context=camel-2,type=endpoints,name="sql-start-connector://SELECT%20\*%20FROM%20NAME%20ORDER%20BY%20id" 06:33:17.862 [ector-component] WARN  .component.timer.TimerConsumer - Error processing exchange. Exchange[ID-7bcd0c95b122-1512455587207-1-1]. Caused by: [java.util.concurrent.RejectedExecutionException - null] java.util.concurrent.RejectedExecutionException: null at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:435) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.component.timer.TimerConsumer.sendTimerExchange(TimerConsumer.java:197) at org.apache.camel.component.timer.TimerConsumer$1.run(TimerConsumer.java:79) at java.util.TimerThread.mainLoop(Timer.java:555) at java.util.TimerThread.run(Timer.java:505) 06:33:17.863 [main           ] DEBUG agement.DefaultManagementAgent - Unregistered MBean with ObjectName: org.apache.camel:context=camel-2,type=services,name=DefaultRestRegistry 06:33:17.866 [main           ] DEBUG agement.DefaultManagementAgent - Unregistered MBean with ObjectName: org.apache.camel:context=camel-2,type=services,name=DefaultEndpointRegistry 06:33:17.867 [main           ] DEBUG agement.DefaultManagementAgent - Unregistered MBean with ObjectName: org.apache.camel:context=camel-2,type=components,name="timer" 06:33:17.868 [main           ] DEBUG agement.DefaultManagementAgent - Unregistered MBean with ObjectName: org.apache.camel:context=camel-2,type=endpoints,name="timer://sql-sql-start-connector-component\?period=1000" 06:33:17.869 [main           ] DEBUG agement.DefaultManagementAgent - Unregistered MBean with ObjectName: org.apache.camel:context=camel-2,type=services,name=DefaultTransformerRegistry 06:33:17.870 [main           ] DEBUG agement.DefaultManagementAgent - Unregistered MBean with ObjectName: org.apache.camel:context=camel-2,type=services,name=DefaultAsyncProcessorAwaitManager 06:33:17.871 [main           ] DEBUG agement.DefaultManagementAgent - Unregistered MBean with ObjectName: org.apache.camel:context=camel-2,type=services,name=DefaultValidatorRegistry 06:33:17.872 [main           ] DEBUG agement.DefaultManagementAgent - Unregistered MBean with ObjectName: org.apache.camel:context=camel-2,type=processors,name="to3" 06:33:17.874 [main           ] DEBUG agement.DefaultManagementAgent - Unregistered MBean with ObjectName: org.apache.camel:context=camel-2,type=services,name=DefaultTypeConverter 06:33:17.875 [main           ] DEBUG agement.DefaultManagementAgent - Unregistered MBean with ObjectName: org.apache.camel:context=camel-2,type=tracer,name=BacklogDebugger 06:33:17.876 [main           ] DEBUG agement.DefaultManagementAgent - Unregistered MBean with ObjectName: org.apache.camel:context=camel-2,type=components,name="stream" 06:33:17.877 [main           ] DEBUG agement.DefaultManagementAgent - Unregistered MBean with ObjectName: org.apache.camel:context=camel-2,type=services,name=DefaultInflightRepository 06:33:17.877 [main           ] DEBUG .management.MBeanInfoAssembler - Clearing cache[size=24, hits=10, misses=24, evicted=0] 06:33:17.882 [main           ] DEBUG amel.util.IntrospectionSupport - Clearing cache[size=74, hits=101, misses=74, evicted=1] 06:33:17.886 [main           ] INFO  camel.impl.DefaultCamelContext - Apache Camel 2.20.1 (CamelContext: camel-2) uptime 7.600 seconds 06:33:17.887 [main           ] INFO  camel.impl.DefaultCamelContext - Apache Camel 2.20.1 (CamelContext: camel-2) is shutdown in 2.478 seconds Tests run: 2, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 12.983 sec &lt;&lt;&lt; FAILURE! - in io.syndesis.connector.sql.SqlStartConnectorComponentTest camelConnectorTest(io.syndesis.connector.sql.SqlStartConnectorComponentTest)  Time elapsed: 7.68 sec  &lt;&lt;&lt; FAILURE! java.lang.AssertionError: expected:&lt;[{"LASTNAME":"Jackson","FIRSTNAME":"Joe","ID":1},{"LASTNAME":"Waters","FIRSTNAME":"Roger","ID":2}]&gt; but was:&lt;null&gt; at org.junit.Assert.fail(Assert.java:88) at org.junit.Assert.failNotEquals(Assert.java:834) at org.junit.Assert.assertEquals(Assert.java:118) at org.junit.Assert.assertEquals(Assert.java:144) at io.syndesis.connector.sql.SqlStartConnectorComponentTest.camelConnectorTest(SqlStartConnectorComponentTest.java:107) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:367) at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:274) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:161) at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:290) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:242) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:121)   Results :  Failed tests:    SqlStartConnectorComponentTest.camelConnectorTest:107 expected:&lt;[{"LASTNAME":"Jackson","FIRSTNAME":"Joe","ID":1},{"LASTNAME":"Waters","FIRSTNAME":"Roger","ID":2}]&gt; but was:&lt;null&gt; ```</body>
		<created>2017-12-05 06:38:59</created>
		<closed>2017-12-05 14:50:37</closed>
	</bug>
	<bug>
		<id>592</id>
		<title>Flaky SQL test</title>
		<body>There is a flaky SQL test https://ci.fabric8.io/blue/organizations/jenkins/syndesis-pullreq/detail/PR-586/2/pipeline   ``` 18:44:51.494 [main           ] DEBUG amel.util.IntrospectionSupport - Clearing cache[size=76, hits=91, misses=76, evicted=48] 18:44:51.495 [main           ] INFO  camel.impl.DefaultCamelContext - Apache Camel 2.20.1 (CamelContext: camel-2) uptime 1.297 seconds 18:44:51.495 [main           ] INFO  camel.impl.DefaultCamelContext - Apache Camel 2.20.1 (CamelContext: camel-2) is shutdown in 0.043 seconds Tests run: 2, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 6.315 sec &lt;&lt;&lt; FAILURE! - in io.syndesis.connector.sql.SqlConnectorComponentTest camelConnectorTest(io.syndesis.connector.sql.SqlConnectorComponentTest)  Time elapsed: 1.361 sec  &lt;&lt;&lt; FAILURE! org.junit.ComparisonFailure: expected:&lt;{ID=[1, FIRSTNAME=Joe, LASTNAME=Jackson]}&gt; but was:&lt;{ID=[2, FIRSTNAME=Roger, LASTNAME=Waters]}&gt; at org.junit.Assert.assertEquals(Assert.java:115) at org.junit.Assert.assertEquals(Assert.java:144) at io.syndesis.connector.sql.SqlConnectorComponentTest.camelConnectorTest(SqlConnectorComponentTest.java:108) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:367) at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:274) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:161) at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:290) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:242) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:121)   Results :  Failed tests:    SqlConnectorComponentTest.camelConnectorTest:108 expected:&lt;{ID=[1, FIRSTNAME=Joe, LASTNAME=Jackson]}&gt; but was:&lt;{ID=[2, FIRSTNAME=Roger, LASTNAME=Waters]}&gt;  Tests run: 2, Failures: 1, Errors: 0, Skipped: 0  ```</body>
		<created>2017-12-04 19:44:20</created>
		<closed>2017-12-05 14:52:51</closed>
	</bug>
	<bug>
		<id>580</id>
		<title>NPE when trying to create connection for OAuth based API connector</title>
		<body>For API connector generated from petstore Swagger.  ``` java.lang.NullPointerException: null at io.syndesis.credential.CredentialProviderRegistry.providerWithId(CredentialProviderRegistry.java:71) ~[credential-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] at io.syndesis.credential.Credentials.providerFor(Credentials.java:87) ~[credential-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] at io.syndesis.credential.Credentials.acquisitionMethodFor(Credentials.java:65) ~[credential-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] at io.syndesis.rest.v1.handler.connection.ConnectorCredentialHandler.get(ConnectorCredentialHandler.java:82) ~[rest-1.2-SNAPSHOT.jar!/:1.2-SNAPSHOT] ```   </body>
		<created>2017-12-04 12:01:59</created>
		<closed>2017-12-05 09:26:44</closed>
	</bug>
	<bug>
		<id>521</id>
		<title>No padding between toolbar and list</title>
		<body>@dongniwang Isn't there supposed to be some blank space above the list, not sure what happened to it:  ![screen shot 2017-11-29 at 16 03 19](https://user-images.githubusercontent.com/351660/33399011-ecfbc9fc-d51e-11e7-9ecd-f54d3ca077c2.png) </body>
		<created>2017-11-29 21:04:24</created>
		<closed>2018-03-21 21:36:06</closed>
	</bug>
	<bug>
		<id>516</id>
		<title>Any way to make the guided tour go away?</title>
		<body>It's popups always appear and it's not clear what to do to make them stop showing up altogether.</body>
		<created>2017-11-29 19:31:36</created>
		<closed>2018-02-22 13:57:23</closed>
	</bug>
	<bug>
		<id>515</id>
		<title>Javascript errors from ng-tour annotated elements</title>
		<body>I see these a lot in the editor mostly while creating an integration:  ``` anchorId integrations.step already registered! ```  @kahboom is there something we can do about this?</body>
		<created>2017-11-29 19:29:22</created>
		<closed>2018-02-22 13:57:10</closed>
	</bug>
	<bug>
		<id>502</id>
		<title>Integrations - Basic filter step: allow to remove 1st contition</title>
		<body>Allow to remove 1st condition if there is more than 1. A User can fill many conditions and then he realizes that the 1st one is not needed. He can't simply remove it now. ![basicfilterdeletefirstrow](https://user-images.githubusercontent.com/8707251/33381223-aac8f90c-d51d-11e7-82d5-914877978b36.png) </body>
		<created>2017-11-29 14:55:24</created>
		<closed>2018-03-21 13:35:08</closed>
	</bug>
	<bug>
		<id>482</id>
		<title>After "Action" deserialization "actionType" allways null</title>
		<body>In our rest testsuite, when I try to deserialize received connector, all connector's actions contain actionType null. This causes some serious issues in the testing. There is a code snippet which demonstrates the issue:  ```java Invocation.Builder invocation = client .target(SYNDESIS_URL + "/connectors/twitter") .request(MediaType.APPLICATION_JSON) .header("X-Forwarded-User", "xxx") .header("X-Forwarded-Access-Token", "xxx"); Response response = invocation.get();  Connector result = response.readEntity(Connector.class); ObjectMapper mapper = new ObjectMapper().registerModules(new Jdk8Module()); ObjectWriter ow = mapper.writer(); String json = ow.writeValueAsString(result); ``` when examined, the json will contain only actions with action type "actionType": null</body>
		<created>2017-11-28 15:30:32</created>
		<closed>2017-11-29 07:02:29</closed>
	</bug>
	<bug>
		<id>458</id>
		<title>error building rest module on Jenkins</title>
		<body>We have this error when building on Jenkins (see [#456 build](https://jenkins-syndesis-ci.b6ff.rh-idev.openshiftapps.com/blue/organizations/jenkins/syndesis/detail/PR-456/1/pipeline))  Command: ``` mvn -B -U clean install fabric8:build -Pci ``` Error: ``` [ERROR] Failed to execute goal org.apache.maven.plugins:maven-checkstyle-plugin:2.17:check (default) on project syndesis-rest-parent: Failed during checkstyle execution: Unable to find configuration file at location: ${syndesis.basedir}/checkstyle.xml: Could not find resource '${syndesis.basedir}/checkstyle.xml'. -&gt; [Help 1] ```</body>
		<created>2017-11-26 09:41:02</created>
		<closed>2017-12-01 11:21:46</closed>
	</bug>
	<bug>
		<id>430</id>
		<title>Integration detail: name is missing/empty</title>
		<body>```html &lt;h1 _ngcontent-c3=""&gt;     &lt;syndesis-editable-text _ngcontent-c3="" _nghost-c5=""&gt;     &lt;!----&gt;&lt;!----&gt;      &lt;!----&gt;   &lt;/syndesis-editable-text&gt; &lt;/h1&gt; ```  TP2 ![screen shot 2017-11-23 at 08 05 50](https://user-images.githubusercontent.com/5637792/33161687-6bd6c6cc-d025-11e7-8dbd-7e90a5437326.png)  Master ![screen shot 2017-11-23 at 08 06 05](https://user-images.githubusercontent.com/5637792/33161688-6bf1b73e-d025-11e7-9529-1c349f5ac4c2.png) </body>
		<created>2017-11-23 07:11:09</created>
		<closed>2017-12-20 22:47:32</closed>
	</bug>
	<bug>
		<id>421</id>
		<title>Incompatibility in atlasmap/ui and atlasmap/runtime</title>
		<body>This is caused by the old runtime model which doesn't have `id` attribute. atlasmap-ui should be downgraded until we make atlasmap/camel release and let integration runtime use it. ``` Caused by: com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException: Unrecognized field "id" (class io.atlasmap.v2.Mapping), not marked as ignorable (10 known properties: "alias", "strategy", "delimiter", "mappingType", "outputField", "description", "lookupTableName", "inputField", "delimiterString", "strategyClassName"]) ```</body>
		<created>2017-11-22 14:36:23</created>
		<closed>2017-11-27 11:17:36</closed>
	</bug>
	<bug>
		<id>416</id>
		<title>Backend is not starting due to missing features.filestore.enabled property</title>
		<body>``` 2017-11-22 09:59:48.463  WARN [-,,,] 1 --- [           main] ationConfigEmbeddedWebApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'onlineHandlerProvider' defined in URL [jar:file:/deployments/runtime.jar!/BOOT-INF/lib/controllers-1.1-SNAPSHOT.jar!/io/syndesis/controllers/integration/online/OnlineHandlerProvider.class]: Unsatisfied dependency expressed through constructor parameter 2; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'io.syndesis.project.converter.ProjectGeneratorConfiguration': Unsatisfied dependency expressed through field 'extensionDataManager'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'extensionDataManager' defined in class path resource [io/syndesis/runtime/ExtensionConfiguration.class]: Unsatisfied dependency expressed through method 'extensionDataManager' parameter 1; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'io.syndesis.dao.extension.ExtensionDataAccessObject' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {} 2017-11-22 09:59:48.492  INFO [-,,,] 1 --- [           main] utoConfigurationReportLoggingInitializer :  Error starting ApplicationContext. To display the auto-configuration report re-run your application with 'debug' enabled. 2017-11-22 09:59:48.807 ERROR [-,,,] 1 --- [           main] o.s.b.d.LoggingFailureAnalysisReporter   :  *************************** APPLICATION FAILED TO START ***************************  Description:  Parameter 1 of method extensionDataManager in io.syndesis.runtime.ExtensionConfiguration required a bean of type 'io.syndesis.dao.extension.ExtensionDataAccessObject' that could not be found. - Bean method 'fileStore' not loaded because @ConditionalOnProperty (features.filestore.enabled) found different value in property 'features.filestore.enabled'   Action:  Consider revisiting the conditions above or defining a bean of type 'io.syndesis.dao.extension.ExtensionDataAccessObject' in your configuration. ```</body>
		<created>2017-11-22 10:02:39</created>
		<closed>2017-11-23 13:39:20</closed>
	</bug>
	<bug>
		<id>307</id>
		<title>Add null checks to Salesforce connectors</title>
		<body>|&lt;img src="https://avatars0.githubusercontent.com/u/1306050?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @zregvart | [2017-11-02](https://github.com/syndesisio/connectors/issues/106) | bug  | |-|-|-|  Seems that the body from the exchange can sometimes be `null`, we need to guard from that in afterProcessors in Salesforce connectors</body>
		<created>2017-11-15 20:34:22</created>
		<closed>2017-12-19 13:37:18</closed>
	</bug>
	<bug>
		<id>293</id>
		<title>Console errors showing up in create connection pages</title>
		<body>|&lt;img src="https://avatars2.githubusercontent.com/u/351660?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @gashcrumb | [2017-11-14](https://github.com/syndesisio/syndesis-ui/issues/1227) | bug  | |-|-|-|  @kahboom wonder, do we need to just catch these errors or dispose of the tour service instance?  Not sure...  ![screenshot from 2017-11-14 14-43-09](https://user-images.githubusercontent.com/351660/32801165-4483a9be-c94a-11e7-9b9b-cb35e8988283.png) </body>
		<created>2017-11-15 20:13:26</created>
		<closed>2017-11-20 13:37:51</closed>
	</bug>
	<bug>
		<id>292</id>
		<title>Actions tooltips in the data mapper are covered by the toolbar</title>
		<body>|&lt;img src="https://avatars0.githubusercontent.com/u/366207?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @astefanutti | [2017-09-27](https://github.com/syndesisio/syndesis-ui/issues/1027) | bug, Priority - High  | |-|-|-|  &lt;img width="616" alt="screen shot 2017-09-27 at 13 37 26" src="https://user-images.githubusercontent.com/366207/30911508-30b8e610-a389-11e7-93d7-45532ff5c1e4.png"&gt; </body>
		<created>2017-11-15 20:13:14</created>
		<closed>2018-03-16 15:00:45</closed>
	</bug>
	<bug>
		<id>287</id>
		<title>Create Integration Guided Tour: Check for ID</title>
		<body>|&lt;img src="https://avatars3.githubusercontent.com/u/3844502?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @kahboom | [2017-11-10](https://github.com/syndesisio/syndesis-ui/issues/1212) | bug  | |-|-|-|  So it doesn't repeat the same steps for the second connection configuration.</body>
		<created>2017-11-15 20:12:02</created>
		<closed>2018-03-15 14:44:54</closed>
	</bug>
	<bug>
		<id>285</id>
		<title>Manual trigger of guided tour redirects you to previous step</title>
		<body>|&lt;img src="https://avatars3.githubusercontent.com/u/3844502?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @kahboom | [2017-11-10](https://github.com/syndesisio/syndesis-ui/issues/1210) | bug  | |-|-|-|  It will redirect you to the step you dismissed the guided tour on, rather than basing it on the route you are on at the moment.</body>
		<created>2017-11-15 20:11:51</created>
		<closed>2018-03-15 14:44:30</closed>
	</bug>
	<bug>
		<id>277</id>
		<title>Connection validate success message should appear above the "Validate" button</title>
		<body>|&lt;img src="https://avatars2.githubusercontent.com/u/24943812?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @dongniwang | [2017-09-15](https://github.com/syndesisio/syndesis-ui/issues/965) | bug, good first issue, Priority - Low  | |-|-|-|  PatternFly recommends [inline notifications](http://www.patternfly.org/pattern-library/communication/inline-notifications/) be shown at the top of the main content area. See screenshot below.   ![connection validate success msg](https://user-images.githubusercontent.com/24943812/30489780-2a08f670-9a06-11e7-850c-5869aab6746d.png)   </body>
		<created>2017-11-15 20:09:21</created>
		<closed>2018-03-15 14:43:54</closed>
	</bug>
	<bug>
		<id>270</id>
		<title>datamapper after integration is reedited behaves strangely</title>
		<body>|&lt;img src="https://avatars1.githubusercontent.com/u/2714974?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @Stefan365 | [2017-11-02](https://github.com/syndesisio/syndesis-ui/issues/1170) | bug, good first issue, Priority - High  | |-|-|-|   [datamapper_collapse.mp4.gz](https://github.com/syndesisio/syndesis-ui/files/1438146/datamapper_collapse.mp4.gz)  After saving integration, and editing it again, If I add datamapper step (and do nothing else) datamapper ui collapses suddenly, as per attached video. I don't see any specific error in web console. </body>
		<created>2017-11-15 20:07:56</created>
		<closed>2018-03-14 16:53:48</closed>
	</bug>
	<bug>
		<id>268</id>
		<title>Connections - edit vs view kebab option</title>
		<body>|&lt;img src="https://avatars1.githubusercontent.com/u/14313995?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @mcada | [2017-11-09](https://github.com/syndesisio/syndesis-ui/issues/1199) | bug, good first issue, Priority - Low  | |-|-|-|  There is option to open Connection Details with either edit or view button (third option is to delete it). What is the point of having those options when the result is the same with both - you end up in Connection Details? There is edit=true if you open details with edit button, but you can edit connection even if you use view button and you still have to click edit button inside Connection Details if you went there with edit=true.</body>
		<created>2017-11-15 20:07:32</created>
		<closed>2018-03-16 18:05:25</closed>
	</bug>
	<bug>
		<id>265</id>
		<title>Misaligned number of integrations in integration chart thinggy</title>
		<body>|&lt;img src="https://avatars0.githubusercontent.com/u/1306050?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @zregvart | [2017-10-25](https://github.com/syndesisio/syndesis-ui/issues/1135) | bug, good first issue, Priority - Low  | |-|-|-|  Looks something like this in Chrome and Firefox on my end:  ![selection_301](https://user-images.githubusercontent.com/1306050/31991621-7b2bd734-b978-11e7-87a3-33f5596e2ddb.png)  I guess we still are few years away from CSS centring properly :)</body>
		<created>2017-11-15 20:07:02</created>
		<closed>2018-02-28 18:22:29</closed>
	</bug>
	<bug>
		<id>261</id>
		<title>Strange behaviour for autocomplete pull downs in "Basic Filter" step</title>
		<body>|&lt;img src="https://avatars3.githubusercontent.com/u/99080?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @rhuss | [2017-09-21](https://github.com/syndesisio/syndesis-ui/issues/999) | bug, good first issue, Priority - Low  | |-|-|-|  When I'm on the form for defining a basic filter, I experience consistently a very strange behaviour. My setup is a three-screen setup with a 24'' on the left (vertical mode), a 21:9 34'' in the middle and my notebook on the right.  * When my browser window is on the middle screen in the _left_ half, the typing in the autocomplete field will show the pulldown with the sugggestion on my left screen, (with an offset of maybe 600 px). But when I enter 2 letters, it moves back to below the input field where it belongs to. * When my browser is in the _right_ half, everything works fine.  In addition, the pulldown feels a bit sluggish when there are 20 or more fields.  ![image](https://user-images.githubusercontent.com/99080/30686608-18587f6a-9eb9-11e7-9b4c-9fe9c6cf680f.png)   ![image](https://user-images.githubusercontent.com/99080/30686630-25ee1f68-9eb9-11e7-9a0a-3bc23d841631.png) </body>
		<created>2017-11-15 20:06:15</created>
		<closed>2018-03-26 18:53:23</closed>
	</bug>
	<bug>
		<id>260</id>
		<title>Create Connection - Create Button is always Enabled</title>
		<body>|&lt;img src="https://avatars3.githubusercontent.com/u/3844502?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @kahboom | [2017-11-08](https://github.com/syndesisio/syndesis-ui/issues/1193) | bug  | |-|-|-|  If the user has not filled out the Connector Name, which is a required field (per the UI), then the 'Create' button should not be enabled until some valid text is filled out there.  &lt;img width="1526" alt="screenshot 2017-11-08 12 29 43" src="https://user-images.githubusercontent.com/3844502/32564182-6b08b57a-c481-11e7-9f7b-9331a7dd2022.png"&gt; </body>
		<created>2017-11-15 20:05:57</created>
		<closed>2018-03-15 17:59:11</closed>
	</bug>
	<bug>
		<id>258</id>
		<title>OAuth Application Management page title is inconsistent with title in breadcrumb</title>
		<body>|&lt;img src="https://avatars2.githubusercontent.com/u/25067106?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @TovaCohen | [2017-10-15](https://github.com/syndesisio/syndesis-ui/issues/1099) | bug, good first issue, Priority - Low  | |-|-|-|  I'm working through the official TP1 release and I noticed that the Settings page has "OAuth Client Management" in the breadcrumbs but "OAuth Application Management" in the title. I think these need to be the same. Or maybe the breadcrumbs could be removed from this page until there is some value they would add. Right now, they don't add value.  I understand we're trying to build a foundation for adding features so I probably just don't know the long-term plan, which likely has a reason for why the breadcrumbs are here now. Here's a screen capture:  ![oauth-client-vs-application-management](https://user-images.githubusercontent.com/25067106/31584634-37553a1e-b180-11e7-97a7-079a5d5a88c5.png) </body>
		<created>2017-11-15 20:05:21</created>
		<closed>2018-03-15 14:00:05</closed>
	</bug>
	<bug>
		<id>257</id>
		<title>Line of the "integration flow" is one-pixel shifted when Datamapper is used</title>
		<body>|&lt;img src="https://avatars2.githubusercontent.com/u/1105127?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @apupier | [2017-11-02](https://github.com/syndesisio/syndesis-ui/issues/1166) | bug, good first issue, Priority - Low  | |-|-|-|  - create flow with several steps, including one Data mapper. - try to edit the Data mapper step  ![image](https://user-images.githubusercontent.com/1105127/32324956-62b8fec4-bfcd-11e7-8753-1844fbe4326f.png) </body>
		<created>2017-11-15 20:04:15</created>
		<closed>2018-03-15 14:05:10</closed>
	</bug>
	<bug>
		<id>252</id>
		<title>Empty state should not display Create card</title>
		<body>|&lt;img src="https://avatars3.githubusercontent.com/u/3844502?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @kahboom | [2017-10-27](https://github.com/syndesisio/syndesis-ui/issues/1153) | bug  | |-|-|-|  Will post screenshot soon</body>
		<created>2017-11-15 20:03:15</created>
		<closed>2018-03-14 21:07:49</closed>
	</bug>
	<bug>
		<id>249</id>
		<title>Changing the inputShape of an existing data mapping</title>
		<body>|&lt;img src="https://avatars3.githubusercontent.com/u/99080?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @rhuss | [2017-10-25](https://github.com/syndesisio/syndesis-ui/issues/1136) | bug, data mapper, Priority - Low, UX Design  | |-|-|-|  When changing e.g. the SF connection for using a different object (e.g. Lead instead of Contact) for an existing integration which already contains a datamapping, then in tabular view every mappings have been removed:  ![image](https://user-images.githubusercontent.com/99080/31991524-42216a1c-b978-11e7-9cfa-3e5d5be65109.png)  But in the 'arrow view' there are still the blue dots from the previous mappings:  ![image](https://user-images.githubusercontent.com/99080/31991547-53d2ee16-b978-11e7-850b-fcd023fd02fd.png)  Also in the console:  ![image](https://user-images.githubusercontent.com/99080/31991580-6577ccf4-b978-11e7-9197-9f59b0f33cdb.png) </body>
		<created>2017-11-15 20:01:34</created>
		<closed>2018-03-16 13:21:47</closed>
	</bug>
	<bug>
		<id>245</id>
		<title>CI for master is failing</title>
		<body>|&lt;img src="https://avatars2.githubusercontent.com/u/351660?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @gashcrumb | [2017-10-20](https://github.com/syndesisio/syndesis-ui/issues/1128) | dev process, Priority - High  | |-|-|-|  ``` Using project "bayesian-appsec". Welcome! See 'oc help' to get started. Now using project "syndesis-staging" on server "https://api.rh-idev.openshift.com:443". error: tag "latest" points to existing ImageStreamImage "syndesis-ui@sha256:695b5288e5f7c250d08a56ed9daf026b6b28133394c2e907c607d6bc30fe5e15", it cannot be re-imported ```  Note the project that `oc` is pointing to doesn't look right besides the error.</body>
		<created>2017-11-15 20:01:05</created>
		<closed>2018-03-14 15:14:32</closed>
	</bug>
	<bug>
		<id>241</id>
		<title>The copyright or trademark is unreadable in top menu </title>
		<body>|&lt;img src="https://avatars2.githubusercontent.com/u/1105127?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @apupier | [2017-10-12](https://github.com/syndesisio/syndesis-ui/issues/1084) | bug, Priority - Low  | |-|-|-|  there is a little  or  or maybe something else close to RED HAT and JBOSS in the title bar but it is unreadable  ![image](https://user-images.githubusercontent.com/1105127/31486214-f7ba21c6-af36-11e7-841d-0701f8d1b93d.png)  </body>
		<created>2017-11-15 19:59:22</created>
		<closed>2018-03-14 15:18:31</closed>
	</bug>
	<bug>
		<id>237</id>
		<title>Adding filter after datamapper doesn't load proper autosuggest fields</title>
		<body>|&lt;img src="https://avatars3.githubusercontent.com/u/99080?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @rhuss | [2017-10-06](https://github.com/syndesisio/syndesis-ui/issues/1058) | bug, Priority - High  | |-|-|-|  ![image](https://user-images.githubusercontent.com/99080/31283070-e1c9cc8a-aab4-11e7-9d42-b78b51163453.png)  I'd expect here the fields for the salesforce contact to be available here. Might be a backend issue, too.</body>
		<created>2017-11-15 19:56:47</created>
		<closed>2018-09-21 12:33:58</closed>
	</bug>
	<bug>
		<id>232</id>
		<title>Issue with syndesis session on OpenShift v3.6.26</title>
		<body>|&lt;img src="https://avatars3.githubusercontent.com/u/4180208?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @tplevko | [2017-10-09](https://github.com/syndesisio/syndesis-ui/issues/1064) | bug, TP1  | |-|-|-|  I experience issue with syndesis TP1 running OS: https://console.fuse-ignite.openshift.com/ Every time I open syndesis in new browser tab, the session is not propagated and I am always asked to log in again.</body>
		<created>2017-11-15 19:55:59</created>
		<closed>2018-03-14 20:58:45</closed>
	</bug>
	<bug>
		<id>227</id>
		<title>Create Connection: Navbar shouldn't hide UI elements</title>
		<body>|&lt;img src="https://avatars1.githubusercontent.com/u/8707241?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @jludvice | [2017-04-11](https://github.com/syndesisio/syndesis-ui/issues/409) | bug, Priority - Low  | |-|-|-|  Vertical navbar overlay shouldn't be a big issue, but I think we shoul fix the Next, Back and Cancel button that might disappear (end of the video). Screencast: https://youtu.be/KFL1tvshpK4  </body>
		<created>2017-11-15 19:54:35</created>
		<closed>2018-03-14 15:29:06</closed>
	</bug>
	<bug>
		<id>226</id>
		<title>Navigation menu is covering up integration workflow </title>
		<body>|&lt;img src="https://avatars2.githubusercontent.com/u/24943812?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @dongniwang | [2017-08-28](https://github.com/syndesisio/syndesis-ui/issues/850) | bug, Priority - Low  | |-|-|-|  I was in the create an integration workflow and wanted to open up the navigation menu to check on something.   As the menu opened up, it also covered part of integration workflow interface. My understanding is that opening up the navigation menu would push the integration visualization pane to the right without laying on top of the visualization pane.   Is this intentional or it's just a bug?   ![image](https://user-images.githubusercontent.com/24943812/29787345-8a976660-8bfc-11e7-95de-f80a755a9763.png) </body>
		<created>2017-11-15 19:54:00</created>
		<closed>2018-03-14 15:29:52</closed>
	</bug>
	<bug>
		<id>216</id>
		<title>Code generator can't deal with plural type names</title>
		<body>|&lt;img src="https://avatars2.githubusercontent.com/u/351660?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @gashcrumb | [2017-07-25](https://github.com/syndesisio/syndesis-ui/issues/657) | bug, dev process, Priority - Low  | |-|-|-|  When running `yarn generate` against the current swagger that contains `FilterOptions` we get:  ``` ERROR in C:/Users/gashcrumb/GitHub/syndesis-ui/src/app/model.ts (216,18): Duplicate identifier 'FilterOptions'.  ERROR in C:/Users/gashcrumb/GitHub/syndesis-ui/src/app/model.ts (222,13): Duplicate identifier 'FilterOptions'. ```  As the class is plural but the generator also creates an array with the plural name.  This can be fixed manually but it'd be nice if the generator could handle this case.</body>
		<created>2017-11-15 19:49:16</created>
		<closed>2018-01-31 18:43:50</closed>
	</bug>
	<bug>
		<id>160</id>
		<title>Empty validation message when creating a new Connection with invalid values</title>
		<body>|&lt;img src="https://avatars2.githubusercontent.com/u/1105127?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @apupier | [2017-10-03](https://github.com/syndesisio/syndesis-project/issues/111) | Blocker, Bug, TP1  | |-|-|-|  ![image](https://user-images.githubusercontent.com/1105127/31130584-17ea5c8a-a858-11e7-8d7e-7bf8e6ec06f7.png) </body>
		<created>2017-11-15 18:43:07</created>
		<closed>2018-01-09 09:40:27</closed>
	</bug>
	<bug>
		<id>154</id>
		<title>fix jenkins CI cleanup</title>
		<body>|&lt;img src="https://avatars1.githubusercontent.com/u/8707241?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @jludvice | [2017-09-04](https://github.com/syndesisio/syndesis-project/issues/91) | Bug  | |-|-|-|  CC @dsimansk   We have a ton of useless projects on openshfit ```  jludvice@jludvice-potvora  ~/devel/redhat/ipaas/syndesis-e2e-tests   settings   oc get projects | grep syndesis syndesis-ci                                                                                                Active syndesis-datamapper-release-work-1-11-0-fuse-000-1-201706291238                                            Active syndesis-datamapper-syndesis-rebrand-1-201706291238                                                        Active syndesis-qe                                                                                                Active syndesis-rest-master-100-201708290941                                                                      Active syndesis-rest-master-101-201708291229                                                                      Active syndesis-rest-master-102-201708291616                                                                      Active syndesis-rest-master-103-201708301014                                                                      Active syndesis-rest-master-104-201708301214                                                                      Active syndesis-rest-master-105-201708311221                                                                      Active syndesis-rest-master-106-201708311316                                                                      Active syndesis-rest-master-107-201708311400                                                                      Active syndesis-rest-master-108-201708311821                                                                      Active syndesis-rest-master-109-201708311902                                                                      Active syndesis-rest-master-110-201709010640                                                                      Active syndesis-rest-master-113-201709010807                                                                      Active syndesis-rest-master-114-201709010945                                                                      Active syndesis-rest-master-115-201709011718                                                                      Active syndesis-rest-master-95-201708251942                                                                       Active syndesis-rest-master-96-201708251959                                                                       Active syndesis-rest-master-97-201708281706                                                                       Active syndesis-rest-master-99-201708290726                                                                       Active syndesis-rest-pr-493-5-201708301829                                                                        Active syndesis-rest-pr-533-6-201708251928                                                                        Active syndesis-rest-pr-535-11-201708252000                                                                       Active syndesis-rest-pr-535-15-201708281338                                                                       Active syndesis-rest-pr-535-7-201708251035                                                                        Active syndesis-rest-pr-539-4-201708251027                                                                        Active syndesis-rest-pr-542-1-201708251543                                                                        Active syndesis-rest-pr-544-1-201708281337                                                                        Active syndesis-rest-pr-544-2-201708281412                                                                        Active syndesis-rest-pr-546-1-201708291202                                                                        Active syndesis-rest-pr-547-2-201708291520                                                                        Active syndesis-rest-pr-547-3-201708291522                                                                        Active syndesis-rest-pr-547-4-201708291526                                                                        Active syndesis-rest-pr-548-10-201708312218                                                                       Active syndesis-rest-pr-548-12-201709011649                                                                       Active syndesis-rest-pr-548-2-201708300838                                                                        Active syndesis-rest-pr-548-3-201708300947                                                                        Active syndesis-rest-pr-548-5-201708311005                                                                        Active syndesis-rest-pr-550-1-201708300940                                                                        Active syndesis-rest-pr-551-1-201708301150                                                                        Active syndesis-rest-pr-553-2-201708310623                                                                        Active syndesis-rest-pr-554-1-201708310835                                                                        Active syndesis-rest-pr-554-2-201708310910                                                                        Active syndesis-rest-pr-554-4-201708311125                                                                        Active syndesis-rest-pr-555-3-201708311047                                                                        Active syndesis-rest-pr-556-1-201708311301                                                                        Active syndesis-rest-pr-558-1-201708311646                                                                        Active syndesis-rest-pr-563-2-201708312215                                                                        Active syndesis-rest-pr-568-1-201709010919                                                                        Active syndesis-rest-testsupport-deployments-4-201708031308                                                       Active syndesis-staging                                                                                           Active syndesis-staging-bak                                                                                       Active ```</body>
		<created>2017-11-15 18:42:25</created>
		<closed>2018-03-14 20:13:26</closed>
	</bug>
	<bug>
		<id>150</id>
		<title>Data mapper - cannot map date fields Twitter -&gt; Salesforce</title>
		<body>|&lt;img src="https://avatars0.githubusercontent.com/u/11435422?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @nichmoore | [2017-09-13](https://github.com/syndesisio/syndesis-project/issues/93) | Bug  | |-|-|-|  1. On the Twitter to Salesforce scenario, the date fields cannot be mapped because they are different data types. One is a huge group field, and the other is a standard date format.    2. If you try to map the date fields, an error message is displayed which says 'Conversion between source and target types is supported.' It appears in red and I assume it should read '... is NOT supported'.  It's not helpful. </body>
		<created>2017-11-15 18:41:49</created>
		<closed>2018-03-14 20:12:30</closed>
	</bug>
	<bug>
		<id>129</id>
		<title>Updating an integration should trigger a redeployment of the integration deployment</title>
		<body>|&lt;img src="https://avatars0.githubusercontent.com/u/103255?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @chirino | [2017-06-09](https://github.com/syndesisio/syndesis-project/issues/9) | Bug  | |-|-|-|  Right now once an integration is deployed, making update to it via the UI does not make it pick up the updates.</body>
		<created>2017-11-15 18:06:10</created>
		<closed>2018-02-02 00:16:21</closed>
	</bug>
	<bug>
		<id>102</id>
		<title>Integration status stalled on `In Progress`</title>
		<body>|&lt;img src="https://avatars0.githubusercontent.com/u/5637792?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @dsimansk | [2017-09-25](https://github.com/syndesisio/syndesis-rest/issues/639) | bug  | |-|-|-|  After implementing TW-&gt;SF runtime itself seems to be working just fine. E.g. application is running and updating/creating Contacts in SF correctly. But backend seems to be failing in reaching desired state.  I wonder if `token expired` is responsible for that. As this message is false judging from runtime working fine.  Cc @rhuss @jimmidyson   ``` 2017-09-25 13:04:12.872  INFO [-,,,] 1 --- [pool-5-thread-1] i.s.c.integration.IntegrationController  : Integration -KusuUxjPMiCfmsZ2-cC : Desired status "Activated" != current status "Pending" --&gt; calling status change handler 2017-09-25 13:04:13.456  INFO [-,,,] 1 --- [pool-4-thread-1] i.s.c.integration.IntegrationController  : Integration -KusuUxjPMiCfmsZ2-cC : Start processing integration with ActivateHandler 2017-09-25 13:04:13.456  INFO [-,,,] 1 --- [pool-4-thread-1] i.s.c.i.online.ActivateHandler           : Integration -KusuUxjPMiCfmsZ2-cC : Token is expired 2017-09-25 13:04:13.456  INFO [-,,,] 1 --- [pool-4-thread-1] i.s.c.integration.IntegrationController  : Integration -KusuUxjPMiCfmsZ2-cC : Setting status to Pending ```</body>
		<created>2017-11-15 17:58:07</created>
		<closed>2018-01-09 09:44:34</closed>
	</bug>
	<bug>
		<id>101</id>
		<title>NPE with Twitter to Saleforce integration</title>
		<body>|&lt;img src="https://avatars3.githubusercontent.com/u/1520602?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @paoloantinori | [2017-10-20](https://github.com/syndesisio/syndesis-rest/issues/740) | bug  | |-|-|-|  Hi, I'm currently hitting a NPE following the tutorial:  &lt;details&gt;   &lt;summary&gt;Click to expand&lt;/summary&gt; &lt;pre&gt; 15:30:07.475 [HttpClient@1885991030-21] ERROR o.a.c.processor.DefaultErrorHandler - Failed delivery for (MessageId: ID-twitter-to-salesforce-sample-integration-12-7kzwd-1508426997277-0-42 on ExchangeId: ID-twitter-to-salesforce-sample-integration-12-7kzwd-1508426997277-0-39). Exhausted after delivery attempt: 1 caught: java.lang.NullPointerException  Message History --------------------------------------------------------------------------------------------------------------------------------------- RouteId              ProcessorId          Processor                                                                        Elapsed (ms) [flow1             ] [flow1             ] [twitter-mention-connector-component://MENTIONS?delay=30000&amp;sinceId=1          ] [       182] [flow1             ] [filter1           ] [filter[{io.syndesis.integration.runtime.util.JsonSimplePredicate@2251b3bc}]   ] [       182] [flow1             ] [to1               ] [atlas:mapping-step-3.json                                                     ] [         2] [flow1             ] [to2               ] [salesforce-create-sobject?sObjectName=Contact                                 ] [       179]  Stacktrace --------------------------------------------------------------------------------------------------------------------------------------- java.lang.NullPointerException: null at com.fasterxml.jackson.core.JsonFactory.createParser(JsonFactory.java:879) at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2858) at io.syndesis.connector.salesforce.SalesforceCreateSObjectComponent.lambda$new$0(SalesforceCreateSObjectComponent.java:40) at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) ... &lt;/pre&gt; &lt;/details&gt;   I suspect that I have either made an error at mapping level, despite I have checked multiple times.  &lt;details&gt;   &lt;summary&gt;Click to expand&lt;/summary&gt; &lt;pre&gt; bash-4.2$ unzip -c project-0.1-SNAPSHOT.jar BOOT-INF/classes/syndesis.yml                                                                                                                                                                                                       Archive:  project-0.1-SNAPSHOT.jar   inflating: BOOT-INF/classes/syndesis.yml   --- flows: - steps:   - kind: endpoint     uri: twitter-mention-connector:MENTIONS   - kind: filter     expression: ${body.text} contains '#signorefammistrumentodipace'     steps:     - kind: endpoint       uri: atlas:mapping-step-3.json     - kind: endpoint       uri: salesforce-create-sobject?sObjectName=Contact &lt;/pre&gt; &lt;/details&gt;  &lt;details&gt;   &lt;summary&gt;Click to expand&lt;/summary&gt; &lt;pre&gt; bash-4.2$ unzip -q -c project-0.1-SNAPSHOT.jar BOOT-INF/classes/mapping-step-3.json | python -m json.tool {     "AtlasMapping": {         "dataSource": [             {                 "dataSourceType": "SOURCE",                 "id": "twitter4j.Status",                 "jsonType": "io.atlasmap.v2.DataSource",                 "uri": "atlas:java?className=twitter4j.Status"             },             {                 "dataSourceType": "TARGET",                 "id": "Contact",                 "jsonType": "io.atlasmap.json.v2.JsonDataSource",                 "template": null,                 "uri": "atlas:json:Contact"             }         ],         "jsonType": "io.atlasmap.v2.AtlasMapping",         "lookupTables": {             "lookupTable": []         },         "mappings": {             "mapping": [                 {                     "inputField": [                         {                             "docId": "twitter4j.Status",                             "fieldType": "STRING",                             "jsonType": "io.atlasmap.java.v2.JavaField",                             "name": "name",                             "path": "/user/name"                         }                     ],                     "jsonType": "io.atlasmap.v2.Mapping",                     "mappingType": "SEPARATE",                     "outputField": [                         {                             "docId": "Contact",                             "fieldType": "STRING",                             "index": 0,                             "jsonType": "io.atlasmap.json.v2.JsonComplexType",                             "name": "FirstName",                             "path": "/FirstName",                             "userCreated": false                         },                         {                             "docId": "Contact",                             "fieldType": "STRING",                             "index": 1,                             "jsonType": "io.atlasmap.json.v2.JsonComplexType",                             "name": "LastName",                             "path": "/LastName",                             "userCreated": false                         }                     ],                     "strategy": "Space"                 },                 {                     "inputField": [                         {                             "docId": "twitter4j.Status",                             "fieldType": "STRING",                             "jsonType": "io.atlasmap.java.v2.JavaField",                             "name": "screenName",                             "path": "/user/screenName"                         }                     ],                     "jsonType": "io.atlasmap.v2.Mapping",                     "mappingType": "MAP",                     "outputField": [                         {                             "docId": "Contact",                             "fieldType": "STRING",                             "jsonType": "io.atlasmap.json.v2.JsonComplexType",                             "name": "Title",                             "path": "/Title",                             "userCreated": false                         }                     ]                 },                 {                     "inputField": [                         {                             "docId": "twitter4j.Status",                             "fieldType": "STRING",                             "jsonType": "io.atlasmap.java.v2.JavaField",                             "name": "text",                             "path": "/text"                         }                     ],                     "jsonType": "io.atlasmap.v2.Mapping",                     "mappingType": "MAP",                     "outputField": [                         {                             "docId": "Contact",                             "fieldType": "STRING",                             "jsonType": "io.atlasmap.json.v2.JsonComplexType",                             "name": "Description",                             "path": "/Description",                             "userCreated": false                         }                     ]                 }             ]         },         "name": "UI.278186",         "properties": {             "property": []         }     } }  &lt;/pre&gt; &lt;/details&gt;   ![screenshot from 2017-10-20 10-07-34](https://user-images.githubusercontent.com/1520602/31811094-91f38028-b57e-11e7-8232-e94380adcdbd.png) </body>
		<created>2017-11-15 17:57:57</created>
		<closed>2018-01-10 11:40:58</closed>
	</bug>
	<bug>
		<id>96</id>
		<title>OpenShift error when creating build configuration</title>
		<body>|&lt;img src="https://avatars3.githubusercontent.com/u/99080?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @rhuss | [2017-10-23](https://github.com/syndesisio/syndesis-rest/issues/747) | bug, TP2  | |-|-|-|  ``` io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: GET at: https://openshift.default.svc/apis/build.openshift.io/v1/namespaces/proj7630/builds?labelSelector=openshift.io/build-config.name%3Dtwsf&amp;fieldSelector=status%3DRunning. Message: No field label conversion function found for version: build.openshift.io/v1. Received status: Status(apiVersion=v1, code=400, details=null, kind=Status, message=No field label conversion function found for version: build.openshift.io/v1, metadata=ListMeta(resourceVersion=null, selfLink=null, additionalProperties={}), reason=BadRequest, status=Failure, additionalProperties={}). at io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:470) ~[kubernetes-client-2.6.0-000015.fuse-000002.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:409) ~[kubernetes-client-2.6.0-000015.fuse-000002.jar!/:na] at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:379) ~[kubernetes-client-2.6.0-000015.fuse-000002.jar!/:na] ```  the corresponding code looks like  ```java     @Override     public boolean isBuildStarted(String name) {         String sName = Names.sanitize(name);         return !openShiftClient.builds()                                .withLabel("openshift.io/build-config.name", sName)                                .withField("status", "Running")                                .list().getItems().isEmpty();     }  ```  and has not changed since 6 weeks.  @iocanel any ideas what this could be ?</body>
		<created>2017-11-15 17:56:50</created>
		<closed>2018-03-14 18:44:24</closed>
	</bug>
	<bug>
		<id>91</id>
		<title>Salesforce OAuth via Spring Social issues a chatter call</title>
		<body>|&lt;img src="https://avatars0.githubusercontent.com/u/1306050?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @zregvart | [2017-10-20](https://github.com/syndesisio/syndesis-rest/issues/741) | bug  | |-|-|-|  This is when a OAuth dance is completed on connection creation and this call sometimes fails and a connection cannot be created.</body>
		<created>2017-11-15 17:56:12</created>
		<closed>2018-03-14 18:43:48</closed>
	</bug>
	<bug>
		<id>90</id>
		<title>WebSocket Upgrade Issue</title>
		<body>|&lt;img src="https://avatars3.githubusercontent.com/u/99080?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @rhuss | [2017-10-18](https://github.com/syndesisio/syndesis-rest/issues/723) | bug  | |-|-|-|  ``` 2017-10-18 10:06:09.646 ERROR [-,,,] 1 --- [   XNIO-3 I/O-2] io.undertow.request                      : UT005071: Undertow request failed HttpServerExchange{ GET /api/v1/event/streams.ws/b222047e-50a0-4ef2-958a-a37e78cc135f request {Cache-Control=[no-cache], Sec-Websocket-Version=[13], Accept-Encoding=[gzip, deflate, br], Sec-Websocket-Key=[wOzUffTq5EDAvJWbRlOUtg==], Dnt=[1], Origin=[https://app-proj7558.6a63.fuse-ignite.openshiftapps.com], Pragma=[no-cache], X-Forwarded-Port=[443], X-Forwarded-For=[91.51.113.82, 10.131.0.1], Cookie=[_oauth_proxy=cmh1c3MxQHJlZGhhdC5jb218cENPR1BjUkRMaGlGdUk3L1RiZjdzR0ZSY1Nsd1M3VUswNUdmMzhVczdOT1Z5bExPaVhUOGw2M2lDMVZmN2dMWElYL1dOTWN1N0JNZm04Zz18LTYyMTM1NTk2ODAwfA==|1508320216|EBw7KXr2mbFgN7yKKLsF9OlUt40=], Host=[app-proj7558.6a63.fuse-ignite.openshiftapps.com], X-Forwarded-Host=[app-proj7558.6a63.fuse-ignite.openshiftapps.com], Accept-Language=[en-US,en;q=0.8,de;q=0.6], X-Forwarded-Email=[rhuss1@redhat.com], User-Agent=[Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36], Sec-Websocket-Extensions=[permessage-deflate; client_max_window_bits], Forwarded=[for=91.51.113.82;host=app-proj7558.6a63.fuse-ignite.openshiftapps.com;proto=https], X-Forwarded-User=[rhuss1], X-Forwarded-Access-Token=[BVVSOH0SiyvaCl12VpOgWtW_wcVRIQxP5MNMXhbdJtI], Authorization=[Basic cmh1c3MxOg==], X-Forwarded-Proto=[https]} response {Access-Control-Allow-Origin=[https://app-proj7558.6a63.fuse-ignite.openshiftapps.com]}}  java.lang.IllegalStateException: UT000133: Request did not contain an Upgrade header, upgrade is not permitted at io.undertow.server.HttpServerExchange.upgradeChannel(HttpServerExchange.java:876) ~[undertow-core-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.websockets.WebSocketProtocolHandshakeHandler.handleRequest(WebSocketProtocolHandshakeHandler.java:193) ~[undertow-core-1.4.18.Final.jar!/:1.4.18.Final] at io.syndesis.runtime.EventBusToWebSocket$1.handleRequest(EventBusToWebSocket.java:67) ~[classes!/:0.1-SNAPSHOT] at io.undertow.server.handlers.PathHandler.handleRequest(PathHandler.java:94) ~[undertow-core-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.server.handlers.PathHandler.handleRequest(PathHandler.java:94) ~[undertow-core-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.server.handlers.HttpContinueReadHandler.handleRequest(HttpContinueReadHandler.java:65) ~[undertow-core-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.server.handlers.ProxyPeerAddressHandler.handleRequest(ProxyPeerAddressHandler.java:112) ~[undertow-core-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.server.Connectors.executeRootHandler(Connectors.java:326) ~[undertow-core-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.server.protocol.http.HttpReadListener.handleEventWithNoRunningRequest(HttpReadListener.java:254) ~[undertow-core-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.server.protocol.http.HttpReadListener.handleEvent(HttpReadListener.java:136) ~[undertow-core-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.server.protocol.http.HttpReadListener.handleEvent(HttpReadListener.java:59) ~[undertow-core-1.4.18.Final.jar!/:1.4.18.Final] at org.xnio.ChannelListeners.invokeChannelListener(ChannelListeners.java:92) [xnio-api-3.3.8.Final.jar!/:3.3.8.Final] at org.xnio.conduits.ReadReadyHandler$ChannelListenerHandler.readReady(ReadReadyHandler.java:66) [xnio-api-3.3.8.Final.jar!/:3.3.8.Final] at org.xnio.nio.NioSocketConduit.handleReady(NioSocketConduit.java:88) [xnio-nio-3.3.8.Final.jar!/:3.3.8.Final] at org.xnio.nio.WorkerThread.run(WorkerThread.java:561) [xnio-nio-3.3.8.Final.jar!/:3.3.8.Final] ```  Guess its due to the OAuth switch.</body>
		<created>2017-11-15 17:55:52</created>
		<closed>2018-03-14 18:43:30</closed>
	</bug>
	<bug>
		<id>82</id>
		<title>IllegalStateException when selecting any of the SF's actions</title>
		<body>|&lt;img src="https://avatars0.githubusercontent.com/u/5637792?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @dsimansk | [2017-09-14](https://github.com/syndesisio/syndesis-rest/issues/594) | bug  | |-|-|-|  I've spotted exception in UI when any of the SF's action is selected.  Cc @zregvart   ``` 2017-09-14 07:29:04.974 ERROR [-,,,] 1 --- [ XNIO-3 task-17] io.undertow.request                      : UT005023: Exception handling request to /api/v1/connections/2/actions/io.syndesis:salesforce-upsert-contact-connector:latest  java.lang.IllegalStateException: RESTEASY003765: Response is closed. at org.jboss.resteasy.specimpl.BuiltResponse.abortIfClosed(BuiltResponse.java:257) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.client.jaxrs.internal.ClientResponse.abortIfClosed(ClientResponse.java:343) ~[resteasy-client-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.client.jaxrs.internal.ClientResponse.getEntity(ClientResponse.java:75) ~[resteasy-client-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.core.ExceptionHandler.unwrapException(ExceptionHandler.java:128) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.core.ExceptionHandler.handleApplicationException(ExceptionHandler.java:76) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.core.ExceptionHandler.handleException(ExceptionHandler.java:222) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.core.SynchronousDispatcher.writeException(SynchronousDispatcher.java:175) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:418) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:209) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.plugins.server.servlet.ServletContainerDispatcher.service(ServletContainerDispatcher.java:227) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:56) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:51) ~[resteasy-jaxrs-3.1.4.Final.jar!/:3.1.4.Final] at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) ~[javax.servlet-api-3.1.0.jar!/:3.1.0] at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:85) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) ~[spring-boot-1.5.6.RELEASE.jar!/:1.5.6.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96) ~[spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110) ~[spring-boot-actuator-1.5.6.RELEASE.jar!/:1.5.6.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.keycloak.adapters.springsecurity.filter.KeycloakAuthenticationProcessingFilter.successfulAuthentication(KeycloakAuthenticationProcessingFilter.java:206) ~[keycloak-spring-security-adapter-2.5.4.Final.jar!/:2.5.4.Final] at org.springframework.security.web.authentication.AbstractAuthenticationProcessingFilter.doFilter(AbstractAuthenticationProcessingFilter.java:240) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.keycloak.adapters.springsecurity.filter.KeycloakPreAuthActionsFilter.doFilter(KeycloakPreAuthActionsFilter.java:84) ~[keycloak-spring-security-adapter-2.5.4.Final.jar!/:2.5.4.Final] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:64) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) ~[spring-security-web-4.2.3.RELEASE.jar!/:4.2.3.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:346) ~[spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:262) ~[spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:105) ~[spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81) ~[spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at org.springframework.cloud.sleuth.instrument.web.TraceFilter.doFilter(TraceFilter.java:169) ~[spring-cloud-sleuth-core-1.2.2.RELEASE.jar!/:1.2.2.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) ~[spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:106) ~[spring-boot-actuator-1.5.6.RELEASE.jar!/:1.5.6.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:131) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) ~[undertow-core-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) ~[undertow-core-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) ~[undertow-core-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) [undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) ~[undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) [undertow-servlet-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.server.Connectors.executeRootHandler(Connectors.java:326) [undertow-core-1.4.18.Final.jar!/:1.4.18.Final] at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:812) [undertow-core-1.4.18.Final.jar!/:1.4.18.Final] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_131] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_131] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]  ```</body>
		<created>2017-11-15 17:54:34</created>
		<closed>2018-03-14 18:40:33</closed>
	</bug>
	<bug>
		<id>67</id>
		<title>Integration edit doesn't work</title>
		<body>|&lt;img src="https://avatars1.githubusercontent.com/u/8707241?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @jludvice | [2017-09-04](https://github.com/syndesisio/syndesis-rest/issues/571) | bug  | |-|-|-|  Screencast https://youtu.be/y3e1ptGnBo8  CC @dsimansk   * Create integration as syndesisqe user * integration repo created on syndesisqe/REPO_NAME with one commit * login as another user  * edit this integration * add log step * NO COMMIT ADDED to REPO_NAME -&gt; where did we store the additional integration step?</body>
		<created>2017-11-15 17:52:05</created>
		<closed>2018-03-14 18:31:28</closed>
	</bug>
	<bug>
		<id>60</id>
		<title>Error: Expected BEGIN_OBJECT but was STRING during create integration</title>
		<body>|&lt;img src="https://avatars1.githubusercontent.com/u/8707241?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @jludvice | [2017-08-23](https://github.com/syndesisio/syndesis-rest/issues/534) | bug  | |-|-|-|  Can't create integration on syndesis-staging because rest fails with this error: ``` 2017-08-23 08:50:45.376  INFO [-,,,] 1 --- [pool-4-thread-1] i.s.c.integration.IntegrationController  : Integration 5 : Start processing integration with ActivateHandler 2017-08-23 08:50:45.376  INFO [-,,,] 1 --- [pool-4-thread-1] i.s.c.integration.IntegrationController  : Integration 5 : Setting status to Pending 2017-08-23 08:50:46.202  INFO [-,,,] 1 --- [pool-5-thread-1] i.s.c.integration.IntegrationController  : Integration -KsDGedpYDLM4EN0HL4d : Desired status "Activated" != current status "Pending" --&gt; calling status change handler 2017-08-23 08:50:46.202  INFO [-,,,] 1 --- [pool-4-thread-1] i.s.c.integration.IntegrationController  : Integration -KsDGedpYDLM4EN0HL4d : Start processing integration with ActivateHandler 2017-08-23 08:50:46.338 ERROR [-,,,] 1 --- [pool-4-thread-1] i.s.c.i.online.ActivateHandler           : Integration -KsDGedpYDLM4EN0HL4d : Failure  io.syndesis.core.SyndesisServerException: An error has occurred. at io.syndesis.core.SyndesisServerException.launderThrowable(SyndesisServerException.java:53) ~[core-0.1-SNAPSHOT.jar!/:0.1-SNAPSHOT] at io.syndesis.core.SyndesisServerException.launderThrowable(SyndesisServerException.java:44) ~[core-0.1-SNAPSHOT.jar!/:0.1-SNAPSHOT] at io.syndesis.controllers.integration.online.ActivateHandler.getGitHubUser(ActivateHandler.java:197) ~[controllers-0.1-SNAPSHOT.jar!/:0.1-SNAPSHOT] at io.syndesis.controllers.integration.online.ActivateHandler.execute(ActivateHandler.java:106) ~[controllers-0.1-SNAPSHOT.jar!/:0.1-SNAPSHOT] at io.syndesis.controllers.integration.IntegrationController.lambda$callStatusChangeHandler$10(IntegrationController.java:173) [controllers-0.1-SNAPSHOT.jar!/:0.1-SNAPSHOT] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_131] at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_131] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_131] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_131] at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131] Caused by: java.io.IOException: Parse exception converting JSON to object at org.eclipse.egit.github.core.client.GitHubClient.parseJson(GitHubClient.java:424) ~[org.eclipse.egit.github.core-2.1.5.jar!/:na] at org.eclipse.egit.github.core.client.GitHubClient.parseJson(GitHubClient.java:403) ~[org.eclipse.egit.github.core-2.1.5.jar!/:na] at org.eclipse.egit.github.core.client.GitHubClient.parseError(GitHubClient.java:514) ~[org.eclipse.egit.github.core-2.1.5.jar!/:na] at org.eclipse.egit.github.core.client.GitHubClient.createException(GitHubClient.java:547) ~[org.eclipse.egit.github.core-2.1.5.jar!/:na] at org.eclipse.egit.github.core.client.GitHubClient.get(GitHubClient.java:740) ~[org.eclipse.egit.github.core-2.1.5.jar!/:na] at org.eclipse.egit.github.core.service.UserService.getUser(UserService.java:95) ~[org.eclipse.egit.github.core-2.1.5.jar!/:na] at io.syndesis.github.GitHubServiceImpl.getApiUser(GitHubServiceImpl.java:82) ~[github-0.1-SNAPSHOT.jar!/:0.1-SNAPSHOT] at io.syndesis.controllers.integration.online.ActivateHandler.getGitHubUser(ActivateHandler.java:195) ~[controllers-0.1-SNAPSHOT.jar!/:0.1-SNAPSHOT] ... 7 common frames omitted Caused by: com.google.gson.JsonSyntaxException: java.lang.IllegalStateException: Expected BEGIN_OBJECT but was STRING at line 1 column 1 path $ at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:224) ~[gson-2.8.1.jar!/:na] at com.google.gson.Gson.fromJson(Gson.java:887) ~[gson-2.8.1.jar!/:na] at com.google.gson.Gson.fromJson(Gson.java:852) ~[gson-2.8.1.jar!/:na] at org.eclipse.egit.github.core.client.GitHubClient.parseJson(GitHubClient.java:422) ~[org.eclipse.egit.github.core-2.1.5.jar!/:na] ... 14 common frames omitted Caused by: java.lang.IllegalStateException: Expected BEGIN_OBJECT but was STRING at line 1 column 1 path $ at com.google.gson.stream.JsonReader.beginObject(JsonReader.java:385) ~[gson-2.8.1.jar!/:na] at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:213) ~[gson-2.8.1.jar!/:na] ... 17 common frames omitted ```</body>
		<created>2017-11-15 17:51:35</created>
		<closed>2018-03-14 18:27:43</closed>
	</bug>
	<bug>
		<id>57</id>
		<title>Project generator omits configurations properties</title>
		<body>|&lt;img src="https://avatars0.githubusercontent.com/u/5637792?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @dsimansk | [2017-07-28](https://github.com/syndesisio/syndesis-rest/issues/469) | bug  | |-|-|-|  Integration source code: https://github.com/dsimansk/kitchensink-test/commit/41f9c70737505eb692fb9501f9da8e310b9e742f  I've tried to create simple Twitter Search to HTTP POST integration, as can be seen in the generated steps, but any other parameters aren't present. E.g. hostname, path, port, for [the refence](https://github.com/syndesisio/connectors/blob/master/connectors/http-post-connector/src/main/resources/camel-connector.json#L18-L19)  JsonDB has only one property and that's httpUri ```json     "action": {         "description": "Call a service that is internal (within your company) or external (on the internet) by specifying the service's URL",         "camelConnectorGAV": "io.syndesis:http-post-connector:0.4.5",         "camelConnectorPrefix": "http-post",         "inputDataShape": {           "kind": "any"         },         "outputDataShape": {           "kind": "any"         },         "id": "io.syndesis:http-post-connector:latest",         "name": "HTTP POST",         "properties": {           "httpUri": {             "kind": "path",             "displayName": "Http Uri",             "group": "producer",             "label": "producer",             "required": true,             "type": "string",             "javaType": "java.net.URI",             "deprecated": false,             "secret": false,             "componentProperty": false,             "description": "The url of the HTTP endpoint to call."           }         }       },       "connection": {         "connectorId": "http",         "configuredProperties": {},         "options": {},         "icon": "fa-globe",         "description": "HTTP Connection",         "lastUpdated": 1492095344060,         "createdDate": 1492095344060,         "id": "3",         "tags": ["example", "test"],         "name": "HTTP Example"       },       "stepKind": "endpoint",       "configuredProperties": {         "httpUri": "kitchensink-service:8080/mirror/post"       } ```  </body>
		<created>2017-11-15 17:51:14</created>
		<closed>2018-03-14 18:26:39</closed>
	</bug>
	<bug>
		<id>56</id>
		<title>Deleting an integration doesn't delete runtime</title>
		<body>|&lt;img src="https://avatars3.githubusercontent.com/u/99080?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @rhuss | [2017-07-27](https://github.com/syndesisio/syndesis-rest/issues/467) | bug  | |-|-|-|  When deleting an itnegration via the UI the corresponding OpenShift resources are not removed.</body>
		<created>2017-11-15 17:51:10</created>
		<closed>2018-03-14 18:26:21</closed>
	</bug>
	<bug>
		<id>55</id>
		<title>Exception handler missing or not working</title>
		<body>|&lt;img src="https://avatars3.githubusercontent.com/u/99080?v=4" valign="middle" width="22px"&gt;&lt;/img&gt; @rhuss | [2017-07-21](https://github.com/syndesisio/syndesis-rest/issues/454) | bug  | |-|-|-|  See https://github.com/syndesisio/syndesis-ui/issues/630 or #451 for where an internal error (500) is thrown and not the appropriate HTTP code.</body>
		<created>2017-11-15 17:51:01</created>
		<closed>2018-03-14 18:26:05</closed>
	</bug>
</bugs>
